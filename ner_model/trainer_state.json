{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 12900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003875968992248062,
      "grad_norm": 8.92837142944336,
      "learning_rate": 4.9996124031007755e-05,
      "loss": 2.727,
      "step": 1
    },
    {
      "epoch": 0.007751937984496124,
      "grad_norm": 18.462818145751953,
      "learning_rate": 4.999224806201551e-05,
      "loss": 2.6108,
      "step": 2
    },
    {
      "epoch": 0.011627906976744186,
      "grad_norm": 10.855439186096191,
      "learning_rate": 4.998837209302325e-05,
      "loss": 2.4634,
      "step": 3
    },
    {
      "epoch": 0.015503875968992248,
      "grad_norm": 7.496056079864502,
      "learning_rate": 4.998449612403101e-05,
      "loss": 2.1601,
      "step": 4
    },
    {
      "epoch": 0.01937984496124031,
      "grad_norm": 6.556685924530029,
      "learning_rate": 4.998062015503876e-05,
      "loss": 1.9458,
      "step": 5
    },
    {
      "epoch": 0.023255813953488372,
      "grad_norm": 12.64666748046875,
      "learning_rate": 4.997674418604652e-05,
      "loss": 1.8153,
      "step": 6
    },
    {
      "epoch": 0.027131782945736434,
      "grad_norm": 7.917841911315918,
      "learning_rate": 4.997286821705426e-05,
      "loss": 1.6456,
      "step": 7
    },
    {
      "epoch": 0.031007751937984496,
      "grad_norm": 8.953779220581055,
      "learning_rate": 4.996899224806202e-05,
      "loss": 1.7368,
      "step": 8
    },
    {
      "epoch": 0.03488372093023256,
      "grad_norm": 7.47674036026001,
      "learning_rate": 4.996511627906977e-05,
      "loss": 1.3297,
      "step": 9
    },
    {
      "epoch": 0.03875968992248062,
      "grad_norm": 7.910426616668701,
      "learning_rate": 4.996124031007752e-05,
      "loss": 1.7458,
      "step": 10
    },
    {
      "epoch": 0.04263565891472868,
      "grad_norm": 8.476720809936523,
      "learning_rate": 4.995736434108527e-05,
      "loss": 1.3151,
      "step": 11
    },
    {
      "epoch": 0.046511627906976744,
      "grad_norm": 12.999739646911621,
      "learning_rate": 4.9953488372093025e-05,
      "loss": 2.0788,
      "step": 12
    },
    {
      "epoch": 0.050387596899224806,
      "grad_norm": 13.441725730895996,
      "learning_rate": 4.994961240310078e-05,
      "loss": 1.6127,
      "step": 13
    },
    {
      "epoch": 0.05426356589147287,
      "grad_norm": 12.28435230255127,
      "learning_rate": 4.994573643410853e-05,
      "loss": 1.5135,
      "step": 14
    },
    {
      "epoch": 0.05813953488372093,
      "grad_norm": 10.158463478088379,
      "learning_rate": 4.994186046511628e-05,
      "loss": 1.3894,
      "step": 15
    },
    {
      "epoch": 0.06201550387596899,
      "grad_norm": 9.327279090881348,
      "learning_rate": 4.9937984496124034e-05,
      "loss": 1.7109,
      "step": 16
    },
    {
      "epoch": 0.06589147286821706,
      "grad_norm": 9.950181007385254,
      "learning_rate": 4.993410852713179e-05,
      "loss": 1.437,
      "step": 17
    },
    {
      "epoch": 0.06976744186046512,
      "grad_norm": 12.124527931213379,
      "learning_rate": 4.993023255813954e-05,
      "loss": 0.731,
      "step": 18
    },
    {
      "epoch": 0.07364341085271318,
      "grad_norm": 7.477088451385498,
      "learning_rate": 4.992635658914729e-05,
      "loss": 1.0352,
      "step": 19
    },
    {
      "epoch": 0.07751937984496124,
      "grad_norm": 7.296858310699463,
      "learning_rate": 4.9922480620155044e-05,
      "loss": 1.2501,
      "step": 20
    },
    {
      "epoch": 0.08139534883720931,
      "grad_norm": 5.269233226776123,
      "learning_rate": 4.991860465116279e-05,
      "loss": 0.7175,
      "step": 21
    },
    {
      "epoch": 0.08527131782945736,
      "grad_norm": 15.531791687011719,
      "learning_rate": 4.991472868217055e-05,
      "loss": 1.1863,
      "step": 22
    },
    {
      "epoch": 0.08914728682170543,
      "grad_norm": 12.177270889282227,
      "learning_rate": 4.9910852713178295e-05,
      "loss": 0.936,
      "step": 23
    },
    {
      "epoch": 0.09302325581395349,
      "grad_norm": 10.601073265075684,
      "learning_rate": 4.9906976744186054e-05,
      "loss": 1.2195,
      "step": 24
    },
    {
      "epoch": 0.09689922480620156,
      "grad_norm": 11.805795669555664,
      "learning_rate": 4.99031007751938e-05,
      "loss": 1.7745,
      "step": 25
    },
    {
      "epoch": 0.10077519379844961,
      "grad_norm": 6.780973434448242,
      "learning_rate": 4.989922480620156e-05,
      "loss": 0.4883,
      "step": 26
    },
    {
      "epoch": 0.10465116279069768,
      "grad_norm": 12.263113975524902,
      "learning_rate": 4.9895348837209304e-05,
      "loss": 1.1692,
      "step": 27
    },
    {
      "epoch": 0.10852713178294573,
      "grad_norm": 7.80493688583374,
      "learning_rate": 4.989147286821706e-05,
      "loss": 0.7407,
      "step": 28
    },
    {
      "epoch": 0.1124031007751938,
      "grad_norm": 16.770774841308594,
      "learning_rate": 4.988759689922481e-05,
      "loss": 0.7181,
      "step": 29
    },
    {
      "epoch": 0.11627906976744186,
      "grad_norm": 7.384441375732422,
      "learning_rate": 4.9883720930232555e-05,
      "loss": 0.4862,
      "step": 30
    },
    {
      "epoch": 0.12015503875968993,
      "grad_norm": 6.14987850189209,
      "learning_rate": 4.9879844961240314e-05,
      "loss": 0.4636,
      "step": 31
    },
    {
      "epoch": 0.12403100775193798,
      "grad_norm": 6.391669750213623,
      "learning_rate": 4.987596899224806e-05,
      "loss": 0.4199,
      "step": 32
    },
    {
      "epoch": 0.12790697674418605,
      "grad_norm": 7.334310531616211,
      "learning_rate": 4.987209302325582e-05,
      "loss": 0.4317,
      "step": 33
    },
    {
      "epoch": 0.13178294573643412,
      "grad_norm": 5.845623016357422,
      "learning_rate": 4.9868217054263564e-05,
      "loss": 0.5255,
      "step": 34
    },
    {
      "epoch": 0.13565891472868216,
      "grad_norm": 14.999042510986328,
      "learning_rate": 4.9864341085271324e-05,
      "loss": 1.3499,
      "step": 35
    },
    {
      "epoch": 0.13953488372093023,
      "grad_norm": 21.08513832092285,
      "learning_rate": 4.986046511627907e-05,
      "loss": 0.9617,
      "step": 36
    },
    {
      "epoch": 0.1434108527131783,
      "grad_norm": 4.825572490692139,
      "learning_rate": 4.985658914728683e-05,
      "loss": 0.3499,
      "step": 37
    },
    {
      "epoch": 0.14728682170542637,
      "grad_norm": 16.05385971069336,
      "learning_rate": 4.9852713178294574e-05,
      "loss": 0.9596,
      "step": 38
    },
    {
      "epoch": 0.1511627906976744,
      "grad_norm": 14.382662773132324,
      "learning_rate": 4.9848837209302327e-05,
      "loss": 0.9566,
      "step": 39
    },
    {
      "epoch": 0.15503875968992248,
      "grad_norm": 3.9947216510772705,
      "learning_rate": 4.984496124031008e-05,
      "loss": 0.1872,
      "step": 40
    },
    {
      "epoch": 0.15891472868217055,
      "grad_norm": 8.584233283996582,
      "learning_rate": 4.984108527131783e-05,
      "loss": 0.3622,
      "step": 41
    },
    {
      "epoch": 0.16279069767441862,
      "grad_norm": 12.678696632385254,
      "learning_rate": 4.9837209302325584e-05,
      "loss": 0.4933,
      "step": 42
    },
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 8.378549575805664,
      "learning_rate": 4.9833333333333336e-05,
      "loss": 0.5642,
      "step": 43
    },
    {
      "epoch": 0.17054263565891473,
      "grad_norm": 7.524313449859619,
      "learning_rate": 4.982945736434109e-05,
      "loss": 0.2085,
      "step": 44
    },
    {
      "epoch": 0.1744186046511628,
      "grad_norm": 9.443062782287598,
      "learning_rate": 4.982558139534884e-05,
      "loss": 0.4217,
      "step": 45
    },
    {
      "epoch": 0.17829457364341086,
      "grad_norm": 3.156090021133423,
      "learning_rate": 4.9821705426356593e-05,
      "loss": 0.1514,
      "step": 46
    },
    {
      "epoch": 0.1821705426356589,
      "grad_norm": 4.6595139503479,
      "learning_rate": 4.9817829457364346e-05,
      "loss": 0.1812,
      "step": 47
    },
    {
      "epoch": 0.18604651162790697,
      "grad_norm": 1.7847744226455688,
      "learning_rate": 4.981395348837209e-05,
      "loss": 0.0655,
      "step": 48
    },
    {
      "epoch": 0.18992248062015504,
      "grad_norm": 2.1939308643341064,
      "learning_rate": 4.981007751937985e-05,
      "loss": 0.1245,
      "step": 49
    },
    {
      "epoch": 0.1937984496124031,
      "grad_norm": 10.098944664001465,
      "learning_rate": 4.9806201550387596e-05,
      "loss": 0.5705,
      "step": 50
    },
    {
      "epoch": 0.19767441860465115,
      "grad_norm": 4.284256935119629,
      "learning_rate": 4.9802325581395356e-05,
      "loss": 0.1942,
      "step": 51
    },
    {
      "epoch": 0.20155038759689922,
      "grad_norm": 2.5048415660858154,
      "learning_rate": 4.97984496124031e-05,
      "loss": 0.1058,
      "step": 52
    },
    {
      "epoch": 0.2054263565891473,
      "grad_norm": 1.0057957172393799,
      "learning_rate": 4.979457364341086e-05,
      "loss": 0.046,
      "step": 53
    },
    {
      "epoch": 0.20930232558139536,
      "grad_norm": 2.849144697189331,
      "learning_rate": 4.9790697674418606e-05,
      "loss": 0.0786,
      "step": 54
    },
    {
      "epoch": 0.2131782945736434,
      "grad_norm": 13.698037147521973,
      "learning_rate": 4.978682170542636e-05,
      "loss": 0.7115,
      "step": 55
    },
    {
      "epoch": 0.21705426356589147,
      "grad_norm": 2.8959927558898926,
      "learning_rate": 4.978294573643411e-05,
      "loss": 0.0991,
      "step": 56
    },
    {
      "epoch": 0.22093023255813954,
      "grad_norm": 31.47157096862793,
      "learning_rate": 4.977906976744186e-05,
      "loss": 1.613,
      "step": 57
    },
    {
      "epoch": 0.2248062015503876,
      "grad_norm": 6.9574384689331055,
      "learning_rate": 4.9775193798449616e-05,
      "loss": 0.1872,
      "step": 58
    },
    {
      "epoch": 0.22868217054263565,
      "grad_norm": 0.663299024105072,
      "learning_rate": 4.977131782945736e-05,
      "loss": 0.0152,
      "step": 59
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 13.967680931091309,
      "learning_rate": 4.976744186046512e-05,
      "loss": 0.3344,
      "step": 60
    },
    {
      "epoch": 0.2364341085271318,
      "grad_norm": 14.80798053741455,
      "learning_rate": 4.9763565891472866e-05,
      "loss": 0.6367,
      "step": 61
    },
    {
      "epoch": 0.24031007751937986,
      "grad_norm": 3.649872303009033,
      "learning_rate": 4.9759689922480625e-05,
      "loss": 0.0686,
      "step": 62
    },
    {
      "epoch": 0.2441860465116279,
      "grad_norm": 11.265779495239258,
      "learning_rate": 4.975581395348837e-05,
      "loss": 0.6654,
      "step": 63
    },
    {
      "epoch": 0.24806201550387597,
      "grad_norm": 1.2641116380691528,
      "learning_rate": 4.975193798449613e-05,
      "loss": 0.0357,
      "step": 64
    },
    {
      "epoch": 0.25193798449612403,
      "grad_norm": 1.8346046209335327,
      "learning_rate": 4.9748062015503876e-05,
      "loss": 0.0523,
      "step": 65
    },
    {
      "epoch": 0.2558139534883721,
      "grad_norm": 0.9857648611068726,
      "learning_rate": 4.974418604651163e-05,
      "loss": 0.0269,
      "step": 66
    },
    {
      "epoch": 0.2596899224806202,
      "grad_norm": 6.977513790130615,
      "learning_rate": 4.974031007751938e-05,
      "loss": 0.1451,
      "step": 67
    },
    {
      "epoch": 0.26356589147286824,
      "grad_norm": 21.480968475341797,
      "learning_rate": 4.973643410852713e-05,
      "loss": 1.2099,
      "step": 68
    },
    {
      "epoch": 0.26744186046511625,
      "grad_norm": 42.57246017456055,
      "learning_rate": 4.9732558139534886e-05,
      "loss": 1.5601,
      "step": 69
    },
    {
      "epoch": 0.2713178294573643,
      "grad_norm": 14.324069023132324,
      "learning_rate": 4.972868217054264e-05,
      "loss": 0.8496,
      "step": 70
    },
    {
      "epoch": 0.2751937984496124,
      "grad_norm": 2.005380153656006,
      "learning_rate": 4.972480620155039e-05,
      "loss": 0.0187,
      "step": 71
    },
    {
      "epoch": 0.27906976744186046,
      "grad_norm": 14.224885940551758,
      "learning_rate": 4.972093023255814e-05,
      "loss": 0.3001,
      "step": 72
    },
    {
      "epoch": 0.28294573643410853,
      "grad_norm": 5.5013556480407715,
      "learning_rate": 4.9717054263565895e-05,
      "loss": 0.0483,
      "step": 73
    },
    {
      "epoch": 0.2868217054263566,
      "grad_norm": 0.36064445972442627,
      "learning_rate": 4.971317829457365e-05,
      "loss": 0.0189,
      "step": 74
    },
    {
      "epoch": 0.29069767441860467,
      "grad_norm": 19.359371185302734,
      "learning_rate": 4.97093023255814e-05,
      "loss": 0.1353,
      "step": 75
    },
    {
      "epoch": 0.29457364341085274,
      "grad_norm": 1.695703148841858,
      "learning_rate": 4.970542635658915e-05,
      "loss": 0.0325,
      "step": 76
    },
    {
      "epoch": 0.29844961240310075,
      "grad_norm": 0.23479118943214417,
      "learning_rate": 4.97015503875969e-05,
      "loss": 0.0143,
      "step": 77
    },
    {
      "epoch": 0.3023255813953488,
      "grad_norm": 3.6591413021087646,
      "learning_rate": 4.969767441860466e-05,
      "loss": 0.0224,
      "step": 78
    },
    {
      "epoch": 0.3062015503875969,
      "grad_norm": 14.823931694030762,
      "learning_rate": 4.96937984496124e-05,
      "loss": 0.6544,
      "step": 79
    },
    {
      "epoch": 0.31007751937984496,
      "grad_norm": 11.295957565307617,
      "learning_rate": 4.9689922480620155e-05,
      "loss": 0.8413,
      "step": 80
    },
    {
      "epoch": 0.313953488372093,
      "grad_norm": 25.115177154541016,
      "learning_rate": 4.968604651162791e-05,
      "loss": 1.1115,
      "step": 81
    },
    {
      "epoch": 0.3178294573643411,
      "grad_norm": 6.574984073638916,
      "learning_rate": 4.968217054263566e-05,
      "loss": 0.5889,
      "step": 82
    },
    {
      "epoch": 0.32170542635658916,
      "grad_norm": 6.573114395141602,
      "learning_rate": 4.967829457364341e-05,
      "loss": 0.4533,
      "step": 83
    },
    {
      "epoch": 0.32558139534883723,
      "grad_norm": 4.057605743408203,
      "learning_rate": 4.9674418604651165e-05,
      "loss": 0.0418,
      "step": 84
    },
    {
      "epoch": 0.32945736434108525,
      "grad_norm": 6.457533359527588,
      "learning_rate": 4.967054263565892e-05,
      "loss": 0.12,
      "step": 85
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 3.9163830280303955,
      "learning_rate": 4.966666666666667e-05,
      "loss": 0.0804,
      "step": 86
    },
    {
      "epoch": 0.3372093023255814,
      "grad_norm": 5.765766143798828,
      "learning_rate": 4.966279069767442e-05,
      "loss": 0.1148,
      "step": 87
    },
    {
      "epoch": 0.34108527131782945,
      "grad_norm": 1.162348985671997,
      "learning_rate": 4.965891472868217e-05,
      "loss": 0.0316,
      "step": 88
    },
    {
      "epoch": 0.3449612403100775,
      "grad_norm": 37.36605453491211,
      "learning_rate": 4.965503875968993e-05,
      "loss": 0.7171,
      "step": 89
    },
    {
      "epoch": 0.3488372093023256,
      "grad_norm": 1.852637529373169,
      "learning_rate": 4.965116279069767e-05,
      "loss": 0.0224,
      "step": 90
    },
    {
      "epoch": 0.35271317829457366,
      "grad_norm": 5.80088996887207,
      "learning_rate": 4.964728682170543e-05,
      "loss": 0.1195,
      "step": 91
    },
    {
      "epoch": 0.35658914728682173,
      "grad_norm": 6.907949447631836,
      "learning_rate": 4.964341085271318e-05,
      "loss": 0.0951,
      "step": 92
    },
    {
      "epoch": 0.36046511627906974,
      "grad_norm": 7.903088092803955,
      "learning_rate": 4.963953488372094e-05,
      "loss": 0.1636,
      "step": 93
    },
    {
      "epoch": 0.3643410852713178,
      "grad_norm": 4.912467002868652,
      "learning_rate": 4.963565891472868e-05,
      "loss": 0.0912,
      "step": 94
    },
    {
      "epoch": 0.3682170542635659,
      "grad_norm": 7.594090461730957,
      "learning_rate": 4.9631782945736435e-05,
      "loss": 0.419,
      "step": 95
    },
    {
      "epoch": 0.37209302325581395,
      "grad_norm": 2.4609811305999756,
      "learning_rate": 4.962790697674419e-05,
      "loss": 0.0218,
      "step": 96
    },
    {
      "epoch": 0.375968992248062,
      "grad_norm": 23.241641998291016,
      "learning_rate": 4.962403100775194e-05,
      "loss": 0.3051,
      "step": 97
    },
    {
      "epoch": 0.3798449612403101,
      "grad_norm": 28.802522659301758,
      "learning_rate": 4.962015503875969e-05,
      "loss": 1.1551,
      "step": 98
    },
    {
      "epoch": 0.38372093023255816,
      "grad_norm": 14.730079650878906,
      "learning_rate": 4.9616279069767445e-05,
      "loss": 0.7175,
      "step": 99
    },
    {
      "epoch": 0.3875968992248062,
      "grad_norm": 11.175065994262695,
      "learning_rate": 4.96124031007752e-05,
      "loss": 0.8911,
      "step": 100
    },
    {
      "epoch": 0.39147286821705424,
      "grad_norm": 11.494089126586914,
      "learning_rate": 4.960852713178295e-05,
      "loss": 0.525,
      "step": 101
    },
    {
      "epoch": 0.3953488372093023,
      "grad_norm": 2.6047134399414062,
      "learning_rate": 4.96046511627907e-05,
      "loss": 0.053,
      "step": 102
    },
    {
      "epoch": 0.3992248062015504,
      "grad_norm": 1.4592341184616089,
      "learning_rate": 4.9600775193798454e-05,
      "loss": 0.0181,
      "step": 103
    },
    {
      "epoch": 0.40310077519379844,
      "grad_norm": 0.9029625058174133,
      "learning_rate": 4.959689922480621e-05,
      "loss": 0.0144,
      "step": 104
    },
    {
      "epoch": 0.4069767441860465,
      "grad_norm": 10.82321834564209,
      "learning_rate": 4.959302325581396e-05,
      "loss": 0.3697,
      "step": 105
    },
    {
      "epoch": 0.4108527131782946,
      "grad_norm": 2.602217674255371,
      "learning_rate": 4.9589147286821705e-05,
      "loss": 0.0285,
      "step": 106
    },
    {
      "epoch": 0.41472868217054265,
      "grad_norm": 2.616191864013672,
      "learning_rate": 4.958527131782946e-05,
      "loss": 0.0324,
      "step": 107
    },
    {
      "epoch": 0.4186046511627907,
      "grad_norm": 22.543779373168945,
      "learning_rate": 4.958139534883721e-05,
      "loss": 0.227,
      "step": 108
    },
    {
      "epoch": 0.42248062015503873,
      "grad_norm": 41.35540008544922,
      "learning_rate": 4.957751937984496e-05,
      "loss": 1.1152,
      "step": 109
    },
    {
      "epoch": 0.4263565891472868,
      "grad_norm": 0.1517624408006668,
      "learning_rate": 4.9573643410852715e-05,
      "loss": 0.0082,
      "step": 110
    },
    {
      "epoch": 0.43023255813953487,
      "grad_norm": 2.1525397300720215,
      "learning_rate": 4.956976744186047e-05,
      "loss": 0.0382,
      "step": 111
    },
    {
      "epoch": 0.43410852713178294,
      "grad_norm": 22.711538314819336,
      "learning_rate": 4.956589147286822e-05,
      "loss": 0.4141,
      "step": 112
    },
    {
      "epoch": 0.437984496124031,
      "grad_norm": 28.761436462402344,
      "learning_rate": 4.956201550387597e-05,
      "loss": 0.7428,
      "step": 113
    },
    {
      "epoch": 0.4418604651162791,
      "grad_norm": 3.7083749771118164,
      "learning_rate": 4.9558139534883724e-05,
      "loss": 0.1279,
      "step": 114
    },
    {
      "epoch": 0.44573643410852715,
      "grad_norm": 0.27321842312812805,
      "learning_rate": 4.955426356589148e-05,
      "loss": 0.008,
      "step": 115
    },
    {
      "epoch": 0.4496124031007752,
      "grad_norm": 0.11869208514690399,
      "learning_rate": 4.955038759689923e-05,
      "loss": 0.0057,
      "step": 116
    },
    {
      "epoch": 0.45348837209302323,
      "grad_norm": 1.8938857316970825,
      "learning_rate": 4.9546511627906975e-05,
      "loss": 0.0348,
      "step": 117
    },
    {
      "epoch": 0.4573643410852713,
      "grad_norm": 1.2603100538253784,
      "learning_rate": 4.9542635658914734e-05,
      "loss": 0.0133,
      "step": 118
    },
    {
      "epoch": 0.46124031007751937,
      "grad_norm": 13.190129280090332,
      "learning_rate": 4.953875968992248e-05,
      "loss": 0.6977,
      "step": 119
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 19.259645462036133,
      "learning_rate": 4.953488372093024e-05,
      "loss": 1.3195,
      "step": 120
    },
    {
      "epoch": 0.4689922480620155,
      "grad_norm": 6.735519886016846,
      "learning_rate": 4.9531007751937984e-05,
      "loss": 0.098,
      "step": 121
    },
    {
      "epoch": 0.4728682170542636,
      "grad_norm": 4.7848219871521,
      "learning_rate": 4.9527131782945744e-05,
      "loss": 0.0186,
      "step": 122
    },
    {
      "epoch": 0.47674418604651164,
      "grad_norm": 2.1681602001190186,
      "learning_rate": 4.952325581395349e-05,
      "loss": 0.0143,
      "step": 123
    },
    {
      "epoch": 0.4806201550387597,
      "grad_norm": 4.667510032653809,
      "learning_rate": 4.951937984496124e-05,
      "loss": 0.0784,
      "step": 124
    },
    {
      "epoch": 0.4844961240310077,
      "grad_norm": 7.3233208656311035,
      "learning_rate": 4.9515503875968994e-05,
      "loss": 0.0676,
      "step": 125
    },
    {
      "epoch": 0.4883720930232558,
      "grad_norm": 11.812602043151855,
      "learning_rate": 4.9511627906976747e-05,
      "loss": 0.6261,
      "step": 126
    },
    {
      "epoch": 0.49224806201550386,
      "grad_norm": 15.18676471710205,
      "learning_rate": 4.95077519379845e-05,
      "loss": 0.3424,
      "step": 127
    },
    {
      "epoch": 0.49612403100775193,
      "grad_norm": 5.821461200714111,
      "learning_rate": 4.950387596899225e-05,
      "loss": 0.6329,
      "step": 128
    },
    {
      "epoch": 0.5,
      "grad_norm": 9.529936790466309,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.1308,
      "step": 129
    },
    {
      "epoch": 0.5038759689922481,
      "grad_norm": 13.326614379882812,
      "learning_rate": 4.9496124031007756e-05,
      "loss": 0.209,
      "step": 130
    },
    {
      "epoch": 0.5077519379844961,
      "grad_norm": 23.635169982910156,
      "learning_rate": 4.949224806201551e-05,
      "loss": 0.625,
      "step": 131
    },
    {
      "epoch": 0.5116279069767442,
      "grad_norm": 0.28849178552627563,
      "learning_rate": 4.948837209302326e-05,
      "loss": 0.0094,
      "step": 132
    },
    {
      "epoch": 0.5155038759689923,
      "grad_norm": 1.516235113143921,
      "learning_rate": 4.9484496124031013e-05,
      "loss": 0.0205,
      "step": 133
    },
    {
      "epoch": 0.5193798449612403,
      "grad_norm": 0.12231779843568802,
      "learning_rate": 4.948062015503876e-05,
      "loss": 0.0062,
      "step": 134
    },
    {
      "epoch": 0.5232558139534884,
      "grad_norm": 1.801586627960205,
      "learning_rate": 4.947674418604651e-05,
      "loss": 0.0188,
      "step": 135
    },
    {
      "epoch": 0.5271317829457365,
      "grad_norm": 21.311063766479492,
      "learning_rate": 4.9472868217054264e-05,
      "loss": 0.5476,
      "step": 136
    },
    {
      "epoch": 0.5310077519379846,
      "grad_norm": 11.949145317077637,
      "learning_rate": 4.9468992248062016e-05,
      "loss": 0.4747,
      "step": 137
    },
    {
      "epoch": 0.5348837209302325,
      "grad_norm": 9.316930770874023,
      "learning_rate": 4.946511627906977e-05,
      "loss": 0.4789,
      "step": 138
    },
    {
      "epoch": 0.5387596899224806,
      "grad_norm": 10.87692642211914,
      "learning_rate": 4.946124031007752e-05,
      "loss": 0.0991,
      "step": 139
    },
    {
      "epoch": 0.5426356589147286,
      "grad_norm": 0.5167099833488464,
      "learning_rate": 4.9457364341085274e-05,
      "loss": 0.0103,
      "step": 140
    },
    {
      "epoch": 0.5465116279069767,
      "grad_norm": 7.0590081214904785,
      "learning_rate": 4.9453488372093026e-05,
      "loss": 0.1936,
      "step": 141
    },
    {
      "epoch": 0.5503875968992248,
      "grad_norm": 4.925941467285156,
      "learning_rate": 4.944961240310078e-05,
      "loss": 0.0398,
      "step": 142
    },
    {
      "epoch": 0.5542635658914729,
      "grad_norm": 16.25969123840332,
      "learning_rate": 4.944573643410853e-05,
      "loss": 0.1848,
      "step": 143
    },
    {
      "epoch": 0.5581395348837209,
      "grad_norm": 0.2533504068851471,
      "learning_rate": 4.9441860465116277e-05,
      "loss": 0.0088,
      "step": 144
    },
    {
      "epoch": 0.562015503875969,
      "grad_norm": 15.280529022216797,
      "learning_rate": 4.9437984496124036e-05,
      "loss": 0.3293,
      "step": 145
    },
    {
      "epoch": 0.5658914728682171,
      "grad_norm": 0.3006582260131836,
      "learning_rate": 4.943410852713178e-05,
      "loss": 0.0091,
      "step": 146
    },
    {
      "epoch": 0.5697674418604651,
      "grad_norm": 13.204314231872559,
      "learning_rate": 4.943023255813954e-05,
      "loss": 0.8213,
      "step": 147
    },
    {
      "epoch": 0.5736434108527132,
      "grad_norm": 4.718448162078857,
      "learning_rate": 4.9426356589147286e-05,
      "loss": 0.6183,
      "step": 148
    },
    {
      "epoch": 0.5775193798449613,
      "grad_norm": 0.2302594780921936,
      "learning_rate": 4.9422480620155045e-05,
      "loss": 0.0042,
      "step": 149
    },
    {
      "epoch": 0.5813953488372093,
      "grad_norm": 1.6150908470153809,
      "learning_rate": 4.941860465116279e-05,
      "loss": 0.0194,
      "step": 150
    },
    {
      "epoch": 0.5852713178294574,
      "grad_norm": 0.08299290388822556,
      "learning_rate": 4.9414728682170544e-05,
      "loss": 0.0043,
      "step": 151
    },
    {
      "epoch": 0.5891472868217055,
      "grad_norm": 7.737637042999268,
      "learning_rate": 4.9410852713178296e-05,
      "loss": 0.5033,
      "step": 152
    },
    {
      "epoch": 0.5930232558139535,
      "grad_norm": 31.181365966796875,
      "learning_rate": 4.940697674418605e-05,
      "loss": 0.5486,
      "step": 153
    },
    {
      "epoch": 0.5968992248062015,
      "grad_norm": 0.11969808489084244,
      "learning_rate": 4.94031007751938e-05,
      "loss": 0.0056,
      "step": 154
    },
    {
      "epoch": 0.6007751937984496,
      "grad_norm": 8.54731559753418,
      "learning_rate": 4.939922480620155e-05,
      "loss": 0.0215,
      "step": 155
    },
    {
      "epoch": 0.6046511627906976,
      "grad_norm": 4.498117923736572,
      "learning_rate": 4.9395348837209306e-05,
      "loss": 0.0426,
      "step": 156
    },
    {
      "epoch": 0.6085271317829457,
      "grad_norm": 17.428651809692383,
      "learning_rate": 4.939147286821706e-05,
      "loss": 0.7688,
      "step": 157
    },
    {
      "epoch": 0.6124031007751938,
      "grad_norm": 4.7134857177734375,
      "learning_rate": 4.938759689922481e-05,
      "loss": 0.0662,
      "step": 158
    },
    {
      "epoch": 0.6162790697674418,
      "grad_norm": 3.8423120975494385,
      "learning_rate": 4.938372093023256e-05,
      "loss": 0.0376,
      "step": 159
    },
    {
      "epoch": 0.6201550387596899,
      "grad_norm": 4.901227951049805,
      "learning_rate": 4.9379844961240315e-05,
      "loss": 0.0348,
      "step": 160
    },
    {
      "epoch": 0.624031007751938,
      "grad_norm": 1.9964051246643066,
      "learning_rate": 4.937596899224806e-05,
      "loss": 0.0263,
      "step": 161
    },
    {
      "epoch": 0.627906976744186,
      "grad_norm": 0.5035223960876465,
      "learning_rate": 4.937209302325581e-05,
      "loss": 0.0118,
      "step": 162
    },
    {
      "epoch": 0.6317829457364341,
      "grad_norm": 0.18335631489753723,
      "learning_rate": 4.9368217054263566e-05,
      "loss": 0.0094,
      "step": 163
    },
    {
      "epoch": 0.6356589147286822,
      "grad_norm": 0.9559982419013977,
      "learning_rate": 4.936434108527132e-05,
      "loss": 0.0221,
      "step": 164
    },
    {
      "epoch": 0.6395348837209303,
      "grad_norm": 0.08997302502393723,
      "learning_rate": 4.936046511627907e-05,
      "loss": 0.0058,
      "step": 165
    },
    {
      "epoch": 0.6434108527131783,
      "grad_norm": 0.14736202359199524,
      "learning_rate": 4.935658914728682e-05,
      "loss": 0.006,
      "step": 166
    },
    {
      "epoch": 0.6472868217054264,
      "grad_norm": 24.800731658935547,
      "learning_rate": 4.9352713178294575e-05,
      "loss": 0.2511,
      "step": 167
    },
    {
      "epoch": 0.6511627906976745,
      "grad_norm": 12.319514274597168,
      "learning_rate": 4.934883720930233e-05,
      "loss": 1.0279,
      "step": 168
    },
    {
      "epoch": 0.6550387596899225,
      "grad_norm": 14.307503700256348,
      "learning_rate": 4.934496124031008e-05,
      "loss": 0.4246,
      "step": 169
    },
    {
      "epoch": 0.6589147286821705,
      "grad_norm": 20.811851501464844,
      "learning_rate": 4.934108527131783e-05,
      "loss": 0.3724,
      "step": 170
    },
    {
      "epoch": 0.6627906976744186,
      "grad_norm": 0.08383753895759583,
      "learning_rate": 4.9337209302325585e-05,
      "loss": 0.0045,
      "step": 171
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 8.205184936523438,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.1009,
      "step": 172
    },
    {
      "epoch": 0.6705426356589147,
      "grad_norm": 15.536457061767578,
      "learning_rate": 4.932945736434108e-05,
      "loss": 0.2367,
      "step": 173
    },
    {
      "epoch": 0.6744186046511628,
      "grad_norm": 18.677213668823242,
      "learning_rate": 4.932558139534884e-05,
      "loss": 1.1781,
      "step": 174
    },
    {
      "epoch": 0.6782945736434108,
      "grad_norm": 0.8699131608009338,
      "learning_rate": 4.932170542635659e-05,
      "loss": 0.0118,
      "step": 175
    },
    {
      "epoch": 0.6821705426356589,
      "grad_norm": 5.4340386390686035,
      "learning_rate": 4.931782945736435e-05,
      "loss": 0.1454,
      "step": 176
    },
    {
      "epoch": 0.686046511627907,
      "grad_norm": 0.11644978076219559,
      "learning_rate": 4.931395348837209e-05,
      "loss": 0.0051,
      "step": 177
    },
    {
      "epoch": 0.689922480620155,
      "grad_norm": 5.187573432922363,
      "learning_rate": 4.931007751937985e-05,
      "loss": 0.0341,
      "step": 178
    },
    {
      "epoch": 0.6937984496124031,
      "grad_norm": 0.38410648703575134,
      "learning_rate": 4.93062015503876e-05,
      "loss": 0.0066,
      "step": 179
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 6.320468425750732,
      "learning_rate": 4.930232558139535e-05,
      "loss": 0.2148,
      "step": 180
    },
    {
      "epoch": 0.7015503875968992,
      "grad_norm": 77.07634735107422,
      "learning_rate": 4.92984496124031e-05,
      "loss": 0.3092,
      "step": 181
    },
    {
      "epoch": 0.7054263565891473,
      "grad_norm": 0.06368761509656906,
      "learning_rate": 4.9294573643410855e-05,
      "loss": 0.0029,
      "step": 182
    },
    {
      "epoch": 0.7093023255813954,
      "grad_norm": 16.638076782226562,
      "learning_rate": 4.929069767441861e-05,
      "loss": 0.8736,
      "step": 183
    },
    {
      "epoch": 0.7131782945736435,
      "grad_norm": 8.211472511291504,
      "learning_rate": 4.928682170542636e-05,
      "loss": 0.2697,
      "step": 184
    },
    {
      "epoch": 0.7170542635658915,
      "grad_norm": 4.3804545402526855,
      "learning_rate": 4.928294573643411e-05,
      "loss": 0.0547,
      "step": 185
    },
    {
      "epoch": 0.7209302325581395,
      "grad_norm": 13.32889175415039,
      "learning_rate": 4.9279069767441865e-05,
      "loss": 1.1966,
      "step": 186
    },
    {
      "epoch": 0.7248062015503876,
      "grad_norm": 0.5871325135231018,
      "learning_rate": 4.927519379844962e-05,
      "loss": 0.0061,
      "step": 187
    },
    {
      "epoch": 0.7286821705426356,
      "grad_norm": 8.978900909423828,
      "learning_rate": 4.927131782945736e-05,
      "loss": 0.4175,
      "step": 188
    },
    {
      "epoch": 0.7325581395348837,
      "grad_norm": 13.72323989868164,
      "learning_rate": 4.926744186046512e-05,
      "loss": 0.5276,
      "step": 189
    },
    {
      "epoch": 0.7364341085271318,
      "grad_norm": 10.88851261138916,
      "learning_rate": 4.926356589147287e-05,
      "loss": 0.5373,
      "step": 190
    },
    {
      "epoch": 0.7403100775193798,
      "grad_norm": 0.11882268637418747,
      "learning_rate": 4.925968992248062e-05,
      "loss": 0.0048,
      "step": 191
    },
    {
      "epoch": 0.7441860465116279,
      "grad_norm": 19.726318359375,
      "learning_rate": 4.925581395348837e-05,
      "loss": 0.442,
      "step": 192
    },
    {
      "epoch": 0.748062015503876,
      "grad_norm": 9.321101188659668,
      "learning_rate": 4.9251937984496125e-05,
      "loss": 0.1086,
      "step": 193
    },
    {
      "epoch": 0.751937984496124,
      "grad_norm": 8.390666961669922,
      "learning_rate": 4.924806201550388e-05,
      "loss": 0.1512,
      "step": 194
    },
    {
      "epoch": 0.7558139534883721,
      "grad_norm": 24.257991790771484,
      "learning_rate": 4.924418604651163e-05,
      "loss": 0.9838,
      "step": 195
    },
    {
      "epoch": 0.7596899224806202,
      "grad_norm": 18.781023025512695,
      "learning_rate": 4.924031007751938e-05,
      "loss": 0.6215,
      "step": 196
    },
    {
      "epoch": 0.7635658914728682,
      "grad_norm": 13.024923324584961,
      "learning_rate": 4.9236434108527135e-05,
      "loss": 0.5638,
      "step": 197
    },
    {
      "epoch": 0.7674418604651163,
      "grad_norm": 4.074178695678711,
      "learning_rate": 4.923255813953489e-05,
      "loss": 0.044,
      "step": 198
    },
    {
      "epoch": 0.7713178294573644,
      "grad_norm": 9.604290008544922,
      "learning_rate": 4.922868217054264e-05,
      "loss": 0.1206,
      "step": 199
    },
    {
      "epoch": 0.7751937984496124,
      "grad_norm": 8.156810760498047,
      "learning_rate": 4.922480620155039e-05,
      "loss": 0.4326,
      "step": 200
    },
    {
      "epoch": 0.7790697674418605,
      "grad_norm": 12.424420356750488,
      "learning_rate": 4.9220930232558144e-05,
      "loss": 1.1452,
      "step": 201
    },
    {
      "epoch": 0.7829457364341085,
      "grad_norm": 34.87655258178711,
      "learning_rate": 4.921705426356589e-05,
      "loss": 1.4463,
      "step": 202
    },
    {
      "epoch": 0.7868217054263565,
      "grad_norm": 4.298407554626465,
      "learning_rate": 4.921317829457365e-05,
      "loss": 0.0767,
      "step": 203
    },
    {
      "epoch": 0.7906976744186046,
      "grad_norm": 9.711268424987793,
      "learning_rate": 4.9209302325581395e-05,
      "loss": 0.187,
      "step": 204
    },
    {
      "epoch": 0.7945736434108527,
      "grad_norm": 1.0533225536346436,
      "learning_rate": 4.9205426356589154e-05,
      "loss": 0.0191,
      "step": 205
    },
    {
      "epoch": 0.7984496124031008,
      "grad_norm": 9.19139289855957,
      "learning_rate": 4.92015503875969e-05,
      "loss": 0.2661,
      "step": 206
    },
    {
      "epoch": 0.8023255813953488,
      "grad_norm": 14.058769226074219,
      "learning_rate": 4.919767441860466e-05,
      "loss": 0.2873,
      "step": 207
    },
    {
      "epoch": 0.8062015503875969,
      "grad_norm": 24.245725631713867,
      "learning_rate": 4.9193798449612404e-05,
      "loss": 0.3616,
      "step": 208
    },
    {
      "epoch": 0.810077519379845,
      "grad_norm": 10.715070724487305,
      "learning_rate": 4.918992248062016e-05,
      "loss": 0.6163,
      "step": 209
    },
    {
      "epoch": 0.813953488372093,
      "grad_norm": 4.855833053588867,
      "learning_rate": 4.918604651162791e-05,
      "loss": 0.1102,
      "step": 210
    },
    {
      "epoch": 0.8178294573643411,
      "grad_norm": 0.1087569147348404,
      "learning_rate": 4.918217054263566e-05,
      "loss": 0.0054,
      "step": 211
    },
    {
      "epoch": 0.8217054263565892,
      "grad_norm": 7.485576152801514,
      "learning_rate": 4.9178294573643414e-05,
      "loss": 0.1791,
      "step": 212
    },
    {
      "epoch": 0.8255813953488372,
      "grad_norm": 2.9717648029327393,
      "learning_rate": 4.9174418604651167e-05,
      "loss": 0.0306,
      "step": 213
    },
    {
      "epoch": 0.8294573643410853,
      "grad_norm": 4.177436351776123,
      "learning_rate": 4.917054263565892e-05,
      "loss": 0.0217,
      "step": 214
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 1.6010150909423828,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.0316,
      "step": 215
    },
    {
      "epoch": 0.8372093023255814,
      "grad_norm": 3.3936924934387207,
      "learning_rate": 4.9162790697674424e-05,
      "loss": 0.0326,
      "step": 216
    },
    {
      "epoch": 0.8410852713178295,
      "grad_norm": 22.130874633789062,
      "learning_rate": 4.915891472868217e-05,
      "loss": 0.7766,
      "step": 217
    },
    {
      "epoch": 0.8449612403100775,
      "grad_norm": 2.5998570919036865,
      "learning_rate": 4.915503875968993e-05,
      "loss": 0.052,
      "step": 218
    },
    {
      "epoch": 0.8488372093023255,
      "grad_norm": 2.730156660079956,
      "learning_rate": 4.9151162790697674e-05,
      "loss": 0.0281,
      "step": 219
    },
    {
      "epoch": 0.8527131782945736,
      "grad_norm": 2.780231475830078,
      "learning_rate": 4.914728682170543e-05,
      "loss": 0.048,
      "step": 220
    },
    {
      "epoch": 0.8565891472868217,
      "grad_norm": 17.18697166442871,
      "learning_rate": 4.914341085271318e-05,
      "loss": 0.2494,
      "step": 221
    },
    {
      "epoch": 0.8604651162790697,
      "grad_norm": 6.86305570602417,
      "learning_rate": 4.913953488372093e-05,
      "loss": 0.106,
      "step": 222
    },
    {
      "epoch": 0.8643410852713178,
      "grad_norm": 0.18954068422317505,
      "learning_rate": 4.9135658914728684e-05,
      "loss": 0.0068,
      "step": 223
    },
    {
      "epoch": 0.8682170542635659,
      "grad_norm": 0.4189731776714325,
      "learning_rate": 4.9131782945736436e-05,
      "loss": 0.0101,
      "step": 224
    },
    {
      "epoch": 0.872093023255814,
      "grad_norm": 17.457544326782227,
      "learning_rate": 4.912790697674419e-05,
      "loss": 0.2301,
      "step": 225
    },
    {
      "epoch": 0.875968992248062,
      "grad_norm": 0.21759822964668274,
      "learning_rate": 4.912403100775194e-05,
      "loss": 0.0068,
      "step": 226
    },
    {
      "epoch": 0.8798449612403101,
      "grad_norm": 22.064342498779297,
      "learning_rate": 4.9120155038759694e-05,
      "loss": 0.423,
      "step": 227
    },
    {
      "epoch": 0.8837209302325582,
      "grad_norm": 0.2324952930212021,
      "learning_rate": 4.9116279069767446e-05,
      "loss": 0.0061,
      "step": 228
    },
    {
      "epoch": 0.8875968992248062,
      "grad_norm": 9.166587829589844,
      "learning_rate": 4.911240310077519e-05,
      "loss": 0.3423,
      "step": 229
    },
    {
      "epoch": 0.8914728682170543,
      "grad_norm": 23.715023040771484,
      "learning_rate": 4.910852713178295e-05,
      "loss": 0.657,
      "step": 230
    },
    {
      "epoch": 0.8953488372093024,
      "grad_norm": 3.7683591842651367,
      "learning_rate": 4.9104651162790697e-05,
      "loss": 0.2998,
      "step": 231
    },
    {
      "epoch": 0.8992248062015504,
      "grad_norm": 11.137934684753418,
      "learning_rate": 4.9100775193798456e-05,
      "loss": 0.395,
      "step": 232
    },
    {
      "epoch": 0.9031007751937985,
      "grad_norm": 0.13298745453357697,
      "learning_rate": 4.90968992248062e-05,
      "loss": 0.0048,
      "step": 233
    },
    {
      "epoch": 0.9069767441860465,
      "grad_norm": 14.111166000366211,
      "learning_rate": 4.909302325581396e-05,
      "loss": 0.2127,
      "step": 234
    },
    {
      "epoch": 0.9108527131782945,
      "grad_norm": 16.157102584838867,
      "learning_rate": 4.9089147286821706e-05,
      "loss": 0.2259,
      "step": 235
    },
    {
      "epoch": 0.9147286821705426,
      "grad_norm": 23.34251594543457,
      "learning_rate": 4.9085271317829465e-05,
      "loss": 0.1551,
      "step": 236
    },
    {
      "epoch": 0.9186046511627907,
      "grad_norm": 0.4943814277648926,
      "learning_rate": 4.908139534883721e-05,
      "loss": 0.0106,
      "step": 237
    },
    {
      "epoch": 0.9224806201550387,
      "grad_norm": 17.57390022277832,
      "learning_rate": 4.9077519379844964e-05,
      "loss": 1.3505,
      "step": 238
    },
    {
      "epoch": 0.9263565891472868,
      "grad_norm": 18.23067855834961,
      "learning_rate": 4.9073643410852716e-05,
      "loss": 0.621,
      "step": 239
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 4.066821098327637,
      "learning_rate": 4.906976744186046e-05,
      "loss": 0.0536,
      "step": 240
    },
    {
      "epoch": 0.9341085271317829,
      "grad_norm": 0.12150698900222778,
      "learning_rate": 4.906589147286822e-05,
      "loss": 0.0047,
      "step": 241
    },
    {
      "epoch": 0.937984496124031,
      "grad_norm": 16.149642944335938,
      "learning_rate": 4.9062015503875966e-05,
      "loss": 0.7675,
      "step": 242
    },
    {
      "epoch": 0.9418604651162791,
      "grad_norm": 0.08139510452747345,
      "learning_rate": 4.9058139534883726e-05,
      "loss": 0.0041,
      "step": 243
    },
    {
      "epoch": 0.9457364341085271,
      "grad_norm": 7.986517429351807,
      "learning_rate": 4.905426356589147e-05,
      "loss": 0.0919,
      "step": 244
    },
    {
      "epoch": 0.9496124031007752,
      "grad_norm": 39.09908676147461,
      "learning_rate": 4.905038759689923e-05,
      "loss": 0.1598,
      "step": 245
    },
    {
      "epoch": 0.9534883720930233,
      "grad_norm": 15.688275337219238,
      "learning_rate": 4.9046511627906976e-05,
      "loss": 0.1384,
      "step": 246
    },
    {
      "epoch": 0.9573643410852714,
      "grad_norm": 0.14024707674980164,
      "learning_rate": 4.904263565891473e-05,
      "loss": 0.005,
      "step": 247
    },
    {
      "epoch": 0.9612403100775194,
      "grad_norm": 27.455032348632812,
      "learning_rate": 4.903875968992248e-05,
      "loss": 0.4782,
      "step": 248
    },
    {
      "epoch": 0.9651162790697675,
      "grad_norm": 0.7067461013793945,
      "learning_rate": 4.9034883720930233e-05,
      "loss": 0.0071,
      "step": 249
    },
    {
      "epoch": 0.9689922480620154,
      "grad_norm": 2.1618714332580566,
      "learning_rate": 4.9031007751937986e-05,
      "loss": 0.03,
      "step": 250
    },
    {
      "epoch": 0.9728682170542635,
      "grad_norm": 29.85811996459961,
      "learning_rate": 4.902713178294574e-05,
      "loss": 0.2082,
      "step": 251
    },
    {
      "epoch": 0.9767441860465116,
      "grad_norm": 10.769462585449219,
      "learning_rate": 4.902325581395349e-05,
      "loss": 0.1482,
      "step": 252
    },
    {
      "epoch": 0.9806201550387597,
      "grad_norm": 0.11424330621957779,
      "learning_rate": 4.901937984496124e-05,
      "loss": 0.0046,
      "step": 253
    },
    {
      "epoch": 0.9844961240310077,
      "grad_norm": 12.853447914123535,
      "learning_rate": 4.9015503875968996e-05,
      "loss": 0.2377,
      "step": 254
    },
    {
      "epoch": 0.9883720930232558,
      "grad_norm": 1.8728517293930054,
      "learning_rate": 4.901162790697675e-05,
      "loss": 0.0225,
      "step": 255
    },
    {
      "epoch": 0.9922480620155039,
      "grad_norm": 0.06440683454275131,
      "learning_rate": 4.90077519379845e-05,
      "loss": 0.0037,
      "step": 256
    },
    {
      "epoch": 0.9961240310077519,
      "grad_norm": 0.09379862248897552,
      "learning_rate": 4.900387596899225e-05,
      "loss": 0.0041,
      "step": 257
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.029155731201172,
      "learning_rate": 4.9e-05,
      "loss": 0.1227,
      "step": 258
    },
    {
      "epoch": 1.003875968992248,
      "grad_norm": 0.050924528390169144,
      "learning_rate": 4.899612403100776e-05,
      "loss": 0.0031,
      "step": 259
    },
    {
      "epoch": 1.0077519379844961,
      "grad_norm": 0.057508766651153564,
      "learning_rate": 4.89922480620155e-05,
      "loss": 0.0027,
      "step": 260
    },
    {
      "epoch": 1.0116279069767442,
      "grad_norm": 1.611941933631897,
      "learning_rate": 4.898837209302326e-05,
      "loss": 0.0236,
      "step": 261
    },
    {
      "epoch": 1.0155038759689923,
      "grad_norm": 0.08842355757951736,
      "learning_rate": 4.898449612403101e-05,
      "loss": 0.0038,
      "step": 262
    },
    {
      "epoch": 1.0193798449612403,
      "grad_norm": 0.07974132150411606,
      "learning_rate": 4.898062015503877e-05,
      "loss": 0.0037,
      "step": 263
    },
    {
      "epoch": 1.0232558139534884,
      "grad_norm": 0.6458576321601868,
      "learning_rate": 4.897674418604651e-05,
      "loss": 0.0071,
      "step": 264
    },
    {
      "epoch": 1.0271317829457365,
      "grad_norm": 32.954811096191406,
      "learning_rate": 4.8972868217054265e-05,
      "loss": 0.1461,
      "step": 265
    },
    {
      "epoch": 1.0310077519379846,
      "grad_norm": 5.757227420806885,
      "learning_rate": 4.896899224806202e-05,
      "loss": 0.041,
      "step": 266
    },
    {
      "epoch": 1.0348837209302326,
      "grad_norm": 0.029901517555117607,
      "learning_rate": 4.896511627906977e-05,
      "loss": 0.0024,
      "step": 267
    },
    {
      "epoch": 1.0387596899224807,
      "grad_norm": 8.905789375305176,
      "learning_rate": 4.896124031007752e-05,
      "loss": 0.1583,
      "step": 268
    },
    {
      "epoch": 1.0426356589147288,
      "grad_norm": 0.5568385720252991,
      "learning_rate": 4.895736434108527e-05,
      "loss": 0.0087,
      "step": 269
    },
    {
      "epoch": 1.0465116279069768,
      "grad_norm": 4.460921287536621,
      "learning_rate": 4.895348837209303e-05,
      "loss": 0.0516,
      "step": 270
    },
    {
      "epoch": 1.050387596899225,
      "grad_norm": 0.041589267551898956,
      "learning_rate": 4.894961240310077e-05,
      "loss": 0.0027,
      "step": 271
    },
    {
      "epoch": 1.054263565891473,
      "grad_norm": 0.05228111892938614,
      "learning_rate": 4.894573643410853e-05,
      "loss": 0.0031,
      "step": 272
    },
    {
      "epoch": 1.058139534883721,
      "grad_norm": 0.042467959225177765,
      "learning_rate": 4.894186046511628e-05,
      "loss": 0.0026,
      "step": 273
    },
    {
      "epoch": 1.062015503875969,
      "grad_norm": 1.046055555343628,
      "learning_rate": 4.893798449612404e-05,
      "loss": 0.0087,
      "step": 274
    },
    {
      "epoch": 1.0658914728682172,
      "grad_norm": 0.08162426948547363,
      "learning_rate": 4.893410852713178e-05,
      "loss": 0.0027,
      "step": 275
    },
    {
      "epoch": 1.069767441860465,
      "grad_norm": 6.520103931427002,
      "learning_rate": 4.8930232558139535e-05,
      "loss": 0.3674,
      "step": 276
    },
    {
      "epoch": 1.073643410852713,
      "grad_norm": 11.106145858764648,
      "learning_rate": 4.892635658914729e-05,
      "loss": 0.5125,
      "step": 277
    },
    {
      "epoch": 1.0775193798449612,
      "grad_norm": 0.12041594088077545,
      "learning_rate": 4.892248062015504e-05,
      "loss": 0.0039,
      "step": 278
    },
    {
      "epoch": 1.0813953488372092,
      "grad_norm": 0.09718088805675507,
      "learning_rate": 4.891860465116279e-05,
      "loss": 0.0041,
      "step": 279
    },
    {
      "epoch": 1.0852713178294573,
      "grad_norm": 4.486763954162598,
      "learning_rate": 4.8914728682170545e-05,
      "loss": 0.275,
      "step": 280
    },
    {
      "epoch": 1.0891472868217054,
      "grad_norm": 13.63989543914795,
      "learning_rate": 4.89108527131783e-05,
      "loss": 0.326,
      "step": 281
    },
    {
      "epoch": 1.0930232558139534,
      "grad_norm": 1.4158395528793335,
      "learning_rate": 4.890697674418605e-05,
      "loss": 0.007,
      "step": 282
    },
    {
      "epoch": 1.0968992248062015,
      "grad_norm": 0.05550184100866318,
      "learning_rate": 4.89031007751938e-05,
      "loss": 0.0025,
      "step": 283
    },
    {
      "epoch": 1.1007751937984496,
      "grad_norm": 18.293262481689453,
      "learning_rate": 4.8899224806201555e-05,
      "loss": 0.4824,
      "step": 284
    },
    {
      "epoch": 1.1046511627906976,
      "grad_norm": 7.611651420593262,
      "learning_rate": 4.889534883720931e-05,
      "loss": 0.2918,
      "step": 285
    },
    {
      "epoch": 1.1085271317829457,
      "grad_norm": 6.911672115325928,
      "learning_rate": 4.889147286821706e-05,
      "loss": 0.0459,
      "step": 286
    },
    {
      "epoch": 1.1124031007751938,
      "grad_norm": 8.559464454650879,
      "learning_rate": 4.8887596899224805e-05,
      "loss": 0.4001,
      "step": 287
    },
    {
      "epoch": 1.1162790697674418,
      "grad_norm": 14.723292350769043,
      "learning_rate": 4.8883720930232564e-05,
      "loss": 0.4565,
      "step": 288
    },
    {
      "epoch": 1.12015503875969,
      "grad_norm": 0.31560856103897095,
      "learning_rate": 4.887984496124031e-05,
      "loss": 0.005,
      "step": 289
    },
    {
      "epoch": 1.124031007751938,
      "grad_norm": 0.07053127884864807,
      "learning_rate": 4.887596899224807e-05,
      "loss": 0.0034,
      "step": 290
    },
    {
      "epoch": 1.127906976744186,
      "grad_norm": 7.249674320220947,
      "learning_rate": 4.8872093023255815e-05,
      "loss": 0.085,
      "step": 291
    },
    {
      "epoch": 1.1317829457364341,
      "grad_norm": 11.591837882995605,
      "learning_rate": 4.8868217054263574e-05,
      "loss": 1.1423,
      "step": 292
    },
    {
      "epoch": 1.1356589147286822,
      "grad_norm": 1.0882863998413086,
      "learning_rate": 4.886434108527132e-05,
      "loss": 0.0072,
      "step": 293
    },
    {
      "epoch": 1.1395348837209303,
      "grad_norm": 14.346503257751465,
      "learning_rate": 4.886046511627907e-05,
      "loss": 0.1042,
      "step": 294
    },
    {
      "epoch": 1.1434108527131783,
      "grad_norm": 3.4482569694519043,
      "learning_rate": 4.8856589147286824e-05,
      "loss": 0.0326,
      "step": 295
    },
    {
      "epoch": 1.1472868217054264,
      "grad_norm": 12.163590431213379,
      "learning_rate": 4.885271317829458e-05,
      "loss": 0.2024,
      "step": 296
    },
    {
      "epoch": 1.1511627906976745,
      "grad_norm": 15.73624038696289,
      "learning_rate": 4.884883720930233e-05,
      "loss": 0.3665,
      "step": 297
    },
    {
      "epoch": 1.1550387596899225,
      "grad_norm": 8.70119571685791,
      "learning_rate": 4.8844961240310075e-05,
      "loss": 0.2156,
      "step": 298
    },
    {
      "epoch": 1.1589147286821706,
      "grad_norm": 0.057543955743312836,
      "learning_rate": 4.8841085271317834e-05,
      "loss": 0.0029,
      "step": 299
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 7.9128098487854,
      "learning_rate": 4.883720930232558e-05,
      "loss": 0.0721,
      "step": 300
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 50.22510528564453,
      "learning_rate": 4.883333333333334e-05,
      "loss": 0.3304,
      "step": 301
    },
    {
      "epoch": 1.1705426356589148,
      "grad_norm": 0.0266860481351614,
      "learning_rate": 4.8829457364341085e-05,
      "loss": 0.002,
      "step": 302
    },
    {
      "epoch": 1.1744186046511629,
      "grad_norm": 24.263216018676758,
      "learning_rate": 4.8825581395348844e-05,
      "loss": 0.665,
      "step": 303
    },
    {
      "epoch": 1.178294573643411,
      "grad_norm": 11.03193473815918,
      "learning_rate": 4.882170542635659e-05,
      "loss": 0.2963,
      "step": 304
    },
    {
      "epoch": 1.1821705426356588,
      "grad_norm": 8.463224411010742,
      "learning_rate": 4.881782945736434e-05,
      "loss": 0.2145,
      "step": 305
    },
    {
      "epoch": 1.1860465116279069,
      "grad_norm": 3.6201562881469727,
      "learning_rate": 4.8813953488372094e-05,
      "loss": 0.0314,
      "step": 306
    },
    {
      "epoch": 1.189922480620155,
      "grad_norm": 9.740165710449219,
      "learning_rate": 4.881007751937985e-05,
      "loss": 0.2846,
      "step": 307
    },
    {
      "epoch": 1.193798449612403,
      "grad_norm": 1.4584996700286865,
      "learning_rate": 4.88062015503876e-05,
      "loss": 0.009,
      "step": 308
    },
    {
      "epoch": 1.197674418604651,
      "grad_norm": 42.842262268066406,
      "learning_rate": 4.880232558139535e-05,
      "loss": 0.3681,
      "step": 309
    },
    {
      "epoch": 1.2015503875968991,
      "grad_norm": 0.06681367754936218,
      "learning_rate": 4.8798449612403104e-05,
      "loss": 0.0022,
      "step": 310
    },
    {
      "epoch": 1.2054263565891472,
      "grad_norm": 0.30599865317344666,
      "learning_rate": 4.8794573643410856e-05,
      "loss": 0.0073,
      "step": 311
    },
    {
      "epoch": 1.2093023255813953,
      "grad_norm": 1.9647729396820068,
      "learning_rate": 4.879069767441861e-05,
      "loss": 0.0112,
      "step": 312
    },
    {
      "epoch": 1.2131782945736433,
      "grad_norm": 3.2335596084594727,
      "learning_rate": 4.878682170542636e-05,
      "loss": 0.0311,
      "step": 313
    },
    {
      "epoch": 1.2170542635658914,
      "grad_norm": 25.42234992980957,
      "learning_rate": 4.878294573643411e-05,
      "loss": 0.3678,
      "step": 314
    },
    {
      "epoch": 1.2209302325581395,
      "grad_norm": 0.9930465817451477,
      "learning_rate": 4.8779069767441866e-05,
      "loss": 0.0073,
      "step": 315
    },
    {
      "epoch": 1.2248062015503876,
      "grad_norm": 6.416517734527588,
      "learning_rate": 4.877519379844961e-05,
      "loss": 0.3245,
      "step": 316
    },
    {
      "epoch": 1.2286821705426356,
      "grad_norm": 9.554845809936523,
      "learning_rate": 4.877131782945737e-05,
      "loss": 0.373,
      "step": 317
    },
    {
      "epoch": 1.2325581395348837,
      "grad_norm": 15.933238983154297,
      "learning_rate": 4.8767441860465117e-05,
      "loss": 0.4058,
      "step": 318
    },
    {
      "epoch": 1.2364341085271318,
      "grad_norm": 6.443442344665527,
      "learning_rate": 4.8763565891472876e-05,
      "loss": 0.0869,
      "step": 319
    },
    {
      "epoch": 1.2403100775193798,
      "grad_norm": 6.025173187255859,
      "learning_rate": 4.875968992248062e-05,
      "loss": 0.1152,
      "step": 320
    },
    {
      "epoch": 1.244186046511628,
      "grad_norm": 10.050354957580566,
      "learning_rate": 4.8755813953488374e-05,
      "loss": 0.4813,
      "step": 321
    },
    {
      "epoch": 1.248062015503876,
      "grad_norm": 13.04689884185791,
      "learning_rate": 4.8751937984496126e-05,
      "loss": 1.1461,
      "step": 322
    },
    {
      "epoch": 1.251937984496124,
      "grad_norm": 0.17955975234508514,
      "learning_rate": 4.874806201550388e-05,
      "loss": 0.004,
      "step": 323
    },
    {
      "epoch": 1.255813953488372,
      "grad_norm": 5.951097011566162,
      "learning_rate": 4.874418604651163e-05,
      "loss": 0.0557,
      "step": 324
    },
    {
      "epoch": 1.2596899224806202,
      "grad_norm": 10.035880088806152,
      "learning_rate": 4.874031007751938e-05,
      "loss": 0.1915,
      "step": 325
    },
    {
      "epoch": 1.2635658914728682,
      "grad_norm": 7.426272392272949,
      "learning_rate": 4.8736434108527136e-05,
      "loss": 0.1075,
      "step": 326
    },
    {
      "epoch": 1.2674418604651163,
      "grad_norm": 26.495040893554688,
      "learning_rate": 4.873255813953488e-05,
      "loss": 1.5572,
      "step": 327
    },
    {
      "epoch": 1.2713178294573644,
      "grad_norm": 20.095762252807617,
      "learning_rate": 4.872868217054264e-05,
      "loss": 0.2911,
      "step": 328
    },
    {
      "epoch": 1.2751937984496124,
      "grad_norm": 0.13759417831897736,
      "learning_rate": 4.8724806201550386e-05,
      "loss": 0.0053,
      "step": 329
    },
    {
      "epoch": 1.2790697674418605,
      "grad_norm": 9.03809928894043,
      "learning_rate": 4.8720930232558146e-05,
      "loss": 0.1128,
      "step": 330
    },
    {
      "epoch": 1.2829457364341086,
      "grad_norm": 0.22408872842788696,
      "learning_rate": 4.871705426356589e-05,
      "loss": 0.005,
      "step": 331
    },
    {
      "epoch": 1.2868217054263567,
      "grad_norm": 12.786293029785156,
      "learning_rate": 4.8713178294573644e-05,
      "loss": 0.8847,
      "step": 332
    },
    {
      "epoch": 1.2906976744186047,
      "grad_norm": 10.520235061645508,
      "learning_rate": 4.8709302325581396e-05,
      "loss": 0.0532,
      "step": 333
    },
    {
      "epoch": 1.2945736434108528,
      "grad_norm": 0.16058775782585144,
      "learning_rate": 4.870542635658915e-05,
      "loss": 0.006,
      "step": 334
    },
    {
      "epoch": 1.2984496124031009,
      "grad_norm": 0.4893725514411926,
      "learning_rate": 4.87015503875969e-05,
      "loss": 0.0068,
      "step": 335
    },
    {
      "epoch": 1.302325581395349,
      "grad_norm": 31.656734466552734,
      "learning_rate": 4.8697674418604653e-05,
      "loss": 1.443,
      "step": 336
    },
    {
      "epoch": 1.306201550387597,
      "grad_norm": 0.08540133386850357,
      "learning_rate": 4.8693798449612406e-05,
      "loss": 0.0028,
      "step": 337
    },
    {
      "epoch": 1.310077519379845,
      "grad_norm": 0.16015207767486572,
      "learning_rate": 4.868992248062016e-05,
      "loss": 0.0055,
      "step": 338
    },
    {
      "epoch": 1.3139534883720931,
      "grad_norm": 0.11849585175514221,
      "learning_rate": 4.868604651162791e-05,
      "loss": 0.0048,
      "step": 339
    },
    {
      "epoch": 1.3178294573643412,
      "grad_norm": 6.316982746124268,
      "learning_rate": 4.868217054263566e-05,
      "loss": 0.0459,
      "step": 340
    },
    {
      "epoch": 1.3217054263565893,
      "grad_norm": 3.9838180541992188,
      "learning_rate": 4.8678294573643416e-05,
      "loss": 0.0153,
      "step": 341
    },
    {
      "epoch": 1.3255813953488373,
      "grad_norm": 4.267085552215576,
      "learning_rate": 4.867441860465117e-05,
      "loss": 0.117,
      "step": 342
    },
    {
      "epoch": 1.3294573643410852,
      "grad_norm": 1.8339042663574219,
      "learning_rate": 4.8670542635658914e-05,
      "loss": 0.0121,
      "step": 343
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 3.783360242843628,
      "learning_rate": 4.866666666666667e-05,
      "loss": 0.031,
      "step": 344
    },
    {
      "epoch": 1.3372093023255813,
      "grad_norm": 0.04921955615282059,
      "learning_rate": 4.866279069767442e-05,
      "loss": 0.0017,
      "step": 345
    },
    {
      "epoch": 1.3410852713178294,
      "grad_norm": 0.088298000395298,
      "learning_rate": 4.865891472868218e-05,
      "loss": 0.0039,
      "step": 346
    },
    {
      "epoch": 1.3449612403100775,
      "grad_norm": 1.2057020664215088,
      "learning_rate": 4.865503875968992e-05,
      "loss": 0.0177,
      "step": 347
    },
    {
      "epoch": 1.3488372093023255,
      "grad_norm": 1.090997576713562,
      "learning_rate": 4.8651162790697676e-05,
      "loss": 0.0157,
      "step": 348
    },
    {
      "epoch": 1.3527131782945736,
      "grad_norm": 5.636639595031738,
      "learning_rate": 4.864728682170543e-05,
      "loss": 0.3758,
      "step": 349
    },
    {
      "epoch": 1.3565891472868217,
      "grad_norm": 0.6265774369239807,
      "learning_rate": 4.864341085271318e-05,
      "loss": 0.0087,
      "step": 350
    },
    {
      "epoch": 1.3604651162790697,
      "grad_norm": 14.633649826049805,
      "learning_rate": 4.863953488372093e-05,
      "loss": 0.4133,
      "step": 351
    },
    {
      "epoch": 1.3643410852713178,
      "grad_norm": 10.148591041564941,
      "learning_rate": 4.8635658914728685e-05,
      "loss": 0.043,
      "step": 352
    },
    {
      "epoch": 1.3682170542635659,
      "grad_norm": 3.418431520462036,
      "learning_rate": 4.863178294573644e-05,
      "loss": 0.2737,
      "step": 353
    },
    {
      "epoch": 1.372093023255814,
      "grad_norm": 0.40723681449890137,
      "learning_rate": 4.8627906976744183e-05,
      "loss": 0.0035,
      "step": 354
    },
    {
      "epoch": 1.375968992248062,
      "grad_norm": 21.28891372680664,
      "learning_rate": 4.862403100775194e-05,
      "loss": 0.6468,
      "step": 355
    },
    {
      "epoch": 1.37984496124031,
      "grad_norm": 0.6892660856246948,
      "learning_rate": 4.862015503875969e-05,
      "loss": 0.0085,
      "step": 356
    },
    {
      "epoch": 1.3837209302325582,
      "grad_norm": 0.04608047753572464,
      "learning_rate": 4.861627906976745e-05,
      "loss": 0.0024,
      "step": 357
    },
    {
      "epoch": 1.3875968992248062,
      "grad_norm": 1.143424153327942,
      "learning_rate": 4.861240310077519e-05,
      "loss": 0.0131,
      "step": 358
    },
    {
      "epoch": 1.3914728682170543,
      "grad_norm": 19.40751075744629,
      "learning_rate": 4.860852713178295e-05,
      "loss": 0.5673,
      "step": 359
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 0.27032408118247986,
      "learning_rate": 4.86046511627907e-05,
      "loss": 0.0044,
      "step": 360
    },
    {
      "epoch": 1.3992248062015504,
      "grad_norm": 13.576521873474121,
      "learning_rate": 4.860077519379845e-05,
      "loss": 0.2678,
      "step": 361
    },
    {
      "epoch": 1.4031007751937985,
      "grad_norm": 0.062364738434553146,
      "learning_rate": 4.85968992248062e-05,
      "loss": 0.0025,
      "step": 362
    },
    {
      "epoch": 1.4069767441860466,
      "grad_norm": 8.0529146194458,
      "learning_rate": 4.8593023255813955e-05,
      "loss": 0.1487,
      "step": 363
    },
    {
      "epoch": 1.4108527131782946,
      "grad_norm": 13.52864933013916,
      "learning_rate": 4.858914728682171e-05,
      "loss": 0.6222,
      "step": 364
    },
    {
      "epoch": 1.4147286821705427,
      "grad_norm": 3.557441473007202,
      "learning_rate": 4.858527131782946e-05,
      "loss": 0.0815,
      "step": 365
    },
    {
      "epoch": 1.4186046511627908,
      "grad_norm": 0.086192786693573,
      "learning_rate": 4.858139534883721e-05,
      "loss": 0.0021,
      "step": 366
    },
    {
      "epoch": 1.4224806201550386,
      "grad_norm": 0.04522355645895004,
      "learning_rate": 4.8577519379844965e-05,
      "loss": 0.0025,
      "step": 367
    },
    {
      "epoch": 1.4263565891472867,
      "grad_norm": 0.1375836730003357,
      "learning_rate": 4.857364341085272e-05,
      "loss": 0.003,
      "step": 368
    },
    {
      "epoch": 1.4302325581395348,
      "grad_norm": 0.40914255380630493,
      "learning_rate": 4.856976744186047e-05,
      "loss": 0.0072,
      "step": 369
    },
    {
      "epoch": 1.4341085271317828,
      "grad_norm": 8.885880470275879,
      "learning_rate": 4.856589147286822e-05,
      "loss": 0.1011,
      "step": 370
    },
    {
      "epoch": 1.437984496124031,
      "grad_norm": 14.93803596496582,
      "learning_rate": 4.8562015503875975e-05,
      "loss": 0.0477,
      "step": 371
    },
    {
      "epoch": 1.441860465116279,
      "grad_norm": 5.7469329833984375,
      "learning_rate": 4.855813953488372e-05,
      "loss": 0.4845,
      "step": 372
    },
    {
      "epoch": 1.445736434108527,
      "grad_norm": 18.93459701538086,
      "learning_rate": 4.855426356589148e-05,
      "loss": 0.0977,
      "step": 373
    },
    {
      "epoch": 1.449612403100775,
      "grad_norm": 0.16404366493225098,
      "learning_rate": 4.8550387596899225e-05,
      "loss": 0.0028,
      "step": 374
    },
    {
      "epoch": 1.4534883720930232,
      "grad_norm": 6.988367557525635,
      "learning_rate": 4.854651162790698e-05,
      "loss": 0.0295,
      "step": 375
    },
    {
      "epoch": 1.4573643410852712,
      "grad_norm": 0.17309153079986572,
      "learning_rate": 4.854263565891473e-05,
      "loss": 0.0027,
      "step": 376
    },
    {
      "epoch": 1.4612403100775193,
      "grad_norm": 4.736298561096191,
      "learning_rate": 4.853875968992248e-05,
      "loss": 0.3044,
      "step": 377
    },
    {
      "epoch": 1.4651162790697674,
      "grad_norm": 0.028477931395173073,
      "learning_rate": 4.8534883720930235e-05,
      "loss": 0.0015,
      "step": 378
    },
    {
      "epoch": 1.4689922480620154,
      "grad_norm": 19.07328224182129,
      "learning_rate": 4.853100775193799e-05,
      "loss": 0.3418,
      "step": 379
    },
    {
      "epoch": 1.4728682170542635,
      "grad_norm": 0.03385239839553833,
      "learning_rate": 4.852713178294574e-05,
      "loss": 0.0023,
      "step": 380
    },
    {
      "epoch": 1.4767441860465116,
      "grad_norm": 0.057812970131635666,
      "learning_rate": 4.852325581395349e-05,
      "loss": 0.0021,
      "step": 381
    },
    {
      "epoch": 1.4806201550387597,
      "grad_norm": 0.92049640417099,
      "learning_rate": 4.8519379844961244e-05,
      "loss": 0.0074,
      "step": 382
    },
    {
      "epoch": 1.4844961240310077,
      "grad_norm": 9.631571769714355,
      "learning_rate": 4.851550387596899e-05,
      "loss": 0.0322,
      "step": 383
    },
    {
      "epoch": 1.4883720930232558,
      "grad_norm": 11.598877906799316,
      "learning_rate": 4.851162790697675e-05,
      "loss": 0.1456,
      "step": 384
    },
    {
      "epoch": 1.4922480620155039,
      "grad_norm": 0.03426210582256317,
      "learning_rate": 4.8507751937984495e-05,
      "loss": 0.002,
      "step": 385
    },
    {
      "epoch": 1.496124031007752,
      "grad_norm": 4.898332118988037,
      "learning_rate": 4.8503875968992254e-05,
      "loss": 0.1259,
      "step": 386
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.060238838195801,
      "learning_rate": 4.85e-05,
      "loss": 0.4073,
      "step": 387
    },
    {
      "epoch": 1.503875968992248,
      "grad_norm": 34.0492057800293,
      "learning_rate": 4.849612403100776e-05,
      "loss": 0.759,
      "step": 388
    },
    {
      "epoch": 1.5077519379844961,
      "grad_norm": 24.638944625854492,
      "learning_rate": 4.8492248062015505e-05,
      "loss": 1.0695,
      "step": 389
    },
    {
      "epoch": 1.5116279069767442,
      "grad_norm": 17.650236129760742,
      "learning_rate": 4.848837209302326e-05,
      "loss": 0.846,
      "step": 390
    },
    {
      "epoch": 1.5155038759689923,
      "grad_norm": 33.12516403198242,
      "learning_rate": 4.848449612403101e-05,
      "loss": 0.148,
      "step": 391
    },
    {
      "epoch": 1.5193798449612403,
      "grad_norm": 0.22991818189620972,
      "learning_rate": 4.848062015503876e-05,
      "loss": 0.0028,
      "step": 392
    },
    {
      "epoch": 1.5232558139534884,
      "grad_norm": 15.559381484985352,
      "learning_rate": 4.8476744186046514e-05,
      "loss": 0.0504,
      "step": 393
    },
    {
      "epoch": 1.5271317829457365,
      "grad_norm": 24.8973388671875,
      "learning_rate": 4.847286821705427e-05,
      "loss": 0.1472,
      "step": 394
    },
    {
      "epoch": 1.5310077519379846,
      "grad_norm": 37.58092498779297,
      "learning_rate": 4.846899224806202e-05,
      "loss": 0.709,
      "step": 395
    },
    {
      "epoch": 1.5348837209302326,
      "grad_norm": 16.218050003051758,
      "learning_rate": 4.846511627906977e-05,
      "loss": 0.5115,
      "step": 396
    },
    {
      "epoch": 1.5387596899224807,
      "grad_norm": 0.05347912758588791,
      "learning_rate": 4.8461240310077524e-05,
      "loss": 0.0023,
      "step": 397
    },
    {
      "epoch": 1.5426356589147288,
      "grad_norm": 2.9326517581939697,
      "learning_rate": 4.8457364341085276e-05,
      "loss": 0.0054,
      "step": 398
    },
    {
      "epoch": 1.5465116279069768,
      "grad_norm": 0.046315621584653854,
      "learning_rate": 4.845348837209303e-05,
      "loss": 0.002,
      "step": 399
    },
    {
      "epoch": 1.550387596899225,
      "grad_norm": 0.04772137477993965,
      "learning_rate": 4.8449612403100775e-05,
      "loss": 0.0024,
      "step": 400
    },
    {
      "epoch": 1.554263565891473,
      "grad_norm": 0.03223647549748421,
      "learning_rate": 4.844573643410853e-05,
      "loss": 0.0018,
      "step": 401
    },
    {
      "epoch": 1.558139534883721,
      "grad_norm": 0.06985600292682648,
      "learning_rate": 4.844186046511628e-05,
      "loss": 0.0026,
      "step": 402
    },
    {
      "epoch": 1.562015503875969,
      "grad_norm": 7.09365177154541,
      "learning_rate": 4.843798449612403e-05,
      "loss": 0.1305,
      "step": 403
    },
    {
      "epoch": 1.5658914728682172,
      "grad_norm": 26.145307540893555,
      "learning_rate": 4.8434108527131784e-05,
      "loss": 0.0466,
      "step": 404
    },
    {
      "epoch": 1.5697674418604652,
      "grad_norm": 12.859559059143066,
      "learning_rate": 4.843023255813954e-05,
      "loss": 0.2456,
      "step": 405
    },
    {
      "epoch": 1.5736434108527133,
      "grad_norm": 19.448963165283203,
      "learning_rate": 4.842635658914729e-05,
      "loss": 0.2089,
      "step": 406
    },
    {
      "epoch": 1.5775193798449614,
      "grad_norm": 29.0638427734375,
      "learning_rate": 4.842248062015504e-05,
      "loss": 0.2537,
      "step": 407
    },
    {
      "epoch": 1.5813953488372094,
      "grad_norm": 23.252809524536133,
      "learning_rate": 4.8418604651162794e-05,
      "loss": 0.308,
      "step": 408
    },
    {
      "epoch": 1.5852713178294575,
      "grad_norm": 1.1211953163146973,
      "learning_rate": 4.8414728682170546e-05,
      "loss": 0.0117,
      "step": 409
    },
    {
      "epoch": 1.5891472868217056,
      "grad_norm": 0.034879446029663086,
      "learning_rate": 4.841085271317829e-05,
      "loss": 0.0018,
      "step": 410
    },
    {
      "epoch": 1.5930232558139537,
      "grad_norm": 0.1918700635433197,
      "learning_rate": 4.840697674418605e-05,
      "loss": 0.0057,
      "step": 411
    },
    {
      "epoch": 1.5968992248062015,
      "grad_norm": 32.510108947753906,
      "learning_rate": 4.84031007751938e-05,
      "loss": 1.1585,
      "step": 412
    },
    {
      "epoch": 1.6007751937984496,
      "grad_norm": 8.3004789352417,
      "learning_rate": 4.8399224806201556e-05,
      "loss": 0.0248,
      "step": 413
    },
    {
      "epoch": 1.6046511627906976,
      "grad_norm": 6.304377555847168,
      "learning_rate": 4.83953488372093e-05,
      "loss": 0.0649,
      "step": 414
    },
    {
      "epoch": 1.6085271317829457,
      "grad_norm": 0.8417713046073914,
      "learning_rate": 4.839147286821706e-05,
      "loss": 0.0053,
      "step": 415
    },
    {
      "epoch": 1.6124031007751938,
      "grad_norm": 6.137392044067383,
      "learning_rate": 4.8387596899224806e-05,
      "loss": 0.0165,
      "step": 416
    },
    {
      "epoch": 1.6162790697674418,
      "grad_norm": 8.643299102783203,
      "learning_rate": 4.838372093023256e-05,
      "loss": 0.1152,
      "step": 417
    },
    {
      "epoch": 1.62015503875969,
      "grad_norm": 0.06148307025432587,
      "learning_rate": 4.837984496124031e-05,
      "loss": 0.0021,
      "step": 418
    },
    {
      "epoch": 1.624031007751938,
      "grad_norm": 26.959291458129883,
      "learning_rate": 4.8375968992248064e-05,
      "loss": 0.6074,
      "step": 419
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 19.882978439331055,
      "learning_rate": 4.8372093023255816e-05,
      "loss": 0.2394,
      "step": 420
    },
    {
      "epoch": 1.6317829457364341,
      "grad_norm": 0.14412252604961395,
      "learning_rate": 4.836821705426357e-05,
      "loss": 0.0046,
      "step": 421
    },
    {
      "epoch": 1.6356589147286822,
      "grad_norm": 29.581369400024414,
      "learning_rate": 4.836434108527132e-05,
      "loss": 0.1254,
      "step": 422
    },
    {
      "epoch": 1.6395348837209303,
      "grad_norm": 12.326000213623047,
      "learning_rate": 4.8360465116279073e-05,
      "loss": 0.2645,
      "step": 423
    },
    {
      "epoch": 1.6434108527131783,
      "grad_norm": 0.029612720012664795,
      "learning_rate": 4.8356589147286826e-05,
      "loss": 0.0018,
      "step": 424
    },
    {
      "epoch": 1.6472868217054264,
      "grad_norm": 12.831071853637695,
      "learning_rate": 4.835271317829458e-05,
      "loss": 1.1768,
      "step": 425
    },
    {
      "epoch": 1.6511627906976745,
      "grad_norm": 5.735464096069336,
      "learning_rate": 4.834883720930233e-05,
      "loss": 0.4346,
      "step": 426
    },
    {
      "epoch": 1.6550387596899225,
      "grad_norm": 15.292927742004395,
      "learning_rate": 4.8344961240310076e-05,
      "loss": 0.6037,
      "step": 427
    },
    {
      "epoch": 1.6589147286821704,
      "grad_norm": 13.476584434509277,
      "learning_rate": 4.834108527131783e-05,
      "loss": 0.3307,
      "step": 428
    },
    {
      "epoch": 1.6627906976744184,
      "grad_norm": 5.752249717712402,
      "learning_rate": 4.833720930232558e-05,
      "loss": 0.0763,
      "step": 429
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 15.212910652160645,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.4061,
      "step": 430
    },
    {
      "epoch": 1.6705426356589146,
      "grad_norm": 0.4728137254714966,
      "learning_rate": 4.8329457364341086e-05,
      "loss": 0.0085,
      "step": 431
    },
    {
      "epoch": 1.6744186046511627,
      "grad_norm": 2.1169936656951904,
      "learning_rate": 4.832558139534884e-05,
      "loss": 0.0131,
      "step": 432
    },
    {
      "epoch": 1.6782945736434107,
      "grad_norm": 8.47319507598877,
      "learning_rate": 4.832170542635659e-05,
      "loss": 0.107,
      "step": 433
    },
    {
      "epoch": 1.6821705426356588,
      "grad_norm": 0.8619897961616516,
      "learning_rate": 4.831782945736434e-05,
      "loss": 0.024,
      "step": 434
    },
    {
      "epoch": 1.6860465116279069,
      "grad_norm": 2.6043598651885986,
      "learning_rate": 4.8313953488372096e-05,
      "loss": 0.0196,
      "step": 435
    },
    {
      "epoch": 1.689922480620155,
      "grad_norm": 0.8364284634590149,
      "learning_rate": 4.831007751937985e-05,
      "loss": 0.0096,
      "step": 436
    },
    {
      "epoch": 1.693798449612403,
      "grad_norm": 54.08987808227539,
      "learning_rate": 4.83062015503876e-05,
      "loss": 0.6628,
      "step": 437
    },
    {
      "epoch": 1.697674418604651,
      "grad_norm": 8.002341270446777,
      "learning_rate": 4.830232558139535e-05,
      "loss": 0.17,
      "step": 438
    },
    {
      "epoch": 1.7015503875968991,
      "grad_norm": 7.687405109405518,
      "learning_rate": 4.82984496124031e-05,
      "loss": 0.1508,
      "step": 439
    },
    {
      "epoch": 1.7054263565891472,
      "grad_norm": 13.28923511505127,
      "learning_rate": 4.829457364341086e-05,
      "loss": 0.7758,
      "step": 440
    },
    {
      "epoch": 1.7093023255813953,
      "grad_norm": 3.495234489440918,
      "learning_rate": 4.8290697674418603e-05,
      "loss": 0.0251,
      "step": 441
    },
    {
      "epoch": 1.7131782945736433,
      "grad_norm": 0.03794661909341812,
      "learning_rate": 4.828682170542636e-05,
      "loss": 0.0019,
      "step": 442
    },
    {
      "epoch": 1.7170542635658914,
      "grad_norm": 0.7828295826911926,
      "learning_rate": 4.828294573643411e-05,
      "loss": 0.0116,
      "step": 443
    },
    {
      "epoch": 1.7209302325581395,
      "grad_norm": 6.770782470703125,
      "learning_rate": 4.827906976744187e-05,
      "loss": 0.1575,
      "step": 444
    },
    {
      "epoch": 1.7248062015503876,
      "grad_norm": 12.559188842773438,
      "learning_rate": 4.827519379844961e-05,
      "loss": 0.0504,
      "step": 445
    },
    {
      "epoch": 1.7286821705426356,
      "grad_norm": 0.017796749249100685,
      "learning_rate": 4.8271317829457366e-05,
      "loss": 0.0015,
      "step": 446
    },
    {
      "epoch": 1.7325581395348837,
      "grad_norm": 4.919593334197998,
      "learning_rate": 4.826744186046512e-05,
      "loss": 0.2433,
      "step": 447
    },
    {
      "epoch": 1.7364341085271318,
      "grad_norm": 8.742671966552734,
      "learning_rate": 4.826356589147287e-05,
      "loss": 0.4332,
      "step": 448
    },
    {
      "epoch": 1.7403100775193798,
      "grad_norm": 0.0782061219215393,
      "learning_rate": 4.825968992248062e-05,
      "loss": 0.0021,
      "step": 449
    },
    {
      "epoch": 1.744186046511628,
      "grad_norm": 1.6209321022033691,
      "learning_rate": 4.8255813953488375e-05,
      "loss": 0.015,
      "step": 450
    },
    {
      "epoch": 1.748062015503876,
      "grad_norm": 8.752646446228027,
      "learning_rate": 4.825193798449613e-05,
      "loss": 0.3269,
      "step": 451
    },
    {
      "epoch": 1.751937984496124,
      "grad_norm": 0.023142065852880478,
      "learning_rate": 4.824806201550388e-05,
      "loss": 0.0016,
      "step": 452
    },
    {
      "epoch": 1.755813953488372,
      "grad_norm": 0.12270060926675797,
      "learning_rate": 4.824418604651163e-05,
      "loss": 0.0044,
      "step": 453
    },
    {
      "epoch": 1.7596899224806202,
      "grad_norm": 8.502476692199707,
      "learning_rate": 4.824031007751938e-05,
      "loss": 0.1387,
      "step": 454
    },
    {
      "epoch": 1.7635658914728682,
      "grad_norm": 0.2171858847141266,
      "learning_rate": 4.823643410852714e-05,
      "loss": 0.0033,
      "step": 455
    },
    {
      "epoch": 1.7674418604651163,
      "grad_norm": 5.977733135223389,
      "learning_rate": 4.823255813953488e-05,
      "loss": 0.2269,
      "step": 456
    },
    {
      "epoch": 1.7713178294573644,
      "grad_norm": 3.377279281616211,
      "learning_rate": 4.8228682170542635e-05,
      "loss": 0.3492,
      "step": 457
    },
    {
      "epoch": 1.7751937984496124,
      "grad_norm": 1.515805721282959,
      "learning_rate": 4.822480620155039e-05,
      "loss": 0.0155,
      "step": 458
    },
    {
      "epoch": 1.7790697674418605,
      "grad_norm": 8.125455856323242,
      "learning_rate": 4.822093023255814e-05,
      "loss": 0.1087,
      "step": 459
    },
    {
      "epoch": 1.7829457364341086,
      "grad_norm": 0.4275156259536743,
      "learning_rate": 4.821705426356589e-05,
      "loss": 0.0049,
      "step": 460
    },
    {
      "epoch": 1.7868217054263567,
      "grad_norm": 0.26364314556121826,
      "learning_rate": 4.8213178294573645e-05,
      "loss": 0.0065,
      "step": 461
    },
    {
      "epoch": 1.7906976744186047,
      "grad_norm": 9.634416580200195,
      "learning_rate": 4.82093023255814e-05,
      "loss": 0.3937,
      "step": 462
    },
    {
      "epoch": 1.7945736434108528,
      "grad_norm": 0.3734533190727234,
      "learning_rate": 4.820542635658915e-05,
      "loss": 0.0052,
      "step": 463
    },
    {
      "epoch": 1.7984496124031009,
      "grad_norm": 2.554035186767578,
      "learning_rate": 4.82015503875969e-05,
      "loss": 0.0238,
      "step": 464
    },
    {
      "epoch": 1.802325581395349,
      "grad_norm": 0.11261093616485596,
      "learning_rate": 4.8197674418604655e-05,
      "loss": 0.0036,
      "step": 465
    },
    {
      "epoch": 1.806201550387597,
      "grad_norm": 5.249948978424072,
      "learning_rate": 4.819379844961241e-05,
      "loss": 0.02,
      "step": 466
    },
    {
      "epoch": 1.810077519379845,
      "grad_norm": 0.055764421820640564,
      "learning_rate": 4.818992248062016e-05,
      "loss": 0.0023,
      "step": 467
    },
    {
      "epoch": 1.8139534883720931,
      "grad_norm": 0.08237708359956741,
      "learning_rate": 4.8186046511627905e-05,
      "loss": 0.003,
      "step": 468
    },
    {
      "epoch": 1.8178294573643412,
      "grad_norm": 0.26589855551719666,
      "learning_rate": 4.8182170542635665e-05,
      "loss": 0.0053,
      "step": 469
    },
    {
      "epoch": 1.8217054263565893,
      "grad_norm": 6.616302967071533,
      "learning_rate": 4.817829457364341e-05,
      "loss": 0.0524,
      "step": 470
    },
    {
      "epoch": 1.8255813953488373,
      "grad_norm": 1.0380384922027588,
      "learning_rate": 4.817441860465117e-05,
      "loss": 0.0146,
      "step": 471
    },
    {
      "epoch": 1.8294573643410854,
      "grad_norm": 5.735818862915039,
      "learning_rate": 4.8170542635658915e-05,
      "loss": 0.631,
      "step": 472
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 0.34626808762550354,
      "learning_rate": 4.8166666666666674e-05,
      "loss": 0.0088,
      "step": 473
    },
    {
      "epoch": 1.8372093023255816,
      "grad_norm": 17.058624267578125,
      "learning_rate": 4.816279069767442e-05,
      "loss": 0.8908,
      "step": 474
    },
    {
      "epoch": 1.8410852713178296,
      "grad_norm": 9.135358810424805,
      "learning_rate": 4.815891472868217e-05,
      "loss": 0.4544,
      "step": 475
    },
    {
      "epoch": 1.8449612403100775,
      "grad_norm": 14.146099090576172,
      "learning_rate": 4.8155038759689925e-05,
      "loss": 1.3415,
      "step": 476
    },
    {
      "epoch": 1.8488372093023255,
      "grad_norm": 0.1380094289779663,
      "learning_rate": 4.815116279069768e-05,
      "loss": 0.0031,
      "step": 477
    },
    {
      "epoch": 1.8527131782945736,
      "grad_norm": 0.03338676318526268,
      "learning_rate": 4.814728682170543e-05,
      "loss": 0.0018,
      "step": 478
    },
    {
      "epoch": 1.8565891472868217,
      "grad_norm": 0.2197599709033966,
      "learning_rate": 4.814341085271318e-05,
      "loss": 0.004,
      "step": 479
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 0.1937342882156372,
      "learning_rate": 4.8139534883720934e-05,
      "loss": 0.0059,
      "step": 480
    },
    {
      "epoch": 1.8643410852713178,
      "grad_norm": 23.48685073852539,
      "learning_rate": 4.813565891472868e-05,
      "loss": 0.7711,
      "step": 481
    },
    {
      "epoch": 1.8682170542635659,
      "grad_norm": 23.390392303466797,
      "learning_rate": 4.813178294573644e-05,
      "loss": 0.4203,
      "step": 482
    },
    {
      "epoch": 1.872093023255814,
      "grad_norm": 22.7125244140625,
      "learning_rate": 4.8127906976744185e-05,
      "loss": 0.8607,
      "step": 483
    },
    {
      "epoch": 1.875968992248062,
      "grad_norm": 0.04838625714182854,
      "learning_rate": 4.8124031007751944e-05,
      "loss": 0.0027,
      "step": 484
    },
    {
      "epoch": 1.87984496124031,
      "grad_norm": 0.048687469214200974,
      "learning_rate": 4.812015503875969e-05,
      "loss": 0.0022,
      "step": 485
    },
    {
      "epoch": 1.8837209302325582,
      "grad_norm": 0.04110053926706314,
      "learning_rate": 4.811627906976744e-05,
      "loss": 0.0022,
      "step": 486
    },
    {
      "epoch": 1.8875968992248062,
      "grad_norm": 0.10343495011329651,
      "learning_rate": 4.8112403100775195e-05,
      "loss": 0.0039,
      "step": 487
    },
    {
      "epoch": 1.8914728682170543,
      "grad_norm": 0.05888994783163071,
      "learning_rate": 4.810852713178295e-05,
      "loss": 0.0028,
      "step": 488
    },
    {
      "epoch": 1.8953488372093024,
      "grad_norm": 0.19988706707954407,
      "learning_rate": 4.81046511627907e-05,
      "loss": 0.0039,
      "step": 489
    },
    {
      "epoch": 1.8992248062015504,
      "grad_norm": 0.14940446615219116,
      "learning_rate": 4.810077519379845e-05,
      "loss": 0.0034,
      "step": 490
    },
    {
      "epoch": 1.9031007751937985,
      "grad_norm": 45.62135314941406,
      "learning_rate": 4.8096899224806204e-05,
      "loss": 0.5879,
      "step": 491
    },
    {
      "epoch": 1.9069767441860463,
      "grad_norm": 4.039736747741699,
      "learning_rate": 4.809302325581396e-05,
      "loss": 0.3887,
      "step": 492
    },
    {
      "epoch": 1.9108527131782944,
      "grad_norm": 0.28260621428489685,
      "learning_rate": 4.808914728682171e-05,
      "loss": 0.0071,
      "step": 493
    },
    {
      "epoch": 1.9147286821705425,
      "grad_norm": 8.181218147277832,
      "learning_rate": 4.808527131782946e-05,
      "loss": 0.9508,
      "step": 494
    },
    {
      "epoch": 1.9186046511627906,
      "grad_norm": 0.25488361716270447,
      "learning_rate": 4.808139534883721e-05,
      "loss": 0.0038,
      "step": 495
    },
    {
      "epoch": 1.9224806201550386,
      "grad_norm": 4.29771614074707,
      "learning_rate": 4.8077519379844966e-05,
      "loss": 0.0849,
      "step": 496
    },
    {
      "epoch": 1.9263565891472867,
      "grad_norm": 0.06519221514463425,
      "learning_rate": 4.807364341085271e-05,
      "loss": 0.0026,
      "step": 497
    },
    {
      "epoch": 1.9302325581395348,
      "grad_norm": 9.38291072845459,
      "learning_rate": 4.806976744186047e-05,
      "loss": 0.1016,
      "step": 498
    },
    {
      "epoch": 1.9341085271317828,
      "grad_norm": 10.347794532775879,
      "learning_rate": 4.806589147286822e-05,
      "loss": 0.1953,
      "step": 499
    },
    {
      "epoch": 1.937984496124031,
      "grad_norm": 8.11950397491455,
      "learning_rate": 4.8062015503875976e-05,
      "loss": 0.3051,
      "step": 500
    },
    {
      "epoch": 1.941860465116279,
      "grad_norm": 9.95611572265625,
      "learning_rate": 4.805813953488372e-05,
      "loss": 0.3916,
      "step": 501
    },
    {
      "epoch": 1.945736434108527,
      "grad_norm": 4.353364944458008,
      "learning_rate": 4.805426356589148e-05,
      "loss": 0.2818,
      "step": 502
    },
    {
      "epoch": 1.949612403100775,
      "grad_norm": 4.1724958419799805,
      "learning_rate": 4.8050387596899227e-05,
      "loss": 0.064,
      "step": 503
    },
    {
      "epoch": 1.9534883720930232,
      "grad_norm": 0.4834252893924713,
      "learning_rate": 4.804651162790698e-05,
      "loss": 0.0111,
      "step": 504
    },
    {
      "epoch": 1.9573643410852712,
      "grad_norm": 1.3104493618011475,
      "learning_rate": 4.804263565891473e-05,
      "loss": 0.0052,
      "step": 505
    },
    {
      "epoch": 1.9612403100775193,
      "grad_norm": 0.22729207575321198,
      "learning_rate": 4.8038759689922484e-05,
      "loss": 0.0047,
      "step": 506
    },
    {
      "epoch": 1.9651162790697674,
      "grad_norm": 0.7695234417915344,
      "learning_rate": 4.8034883720930236e-05,
      "loss": 0.0222,
      "step": 507
    },
    {
      "epoch": 1.9689922480620154,
      "grad_norm": 6.6595635414123535,
      "learning_rate": 4.803100775193798e-05,
      "loss": 0.1853,
      "step": 508
    },
    {
      "epoch": 1.9728682170542635,
      "grad_norm": 1.2426406145095825,
      "learning_rate": 4.802713178294574e-05,
      "loss": 0.0148,
      "step": 509
    },
    {
      "epoch": 1.9767441860465116,
      "grad_norm": 1.5448143482208252,
      "learning_rate": 4.802325581395349e-05,
      "loss": 0.0251,
      "step": 510
    },
    {
      "epoch": 1.9806201550387597,
      "grad_norm": 0.3621924817562103,
      "learning_rate": 4.8019379844961246e-05,
      "loss": 0.0051,
      "step": 511
    },
    {
      "epoch": 1.9844961240310077,
      "grad_norm": 0.34867340326309204,
      "learning_rate": 4.801550387596899e-05,
      "loss": 0.0036,
      "step": 512
    },
    {
      "epoch": 1.9883720930232558,
      "grad_norm": 5.548105716705322,
      "learning_rate": 4.8011627906976744e-05,
      "loss": 0.422,
      "step": 513
    },
    {
      "epoch": 1.9922480620155039,
      "grad_norm": 0.04203525930643082,
      "learning_rate": 4.8007751937984496e-05,
      "loss": 0.0016,
      "step": 514
    },
    {
      "epoch": 1.996124031007752,
      "grad_norm": 0.016886427998542786,
      "learning_rate": 4.800387596899225e-05,
      "loss": 0.0013,
      "step": 515
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.10707172751426697,
      "learning_rate": 4.8e-05,
      "loss": 0.0015,
      "step": 516
    },
    {
      "epoch": 2.003875968992248,
      "grad_norm": 11.694976806640625,
      "learning_rate": 4.7996124031007754e-05,
      "loss": 1.1467,
      "step": 517
    },
    {
      "epoch": 2.007751937984496,
      "grad_norm": 0.03842238709330559,
      "learning_rate": 4.7992248062015506e-05,
      "loss": 0.0015,
      "step": 518
    },
    {
      "epoch": 2.011627906976744,
      "grad_norm": 0.04444650933146477,
      "learning_rate": 4.798837209302326e-05,
      "loss": 0.0016,
      "step": 519
    },
    {
      "epoch": 2.0155038759689923,
      "grad_norm": 1.793593406677246,
      "learning_rate": 4.798449612403101e-05,
      "loss": 0.0287,
      "step": 520
    },
    {
      "epoch": 2.0193798449612403,
      "grad_norm": 0.06251934915781021,
      "learning_rate": 4.798062015503876e-05,
      "loss": 0.0028,
      "step": 521
    },
    {
      "epoch": 2.0232558139534884,
      "grad_norm": 0.04889475554227829,
      "learning_rate": 4.7976744186046516e-05,
      "loss": 0.0022,
      "step": 522
    },
    {
      "epoch": 2.0271317829457365,
      "grad_norm": 0.3183971345424652,
      "learning_rate": 4.797286821705427e-05,
      "loss": 0.005,
      "step": 523
    },
    {
      "epoch": 2.0310077519379846,
      "grad_norm": 0.23216506838798523,
      "learning_rate": 4.7968992248062014e-05,
      "loss": 0.0022,
      "step": 524
    },
    {
      "epoch": 2.0348837209302326,
      "grad_norm": 0.027076903730630875,
      "learning_rate": 4.796511627906977e-05,
      "loss": 0.0014,
      "step": 525
    },
    {
      "epoch": 2.0387596899224807,
      "grad_norm": 24.776033401489258,
      "learning_rate": 4.796124031007752e-05,
      "loss": 0.7514,
      "step": 526
    },
    {
      "epoch": 2.0426356589147288,
      "grad_norm": 0.017095033079385757,
      "learning_rate": 4.795736434108528e-05,
      "loss": 0.0013,
      "step": 527
    },
    {
      "epoch": 2.046511627906977,
      "grad_norm": 1.4311449527740479,
      "learning_rate": 4.7953488372093023e-05,
      "loss": 0.0328,
      "step": 528
    },
    {
      "epoch": 2.050387596899225,
      "grad_norm": 0.01597471721470356,
      "learning_rate": 4.794961240310078e-05,
      "loss": 0.001,
      "step": 529
    },
    {
      "epoch": 2.054263565891473,
      "grad_norm": 13.813653945922852,
      "learning_rate": 4.794573643410853e-05,
      "loss": 0.0459,
      "step": 530
    },
    {
      "epoch": 2.058139534883721,
      "grad_norm": 0.01676708273589611,
      "learning_rate": 4.794186046511628e-05,
      "loss": 0.0013,
      "step": 531
    },
    {
      "epoch": 2.062015503875969,
      "grad_norm": 0.015011511743068695,
      "learning_rate": 4.793798449612403e-05,
      "loss": 0.0012,
      "step": 532
    },
    {
      "epoch": 2.065891472868217,
      "grad_norm": 0.012354323640465736,
      "learning_rate": 4.7934108527131786e-05,
      "loss": 0.0012,
      "step": 533
    },
    {
      "epoch": 2.0697674418604652,
      "grad_norm": 21.211978912353516,
      "learning_rate": 4.793023255813954e-05,
      "loss": 0.3058,
      "step": 534
    },
    {
      "epoch": 2.0736434108527133,
      "grad_norm": 3.6146390438079834,
      "learning_rate": 4.7926356589147284e-05,
      "loss": 0.0159,
      "step": 535
    },
    {
      "epoch": 2.0775193798449614,
      "grad_norm": 0.027086295187473297,
      "learning_rate": 4.792248062015504e-05,
      "loss": 0.0017,
      "step": 536
    },
    {
      "epoch": 2.0813953488372094,
      "grad_norm": 0.01886659674346447,
      "learning_rate": 4.791860465116279e-05,
      "loss": 0.0011,
      "step": 537
    },
    {
      "epoch": 2.0852713178294575,
      "grad_norm": 2.2379512786865234,
      "learning_rate": 4.791472868217055e-05,
      "loss": 0.249,
      "step": 538
    },
    {
      "epoch": 2.0891472868217056,
      "grad_norm": 4.138856887817383,
      "learning_rate": 4.791085271317829e-05,
      "loss": 0.4614,
      "step": 539
    },
    {
      "epoch": 2.0930232558139537,
      "grad_norm": 0.018003040924668312,
      "learning_rate": 4.790697674418605e-05,
      "loss": 0.0011,
      "step": 540
    },
    {
      "epoch": 2.0968992248062017,
      "grad_norm": 0.014738519676029682,
      "learning_rate": 4.79031007751938e-05,
      "loss": 0.0012,
      "step": 541
    },
    {
      "epoch": 2.10077519379845,
      "grad_norm": 0.6235677599906921,
      "learning_rate": 4.789922480620155e-05,
      "loss": 0.0081,
      "step": 542
    },
    {
      "epoch": 2.104651162790698,
      "grad_norm": 6.088737487792969,
      "learning_rate": 4.78953488372093e-05,
      "loss": 0.1281,
      "step": 543
    },
    {
      "epoch": 2.108527131782946,
      "grad_norm": 0.025047894567251205,
      "learning_rate": 4.7891472868217055e-05,
      "loss": 0.0016,
      "step": 544
    },
    {
      "epoch": 2.112403100775194,
      "grad_norm": 0.2646596133708954,
      "learning_rate": 4.788759689922481e-05,
      "loss": 0.0034,
      "step": 545
    },
    {
      "epoch": 2.116279069767442,
      "grad_norm": 0.07489413768053055,
      "learning_rate": 4.788372093023256e-05,
      "loss": 0.0019,
      "step": 546
    },
    {
      "epoch": 2.12015503875969,
      "grad_norm": 3.393834114074707,
      "learning_rate": 4.787984496124031e-05,
      "loss": 0.1254,
      "step": 547
    },
    {
      "epoch": 2.124031007751938,
      "grad_norm": 4.07564640045166,
      "learning_rate": 4.7875968992248065e-05,
      "loss": 0.0413,
      "step": 548
    },
    {
      "epoch": 2.1279069767441863,
      "grad_norm": 4.412267684936523,
      "learning_rate": 4.787209302325582e-05,
      "loss": 0.0134,
      "step": 549
    },
    {
      "epoch": 2.1317829457364343,
      "grad_norm": 0.0931975468993187,
      "learning_rate": 4.786821705426357e-05,
      "loss": 0.0017,
      "step": 550
    },
    {
      "epoch": 2.135658914728682,
      "grad_norm": 0.6055824160575867,
      "learning_rate": 4.786434108527132e-05,
      "loss": 0.0106,
      "step": 551
    },
    {
      "epoch": 2.13953488372093,
      "grad_norm": 0.12670119106769562,
      "learning_rate": 4.7860465116279075e-05,
      "loss": 0.0029,
      "step": 552
    },
    {
      "epoch": 2.143410852713178,
      "grad_norm": 0.04163765907287598,
      "learning_rate": 4.785658914728682e-05,
      "loss": 0.0015,
      "step": 553
    },
    {
      "epoch": 2.147286821705426,
      "grad_norm": 0.025897538289427757,
      "learning_rate": 4.785271317829458e-05,
      "loss": 0.0015,
      "step": 554
    },
    {
      "epoch": 2.1511627906976742,
      "grad_norm": 21.628355026245117,
      "learning_rate": 4.7848837209302325e-05,
      "loss": 0.4095,
      "step": 555
    },
    {
      "epoch": 2.1550387596899223,
      "grad_norm": 0.018367091193795204,
      "learning_rate": 4.7844961240310085e-05,
      "loss": 0.0013,
      "step": 556
    },
    {
      "epoch": 2.1589147286821704,
      "grad_norm": 0.03948173671960831,
      "learning_rate": 4.784108527131783e-05,
      "loss": 0.0018,
      "step": 557
    },
    {
      "epoch": 2.1627906976744184,
      "grad_norm": 5.503848075866699,
      "learning_rate": 4.783720930232559e-05,
      "loss": 0.9082,
      "step": 558
    },
    {
      "epoch": 2.1666666666666665,
      "grad_norm": 0.12050211429595947,
      "learning_rate": 4.7833333333333335e-05,
      "loss": 0.0029,
      "step": 559
    },
    {
      "epoch": 2.1705426356589146,
      "grad_norm": 0.03153517469763756,
      "learning_rate": 4.782945736434109e-05,
      "loss": 0.0015,
      "step": 560
    },
    {
      "epoch": 2.1744186046511627,
      "grad_norm": 0.33603134751319885,
      "learning_rate": 4.782558139534884e-05,
      "loss": 0.008,
      "step": 561
    },
    {
      "epoch": 2.1782945736434107,
      "grad_norm": 15.23031234741211,
      "learning_rate": 4.782170542635659e-05,
      "loss": 0.3509,
      "step": 562
    },
    {
      "epoch": 2.182170542635659,
      "grad_norm": 6.144242763519287,
      "learning_rate": 4.7817829457364345e-05,
      "loss": 0.0639,
      "step": 563
    },
    {
      "epoch": 2.186046511627907,
      "grad_norm": 15.501036643981934,
      "learning_rate": 4.781395348837209e-05,
      "loss": 0.2467,
      "step": 564
    },
    {
      "epoch": 2.189922480620155,
      "grad_norm": 24.556283950805664,
      "learning_rate": 4.781007751937985e-05,
      "loss": 0.3966,
      "step": 565
    },
    {
      "epoch": 2.193798449612403,
      "grad_norm": 6.723607063293457,
      "learning_rate": 4.7806201550387595e-05,
      "loss": 0.0536,
      "step": 566
    },
    {
      "epoch": 2.197674418604651,
      "grad_norm": 7.767771244049072,
      "learning_rate": 4.7802325581395354e-05,
      "loss": 0.7516,
      "step": 567
    },
    {
      "epoch": 2.201550387596899,
      "grad_norm": 1.9234843254089355,
      "learning_rate": 4.77984496124031e-05,
      "loss": 0.0439,
      "step": 568
    },
    {
      "epoch": 2.205426356589147,
      "grad_norm": 0.026549579575657845,
      "learning_rate": 4.779457364341086e-05,
      "loss": 0.0018,
      "step": 569
    },
    {
      "epoch": 2.2093023255813953,
      "grad_norm": 5.842739105224609,
      "learning_rate": 4.7790697674418605e-05,
      "loss": 0.2812,
      "step": 570
    },
    {
      "epoch": 2.2131782945736433,
      "grad_norm": 1.1611472368240356,
      "learning_rate": 4.778682170542636e-05,
      "loss": 0.0085,
      "step": 571
    },
    {
      "epoch": 2.2170542635658914,
      "grad_norm": 0.8593369722366333,
      "learning_rate": 4.778294573643411e-05,
      "loss": 0.0037,
      "step": 572
    },
    {
      "epoch": 2.2209302325581395,
      "grad_norm": 0.1703035533428192,
      "learning_rate": 4.777906976744186e-05,
      "loss": 0.0036,
      "step": 573
    },
    {
      "epoch": 2.2248062015503876,
      "grad_norm": 0.06938798725605011,
      "learning_rate": 4.7775193798449615e-05,
      "loss": 0.0024,
      "step": 574
    },
    {
      "epoch": 2.2286821705426356,
      "grad_norm": 0.034718867391347885,
      "learning_rate": 4.777131782945737e-05,
      "loss": 0.0019,
      "step": 575
    },
    {
      "epoch": 2.2325581395348837,
      "grad_norm": 0.12545102834701538,
      "learning_rate": 4.776744186046512e-05,
      "loss": 0.0033,
      "step": 576
    },
    {
      "epoch": 2.2364341085271318,
      "grad_norm": 0.048350390046834946,
      "learning_rate": 4.776356589147287e-05,
      "loss": 0.0019,
      "step": 577
    },
    {
      "epoch": 2.24031007751938,
      "grad_norm": 1.2589844465255737,
      "learning_rate": 4.7759689922480624e-05,
      "loss": 0.0121,
      "step": 578
    },
    {
      "epoch": 2.244186046511628,
      "grad_norm": 8.528929710388184,
      "learning_rate": 4.775581395348838e-05,
      "loss": 0.0541,
      "step": 579
    },
    {
      "epoch": 2.248062015503876,
      "grad_norm": 5.057423114776611,
      "learning_rate": 4.775193798449612e-05,
      "loss": 0.3006,
      "step": 580
    },
    {
      "epoch": 2.251937984496124,
      "grad_norm": 14.402583122253418,
      "learning_rate": 4.774806201550388e-05,
      "loss": 0.5516,
      "step": 581
    },
    {
      "epoch": 2.255813953488372,
      "grad_norm": 0.06747707724571228,
      "learning_rate": 4.774418604651163e-05,
      "loss": 0.0024,
      "step": 582
    },
    {
      "epoch": 2.25968992248062,
      "grad_norm": 0.016245054081082344,
      "learning_rate": 4.7740310077519386e-05,
      "loss": 0.0012,
      "step": 583
    },
    {
      "epoch": 2.2635658914728682,
      "grad_norm": 1.7928820848464966,
      "learning_rate": 4.773643410852713e-05,
      "loss": 0.0109,
      "step": 584
    },
    {
      "epoch": 2.2674418604651163,
      "grad_norm": 13.128660202026367,
      "learning_rate": 4.773255813953489e-05,
      "loss": 0.3063,
      "step": 585
    },
    {
      "epoch": 2.2713178294573644,
      "grad_norm": 0.021860959008336067,
      "learning_rate": 4.772868217054264e-05,
      "loss": 0.0013,
      "step": 586
    },
    {
      "epoch": 2.2751937984496124,
      "grad_norm": 0.017847705632448196,
      "learning_rate": 4.772480620155039e-05,
      "loss": 0.0014,
      "step": 587
    },
    {
      "epoch": 2.2790697674418605,
      "grad_norm": 3.61130428314209,
      "learning_rate": 4.772093023255814e-05,
      "loss": 0.2541,
      "step": 588
    },
    {
      "epoch": 2.2829457364341086,
      "grad_norm": 2.4307963848114014,
      "learning_rate": 4.7717054263565894e-05,
      "loss": 0.0349,
      "step": 589
    },
    {
      "epoch": 2.2868217054263567,
      "grad_norm": 0.1345854103565216,
      "learning_rate": 4.7713178294573647e-05,
      "loss": 0.0037,
      "step": 590
    },
    {
      "epoch": 2.2906976744186047,
      "grad_norm": 0.4271318018436432,
      "learning_rate": 4.770930232558139e-05,
      "loss": 0.0048,
      "step": 591
    },
    {
      "epoch": 2.294573643410853,
      "grad_norm": 0.03366014361381531,
      "learning_rate": 4.770542635658915e-05,
      "loss": 0.0017,
      "step": 592
    },
    {
      "epoch": 2.298449612403101,
      "grad_norm": 0.17319992184638977,
      "learning_rate": 4.77015503875969e-05,
      "loss": 0.0053,
      "step": 593
    },
    {
      "epoch": 2.302325581395349,
      "grad_norm": 5.6364665031433105,
      "learning_rate": 4.7697674418604656e-05,
      "loss": 0.178,
      "step": 594
    },
    {
      "epoch": 2.306201550387597,
      "grad_norm": 0.017714718356728554,
      "learning_rate": 4.76937984496124e-05,
      "loss": 0.0012,
      "step": 595
    },
    {
      "epoch": 2.310077519379845,
      "grad_norm": 0.02177458256483078,
      "learning_rate": 4.768992248062016e-05,
      "loss": 0.0014,
      "step": 596
    },
    {
      "epoch": 2.313953488372093,
      "grad_norm": 14.226314544677734,
      "learning_rate": 4.768604651162791e-05,
      "loss": 0.3435,
      "step": 597
    },
    {
      "epoch": 2.317829457364341,
      "grad_norm": 0.07765445113182068,
      "learning_rate": 4.768217054263566e-05,
      "loss": 0.002,
      "step": 598
    },
    {
      "epoch": 2.3217054263565893,
      "grad_norm": 0.03641148656606674,
      "learning_rate": 4.767829457364341e-05,
      "loss": 0.0021,
      "step": 599
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 0.19453318417072296,
      "learning_rate": 4.7674418604651164e-05,
      "loss": 0.0035,
      "step": 600
    },
    {
      "epoch": 2.3294573643410854,
      "grad_norm": 0.028272144496440887,
      "learning_rate": 4.7670542635658916e-05,
      "loss": 0.0013,
      "step": 601
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.104130320250988,
      "learning_rate": 4.766666666666667e-05,
      "loss": 0.0031,
      "step": 602
    },
    {
      "epoch": 2.3372093023255816,
      "grad_norm": 0.0767270177602768,
      "learning_rate": 4.766279069767442e-05,
      "loss": 0.0023,
      "step": 603
    },
    {
      "epoch": 2.3410852713178296,
      "grad_norm": 10.832473754882812,
      "learning_rate": 4.7658914728682174e-05,
      "loss": 0.027,
      "step": 604
    },
    {
      "epoch": 2.3449612403100777,
      "grad_norm": 0.7860339283943176,
      "learning_rate": 4.7655038759689926e-05,
      "loss": 0.0126,
      "step": 605
    },
    {
      "epoch": 2.3488372093023258,
      "grad_norm": 6.490811347961426,
      "learning_rate": 4.765116279069768e-05,
      "loss": 0.0394,
      "step": 606
    },
    {
      "epoch": 2.352713178294574,
      "grad_norm": 0.018731001764535904,
      "learning_rate": 4.764728682170543e-05,
      "loss": 0.0013,
      "step": 607
    },
    {
      "epoch": 2.356589147286822,
      "grad_norm": 86.68739318847656,
      "learning_rate": 4.764341085271318e-05,
      "loss": 0.2501,
      "step": 608
    },
    {
      "epoch": 2.3604651162790695,
      "grad_norm": 0.02548719383776188,
      "learning_rate": 4.763953488372093e-05,
      "loss": 0.0012,
      "step": 609
    },
    {
      "epoch": 2.3643410852713176,
      "grad_norm": 0.014181617647409439,
      "learning_rate": 4.763565891472869e-05,
      "loss": 0.0011,
      "step": 610
    },
    {
      "epoch": 2.3682170542635657,
      "grad_norm": 20.107559204101562,
      "learning_rate": 4.7631782945736434e-05,
      "loss": 0.1989,
      "step": 611
    },
    {
      "epoch": 2.3720930232558137,
      "grad_norm": 0.013234683312475681,
      "learning_rate": 4.762790697674419e-05,
      "loss": 0.0009,
      "step": 612
    },
    {
      "epoch": 2.375968992248062,
      "grad_norm": 0.4100876748561859,
      "learning_rate": 4.762403100775194e-05,
      "loss": 0.0076,
      "step": 613
    },
    {
      "epoch": 2.37984496124031,
      "grad_norm": 1.2800028324127197,
      "learning_rate": 4.762015503875969e-05,
      "loss": 0.0065,
      "step": 614
    },
    {
      "epoch": 2.383720930232558,
      "grad_norm": 0.10402634739875793,
      "learning_rate": 4.7616279069767444e-05,
      "loss": 0.0032,
      "step": 615
    },
    {
      "epoch": 2.387596899224806,
      "grad_norm": 0.014313730411231518,
      "learning_rate": 4.7612403100775196e-05,
      "loss": 0.0011,
      "step": 616
    },
    {
      "epoch": 2.391472868217054,
      "grad_norm": 0.02742396667599678,
      "learning_rate": 4.760852713178295e-05,
      "loss": 0.0014,
      "step": 617
    },
    {
      "epoch": 2.395348837209302,
      "grad_norm": 3.8860623836517334,
      "learning_rate": 4.76046511627907e-05,
      "loss": 0.0051,
      "step": 618
    },
    {
      "epoch": 2.39922480620155,
      "grad_norm": 0.012544161640107632,
      "learning_rate": 4.760077519379845e-05,
      "loss": 0.0009,
      "step": 619
    },
    {
      "epoch": 2.4031007751937983,
      "grad_norm": 45.29792785644531,
      "learning_rate": 4.75968992248062e-05,
      "loss": 0.0438,
      "step": 620
    },
    {
      "epoch": 2.4069767441860463,
      "grad_norm": 0.012730339542031288,
      "learning_rate": 4.759302325581396e-05,
      "loss": 0.0008,
      "step": 621
    },
    {
      "epoch": 2.4108527131782944,
      "grad_norm": 0.020764654502272606,
      "learning_rate": 4.7589147286821704e-05,
      "loss": 0.0015,
      "step": 622
    },
    {
      "epoch": 2.4147286821705425,
      "grad_norm": 0.008881410583853722,
      "learning_rate": 4.758527131782946e-05,
      "loss": 0.0009,
      "step": 623
    },
    {
      "epoch": 2.4186046511627906,
      "grad_norm": 3.7123405933380127,
      "learning_rate": 4.758139534883721e-05,
      "loss": 0.041,
      "step": 624
    },
    {
      "epoch": 2.4224806201550386,
      "grad_norm": 2.654566526412964,
      "learning_rate": 4.757751937984497e-05,
      "loss": 0.0029,
      "step": 625
    },
    {
      "epoch": 2.4263565891472867,
      "grad_norm": 0.011350210756063461,
      "learning_rate": 4.757364341085271e-05,
      "loss": 0.0008,
      "step": 626
    },
    {
      "epoch": 2.4302325581395348,
      "grad_norm": 0.026488563045859337,
      "learning_rate": 4.7569767441860466e-05,
      "loss": 0.0011,
      "step": 627
    },
    {
      "epoch": 2.434108527131783,
      "grad_norm": 0.2246178388595581,
      "learning_rate": 4.756589147286822e-05,
      "loss": 0.0065,
      "step": 628
    },
    {
      "epoch": 2.437984496124031,
      "grad_norm": 0.01360230427235365,
      "learning_rate": 4.756201550387597e-05,
      "loss": 0.0009,
      "step": 629
    },
    {
      "epoch": 2.441860465116279,
      "grad_norm": 0.011393958702683449,
      "learning_rate": 4.755813953488372e-05,
      "loss": 0.0009,
      "step": 630
    },
    {
      "epoch": 2.445736434108527,
      "grad_norm": 0.6813092827796936,
      "learning_rate": 4.7554263565891475e-05,
      "loss": 0.0054,
      "step": 631
    },
    {
      "epoch": 2.449612403100775,
      "grad_norm": 10.964561462402344,
      "learning_rate": 4.755038759689923e-05,
      "loss": 0.8325,
      "step": 632
    },
    {
      "epoch": 2.453488372093023,
      "grad_norm": 0.012194688431918621,
      "learning_rate": 4.754651162790698e-05,
      "loss": 0.0011,
      "step": 633
    },
    {
      "epoch": 2.4573643410852712,
      "grad_norm": 0.019808001816272736,
      "learning_rate": 4.754263565891473e-05,
      "loss": 0.0015,
      "step": 634
    },
    {
      "epoch": 2.4612403100775193,
      "grad_norm": 0.011904257349669933,
      "learning_rate": 4.7538759689922485e-05,
      "loss": 0.0009,
      "step": 635
    },
    {
      "epoch": 2.4651162790697674,
      "grad_norm": 0.011815592646598816,
      "learning_rate": 4.753488372093024e-05,
      "loss": 0.0009,
      "step": 636
    },
    {
      "epoch": 2.4689922480620154,
      "grad_norm": 0.10397857427597046,
      "learning_rate": 4.753100775193799e-05,
      "loss": 0.0039,
      "step": 637
    },
    {
      "epoch": 2.4728682170542635,
      "grad_norm": 0.010597864165902138,
      "learning_rate": 4.7527131782945736e-05,
      "loss": 0.0009,
      "step": 638
    },
    {
      "epoch": 2.4767441860465116,
      "grad_norm": 13.151955604553223,
      "learning_rate": 4.7523255813953495e-05,
      "loss": 0.316,
      "step": 639
    },
    {
      "epoch": 2.4806201550387597,
      "grad_norm": 0.43441128730773926,
      "learning_rate": 4.751937984496124e-05,
      "loss": 0.0027,
      "step": 640
    },
    {
      "epoch": 2.4844961240310077,
      "grad_norm": 23.531936645507812,
      "learning_rate": 4.751550387596899e-05,
      "loss": 0.7006,
      "step": 641
    },
    {
      "epoch": 2.488372093023256,
      "grad_norm": 0.023404691368341446,
      "learning_rate": 4.7511627906976745e-05,
      "loss": 0.0009,
      "step": 642
    },
    {
      "epoch": 2.492248062015504,
      "grad_norm": 11.472688674926758,
      "learning_rate": 4.75077519379845e-05,
      "loss": 0.1813,
      "step": 643
    },
    {
      "epoch": 2.496124031007752,
      "grad_norm": 0.04330171272158623,
      "learning_rate": 4.750387596899225e-05,
      "loss": 0.0021,
      "step": 644
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.7301478981971741,
      "learning_rate": 4.75e-05,
      "loss": 0.008,
      "step": 645
    },
    {
      "epoch": 2.503875968992248,
      "grad_norm": 0.16973085701465607,
      "learning_rate": 4.7496124031007755e-05,
      "loss": 0.0033,
      "step": 646
    },
    {
      "epoch": 2.507751937984496,
      "grad_norm": 0.025860430672764778,
      "learning_rate": 4.749224806201551e-05,
      "loss": 0.001,
      "step": 647
    },
    {
      "epoch": 2.511627906976744,
      "grad_norm": 0.08649224787950516,
      "learning_rate": 4.748837209302326e-05,
      "loss": 0.0017,
      "step": 648
    },
    {
      "epoch": 2.5155038759689923,
      "grad_norm": 7.3073811531066895,
      "learning_rate": 4.7484496124031006e-05,
      "loss": 0.2675,
      "step": 649
    },
    {
      "epoch": 2.5193798449612403,
      "grad_norm": 0.11310878396034241,
      "learning_rate": 4.7480620155038765e-05,
      "loss": 0.0016,
      "step": 650
    },
    {
      "epoch": 2.5232558139534884,
      "grad_norm": 0.12655548751354218,
      "learning_rate": 4.747674418604651e-05,
      "loss": 0.0033,
      "step": 651
    },
    {
      "epoch": 2.5271317829457365,
      "grad_norm": 37.32570266723633,
      "learning_rate": 4.747286821705427e-05,
      "loss": 0.5163,
      "step": 652
    },
    {
      "epoch": 2.5310077519379846,
      "grad_norm": 12.71884822845459,
      "learning_rate": 4.7468992248062015e-05,
      "loss": 0.768,
      "step": 653
    },
    {
      "epoch": 2.5348837209302326,
      "grad_norm": 0.28331702947616577,
      "learning_rate": 4.7465116279069774e-05,
      "loss": 0.0077,
      "step": 654
    },
    {
      "epoch": 2.5387596899224807,
      "grad_norm": 1.9795299768447876,
      "learning_rate": 4.746124031007752e-05,
      "loss": 0.0058,
      "step": 655
    },
    {
      "epoch": 2.5426356589147288,
      "grad_norm": 0.22288082540035248,
      "learning_rate": 4.745736434108527e-05,
      "loss": 0.0047,
      "step": 656
    },
    {
      "epoch": 2.546511627906977,
      "grad_norm": 0.018153533339500427,
      "learning_rate": 4.7453488372093025e-05,
      "loss": 0.0012,
      "step": 657
    },
    {
      "epoch": 2.550387596899225,
      "grad_norm": 1.0737849473953247,
      "learning_rate": 4.744961240310078e-05,
      "loss": 0.006,
      "step": 658
    },
    {
      "epoch": 2.554263565891473,
      "grad_norm": 12.446097373962402,
      "learning_rate": 4.744573643410853e-05,
      "loss": 1.4077,
      "step": 659
    },
    {
      "epoch": 2.558139534883721,
      "grad_norm": 0.007283015176653862,
      "learning_rate": 4.744186046511628e-05,
      "loss": 0.0004,
      "step": 660
    },
    {
      "epoch": 2.562015503875969,
      "grad_norm": 3.892739772796631,
      "learning_rate": 4.7437984496124035e-05,
      "loss": 0.0255,
      "step": 661
    },
    {
      "epoch": 2.565891472868217,
      "grad_norm": 0.03328968957066536,
      "learning_rate": 4.743410852713179e-05,
      "loss": 0.0012,
      "step": 662
    },
    {
      "epoch": 2.5697674418604652,
      "grad_norm": 0.3051656186580658,
      "learning_rate": 4.743023255813954e-05,
      "loss": 0.0051,
      "step": 663
    },
    {
      "epoch": 2.5736434108527133,
      "grad_norm": 7.445392608642578,
      "learning_rate": 4.742635658914729e-05,
      "loss": 0.088,
      "step": 664
    },
    {
      "epoch": 2.5775193798449614,
      "grad_norm": 2.4857017993927,
      "learning_rate": 4.7422480620155044e-05,
      "loss": 0.3463,
      "step": 665
    },
    {
      "epoch": 2.5813953488372094,
      "grad_norm": 0.34805920720100403,
      "learning_rate": 4.74186046511628e-05,
      "loss": 0.0025,
      "step": 666
    },
    {
      "epoch": 2.5852713178294575,
      "grad_norm": 0.02795979008078575,
      "learning_rate": 4.741472868217054e-05,
      "loss": 0.0008,
      "step": 667
    },
    {
      "epoch": 2.5891472868217056,
      "grad_norm": 16.51799774169922,
      "learning_rate": 4.7410852713178295e-05,
      "loss": 0.8161,
      "step": 668
    },
    {
      "epoch": 2.5930232558139537,
      "grad_norm": 2.923264741897583,
      "learning_rate": 4.740697674418605e-05,
      "loss": 0.0224,
      "step": 669
    },
    {
      "epoch": 2.5968992248062017,
      "grad_norm": 3.848855972290039,
      "learning_rate": 4.74031007751938e-05,
      "loss": 0.961,
      "step": 670
    },
    {
      "epoch": 2.60077519379845,
      "grad_norm": 0.21888846158981323,
      "learning_rate": 4.739922480620155e-05,
      "loss": 0.0043,
      "step": 671
    },
    {
      "epoch": 2.604651162790698,
      "grad_norm": 6.398387432098389,
      "learning_rate": 4.7395348837209304e-05,
      "loss": 0.6238,
      "step": 672
    },
    {
      "epoch": 2.608527131782946,
      "grad_norm": 1.0091748237609863,
      "learning_rate": 4.739147286821706e-05,
      "loss": 0.0108,
      "step": 673
    },
    {
      "epoch": 2.612403100775194,
      "grad_norm": 0.0241868756711483,
      "learning_rate": 4.738759689922481e-05,
      "loss": 0.0013,
      "step": 674
    },
    {
      "epoch": 2.616279069767442,
      "grad_norm": 0.04152163490653038,
      "learning_rate": 4.738372093023256e-05,
      "loss": 0.002,
      "step": 675
    },
    {
      "epoch": 2.62015503875969,
      "grad_norm": 0.0991230234503746,
      "learning_rate": 4.737984496124031e-05,
      "loss": 0.0035,
      "step": 676
    },
    {
      "epoch": 2.624031007751938,
      "grad_norm": 6.081089973449707,
      "learning_rate": 4.7375968992248067e-05,
      "loss": 0.066,
      "step": 677
    },
    {
      "epoch": 2.6279069767441863,
      "grad_norm": 0.121175117790699,
      "learning_rate": 4.737209302325581e-05,
      "loss": 0.004,
      "step": 678
    },
    {
      "epoch": 2.6317829457364343,
      "grad_norm": 25.83530044555664,
      "learning_rate": 4.736821705426357e-05,
      "loss": 0.4994,
      "step": 679
    },
    {
      "epoch": 2.6356589147286824,
      "grad_norm": 0.1738448590040207,
      "learning_rate": 4.736434108527132e-05,
      "loss": 0.0063,
      "step": 680
    },
    {
      "epoch": 2.6395348837209305,
      "grad_norm": 0.1549944132566452,
      "learning_rate": 4.7360465116279076e-05,
      "loss": 0.0051,
      "step": 681
    },
    {
      "epoch": 2.6434108527131785,
      "grad_norm": 0.11764094233512878,
      "learning_rate": 4.735658914728682e-05,
      "loss": 0.0038,
      "step": 682
    },
    {
      "epoch": 2.6472868217054266,
      "grad_norm": 6.676131248474121,
      "learning_rate": 4.7352713178294574e-05,
      "loss": 0.1293,
      "step": 683
    },
    {
      "epoch": 2.6511627906976747,
      "grad_norm": 18.128355026245117,
      "learning_rate": 4.734883720930233e-05,
      "loss": 0.0765,
      "step": 684
    },
    {
      "epoch": 2.6550387596899228,
      "grad_norm": 0.6826328635215759,
      "learning_rate": 4.734496124031008e-05,
      "loss": 0.0054,
      "step": 685
    },
    {
      "epoch": 2.6589147286821704,
      "grad_norm": 0.04263216629624367,
      "learning_rate": 4.734108527131783e-05,
      "loss": 0.0021,
      "step": 686
    },
    {
      "epoch": 2.6627906976744184,
      "grad_norm": 0.8726031184196472,
      "learning_rate": 4.7337209302325584e-05,
      "loss": 0.0067,
      "step": 687
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.06810860335826874,
      "learning_rate": 4.7333333333333336e-05,
      "loss": 0.0016,
      "step": 688
    },
    {
      "epoch": 2.6705426356589146,
      "grad_norm": 7.008254528045654,
      "learning_rate": 4.732945736434109e-05,
      "loss": 0.0297,
      "step": 689
    },
    {
      "epoch": 2.6744186046511627,
      "grad_norm": 20.82591438293457,
      "learning_rate": 4.732558139534884e-05,
      "loss": 0.8071,
      "step": 690
    },
    {
      "epoch": 2.6782945736434107,
      "grad_norm": 0.022111715748906136,
      "learning_rate": 4.7321705426356594e-05,
      "loss": 0.0012,
      "step": 691
    },
    {
      "epoch": 2.682170542635659,
      "grad_norm": 0.04310572147369385,
      "learning_rate": 4.7317829457364346e-05,
      "loss": 0.0016,
      "step": 692
    },
    {
      "epoch": 2.686046511627907,
      "grad_norm": 0.12233828008174896,
      "learning_rate": 4.731395348837209e-05,
      "loss": 0.0023,
      "step": 693
    },
    {
      "epoch": 2.689922480620155,
      "grad_norm": 0.018039004877209663,
      "learning_rate": 4.7310077519379844e-05,
      "loss": 0.0012,
      "step": 694
    },
    {
      "epoch": 2.693798449612403,
      "grad_norm": 14.169367790222168,
      "learning_rate": 4.7306201550387597e-05,
      "loss": 0.3091,
      "step": 695
    },
    {
      "epoch": 2.697674418604651,
      "grad_norm": 5.931276798248291,
      "learning_rate": 4.730232558139535e-05,
      "loss": 0.253,
      "step": 696
    },
    {
      "epoch": 2.701550387596899,
      "grad_norm": 0.6374189257621765,
      "learning_rate": 4.72984496124031e-05,
      "loss": 0.0112,
      "step": 697
    },
    {
      "epoch": 2.705426356589147,
      "grad_norm": 0.08475447446107864,
      "learning_rate": 4.7294573643410854e-05,
      "loss": 0.0023,
      "step": 698
    },
    {
      "epoch": 2.7093023255813953,
      "grad_norm": 13.1023588180542,
      "learning_rate": 4.7290697674418606e-05,
      "loss": 1.554,
      "step": 699
    },
    {
      "epoch": 2.7131782945736433,
      "grad_norm": 1.0023270845413208,
      "learning_rate": 4.728682170542636e-05,
      "loss": 0.0063,
      "step": 700
    },
    {
      "epoch": 2.7170542635658914,
      "grad_norm": 46.4594612121582,
      "learning_rate": 4.728294573643411e-05,
      "loss": 0.0872,
      "step": 701
    },
    {
      "epoch": 2.7209302325581395,
      "grad_norm": 10.553781509399414,
      "learning_rate": 4.7279069767441864e-05,
      "loss": 0.4635,
      "step": 702
    },
    {
      "epoch": 2.7248062015503876,
      "grad_norm": 0.022421281784772873,
      "learning_rate": 4.7275193798449616e-05,
      "loss": 0.0014,
      "step": 703
    },
    {
      "epoch": 2.7286821705426356,
      "grad_norm": 0.06021009758114815,
      "learning_rate": 4.727131782945737e-05,
      "loss": 0.0015,
      "step": 704
    },
    {
      "epoch": 2.7325581395348837,
      "grad_norm": 28.34360694885254,
      "learning_rate": 4.7267441860465114e-05,
      "loss": 0.0268,
      "step": 705
    },
    {
      "epoch": 2.7364341085271318,
      "grad_norm": 5.455530643463135,
      "learning_rate": 4.726356589147287e-05,
      "loss": 0.0408,
      "step": 706
    },
    {
      "epoch": 2.74031007751938,
      "grad_norm": 0.01638050749897957,
      "learning_rate": 4.725968992248062e-05,
      "loss": 0.0012,
      "step": 707
    },
    {
      "epoch": 2.744186046511628,
      "grad_norm": 0.01415978278964758,
      "learning_rate": 4.725581395348838e-05,
      "loss": 0.0011,
      "step": 708
    },
    {
      "epoch": 2.748062015503876,
      "grad_norm": 0.011121117509901524,
      "learning_rate": 4.7251937984496124e-05,
      "loss": 0.001,
      "step": 709
    },
    {
      "epoch": 2.751937984496124,
      "grad_norm": 2.31030011177063,
      "learning_rate": 4.724806201550388e-05,
      "loss": 0.0727,
      "step": 710
    },
    {
      "epoch": 2.755813953488372,
      "grad_norm": 0.021901439875364304,
      "learning_rate": 4.724418604651163e-05,
      "loss": 0.0012,
      "step": 711
    },
    {
      "epoch": 2.75968992248062,
      "grad_norm": 0.5575064420700073,
      "learning_rate": 4.724031007751938e-05,
      "loss": 0.0072,
      "step": 712
    },
    {
      "epoch": 2.7635658914728682,
      "grad_norm": 13.123795509338379,
      "learning_rate": 4.7236434108527133e-05,
      "loss": 1.7402,
      "step": 713
    },
    {
      "epoch": 2.7674418604651163,
      "grad_norm": 10.479844093322754,
      "learning_rate": 4.7232558139534886e-05,
      "loss": 0.5493,
      "step": 714
    },
    {
      "epoch": 2.7713178294573644,
      "grad_norm": 0.01488781813532114,
      "learning_rate": 4.722868217054264e-05,
      "loss": 0.001,
      "step": 715
    },
    {
      "epoch": 2.7751937984496124,
      "grad_norm": 0.09989316016435623,
      "learning_rate": 4.722480620155039e-05,
      "loss": 0.0022,
      "step": 716
    },
    {
      "epoch": 2.7790697674418605,
      "grad_norm": 0.15502604842185974,
      "learning_rate": 4.722093023255814e-05,
      "loss": 0.0042,
      "step": 717
    },
    {
      "epoch": 2.7829457364341086,
      "grad_norm": 3.0642526149749756,
      "learning_rate": 4.7217054263565896e-05,
      "loss": 0.4071,
      "step": 718
    },
    {
      "epoch": 2.7868217054263567,
      "grad_norm": 0.9416297674179077,
      "learning_rate": 4.721317829457365e-05,
      "loss": 0.0083,
      "step": 719
    },
    {
      "epoch": 2.7906976744186047,
      "grad_norm": 22.778398513793945,
      "learning_rate": 4.7209302325581394e-05,
      "loss": 0.0272,
      "step": 720
    },
    {
      "epoch": 2.794573643410853,
      "grad_norm": 0.21318084001541138,
      "learning_rate": 4.720542635658915e-05,
      "loss": 0.0063,
      "step": 721
    },
    {
      "epoch": 2.798449612403101,
      "grad_norm": 53.814186096191406,
      "learning_rate": 4.72015503875969e-05,
      "loss": 0.3252,
      "step": 722
    },
    {
      "epoch": 2.802325581395349,
      "grad_norm": 0.9739513993263245,
      "learning_rate": 4.719767441860465e-05,
      "loss": 0.0093,
      "step": 723
    },
    {
      "epoch": 2.806201550387597,
      "grad_norm": 6.483887672424316,
      "learning_rate": 4.71937984496124e-05,
      "loss": 0.3236,
      "step": 724
    },
    {
      "epoch": 2.810077519379845,
      "grad_norm": 1.6831389665603638,
      "learning_rate": 4.7189922480620156e-05,
      "loss": 0.0422,
      "step": 725
    },
    {
      "epoch": 2.813953488372093,
      "grad_norm": 10.188960075378418,
      "learning_rate": 4.718604651162791e-05,
      "loss": 0.341,
      "step": 726
    },
    {
      "epoch": 2.817829457364341,
      "grad_norm": 0.44750627875328064,
      "learning_rate": 4.718217054263566e-05,
      "loss": 0.0114,
      "step": 727
    },
    {
      "epoch": 2.8217054263565893,
      "grad_norm": 0.13531099259853363,
      "learning_rate": 4.717829457364341e-05,
      "loss": 0.0046,
      "step": 728
    },
    {
      "epoch": 2.8255813953488373,
      "grad_norm": 14.118817329406738,
      "learning_rate": 4.7174418604651165e-05,
      "loss": 0.2094,
      "step": 729
    },
    {
      "epoch": 2.8294573643410854,
      "grad_norm": 5.589913845062256,
      "learning_rate": 4.717054263565892e-05,
      "loss": 0.0342,
      "step": 730
    },
    {
      "epoch": 2.8333333333333335,
      "grad_norm": 0.8535629510879517,
      "learning_rate": 4.716666666666667e-05,
      "loss": 0.0134,
      "step": 731
    },
    {
      "epoch": 2.8372093023255816,
      "grad_norm": 0.05273403227329254,
      "learning_rate": 4.716279069767442e-05,
      "loss": 0.0019,
      "step": 732
    },
    {
      "epoch": 2.8410852713178296,
      "grad_norm": 0.04128725081682205,
      "learning_rate": 4.7158914728682175e-05,
      "loss": 0.0016,
      "step": 733
    },
    {
      "epoch": 2.8449612403100772,
      "grad_norm": 0.058774787932634354,
      "learning_rate": 4.715503875968992e-05,
      "loss": 0.0022,
      "step": 734
    },
    {
      "epoch": 2.8488372093023253,
      "grad_norm": 0.04369334876537323,
      "learning_rate": 4.715116279069768e-05,
      "loss": 0.0016,
      "step": 735
    },
    {
      "epoch": 2.8527131782945734,
      "grad_norm": 0.09263446182012558,
      "learning_rate": 4.7147286821705426e-05,
      "loss": 0.0015,
      "step": 736
    },
    {
      "epoch": 2.8565891472868215,
      "grad_norm": 0.01073611993342638,
      "learning_rate": 4.7143410852713185e-05,
      "loss": 0.001,
      "step": 737
    },
    {
      "epoch": 2.8604651162790695,
      "grad_norm": 13.438448905944824,
      "learning_rate": 4.713953488372093e-05,
      "loss": 0.5241,
      "step": 738
    },
    {
      "epoch": 2.8643410852713176,
      "grad_norm": 81.18487548828125,
      "learning_rate": 4.713565891472869e-05,
      "loss": 0.968,
      "step": 739
    },
    {
      "epoch": 2.8682170542635657,
      "grad_norm": 0.01406448520720005,
      "learning_rate": 4.7131782945736435e-05,
      "loss": 0.001,
      "step": 740
    },
    {
      "epoch": 2.8720930232558137,
      "grad_norm": 2.286710500717163,
      "learning_rate": 4.712790697674419e-05,
      "loss": 0.1607,
      "step": 741
    },
    {
      "epoch": 2.875968992248062,
      "grad_norm": 2.3871328830718994,
      "learning_rate": 4.712403100775194e-05,
      "loss": 0.2156,
      "step": 742
    },
    {
      "epoch": 2.87984496124031,
      "grad_norm": 0.034753214567899704,
      "learning_rate": 4.712015503875969e-05,
      "loss": 0.0014,
      "step": 743
    },
    {
      "epoch": 2.883720930232558,
      "grad_norm": 6.7466206550598145,
      "learning_rate": 4.7116279069767445e-05,
      "loss": 0.0352,
      "step": 744
    },
    {
      "epoch": 2.887596899224806,
      "grad_norm": 11.850481986999512,
      "learning_rate": 4.71124031007752e-05,
      "loss": 0.2132,
      "step": 745
    },
    {
      "epoch": 2.891472868217054,
      "grad_norm": 8.844478607177734,
      "learning_rate": 4.710852713178295e-05,
      "loss": 0.0353,
      "step": 746
    },
    {
      "epoch": 2.895348837209302,
      "grad_norm": 5.502770900726318,
      "learning_rate": 4.7104651162790695e-05,
      "loss": 0.0153,
      "step": 747
    },
    {
      "epoch": 2.89922480620155,
      "grad_norm": 1.1147723197937012,
      "learning_rate": 4.7100775193798455e-05,
      "loss": 0.0354,
      "step": 748
    },
    {
      "epoch": 2.9031007751937983,
      "grad_norm": 1.1505351066589355,
      "learning_rate": 4.70968992248062e-05,
      "loss": 0.0045,
      "step": 749
    },
    {
      "epoch": 2.9069767441860463,
      "grad_norm": 29.256622314453125,
      "learning_rate": 4.709302325581396e-05,
      "loss": 0.1329,
      "step": 750
    },
    {
      "epoch": 2.9108527131782944,
      "grad_norm": 0.4539623558521271,
      "learning_rate": 4.7089147286821705e-05,
      "loss": 0.0128,
      "step": 751
    },
    {
      "epoch": 2.9147286821705425,
      "grad_norm": 0.058650385588407516,
      "learning_rate": 4.708527131782946e-05,
      "loss": 0.0015,
      "step": 752
    },
    {
      "epoch": 2.9186046511627906,
      "grad_norm": 9.668570518493652,
      "learning_rate": 4.708139534883721e-05,
      "loss": 0.3918,
      "step": 753
    },
    {
      "epoch": 2.9224806201550386,
      "grad_norm": 21.247337341308594,
      "learning_rate": 4.707751937984496e-05,
      "loss": 0.0404,
      "step": 754
    },
    {
      "epoch": 2.9263565891472867,
      "grad_norm": 3.575467348098755,
      "learning_rate": 4.7073643410852715e-05,
      "loss": 0.0442,
      "step": 755
    },
    {
      "epoch": 2.9302325581395348,
      "grad_norm": 0.20419810712337494,
      "learning_rate": 4.706976744186047e-05,
      "loss": 0.0072,
      "step": 756
    },
    {
      "epoch": 2.934108527131783,
      "grad_norm": 2.155090570449829,
      "learning_rate": 4.706589147286822e-05,
      "loss": 0.0097,
      "step": 757
    },
    {
      "epoch": 2.937984496124031,
      "grad_norm": 0.38174039125442505,
      "learning_rate": 4.706201550387597e-05,
      "loss": 0.0094,
      "step": 758
    },
    {
      "epoch": 2.941860465116279,
      "grad_norm": 0.055791646242141724,
      "learning_rate": 4.7058139534883724e-05,
      "loss": 0.0015,
      "step": 759
    },
    {
      "epoch": 2.945736434108527,
      "grad_norm": 29.180500030517578,
      "learning_rate": 4.705426356589148e-05,
      "loss": 1.4512,
      "step": 760
    },
    {
      "epoch": 2.949612403100775,
      "grad_norm": 0.02213297411799431,
      "learning_rate": 4.705038759689922e-05,
      "loss": 0.0012,
      "step": 761
    },
    {
      "epoch": 2.953488372093023,
      "grad_norm": 7.240423202514648,
      "learning_rate": 4.704651162790698e-05,
      "loss": 0.1974,
      "step": 762
    },
    {
      "epoch": 2.9573643410852712,
      "grad_norm": 0.0862002745270729,
      "learning_rate": 4.704263565891473e-05,
      "loss": 0.0029,
      "step": 763
    },
    {
      "epoch": 2.9612403100775193,
      "grad_norm": 9.391178131103516,
      "learning_rate": 4.7038759689922487e-05,
      "loss": 0.2587,
      "step": 764
    },
    {
      "epoch": 2.9651162790697674,
      "grad_norm": 19.975658416748047,
      "learning_rate": 4.703488372093023e-05,
      "loss": 0.3695,
      "step": 765
    },
    {
      "epoch": 2.9689922480620154,
      "grad_norm": 0.4096110761165619,
      "learning_rate": 4.703100775193799e-05,
      "loss": 0.0115,
      "step": 766
    },
    {
      "epoch": 2.9728682170542635,
      "grad_norm": 64.08584594726562,
      "learning_rate": 4.702713178294574e-05,
      "loss": 0.6484,
      "step": 767
    },
    {
      "epoch": 2.9767441860465116,
      "grad_norm": 11.926641464233398,
      "learning_rate": 4.7023255813953496e-05,
      "loss": 0.111,
      "step": 768
    },
    {
      "epoch": 2.9806201550387597,
      "grad_norm": 9.15672492980957,
      "learning_rate": 4.701937984496124e-05,
      "loss": 0.5072,
      "step": 769
    },
    {
      "epoch": 2.9844961240310077,
      "grad_norm": 0.1436379998922348,
      "learning_rate": 4.7015503875968994e-05,
      "loss": 0.0012,
      "step": 770
    },
    {
      "epoch": 2.988372093023256,
      "grad_norm": 0.029244521632790565,
      "learning_rate": 4.701162790697675e-05,
      "loss": 0.0015,
      "step": 771
    },
    {
      "epoch": 2.992248062015504,
      "grad_norm": 0.058106679469347,
      "learning_rate": 4.70077519379845e-05,
      "loss": 0.0022,
      "step": 772
    },
    {
      "epoch": 2.996124031007752,
      "grad_norm": 6.3132548332214355,
      "learning_rate": 4.700387596899225e-05,
      "loss": 0.0371,
      "step": 773
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.5860494375228882,
      "learning_rate": 4.7e-05,
      "loss": 0.0109,
      "step": 774
    },
    {
      "epoch": 3.003875968992248,
      "grad_norm": 0.8623790144920349,
      "learning_rate": 4.6996124031007756e-05,
      "loss": 0.0039,
      "step": 775
    },
    {
      "epoch": 3.007751937984496,
      "grad_norm": 0.07692942768335342,
      "learning_rate": 4.69922480620155e-05,
      "loss": 0.0023,
      "step": 776
    },
    {
      "epoch": 3.011627906976744,
      "grad_norm": 0.018077963963150978,
      "learning_rate": 4.698837209302326e-05,
      "loss": 0.0012,
      "step": 777
    },
    {
      "epoch": 3.0155038759689923,
      "grad_norm": 0.793308436870575,
      "learning_rate": 4.698449612403101e-05,
      "loss": 0.0048,
      "step": 778
    },
    {
      "epoch": 3.0193798449612403,
      "grad_norm": 9.802107810974121,
      "learning_rate": 4.698062015503876e-05,
      "loss": 0.1047,
      "step": 779
    },
    {
      "epoch": 3.0232558139534884,
      "grad_norm": 0.1216052696108818,
      "learning_rate": 4.697674418604651e-05,
      "loss": 0.0039,
      "step": 780
    },
    {
      "epoch": 3.0271317829457365,
      "grad_norm": 0.059810034930706024,
      "learning_rate": 4.6972868217054264e-05,
      "loss": 0.0015,
      "step": 781
    },
    {
      "epoch": 3.0310077519379846,
      "grad_norm": 3.77724289894104,
      "learning_rate": 4.6968992248062017e-05,
      "loss": 0.0864,
      "step": 782
    },
    {
      "epoch": 3.0348837209302326,
      "grad_norm": 26.909374237060547,
      "learning_rate": 4.696511627906977e-05,
      "loss": 0.2888,
      "step": 783
    },
    {
      "epoch": 3.0387596899224807,
      "grad_norm": 0.5113133788108826,
      "learning_rate": 4.696124031007752e-05,
      "loss": 0.0034,
      "step": 784
    },
    {
      "epoch": 3.0426356589147288,
      "grad_norm": 0.02163320779800415,
      "learning_rate": 4.6957364341085274e-05,
      "loss": 0.0009,
      "step": 785
    },
    {
      "epoch": 3.046511627906977,
      "grad_norm": 0.0839185044169426,
      "learning_rate": 4.6953488372093026e-05,
      "loss": 0.0019,
      "step": 786
    },
    {
      "epoch": 3.050387596899225,
      "grad_norm": 0.014619283378124237,
      "learning_rate": 4.694961240310078e-05,
      "loss": 0.001,
      "step": 787
    },
    {
      "epoch": 3.054263565891473,
      "grad_norm": 0.2940784990787506,
      "learning_rate": 4.694573643410853e-05,
      "loss": 0.0031,
      "step": 788
    },
    {
      "epoch": 3.058139534883721,
      "grad_norm": 0.03673214465379715,
      "learning_rate": 4.6941860465116284e-05,
      "loss": 0.0013,
      "step": 789
    },
    {
      "epoch": 3.062015503875969,
      "grad_norm": 0.07057037949562073,
      "learning_rate": 4.693798449612403e-05,
      "loss": 0.0028,
      "step": 790
    },
    {
      "epoch": 3.065891472868217,
      "grad_norm": 0.13409461081027985,
      "learning_rate": 4.693410852713179e-05,
      "loss": 0.0042,
      "step": 791
    },
    {
      "epoch": 3.0697674418604652,
      "grad_norm": 14.663955688476562,
      "learning_rate": 4.6930232558139534e-05,
      "loss": 0.252,
      "step": 792
    },
    {
      "epoch": 3.0736434108527133,
      "grad_norm": 0.01654435694217682,
      "learning_rate": 4.692635658914729e-05,
      "loss": 0.0011,
      "step": 793
    },
    {
      "epoch": 3.0775193798449614,
      "grad_norm": 0.29501715302467346,
      "learning_rate": 4.692248062015504e-05,
      "loss": 0.0017,
      "step": 794
    },
    {
      "epoch": 3.0813953488372094,
      "grad_norm": 0.051011331379413605,
      "learning_rate": 4.69186046511628e-05,
      "loss": 0.0013,
      "step": 795
    },
    {
      "epoch": 3.0852713178294575,
      "grad_norm": 8.208465576171875,
      "learning_rate": 4.6914728682170544e-05,
      "loss": 0.019,
      "step": 796
    },
    {
      "epoch": 3.0891472868217056,
      "grad_norm": 0.02094164490699768,
      "learning_rate": 4.6910852713178296e-05,
      "loss": 0.0011,
      "step": 797
    },
    {
      "epoch": 3.0930232558139537,
      "grad_norm": 0.010369468480348587,
      "learning_rate": 4.690697674418605e-05,
      "loss": 0.0009,
      "step": 798
    },
    {
      "epoch": 3.0968992248062017,
      "grad_norm": 15.085713386535645,
      "learning_rate": 4.69031007751938e-05,
      "loss": 0.1578,
      "step": 799
    },
    {
      "epoch": 3.10077519379845,
      "grad_norm": 0.015295518562197685,
      "learning_rate": 4.6899224806201553e-05,
      "loss": 0.0008,
      "step": 800
    },
    {
      "epoch": 3.104651162790698,
      "grad_norm": 0.014182185754179955,
      "learning_rate": 4.68953488372093e-05,
      "loss": 0.001,
      "step": 801
    },
    {
      "epoch": 3.108527131782946,
      "grad_norm": 1.1979764699935913,
      "learning_rate": 4.689147286821706e-05,
      "loss": 0.0037,
      "step": 802
    },
    {
      "epoch": 3.112403100775194,
      "grad_norm": 7.586402416229248,
      "learning_rate": 4.6887596899224804e-05,
      "loss": 0.0417,
      "step": 803
    },
    {
      "epoch": 3.116279069767442,
      "grad_norm": 4.54583215713501,
      "learning_rate": 4.688372093023256e-05,
      "loss": 0.0569,
      "step": 804
    },
    {
      "epoch": 3.12015503875969,
      "grad_norm": 10.70837116241455,
      "learning_rate": 4.687984496124031e-05,
      "loss": 0.4084,
      "step": 805
    },
    {
      "epoch": 3.124031007751938,
      "grad_norm": 15.011202812194824,
      "learning_rate": 4.687596899224807e-05,
      "loss": 0.457,
      "step": 806
    },
    {
      "epoch": 3.1279069767441863,
      "grad_norm": 24.88160514831543,
      "learning_rate": 4.6872093023255814e-05,
      "loss": 0.8751,
      "step": 807
    },
    {
      "epoch": 3.1317829457364343,
      "grad_norm": 0.6952677965164185,
      "learning_rate": 4.6868217054263566e-05,
      "loss": 0.0054,
      "step": 808
    },
    {
      "epoch": 3.135658914728682,
      "grad_norm": 0.054705195128917694,
      "learning_rate": 4.686434108527132e-05,
      "loss": 0.001,
      "step": 809
    },
    {
      "epoch": 3.13953488372093,
      "grad_norm": 0.06601244956254959,
      "learning_rate": 4.686046511627907e-05,
      "loss": 0.0011,
      "step": 810
    },
    {
      "epoch": 3.143410852713178,
      "grad_norm": 0.01012441422790289,
      "learning_rate": 4.685658914728682e-05,
      "loss": 0.0008,
      "step": 811
    },
    {
      "epoch": 3.147286821705426,
      "grad_norm": 9.832378387451172,
      "learning_rate": 4.6852713178294576e-05,
      "loss": 0.2001,
      "step": 812
    },
    {
      "epoch": 3.1511627906976742,
      "grad_norm": 2.513763189315796,
      "learning_rate": 4.684883720930233e-05,
      "loss": 0.0196,
      "step": 813
    },
    {
      "epoch": 3.1550387596899223,
      "grad_norm": 0.11043836176395416,
      "learning_rate": 4.684496124031008e-05,
      "loss": 0.0014,
      "step": 814
    },
    {
      "epoch": 3.1589147286821704,
      "grad_norm": 0.06648337095975876,
      "learning_rate": 4.684108527131783e-05,
      "loss": 0.0015,
      "step": 815
    },
    {
      "epoch": 3.1627906976744184,
      "grad_norm": 0.07525386661291122,
      "learning_rate": 4.6837209302325585e-05,
      "loss": 0.0013,
      "step": 816
    },
    {
      "epoch": 3.1666666666666665,
      "grad_norm": 16.181791305541992,
      "learning_rate": 4.683333333333334e-05,
      "loss": 0.1047,
      "step": 817
    },
    {
      "epoch": 3.1705426356589146,
      "grad_norm": 0.18283312022686005,
      "learning_rate": 4.682945736434109e-05,
      "loss": 0.002,
      "step": 818
    },
    {
      "epoch": 3.1744186046511627,
      "grad_norm": 0.16302132606506348,
      "learning_rate": 4.6825581395348836e-05,
      "loss": 0.0015,
      "step": 819
    },
    {
      "epoch": 3.1782945736434107,
      "grad_norm": 0.057230256497859955,
      "learning_rate": 4.6821705426356595e-05,
      "loss": 0.0012,
      "step": 820
    },
    {
      "epoch": 3.182170542635659,
      "grad_norm": 0.03327612578868866,
      "learning_rate": 4.681782945736434e-05,
      "loss": 0.0009,
      "step": 821
    },
    {
      "epoch": 3.186046511627907,
      "grad_norm": 5.285333156585693,
      "learning_rate": 4.68139534883721e-05,
      "loss": 0.1266,
      "step": 822
    },
    {
      "epoch": 3.189922480620155,
      "grad_norm": 18.167085647583008,
      "learning_rate": 4.6810077519379846e-05,
      "loss": 0.4367,
      "step": 823
    },
    {
      "epoch": 3.193798449612403,
      "grad_norm": 4.610986232757568,
      "learning_rate": 4.6806201550387605e-05,
      "loss": 0.3944,
      "step": 824
    },
    {
      "epoch": 3.197674418604651,
      "grad_norm": 0.5411829948425293,
      "learning_rate": 4.680232558139535e-05,
      "loss": 0.0023,
      "step": 825
    },
    {
      "epoch": 3.201550387596899,
      "grad_norm": 0.009309029206633568,
      "learning_rate": 4.67984496124031e-05,
      "loss": 0.0009,
      "step": 826
    },
    {
      "epoch": 3.205426356589147,
      "grad_norm": 0.011581950820982456,
      "learning_rate": 4.6794573643410855e-05,
      "loss": 0.0008,
      "step": 827
    },
    {
      "epoch": 3.2093023255813953,
      "grad_norm": 180.91275024414062,
      "learning_rate": 4.679069767441861e-05,
      "loss": 1.599,
      "step": 828
    },
    {
      "epoch": 3.2131782945736433,
      "grad_norm": 2.929210901260376,
      "learning_rate": 4.678682170542636e-05,
      "loss": 0.1087,
      "step": 829
    },
    {
      "epoch": 3.2170542635658914,
      "grad_norm": 27.249065399169922,
      "learning_rate": 4.6782945736434106e-05,
      "loss": 0.3652,
      "step": 830
    },
    {
      "epoch": 3.2209302325581395,
      "grad_norm": 38.489192962646484,
      "learning_rate": 4.6779069767441865e-05,
      "loss": 0.115,
      "step": 831
    },
    {
      "epoch": 3.2248062015503876,
      "grad_norm": 4.840194225311279,
      "learning_rate": 4.677519379844961e-05,
      "loss": 0.0192,
      "step": 832
    },
    {
      "epoch": 3.2286821705426356,
      "grad_norm": 1.1804237365722656,
      "learning_rate": 4.677131782945737e-05,
      "loss": 0.0201,
      "step": 833
    },
    {
      "epoch": 3.2325581395348837,
      "grad_norm": 0.9192288517951965,
      "learning_rate": 4.6767441860465115e-05,
      "loss": 0.0053,
      "step": 834
    },
    {
      "epoch": 3.2364341085271318,
      "grad_norm": 10.577096939086914,
      "learning_rate": 4.6763565891472875e-05,
      "loss": 0.9683,
      "step": 835
    },
    {
      "epoch": 3.24031007751938,
      "grad_norm": 0.07840564101934433,
      "learning_rate": 4.675968992248062e-05,
      "loss": 0.0019,
      "step": 836
    },
    {
      "epoch": 3.244186046511628,
      "grad_norm": 0.019206583499908447,
      "learning_rate": 4.675581395348837e-05,
      "loss": 0.0011,
      "step": 837
    },
    {
      "epoch": 3.248062015503876,
      "grad_norm": 1.5534226894378662,
      "learning_rate": 4.6751937984496125e-05,
      "loss": 0.0224,
      "step": 838
    },
    {
      "epoch": 3.251937984496124,
      "grad_norm": 50.613948822021484,
      "learning_rate": 4.674806201550388e-05,
      "loss": 1.2672,
      "step": 839
    },
    {
      "epoch": 3.255813953488372,
      "grad_norm": 46.38253402709961,
      "learning_rate": 4.674418604651163e-05,
      "loss": 0.1189,
      "step": 840
    },
    {
      "epoch": 3.25968992248062,
      "grad_norm": 10.688618659973145,
      "learning_rate": 4.674031007751938e-05,
      "loss": 0.473,
      "step": 841
    },
    {
      "epoch": 3.2635658914728682,
      "grad_norm": 9.892354965209961,
      "learning_rate": 4.6736434108527135e-05,
      "loss": 0.0965,
      "step": 842
    },
    {
      "epoch": 3.2674418604651163,
      "grad_norm": 0.03370816633105278,
      "learning_rate": 4.673255813953489e-05,
      "loss": 0.0014,
      "step": 843
    },
    {
      "epoch": 3.2713178294573644,
      "grad_norm": 0.7463156580924988,
      "learning_rate": 4.672868217054264e-05,
      "loss": 0.0056,
      "step": 844
    },
    {
      "epoch": 3.2751937984496124,
      "grad_norm": 15.373685836791992,
      "learning_rate": 4.672480620155039e-05,
      "loss": 0.1213,
      "step": 845
    },
    {
      "epoch": 3.2790697674418605,
      "grad_norm": 0.0743514746427536,
      "learning_rate": 4.672093023255814e-05,
      "loss": 0.0032,
      "step": 846
    },
    {
      "epoch": 3.2829457364341086,
      "grad_norm": 1.5101741552352905,
      "learning_rate": 4.67170542635659e-05,
      "loss": 0.0062,
      "step": 847
    },
    {
      "epoch": 3.2868217054263567,
      "grad_norm": 0.14606310427188873,
      "learning_rate": 4.671317829457364e-05,
      "loss": 0.0038,
      "step": 848
    },
    {
      "epoch": 3.2906976744186047,
      "grad_norm": 5.358242988586426,
      "learning_rate": 4.67093023255814e-05,
      "loss": 0.1688,
      "step": 849
    },
    {
      "epoch": 3.294573643410853,
      "grad_norm": 0.6841228008270264,
      "learning_rate": 4.670542635658915e-05,
      "loss": 0.0072,
      "step": 850
    },
    {
      "epoch": 3.298449612403101,
      "grad_norm": 25.496469497680664,
      "learning_rate": 4.6701550387596907e-05,
      "loss": 0.2589,
      "step": 851
    },
    {
      "epoch": 3.302325581395349,
      "grad_norm": 13.278011322021484,
      "learning_rate": 4.669767441860465e-05,
      "loss": 0.2463,
      "step": 852
    },
    {
      "epoch": 3.306201550387597,
      "grad_norm": 0.0561901293694973,
      "learning_rate": 4.6693798449612405e-05,
      "loss": 0.002,
      "step": 853
    },
    {
      "epoch": 3.310077519379845,
      "grad_norm": 7.20294189453125,
      "learning_rate": 4.668992248062016e-05,
      "loss": 0.022,
      "step": 854
    },
    {
      "epoch": 3.313953488372093,
      "grad_norm": 0.01714216358959675,
      "learning_rate": 4.668604651162791e-05,
      "loss": 0.0011,
      "step": 855
    },
    {
      "epoch": 3.317829457364341,
      "grad_norm": 0.021867912262678146,
      "learning_rate": 4.668217054263566e-05,
      "loss": 0.0013,
      "step": 856
    },
    {
      "epoch": 3.3217054263565893,
      "grad_norm": 1.164422869682312,
      "learning_rate": 4.667829457364341e-05,
      "loss": 0.1245,
      "step": 857
    },
    {
      "epoch": 3.3255813953488373,
      "grad_norm": 0.02695322036743164,
      "learning_rate": 4.667441860465117e-05,
      "loss": 0.0013,
      "step": 858
    },
    {
      "epoch": 3.3294573643410854,
      "grad_norm": 14.035879135131836,
      "learning_rate": 4.667054263565891e-05,
      "loss": 0.0672,
      "step": 859
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 170.32595825195312,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.8968,
      "step": 860
    },
    {
      "epoch": 3.3372093023255816,
      "grad_norm": 33.94546890258789,
      "learning_rate": 4.666279069767442e-05,
      "loss": 1.0013,
      "step": 861
    },
    {
      "epoch": 3.3410852713178296,
      "grad_norm": 11.570001602172852,
      "learning_rate": 4.6658914728682176e-05,
      "loss": 0.5968,
      "step": 862
    },
    {
      "epoch": 3.3449612403100777,
      "grad_norm": 0.03607526049017906,
      "learning_rate": 4.665503875968992e-05,
      "loss": 0.0014,
      "step": 863
    },
    {
      "epoch": 3.3488372093023258,
      "grad_norm": 0.6279116868972778,
      "learning_rate": 4.6651162790697675e-05,
      "loss": 0.0027,
      "step": 864
    },
    {
      "epoch": 3.352713178294574,
      "grad_norm": 7.827648162841797,
      "learning_rate": 4.664728682170543e-05,
      "loss": 0.041,
      "step": 865
    },
    {
      "epoch": 3.356589147286822,
      "grad_norm": 3.4455020427703857,
      "learning_rate": 4.664341085271318e-05,
      "loss": 0.108,
      "step": 866
    },
    {
      "epoch": 3.3604651162790695,
      "grad_norm": 0.014229713007807732,
      "learning_rate": 4.663953488372093e-05,
      "loss": 0.001,
      "step": 867
    },
    {
      "epoch": 3.3643410852713176,
      "grad_norm": 0.09669867157936096,
      "learning_rate": 4.6635658914728684e-05,
      "loss": 0.0014,
      "step": 868
    },
    {
      "epoch": 3.3682170542635657,
      "grad_norm": 0.022398579865694046,
      "learning_rate": 4.663178294573644e-05,
      "loss": 0.0013,
      "step": 869
    },
    {
      "epoch": 3.3720930232558137,
      "grad_norm": 0.029455682262778282,
      "learning_rate": 4.662790697674419e-05,
      "loss": 0.0012,
      "step": 870
    },
    {
      "epoch": 3.375968992248062,
      "grad_norm": 11.565709114074707,
      "learning_rate": 4.662403100775194e-05,
      "loss": 0.0105,
      "step": 871
    },
    {
      "epoch": 3.37984496124031,
      "grad_norm": 0.010032923892140388,
      "learning_rate": 4.6620155038759694e-05,
      "loss": 0.0009,
      "step": 872
    },
    {
      "epoch": 3.383720930232558,
      "grad_norm": 0.2630246877670288,
      "learning_rate": 4.6616279069767446e-05,
      "loss": 0.0034,
      "step": 873
    },
    {
      "epoch": 3.387596899224806,
      "grad_norm": 7.328741550445557,
      "learning_rate": 4.66124031007752e-05,
      "loss": 0.4618,
      "step": 874
    },
    {
      "epoch": 3.391472868217054,
      "grad_norm": 23.16428565979004,
      "learning_rate": 4.6608527131782944e-05,
      "loss": 0.1602,
      "step": 875
    },
    {
      "epoch": 3.395348837209302,
      "grad_norm": 6.228066444396973,
      "learning_rate": 4.6604651162790704e-05,
      "loss": 0.332,
      "step": 876
    },
    {
      "epoch": 3.39922480620155,
      "grad_norm": 1.7548078298568726,
      "learning_rate": 4.660077519379845e-05,
      "loss": 0.157,
      "step": 877
    },
    {
      "epoch": 3.4031007751937983,
      "grad_norm": 30.55132484436035,
      "learning_rate": 4.659689922480621e-05,
      "loss": 0.4714,
      "step": 878
    },
    {
      "epoch": 3.4069767441860463,
      "grad_norm": 0.7535462975502014,
      "learning_rate": 4.6593023255813954e-05,
      "loss": 0.0277,
      "step": 879
    },
    {
      "epoch": 3.4108527131782944,
      "grad_norm": 0.010324371047317982,
      "learning_rate": 4.6589147286821706e-05,
      "loss": 0.0008,
      "step": 880
    },
    {
      "epoch": 3.4147286821705425,
      "grad_norm": 14.066651344299316,
      "learning_rate": 4.658527131782946e-05,
      "loss": 1.2284,
      "step": 881
    },
    {
      "epoch": 3.4186046511627906,
      "grad_norm": 2.1608424186706543,
      "learning_rate": 4.658139534883721e-05,
      "loss": 0.0086,
      "step": 882
    },
    {
      "epoch": 3.4224806201550386,
      "grad_norm": 0.009037962183356285,
      "learning_rate": 4.6577519379844964e-05,
      "loss": 0.0008,
      "step": 883
    },
    {
      "epoch": 3.4263565891472867,
      "grad_norm": 14.568426132202148,
      "learning_rate": 4.6573643410852716e-05,
      "loss": 0.645,
      "step": 884
    },
    {
      "epoch": 3.4302325581395348,
      "grad_norm": 0.10001515597105026,
      "learning_rate": 4.656976744186047e-05,
      "loss": 0.002,
      "step": 885
    },
    {
      "epoch": 3.434108527131783,
      "grad_norm": 0.036351144313812256,
      "learning_rate": 4.6565891472868214e-05,
      "loss": 0.0014,
      "step": 886
    },
    {
      "epoch": 3.437984496124031,
      "grad_norm": 0.013076403178274632,
      "learning_rate": 4.6562015503875973e-05,
      "loss": 0.0009,
      "step": 887
    },
    {
      "epoch": 3.441860465116279,
      "grad_norm": 4.443209648132324,
      "learning_rate": 4.655813953488372e-05,
      "loss": 0.2798,
      "step": 888
    },
    {
      "epoch": 3.445736434108527,
      "grad_norm": 0.016568947583436966,
      "learning_rate": 4.655426356589148e-05,
      "loss": 0.0011,
      "step": 889
    },
    {
      "epoch": 3.449612403100775,
      "grad_norm": 23.092037200927734,
      "learning_rate": 4.6550387596899224e-05,
      "loss": 0.0421,
      "step": 890
    },
    {
      "epoch": 3.453488372093023,
      "grad_norm": 12.386972427368164,
      "learning_rate": 4.654651162790698e-05,
      "loss": 0.0341,
      "step": 891
    },
    {
      "epoch": 3.4573643410852712,
      "grad_norm": 46.095211029052734,
      "learning_rate": 4.654263565891473e-05,
      "loss": 0.2909,
      "step": 892
    },
    {
      "epoch": 3.4612403100775193,
      "grad_norm": 0.11495757102966309,
      "learning_rate": 4.653875968992248e-05,
      "loss": 0.0026,
      "step": 893
    },
    {
      "epoch": 3.4651162790697674,
      "grad_norm": 2.115802049636841,
      "learning_rate": 4.6534883720930234e-05,
      "loss": 0.0248,
      "step": 894
    },
    {
      "epoch": 3.4689922480620154,
      "grad_norm": 2.2213709354400635,
      "learning_rate": 4.6531007751937986e-05,
      "loss": 0.0065,
      "step": 895
    },
    {
      "epoch": 3.4728682170542635,
      "grad_norm": 2.1170334815979004,
      "learning_rate": 4.652713178294574e-05,
      "loss": 0.0241,
      "step": 896
    },
    {
      "epoch": 3.4767441860465116,
      "grad_norm": 9.742042541503906,
      "learning_rate": 4.652325581395349e-05,
      "loss": 0.2317,
      "step": 897
    },
    {
      "epoch": 3.4806201550387597,
      "grad_norm": 0.7832140326499939,
      "learning_rate": 4.651937984496124e-05,
      "loss": 0.0161,
      "step": 898
    },
    {
      "epoch": 3.4844961240310077,
      "grad_norm": 0.010960365645587444,
      "learning_rate": 4.6515503875968996e-05,
      "loss": 0.001,
      "step": 899
    },
    {
      "epoch": 3.488372093023256,
      "grad_norm": 0.011653810739517212,
      "learning_rate": 4.651162790697675e-05,
      "loss": 0.0009,
      "step": 900
    },
    {
      "epoch": 3.492248062015504,
      "grad_norm": 0.5790837407112122,
      "learning_rate": 4.65077519379845e-05,
      "loss": 0.0041,
      "step": 901
    },
    {
      "epoch": 3.496124031007752,
      "grad_norm": 0.010744530707597733,
      "learning_rate": 4.650387596899225e-05,
      "loss": 0.0009,
      "step": 902
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.3473789393901825,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.0064,
      "step": 903
    },
    {
      "epoch": 3.503875968992248,
      "grad_norm": 0.017259426414966583,
      "learning_rate": 4.649612403100775e-05,
      "loss": 0.0009,
      "step": 904
    },
    {
      "epoch": 3.507751937984496,
      "grad_norm": 0.051795054227113724,
      "learning_rate": 4.649224806201551e-05,
      "loss": 0.0027,
      "step": 905
    },
    {
      "epoch": 3.511627906976744,
      "grad_norm": 0.12605397403240204,
      "learning_rate": 4.6488372093023256e-05,
      "loss": 0.0021,
      "step": 906
    },
    {
      "epoch": 3.5155038759689923,
      "grad_norm": 0.01031036488711834,
      "learning_rate": 4.648449612403101e-05,
      "loss": 0.0008,
      "step": 907
    },
    {
      "epoch": 3.5193798449612403,
      "grad_norm": 0.09213346242904663,
      "learning_rate": 4.648062015503876e-05,
      "loss": 0.0011,
      "step": 908
    },
    {
      "epoch": 3.5232558139534884,
      "grad_norm": 4.28066873550415,
      "learning_rate": 4.647674418604651e-05,
      "loss": 0.5219,
      "step": 909
    },
    {
      "epoch": 3.5271317829457365,
      "grad_norm": 0.011787448078393936,
      "learning_rate": 4.6472868217054266e-05,
      "loss": 0.0008,
      "step": 910
    },
    {
      "epoch": 3.5310077519379846,
      "grad_norm": 0.7723800539970398,
      "learning_rate": 4.646899224806202e-05,
      "loss": 0.0065,
      "step": 911
    },
    {
      "epoch": 3.5348837209302326,
      "grad_norm": 6.824936866760254,
      "learning_rate": 4.646511627906977e-05,
      "loss": 0.2643,
      "step": 912
    },
    {
      "epoch": 3.5387596899224807,
      "grad_norm": 0.09713135659694672,
      "learning_rate": 4.646124031007752e-05,
      "loss": 0.0009,
      "step": 913
    },
    {
      "epoch": 3.5426356589147288,
      "grad_norm": 1.4121750593185425,
      "learning_rate": 4.6457364341085275e-05,
      "loss": 0.022,
      "step": 914
    },
    {
      "epoch": 3.546511627906977,
      "grad_norm": 0.018516264855861664,
      "learning_rate": 4.645348837209302e-05,
      "loss": 0.0011,
      "step": 915
    },
    {
      "epoch": 3.550387596899225,
      "grad_norm": 0.01770949736237526,
      "learning_rate": 4.644961240310078e-05,
      "loss": 0.0008,
      "step": 916
    },
    {
      "epoch": 3.554263565891473,
      "grad_norm": 19.535131454467773,
      "learning_rate": 4.6445736434108526e-05,
      "loss": 0.1375,
      "step": 917
    },
    {
      "epoch": 3.558139534883721,
      "grad_norm": 4.502899169921875,
      "learning_rate": 4.6441860465116285e-05,
      "loss": 0.0688,
      "step": 918
    },
    {
      "epoch": 3.562015503875969,
      "grad_norm": 4.018139362335205,
      "learning_rate": 4.643798449612403e-05,
      "loss": 0.3523,
      "step": 919
    },
    {
      "epoch": 3.565891472868217,
      "grad_norm": 4.6662211418151855,
      "learning_rate": 4.643410852713179e-05,
      "loss": 0.4478,
      "step": 920
    },
    {
      "epoch": 3.5697674418604652,
      "grad_norm": 0.5752665400505066,
      "learning_rate": 4.6430232558139535e-05,
      "loss": 0.0022,
      "step": 921
    },
    {
      "epoch": 3.5736434108527133,
      "grad_norm": 37.06422805786133,
      "learning_rate": 4.642635658914729e-05,
      "loss": 1.1553,
      "step": 922
    },
    {
      "epoch": 3.5775193798449614,
      "grad_norm": 0.014900666661560535,
      "learning_rate": 4.642248062015504e-05,
      "loss": 0.0009,
      "step": 923
    },
    {
      "epoch": 3.5813953488372094,
      "grad_norm": 1.7966867685317993,
      "learning_rate": 4.641860465116279e-05,
      "loss": 0.114,
      "step": 924
    },
    {
      "epoch": 3.5852713178294575,
      "grad_norm": 0.05686889588832855,
      "learning_rate": 4.6414728682170545e-05,
      "loss": 0.0013,
      "step": 925
    },
    {
      "epoch": 3.5891472868217056,
      "grad_norm": 3.120331287384033,
      "learning_rate": 4.64108527131783e-05,
      "loss": 0.3511,
      "step": 926
    },
    {
      "epoch": 3.5930232558139537,
      "grad_norm": 0.018049901351332664,
      "learning_rate": 4.640697674418605e-05,
      "loss": 0.0011,
      "step": 927
    },
    {
      "epoch": 3.5968992248062017,
      "grad_norm": 0.1574021279811859,
      "learning_rate": 4.64031007751938e-05,
      "loss": 0.0023,
      "step": 928
    },
    {
      "epoch": 3.60077519379845,
      "grad_norm": 0.30252590775489807,
      "learning_rate": 4.6399224806201555e-05,
      "loss": 0.0062,
      "step": 929
    },
    {
      "epoch": 3.604651162790698,
      "grad_norm": 0.011939135380089283,
      "learning_rate": 4.639534883720931e-05,
      "loss": 0.0009,
      "step": 930
    },
    {
      "epoch": 3.608527131782946,
      "grad_norm": 0.1584254801273346,
      "learning_rate": 4.639147286821706e-05,
      "loss": 0.0022,
      "step": 931
    },
    {
      "epoch": 3.612403100775194,
      "grad_norm": 4.680409908294678,
      "learning_rate": 4.638759689922481e-05,
      "loss": 0.7814,
      "step": 932
    },
    {
      "epoch": 3.616279069767442,
      "grad_norm": 0.01156857144087553,
      "learning_rate": 4.638372093023256e-05,
      "loss": 0.0009,
      "step": 933
    },
    {
      "epoch": 3.62015503875969,
      "grad_norm": 2.8066163063049316,
      "learning_rate": 4.637984496124031e-05,
      "loss": 0.1397,
      "step": 934
    },
    {
      "epoch": 3.624031007751938,
      "grad_norm": 0.013539555482566357,
      "learning_rate": 4.637596899224806e-05,
      "loss": 0.0009,
      "step": 935
    },
    {
      "epoch": 3.6279069767441863,
      "grad_norm": 7.294668674468994,
      "learning_rate": 4.6372093023255815e-05,
      "loss": 0.1022,
      "step": 936
    },
    {
      "epoch": 3.6317829457364343,
      "grad_norm": 0.02049320563673973,
      "learning_rate": 4.636821705426357e-05,
      "loss": 0.0015,
      "step": 937
    },
    {
      "epoch": 3.6356589147286824,
      "grad_norm": 0.012198780663311481,
      "learning_rate": 4.636434108527132e-05,
      "loss": 0.001,
      "step": 938
    },
    {
      "epoch": 3.6395348837209305,
      "grad_norm": 4.345522880554199,
      "learning_rate": 4.636046511627907e-05,
      "loss": 0.0096,
      "step": 939
    },
    {
      "epoch": 3.6434108527131785,
      "grad_norm": 0.04781436547636986,
      "learning_rate": 4.6356589147286825e-05,
      "loss": 0.0019,
      "step": 940
    },
    {
      "epoch": 3.6472868217054266,
      "grad_norm": 0.09927357733249664,
      "learning_rate": 4.635271317829458e-05,
      "loss": 0.0018,
      "step": 941
    },
    {
      "epoch": 3.6511627906976747,
      "grad_norm": 12.445664405822754,
      "learning_rate": 4.634883720930232e-05,
      "loss": 2.151,
      "step": 942
    },
    {
      "epoch": 3.6550387596899228,
      "grad_norm": 0.21520628035068512,
      "learning_rate": 4.634496124031008e-05,
      "loss": 0.0084,
      "step": 943
    },
    {
      "epoch": 3.6589147286821704,
      "grad_norm": 19.426210403442383,
      "learning_rate": 4.634108527131783e-05,
      "loss": 1.0087,
      "step": 944
    },
    {
      "epoch": 3.6627906976744184,
      "grad_norm": 0.04716916382312775,
      "learning_rate": 4.633720930232559e-05,
      "loss": 0.0021,
      "step": 945
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.24166926741600037,
      "learning_rate": 4.633333333333333e-05,
      "loss": 0.0085,
      "step": 946
    },
    {
      "epoch": 3.6705426356589146,
      "grad_norm": 0.03301918879151344,
      "learning_rate": 4.632945736434109e-05,
      "loss": 0.0016,
      "step": 947
    },
    {
      "epoch": 3.6744186046511627,
      "grad_norm": 0.06298219412565231,
      "learning_rate": 4.632558139534884e-05,
      "loss": 0.0026,
      "step": 948
    },
    {
      "epoch": 3.6782945736434107,
      "grad_norm": 0.059647087007761,
      "learning_rate": 4.632170542635659e-05,
      "loss": 0.0031,
      "step": 949
    },
    {
      "epoch": 3.682170542635659,
      "grad_norm": 0.08461887389421463,
      "learning_rate": 4.631782945736434e-05,
      "loss": 0.0026,
      "step": 950
    },
    {
      "epoch": 3.686046511627907,
      "grad_norm": 1.0669686794281006,
      "learning_rate": 4.6313953488372095e-05,
      "loss": 0.0297,
      "step": 951
    },
    {
      "epoch": 3.689922480620155,
      "grad_norm": 0.04764999821782112,
      "learning_rate": 4.631007751937985e-05,
      "loss": 0.002,
      "step": 952
    },
    {
      "epoch": 3.693798449612403,
      "grad_norm": 0.03878772631287575,
      "learning_rate": 4.63062015503876e-05,
      "loss": 0.0018,
      "step": 953
    },
    {
      "epoch": 3.697674418604651,
      "grad_norm": 0.16745269298553467,
      "learning_rate": 4.630232558139535e-05,
      "loss": 0.0034,
      "step": 954
    },
    {
      "epoch": 3.701550387596899,
      "grad_norm": 2.7602429389953613,
      "learning_rate": 4.6298449612403104e-05,
      "loss": 0.04,
      "step": 955
    },
    {
      "epoch": 3.705426356589147,
      "grad_norm": 13.313152313232422,
      "learning_rate": 4.629457364341086e-05,
      "loss": 0.3079,
      "step": 956
    },
    {
      "epoch": 3.7093023255813953,
      "grad_norm": 7.850517749786377,
      "learning_rate": 4.629069767441861e-05,
      "loss": 0.4259,
      "step": 957
    },
    {
      "epoch": 3.7131782945736433,
      "grad_norm": 7.219003677368164,
      "learning_rate": 4.628682170542636e-05,
      "loss": 0.2638,
      "step": 958
    },
    {
      "epoch": 3.7170542635658914,
      "grad_norm": 0.020013324916362762,
      "learning_rate": 4.6282945736434114e-05,
      "loss": 0.0013,
      "step": 959
    },
    {
      "epoch": 3.7209302325581395,
      "grad_norm": 0.06630471348762512,
      "learning_rate": 4.627906976744186e-05,
      "loss": 0.0037,
      "step": 960
    },
    {
      "epoch": 3.7248062015503876,
      "grad_norm": 0.25951340794563293,
      "learning_rate": 4.627519379844961e-05,
      "loss": 0.0073,
      "step": 961
    },
    {
      "epoch": 3.7286821705426356,
      "grad_norm": 2.4046080112457275,
      "learning_rate": 4.6271317829457364e-05,
      "loss": 0.0381,
      "step": 962
    },
    {
      "epoch": 3.7325581395348837,
      "grad_norm": 0.0234309583902359,
      "learning_rate": 4.626744186046512e-05,
      "loss": 0.0011,
      "step": 963
    },
    {
      "epoch": 3.7364341085271318,
      "grad_norm": 14.038007736206055,
      "learning_rate": 4.626356589147287e-05,
      "loss": 0.0682,
      "step": 964
    },
    {
      "epoch": 3.74031007751938,
      "grad_norm": 0.4620751440525055,
      "learning_rate": 4.625968992248062e-05,
      "loss": 0.0129,
      "step": 965
    },
    {
      "epoch": 3.744186046511628,
      "grad_norm": 0.04024072736501694,
      "learning_rate": 4.6255813953488374e-05,
      "loss": 0.0024,
      "step": 966
    },
    {
      "epoch": 3.748062015503876,
      "grad_norm": 0.023154322057962418,
      "learning_rate": 4.6251937984496127e-05,
      "loss": 0.0011,
      "step": 967
    },
    {
      "epoch": 3.751937984496124,
      "grad_norm": 0.01204001810401678,
      "learning_rate": 4.624806201550388e-05,
      "loss": 0.0011,
      "step": 968
    },
    {
      "epoch": 3.755813953488372,
      "grad_norm": 5.489136219024658,
      "learning_rate": 4.624418604651163e-05,
      "loss": 0.0284,
      "step": 969
    },
    {
      "epoch": 3.75968992248062,
      "grad_norm": 0.16338640451431274,
      "learning_rate": 4.6240310077519384e-05,
      "loss": 0.0023,
      "step": 970
    },
    {
      "epoch": 3.7635658914728682,
      "grad_norm": 0.06689701974391937,
      "learning_rate": 4.623643410852713e-05,
      "loss": 0.002,
      "step": 971
    },
    {
      "epoch": 3.7674418604651163,
      "grad_norm": 0.2288360446691513,
      "learning_rate": 4.623255813953489e-05,
      "loss": 0.0009,
      "step": 972
    },
    {
      "epoch": 3.7713178294573644,
      "grad_norm": 8.791220664978027,
      "learning_rate": 4.6228682170542634e-05,
      "loss": 0.6774,
      "step": 973
    },
    {
      "epoch": 3.7751937984496124,
      "grad_norm": 4.00551700592041,
      "learning_rate": 4.6224806201550393e-05,
      "loss": 0.3057,
      "step": 974
    },
    {
      "epoch": 3.7790697674418605,
      "grad_norm": 0.02653183415532112,
      "learning_rate": 4.622093023255814e-05,
      "loss": 0.0011,
      "step": 975
    },
    {
      "epoch": 3.7829457364341086,
      "grad_norm": 0.053994908928871155,
      "learning_rate": 4.62170542635659e-05,
      "loss": 0.0014,
      "step": 976
    },
    {
      "epoch": 3.7868217054263567,
      "grad_norm": 14.956106185913086,
      "learning_rate": 4.6213178294573644e-05,
      "loss": 0.3024,
      "step": 977
    },
    {
      "epoch": 3.7906976744186047,
      "grad_norm": 9.36918830871582,
      "learning_rate": 4.6209302325581396e-05,
      "loss": 0.2789,
      "step": 978
    },
    {
      "epoch": 3.794573643410853,
      "grad_norm": 2.481050491333008,
      "learning_rate": 4.620542635658915e-05,
      "loss": 0.0597,
      "step": 979
    },
    {
      "epoch": 3.798449612403101,
      "grad_norm": 8.052173614501953,
      "learning_rate": 4.62015503875969e-05,
      "loss": 0.0478,
      "step": 980
    },
    {
      "epoch": 3.802325581395349,
      "grad_norm": 0.0620732381939888,
      "learning_rate": 4.6197674418604654e-05,
      "loss": 0.002,
      "step": 981
    },
    {
      "epoch": 3.806201550387597,
      "grad_norm": 5.6310248374938965,
      "learning_rate": 4.6193798449612406e-05,
      "loss": 0.3771,
      "step": 982
    },
    {
      "epoch": 3.810077519379845,
      "grad_norm": 0.2969954311847687,
      "learning_rate": 4.618992248062016e-05,
      "loss": 0.0035,
      "step": 983
    },
    {
      "epoch": 3.813953488372093,
      "grad_norm": 0.03417413309216499,
      "learning_rate": 4.618604651162791e-05,
      "loss": 0.0015,
      "step": 984
    },
    {
      "epoch": 3.817829457364341,
      "grad_norm": 0.06531544029712677,
      "learning_rate": 4.618217054263566e-05,
      "loss": 0.0019,
      "step": 985
    },
    {
      "epoch": 3.8217054263565893,
      "grad_norm": 12.73918342590332,
      "learning_rate": 4.6178294573643416e-05,
      "loss": 0.7615,
      "step": 986
    },
    {
      "epoch": 3.8255813953488373,
      "grad_norm": 0.04363396391272545,
      "learning_rate": 4.617441860465117e-05,
      "loss": 0.0014,
      "step": 987
    },
    {
      "epoch": 3.8294573643410854,
      "grad_norm": 0.1477992832660675,
      "learning_rate": 4.6170542635658914e-05,
      "loss": 0.0027,
      "step": 988
    },
    {
      "epoch": 3.8333333333333335,
      "grad_norm": 0.12485706061124802,
      "learning_rate": 4.6166666666666666e-05,
      "loss": 0.0032,
      "step": 989
    },
    {
      "epoch": 3.8372093023255816,
      "grad_norm": 13.143939971923828,
      "learning_rate": 4.616279069767442e-05,
      "loss": 1.5148,
      "step": 990
    },
    {
      "epoch": 3.8410852713178296,
      "grad_norm": 0.10722324252128601,
      "learning_rate": 4.615891472868217e-05,
      "loss": 0.0025,
      "step": 991
    },
    {
      "epoch": 3.8449612403100772,
      "grad_norm": 9.160104751586914,
      "learning_rate": 4.6155038759689924e-05,
      "loss": 0.0275,
      "step": 992
    },
    {
      "epoch": 3.8488372093023253,
      "grad_norm": 0.12175209075212479,
      "learning_rate": 4.6151162790697676e-05,
      "loss": 0.0042,
      "step": 993
    },
    {
      "epoch": 3.8527131782945734,
      "grad_norm": 15.664801597595215,
      "learning_rate": 4.614728682170543e-05,
      "loss": 0.1836,
      "step": 994
    },
    {
      "epoch": 3.8565891472868215,
      "grad_norm": 0.032912299036979675,
      "learning_rate": 4.614341085271318e-05,
      "loss": 0.0008,
      "step": 995
    },
    {
      "epoch": 3.8604651162790695,
      "grad_norm": 21.302804946899414,
      "learning_rate": 4.613953488372093e-05,
      "loss": 0.1054,
      "step": 996
    },
    {
      "epoch": 3.8643410852713176,
      "grad_norm": 2.2216365337371826,
      "learning_rate": 4.6135658914728686e-05,
      "loss": 0.0559,
      "step": 997
    },
    {
      "epoch": 3.8682170542635657,
      "grad_norm": 0.2749447822570801,
      "learning_rate": 4.613178294573644e-05,
      "loss": 0.0037,
      "step": 998
    },
    {
      "epoch": 3.8720930232558137,
      "grad_norm": 0.22190244495868683,
      "learning_rate": 4.612790697674419e-05,
      "loss": 0.0076,
      "step": 999
    },
    {
      "epoch": 3.875968992248062,
      "grad_norm": 3.8907551765441895,
      "learning_rate": 4.6124031007751936e-05,
      "loss": 0.1501,
      "step": 1000
    },
    {
      "epoch": 3.87984496124031,
      "grad_norm": 0.6758817434310913,
      "learning_rate": 4.6120155038759695e-05,
      "loss": 0.0837,
      "step": 1001
    },
    {
      "epoch": 3.883720930232558,
      "grad_norm": 9.355339050292969,
      "learning_rate": 4.611627906976744e-05,
      "loss": 0.1722,
      "step": 1002
    },
    {
      "epoch": 3.887596899224806,
      "grad_norm": 0.08624248951673508,
      "learning_rate": 4.61124031007752e-05,
      "loss": 0.0037,
      "step": 1003
    },
    {
      "epoch": 3.891472868217054,
      "grad_norm": 7.015600204467773,
      "learning_rate": 4.6108527131782946e-05,
      "loss": 0.926,
      "step": 1004
    },
    {
      "epoch": 3.895348837209302,
      "grad_norm": 0.18428079783916473,
      "learning_rate": 4.6104651162790705e-05,
      "loss": 0.0022,
      "step": 1005
    },
    {
      "epoch": 3.89922480620155,
      "grad_norm": 0.5461228489875793,
      "learning_rate": 4.610077519379845e-05,
      "loss": 0.0027,
      "step": 1006
    },
    {
      "epoch": 3.9031007751937983,
      "grad_norm": 6.704484939575195,
      "learning_rate": 4.60968992248062e-05,
      "loss": 0.5038,
      "step": 1007
    },
    {
      "epoch": 3.9069767441860463,
      "grad_norm": 0.2657165229320526,
      "learning_rate": 4.6093023255813955e-05,
      "loss": 0.0029,
      "step": 1008
    },
    {
      "epoch": 3.9108527131782944,
      "grad_norm": 0.013676995411515236,
      "learning_rate": 4.608914728682171e-05,
      "loss": 0.0008,
      "step": 1009
    },
    {
      "epoch": 3.9147286821705425,
      "grad_norm": 0.019081491976976395,
      "learning_rate": 4.608527131782946e-05,
      "loss": 0.0008,
      "step": 1010
    },
    {
      "epoch": 3.9186046511627906,
      "grad_norm": 0.1794043928384781,
      "learning_rate": 4.608139534883721e-05,
      "loss": 0.006,
      "step": 1011
    },
    {
      "epoch": 3.9224806201550386,
      "grad_norm": 0.014710905030369759,
      "learning_rate": 4.6077519379844965e-05,
      "loss": 0.0009,
      "step": 1012
    },
    {
      "epoch": 3.9263565891472867,
      "grad_norm": 4.443178176879883,
      "learning_rate": 4.607364341085271e-05,
      "loss": 0.0641,
      "step": 1013
    },
    {
      "epoch": 3.9302325581395348,
      "grad_norm": 0.14071530103683472,
      "learning_rate": 4.606976744186047e-05,
      "loss": 0.0016,
      "step": 1014
    },
    {
      "epoch": 3.934108527131783,
      "grad_norm": 9.307822227478027,
      "learning_rate": 4.6065891472868216e-05,
      "loss": 0.1139,
      "step": 1015
    },
    {
      "epoch": 3.937984496124031,
      "grad_norm": 35.316001892089844,
      "learning_rate": 4.6062015503875975e-05,
      "loss": 0.4219,
      "step": 1016
    },
    {
      "epoch": 3.941860465116279,
      "grad_norm": 3.9723761081695557,
      "learning_rate": 4.605813953488372e-05,
      "loss": 0.0953,
      "step": 1017
    },
    {
      "epoch": 3.945736434108527,
      "grad_norm": 0.3359166085720062,
      "learning_rate": 4.605426356589147e-05,
      "loss": 0.013,
      "step": 1018
    },
    {
      "epoch": 3.949612403100775,
      "grad_norm": 1.4957001209259033,
      "learning_rate": 4.6050387596899225e-05,
      "loss": 0.009,
      "step": 1019
    },
    {
      "epoch": 3.953488372093023,
      "grad_norm": 0.0341348834335804,
      "learning_rate": 4.604651162790698e-05,
      "loss": 0.0011,
      "step": 1020
    },
    {
      "epoch": 3.9573643410852712,
      "grad_norm": 0.016401950269937515,
      "learning_rate": 4.604263565891473e-05,
      "loss": 0.0009,
      "step": 1021
    },
    {
      "epoch": 3.9612403100775193,
      "grad_norm": 25.351421356201172,
      "learning_rate": 4.603875968992248e-05,
      "loss": 0.3064,
      "step": 1022
    },
    {
      "epoch": 3.9651162790697674,
      "grad_norm": 2.6298060417175293,
      "learning_rate": 4.6034883720930235e-05,
      "loss": 0.2335,
      "step": 1023
    },
    {
      "epoch": 3.9689922480620154,
      "grad_norm": 13.30711841583252,
      "learning_rate": 4.603100775193799e-05,
      "loss": 0.1075,
      "step": 1024
    },
    {
      "epoch": 3.9728682170542635,
      "grad_norm": 0.012646880000829697,
      "learning_rate": 4.602713178294574e-05,
      "loss": 0.0007,
      "step": 1025
    },
    {
      "epoch": 3.9767441860465116,
      "grad_norm": 0.47664356231689453,
      "learning_rate": 4.602325581395349e-05,
      "loss": 0.0012,
      "step": 1026
    },
    {
      "epoch": 3.9806201550387597,
      "grad_norm": 0.18761411309242249,
      "learning_rate": 4.601937984496124e-05,
      "loss": 0.0045,
      "step": 1027
    },
    {
      "epoch": 3.9844961240310077,
      "grad_norm": 0.0660543218255043,
      "learning_rate": 4.6015503875969e-05,
      "loss": 0.0011,
      "step": 1028
    },
    {
      "epoch": 3.988372093023256,
      "grad_norm": 0.019497830420732498,
      "learning_rate": 4.601162790697674e-05,
      "loss": 0.0012,
      "step": 1029
    },
    {
      "epoch": 3.992248062015504,
      "grad_norm": 1.9069783687591553,
      "learning_rate": 4.60077519379845e-05,
      "loss": 0.076,
      "step": 1030
    },
    {
      "epoch": 3.996124031007752,
      "grad_norm": 0.016228297725319862,
      "learning_rate": 4.600387596899225e-05,
      "loss": 0.001,
      "step": 1031
    },
    {
      "epoch": 4.0,
      "grad_norm": 28.67118263244629,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.1309,
      "step": 1032
    },
    {
      "epoch": 4.003875968992248,
      "grad_norm": 0.013061790727078915,
      "learning_rate": 4.599612403100775e-05,
      "loss": 0.0008,
      "step": 1033
    },
    {
      "epoch": 4.007751937984496,
      "grad_norm": 0.1952776163816452,
      "learning_rate": 4.599224806201551e-05,
      "loss": 0.0014,
      "step": 1034
    },
    {
      "epoch": 4.011627906976744,
      "grad_norm": 0.007099104579538107,
      "learning_rate": 4.598837209302326e-05,
      "loss": 0.0007,
      "step": 1035
    },
    {
      "epoch": 4.015503875968992,
      "grad_norm": 6.2562079429626465,
      "learning_rate": 4.598449612403101e-05,
      "loss": 0.0496,
      "step": 1036
    },
    {
      "epoch": 4.01937984496124,
      "grad_norm": 0.01826048456132412,
      "learning_rate": 4.598062015503876e-05,
      "loss": 0.001,
      "step": 1037
    },
    {
      "epoch": 4.023255813953488,
      "grad_norm": 0.08899181336164474,
      "learning_rate": 4.5976744186046515e-05,
      "loss": 0.0016,
      "step": 1038
    },
    {
      "epoch": 4.0271317829457365,
      "grad_norm": 0.7657762169837952,
      "learning_rate": 4.597286821705427e-05,
      "loss": 0.029,
      "step": 1039
    },
    {
      "epoch": 4.0310077519379846,
      "grad_norm": 0.008112645708024502,
      "learning_rate": 4.596899224806201e-05,
      "loss": 0.0007,
      "step": 1040
    },
    {
      "epoch": 4.034883720930233,
      "grad_norm": 11.668313026428223,
      "learning_rate": 4.596511627906977e-05,
      "loss": 0.0666,
      "step": 1041
    },
    {
      "epoch": 4.038759689922481,
      "grad_norm": 0.008932727389037609,
      "learning_rate": 4.596124031007752e-05,
      "loss": 0.0008,
      "step": 1042
    },
    {
      "epoch": 4.042635658914729,
      "grad_norm": 99.70469665527344,
      "learning_rate": 4.595736434108528e-05,
      "loss": 0.5765,
      "step": 1043
    },
    {
      "epoch": 4.046511627906977,
      "grad_norm": 0.008344200439751148,
      "learning_rate": 4.595348837209302e-05,
      "loss": 0.0007,
      "step": 1044
    },
    {
      "epoch": 4.050387596899225,
      "grad_norm": 0.18644337356090546,
      "learning_rate": 4.5949612403100775e-05,
      "loss": 0.0022,
      "step": 1045
    },
    {
      "epoch": 4.054263565891473,
      "grad_norm": 0.010801367461681366,
      "learning_rate": 4.594573643410853e-05,
      "loss": 0.0008,
      "step": 1046
    },
    {
      "epoch": 4.058139534883721,
      "grad_norm": 10.56013011932373,
      "learning_rate": 4.594186046511628e-05,
      "loss": 0.3216,
      "step": 1047
    },
    {
      "epoch": 4.062015503875969,
      "grad_norm": 0.18821892142295837,
      "learning_rate": 4.593798449612403e-05,
      "loss": 0.0058,
      "step": 1048
    },
    {
      "epoch": 4.065891472868217,
      "grad_norm": 0.01281990297138691,
      "learning_rate": 4.5934108527131784e-05,
      "loss": 0.0009,
      "step": 1049
    },
    {
      "epoch": 4.069767441860465,
      "grad_norm": 6.360086917877197,
      "learning_rate": 4.593023255813954e-05,
      "loss": 0.7456,
      "step": 1050
    },
    {
      "epoch": 4.073643410852713,
      "grad_norm": 0.013198647648096085,
      "learning_rate": 4.592635658914729e-05,
      "loss": 0.0008,
      "step": 1051
    },
    {
      "epoch": 4.077519379844961,
      "grad_norm": 1.2058072090148926,
      "learning_rate": 4.592248062015504e-05,
      "loss": 0.0158,
      "step": 1052
    },
    {
      "epoch": 4.0813953488372094,
      "grad_norm": 0.07544583827257156,
      "learning_rate": 4.5918604651162794e-05,
      "loss": 0.0017,
      "step": 1053
    },
    {
      "epoch": 4.0852713178294575,
      "grad_norm": 0.4039522707462311,
      "learning_rate": 4.5914728682170547e-05,
      "loss": 0.0062,
      "step": 1054
    },
    {
      "epoch": 4.089147286821706,
      "grad_norm": 0.5100531578063965,
      "learning_rate": 4.59108527131783e-05,
      "loss": 0.0047,
      "step": 1055
    },
    {
      "epoch": 4.093023255813954,
      "grad_norm": 0.009417220950126648,
      "learning_rate": 4.5906976744186045e-05,
      "loss": 0.0008,
      "step": 1056
    },
    {
      "epoch": 4.096899224806202,
      "grad_norm": 0.03782864287495613,
      "learning_rate": 4.5903100775193804e-05,
      "loss": 0.0011,
      "step": 1057
    },
    {
      "epoch": 4.10077519379845,
      "grad_norm": 15.721975326538086,
      "learning_rate": 4.589922480620155e-05,
      "loss": 1.5669,
      "step": 1058
    },
    {
      "epoch": 4.104651162790698,
      "grad_norm": 0.014181610196828842,
      "learning_rate": 4.589534883720931e-05,
      "loss": 0.0008,
      "step": 1059
    },
    {
      "epoch": 4.108527131782946,
      "grad_norm": 1.9321964979171753,
      "learning_rate": 4.5891472868217054e-05,
      "loss": 0.129,
      "step": 1060
    },
    {
      "epoch": 4.112403100775194,
      "grad_norm": 4.749929904937744,
      "learning_rate": 4.5887596899224813e-05,
      "loss": 0.0232,
      "step": 1061
    },
    {
      "epoch": 4.116279069767442,
      "grad_norm": 0.1694336086511612,
      "learning_rate": 4.588372093023256e-05,
      "loss": 0.004,
      "step": 1062
    },
    {
      "epoch": 4.12015503875969,
      "grad_norm": 0.02258862927556038,
      "learning_rate": 4.587984496124031e-05,
      "loss": 0.001,
      "step": 1063
    },
    {
      "epoch": 4.124031007751938,
      "grad_norm": 0.09448501467704773,
      "learning_rate": 4.5875968992248064e-05,
      "loss": 0.0014,
      "step": 1064
    },
    {
      "epoch": 4.127906976744186,
      "grad_norm": 0.05768981948494911,
      "learning_rate": 4.5872093023255816e-05,
      "loss": 0.0016,
      "step": 1065
    },
    {
      "epoch": 4.131782945736434,
      "grad_norm": 0.03568112105131149,
      "learning_rate": 4.586821705426357e-05,
      "loss": 0.0015,
      "step": 1066
    },
    {
      "epoch": 4.135658914728682,
      "grad_norm": 1.5046017169952393,
      "learning_rate": 4.5864341085271314e-05,
      "loss": 0.1248,
      "step": 1067
    },
    {
      "epoch": 4.1395348837209305,
      "grad_norm": 1.4246305227279663,
      "learning_rate": 4.5860465116279074e-05,
      "loss": 0.0109,
      "step": 1068
    },
    {
      "epoch": 4.1434108527131785,
      "grad_norm": 0.023078497499227524,
      "learning_rate": 4.585658914728682e-05,
      "loss": 0.001,
      "step": 1069
    },
    {
      "epoch": 4.147286821705427,
      "grad_norm": 0.030268734320998192,
      "learning_rate": 4.585271317829458e-05,
      "loss": 0.0012,
      "step": 1070
    },
    {
      "epoch": 4.151162790697675,
      "grad_norm": 0.08053421974182129,
      "learning_rate": 4.5848837209302324e-05,
      "loss": 0.0015,
      "step": 1071
    },
    {
      "epoch": 4.155038759689923,
      "grad_norm": 0.03612703084945679,
      "learning_rate": 4.584496124031008e-05,
      "loss": 0.0013,
      "step": 1072
    },
    {
      "epoch": 4.158914728682171,
      "grad_norm": 0.015184572897851467,
      "learning_rate": 4.584108527131783e-05,
      "loss": 0.0009,
      "step": 1073
    },
    {
      "epoch": 4.162790697674419,
      "grad_norm": 1.3065848350524902,
      "learning_rate": 4.583720930232558e-05,
      "loss": 0.0724,
      "step": 1074
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 7.043627738952637,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 0.8835,
      "step": 1075
    },
    {
      "epoch": 4.170542635658915,
      "grad_norm": 0.016399096697568893,
      "learning_rate": 4.5829457364341086e-05,
      "loss": 0.0011,
      "step": 1076
    },
    {
      "epoch": 4.174418604651163,
      "grad_norm": 23.982276916503906,
      "learning_rate": 4.582558139534884e-05,
      "loss": 0.5348,
      "step": 1077
    },
    {
      "epoch": 4.178294573643411,
      "grad_norm": 0.12941387295722961,
      "learning_rate": 4.582170542635659e-05,
      "loss": 0.0031,
      "step": 1078
    },
    {
      "epoch": 4.182170542635659,
      "grad_norm": 0.656062126159668,
      "learning_rate": 4.5817829457364344e-05,
      "loss": 0.0079,
      "step": 1079
    },
    {
      "epoch": 4.186046511627907,
      "grad_norm": 0.04528944194316864,
      "learning_rate": 4.5813953488372096e-05,
      "loss": 0.0016,
      "step": 1080
    },
    {
      "epoch": 4.189922480620155,
      "grad_norm": 0.6020069122314453,
      "learning_rate": 4.581007751937985e-05,
      "loss": 0.0066,
      "step": 1081
    },
    {
      "epoch": 4.1937984496124034,
      "grad_norm": 0.18329834938049316,
      "learning_rate": 4.58062015503876e-05,
      "loss": 0.0028,
      "step": 1082
    },
    {
      "epoch": 4.1976744186046515,
      "grad_norm": 0.19558969140052795,
      "learning_rate": 4.580232558139535e-05,
      "loss": 0.0028,
      "step": 1083
    },
    {
      "epoch": 4.2015503875969,
      "grad_norm": 3.8087289333343506,
      "learning_rate": 4.5798449612403106e-05,
      "loss": 0.0294,
      "step": 1084
    },
    {
      "epoch": 4.205426356589148,
      "grad_norm": 0.23114682734012604,
      "learning_rate": 4.579457364341085e-05,
      "loss": 0.0051,
      "step": 1085
    },
    {
      "epoch": 4.209302325581396,
      "grad_norm": 0.02814975380897522,
      "learning_rate": 4.579069767441861e-05,
      "loss": 0.0012,
      "step": 1086
    },
    {
      "epoch": 4.213178294573644,
      "grad_norm": 0.1631896048784256,
      "learning_rate": 4.5786821705426356e-05,
      "loss": 0.0035,
      "step": 1087
    },
    {
      "epoch": 4.217054263565892,
      "grad_norm": 11.794660568237305,
      "learning_rate": 4.5782945736434115e-05,
      "loss": 0.3723,
      "step": 1088
    },
    {
      "epoch": 4.22093023255814,
      "grad_norm": 17.747556686401367,
      "learning_rate": 4.577906976744186e-05,
      "loss": 0.5137,
      "step": 1089
    },
    {
      "epoch": 4.224806201550388,
      "grad_norm": 0.010794641450047493,
      "learning_rate": 4.577519379844962e-05,
      "loss": 0.0008,
      "step": 1090
    },
    {
      "epoch": 4.228682170542636,
      "grad_norm": 4.171873092651367,
      "learning_rate": 4.5771317829457366e-05,
      "loss": 0.5874,
      "step": 1091
    },
    {
      "epoch": 4.232558139534884,
      "grad_norm": 0.017664223909378052,
      "learning_rate": 4.576744186046512e-05,
      "loss": 0.0012,
      "step": 1092
    },
    {
      "epoch": 4.236434108527132,
      "grad_norm": 0.07564397156238556,
      "learning_rate": 4.576356589147287e-05,
      "loss": 0.0012,
      "step": 1093
    },
    {
      "epoch": 4.24031007751938,
      "grad_norm": 0.1385471224784851,
      "learning_rate": 4.575968992248062e-05,
      "loss": 0.0015,
      "step": 1094
    },
    {
      "epoch": 4.2441860465116275,
      "grad_norm": 0.019219854846596718,
      "learning_rate": 4.5755813953488375e-05,
      "loss": 0.0008,
      "step": 1095
    },
    {
      "epoch": 4.248062015503876,
      "grad_norm": 0.03760360926389694,
      "learning_rate": 4.575193798449612e-05,
      "loss": 0.0012,
      "step": 1096
    },
    {
      "epoch": 4.251937984496124,
      "grad_norm": 0.008393057622015476,
      "learning_rate": 4.574806201550388e-05,
      "loss": 0.0007,
      "step": 1097
    },
    {
      "epoch": 4.2558139534883725,
      "grad_norm": 1.14341402053833,
      "learning_rate": 4.5744186046511626e-05,
      "loss": 0.002,
      "step": 1098
    },
    {
      "epoch": 4.25968992248062,
      "grad_norm": 13.470817565917969,
      "learning_rate": 4.5740310077519385e-05,
      "loss": 0.2836,
      "step": 1099
    },
    {
      "epoch": 4.263565891472869,
      "grad_norm": 4.350674152374268,
      "learning_rate": 4.573643410852713e-05,
      "loss": 0.3471,
      "step": 1100
    },
    {
      "epoch": 4.267441860465116,
      "grad_norm": 0.009555353783071041,
      "learning_rate": 4.573255813953489e-05,
      "loss": 0.0008,
      "step": 1101
    },
    {
      "epoch": 4.271317829457364,
      "grad_norm": 0.010724800638854504,
      "learning_rate": 4.5728682170542636e-05,
      "loss": 0.0008,
      "step": 1102
    },
    {
      "epoch": 4.275193798449612,
      "grad_norm": 16.83042335510254,
      "learning_rate": 4.572480620155039e-05,
      "loss": 0.4174,
      "step": 1103
    },
    {
      "epoch": 4.27906976744186,
      "grad_norm": 19.728403091430664,
      "learning_rate": 4.572093023255814e-05,
      "loss": 0.2582,
      "step": 1104
    },
    {
      "epoch": 4.282945736434108,
      "grad_norm": 5.354602813720703,
      "learning_rate": 4.571705426356589e-05,
      "loss": 0.283,
      "step": 1105
    },
    {
      "epoch": 4.286821705426356,
      "grad_norm": 5.272909164428711,
      "learning_rate": 4.5713178294573645e-05,
      "loss": 0.0168,
      "step": 1106
    },
    {
      "epoch": 4.290697674418604,
      "grad_norm": 5.507515907287598,
      "learning_rate": 4.57093023255814e-05,
      "loss": 0.1881,
      "step": 1107
    },
    {
      "epoch": 4.294573643410852,
      "grad_norm": 12.549510955810547,
      "learning_rate": 4.570542635658915e-05,
      "loss": 0.5535,
      "step": 1108
    },
    {
      "epoch": 4.2984496124031,
      "grad_norm": 0.009756190702319145,
      "learning_rate": 4.57015503875969e-05,
      "loss": 0.0008,
      "step": 1109
    },
    {
      "epoch": 4.3023255813953485,
      "grad_norm": 0.00972490943968296,
      "learning_rate": 4.5697674418604655e-05,
      "loss": 0.0008,
      "step": 1110
    },
    {
      "epoch": 4.3062015503875966,
      "grad_norm": 0.024494003504514694,
      "learning_rate": 4.569379844961241e-05,
      "loss": 0.0015,
      "step": 1111
    },
    {
      "epoch": 4.310077519379845,
      "grad_norm": 0.011466280557215214,
      "learning_rate": 4.568992248062015e-05,
      "loss": 0.0006,
      "step": 1112
    },
    {
      "epoch": 4.313953488372093,
      "grad_norm": 3.711432933807373,
      "learning_rate": 4.568604651162791e-05,
      "loss": 0.1819,
      "step": 1113
    },
    {
      "epoch": 4.317829457364341,
      "grad_norm": 6.271266460418701,
      "learning_rate": 4.568217054263566e-05,
      "loss": 0.0143,
      "step": 1114
    },
    {
      "epoch": 4.321705426356589,
      "grad_norm": 0.011889935471117496,
      "learning_rate": 4.567829457364342e-05,
      "loss": 0.0008,
      "step": 1115
    },
    {
      "epoch": 4.325581395348837,
      "grad_norm": 0.017777560278773308,
      "learning_rate": 4.567441860465116e-05,
      "loss": 0.001,
      "step": 1116
    },
    {
      "epoch": 4.329457364341085,
      "grad_norm": 0.011356962844729424,
      "learning_rate": 4.567054263565892e-05,
      "loss": 0.0009,
      "step": 1117
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 0.03759348392486572,
      "learning_rate": 4.566666666666667e-05,
      "loss": 0.0011,
      "step": 1118
    },
    {
      "epoch": 4.337209302325581,
      "grad_norm": 6.582840919494629,
      "learning_rate": 4.566279069767443e-05,
      "loss": 0.0792,
      "step": 1119
    },
    {
      "epoch": 4.341085271317829,
      "grad_norm": 0.018119409680366516,
      "learning_rate": 4.565891472868217e-05,
      "loss": 0.001,
      "step": 1120
    },
    {
      "epoch": 4.344961240310077,
      "grad_norm": 1.4248559474945068,
      "learning_rate": 4.5655038759689925e-05,
      "loss": 0.0103,
      "step": 1121
    },
    {
      "epoch": 4.348837209302325,
      "grad_norm": 0.009252450428903103,
      "learning_rate": 4.565116279069768e-05,
      "loss": 0.0008,
      "step": 1122
    },
    {
      "epoch": 4.352713178294573,
      "grad_norm": 1.4905004501342773,
      "learning_rate": 4.564728682170542e-05,
      "loss": 0.0115,
      "step": 1123
    },
    {
      "epoch": 4.3565891472868215,
      "grad_norm": 0.04133016988635063,
      "learning_rate": 4.564341085271318e-05,
      "loss": 0.0011,
      "step": 1124
    },
    {
      "epoch": 4.3604651162790695,
      "grad_norm": 0.008271923288702965,
      "learning_rate": 4.563953488372093e-05,
      "loss": 0.0007,
      "step": 1125
    },
    {
      "epoch": 4.364341085271318,
      "grad_norm": 0.03522658720612526,
      "learning_rate": 4.563565891472869e-05,
      "loss": 0.001,
      "step": 1126
    },
    {
      "epoch": 4.368217054263566,
      "grad_norm": 4.107692241668701,
      "learning_rate": 4.563178294573643e-05,
      "loss": 0.0097,
      "step": 1127
    },
    {
      "epoch": 4.372093023255814,
      "grad_norm": 0.30405446887016296,
      "learning_rate": 4.562790697674419e-05,
      "loss": 0.0105,
      "step": 1128
    },
    {
      "epoch": 4.375968992248062,
      "grad_norm": 0.00812783744186163,
      "learning_rate": 4.562403100775194e-05,
      "loss": 0.0008,
      "step": 1129
    },
    {
      "epoch": 4.37984496124031,
      "grad_norm": 0.007328540086746216,
      "learning_rate": 4.562015503875969e-05,
      "loss": 0.0007,
      "step": 1130
    },
    {
      "epoch": 4.383720930232558,
      "grad_norm": 0.16866929829120636,
      "learning_rate": 4.561627906976744e-05,
      "loss": 0.0045,
      "step": 1131
    },
    {
      "epoch": 4.387596899224806,
      "grad_norm": 0.013167127966880798,
      "learning_rate": 4.5612403100775195e-05,
      "loss": 0.0007,
      "step": 1132
    },
    {
      "epoch": 4.391472868217054,
      "grad_norm": 0.009509684517979622,
      "learning_rate": 4.560852713178295e-05,
      "loss": 0.0007,
      "step": 1133
    },
    {
      "epoch": 4.395348837209302,
      "grad_norm": 0.007315995171666145,
      "learning_rate": 4.56046511627907e-05,
      "loss": 0.0006,
      "step": 1134
    },
    {
      "epoch": 4.39922480620155,
      "grad_norm": 0.07051125913858414,
      "learning_rate": 4.560077519379845e-05,
      "loss": 0.0011,
      "step": 1135
    },
    {
      "epoch": 4.403100775193798,
      "grad_norm": 0.015614674426615238,
      "learning_rate": 4.5596899224806204e-05,
      "loss": 0.0008,
      "step": 1136
    },
    {
      "epoch": 4.406976744186046,
      "grad_norm": 0.04557555168867111,
      "learning_rate": 4.559302325581396e-05,
      "loss": 0.001,
      "step": 1137
    },
    {
      "epoch": 4.410852713178294,
      "grad_norm": 0.01426532119512558,
      "learning_rate": 4.558914728682171e-05,
      "loss": 0.0007,
      "step": 1138
    },
    {
      "epoch": 4.4147286821705425,
      "grad_norm": 1.6971104145050049,
      "learning_rate": 4.558527131782946e-05,
      "loss": 0.0217,
      "step": 1139
    },
    {
      "epoch": 4.4186046511627906,
      "grad_norm": 1.2736475467681885,
      "learning_rate": 4.5581395348837214e-05,
      "loss": 0.111,
      "step": 1140
    },
    {
      "epoch": 4.422480620155039,
      "grad_norm": 0.168552428483963,
      "learning_rate": 4.557751937984496e-05,
      "loss": 0.0044,
      "step": 1141
    },
    {
      "epoch": 4.426356589147287,
      "grad_norm": 3.666764974594116,
      "learning_rate": 4.557364341085272e-05,
      "loss": 0.4269,
      "step": 1142
    },
    {
      "epoch": 4.430232558139535,
      "grad_norm": 0.010004447773098946,
      "learning_rate": 4.5569767441860465e-05,
      "loss": 0.0007,
      "step": 1143
    },
    {
      "epoch": 4.434108527131783,
      "grad_norm": 0.006576388608664274,
      "learning_rate": 4.5565891472868224e-05,
      "loss": 0.0006,
      "step": 1144
    },
    {
      "epoch": 4.437984496124031,
      "grad_norm": 0.015235246159136295,
      "learning_rate": 4.556201550387597e-05,
      "loss": 0.0008,
      "step": 1145
    },
    {
      "epoch": 4.441860465116279,
      "grad_norm": 0.010108647868037224,
      "learning_rate": 4.555813953488373e-05,
      "loss": 0.0006,
      "step": 1146
    },
    {
      "epoch": 4.445736434108527,
      "grad_norm": 17.67706298828125,
      "learning_rate": 4.5554263565891474e-05,
      "loss": 0.9198,
      "step": 1147
    },
    {
      "epoch": 4.449612403100775,
      "grad_norm": 0.18045319616794586,
      "learning_rate": 4.555038759689923e-05,
      "loss": 0.0008,
      "step": 1148
    },
    {
      "epoch": 4.453488372093023,
      "grad_norm": 0.012535377405583858,
      "learning_rate": 4.554651162790698e-05,
      "loss": 0.0007,
      "step": 1149
    },
    {
      "epoch": 4.457364341085271,
      "grad_norm": 0.48599135875701904,
      "learning_rate": 4.554263565891473e-05,
      "loss": 0.0025,
      "step": 1150
    },
    {
      "epoch": 4.461240310077519,
      "grad_norm": 11.050963401794434,
      "learning_rate": 4.5538759689922484e-05,
      "loss": 0.1963,
      "step": 1151
    },
    {
      "epoch": 4.465116279069767,
      "grad_norm": 0.9568628072738647,
      "learning_rate": 4.553488372093023e-05,
      "loss": 0.114,
      "step": 1152
    },
    {
      "epoch": 4.4689922480620154,
      "grad_norm": 0.011987444944679737,
      "learning_rate": 4.553100775193799e-05,
      "loss": 0.0007,
      "step": 1153
    },
    {
      "epoch": 4.4728682170542635,
      "grad_norm": 15.598706245422363,
      "learning_rate": 4.5527131782945734e-05,
      "loss": 0.4799,
      "step": 1154
    },
    {
      "epoch": 4.476744186046512,
      "grad_norm": 4.959723949432373,
      "learning_rate": 4.5523255813953494e-05,
      "loss": 0.6969,
      "step": 1155
    },
    {
      "epoch": 4.48062015503876,
      "grad_norm": 0.007170066237449646,
      "learning_rate": 4.551937984496124e-05,
      "loss": 0.0006,
      "step": 1156
    },
    {
      "epoch": 4.484496124031008,
      "grad_norm": 1.7766897678375244,
      "learning_rate": 4.5515503875969e-05,
      "loss": 0.1133,
      "step": 1157
    },
    {
      "epoch": 4.488372093023256,
      "grad_norm": 0.00987787265330553,
      "learning_rate": 4.5511627906976744e-05,
      "loss": 0.0006,
      "step": 1158
    },
    {
      "epoch": 4.492248062015504,
      "grad_norm": 0.7022089958190918,
      "learning_rate": 4.5507751937984497e-05,
      "loss": 0.0739,
      "step": 1159
    },
    {
      "epoch": 4.496124031007752,
      "grad_norm": 0.007379533722996712,
      "learning_rate": 4.550387596899225e-05,
      "loss": 0.0007,
      "step": 1160
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.2371339797973633,
      "learning_rate": 4.55e-05,
      "loss": 0.022,
      "step": 1161
    },
    {
      "epoch": 4.503875968992248,
      "grad_norm": 0.010547829791903496,
      "learning_rate": 4.5496124031007754e-05,
      "loss": 0.0008,
      "step": 1162
    },
    {
      "epoch": 4.507751937984496,
      "grad_norm": 2.5830159187316895,
      "learning_rate": 4.5492248062015506e-05,
      "loss": 0.1038,
      "step": 1163
    },
    {
      "epoch": 4.511627906976744,
      "grad_norm": 0.7633911371231079,
      "learning_rate": 4.548837209302326e-05,
      "loss": 0.0067,
      "step": 1164
    },
    {
      "epoch": 4.515503875968992,
      "grad_norm": 0.008223515935242176,
      "learning_rate": 4.548449612403101e-05,
      "loss": 0.0005,
      "step": 1165
    },
    {
      "epoch": 4.51937984496124,
      "grad_norm": 0.014487258158624172,
      "learning_rate": 4.5480620155038764e-05,
      "loss": 0.0008,
      "step": 1166
    },
    {
      "epoch": 4.523255813953488,
      "grad_norm": 0.01613520085811615,
      "learning_rate": 4.5476744186046516e-05,
      "loss": 0.0009,
      "step": 1167
    },
    {
      "epoch": 4.5271317829457365,
      "grad_norm": 6.513208866119385,
      "learning_rate": 4.547286821705427e-05,
      "loss": 0.0758,
      "step": 1168
    },
    {
      "epoch": 4.5310077519379846,
      "grad_norm": 1.7893773317337036,
      "learning_rate": 4.546899224806202e-05,
      "loss": 0.0282,
      "step": 1169
    },
    {
      "epoch": 4.534883720930233,
      "grad_norm": 0.022836297750473022,
      "learning_rate": 4.5465116279069766e-05,
      "loss": 0.0012,
      "step": 1170
    },
    {
      "epoch": 4.538759689922481,
      "grad_norm": 4.354649066925049,
      "learning_rate": 4.5461240310077526e-05,
      "loss": 0.0351,
      "step": 1171
    },
    {
      "epoch": 4.542635658914729,
      "grad_norm": 4.984935760498047,
      "learning_rate": 4.545736434108527e-05,
      "loss": 0.7415,
      "step": 1172
    },
    {
      "epoch": 4.546511627906977,
      "grad_norm": 0.3105975389480591,
      "learning_rate": 4.5453488372093024e-05,
      "loss": 0.057,
      "step": 1173
    },
    {
      "epoch": 4.550387596899225,
      "grad_norm": 0.1584721803665161,
      "learning_rate": 4.5449612403100776e-05,
      "loss": 0.0052,
      "step": 1174
    },
    {
      "epoch": 4.554263565891473,
      "grad_norm": 2.6075844764709473,
      "learning_rate": 4.544573643410853e-05,
      "loss": 0.0256,
      "step": 1175
    },
    {
      "epoch": 4.558139534883721,
      "grad_norm": 4.832924842834473,
      "learning_rate": 4.544186046511628e-05,
      "loss": 0.029,
      "step": 1176
    },
    {
      "epoch": 4.562015503875969,
      "grad_norm": 0.06878677010536194,
      "learning_rate": 4.5437984496124033e-05,
      "loss": 0.002,
      "step": 1177
    },
    {
      "epoch": 4.565891472868217,
      "grad_norm": 0.5183767676353455,
      "learning_rate": 4.5434108527131786e-05,
      "loss": 0.0075,
      "step": 1178
    },
    {
      "epoch": 4.569767441860465,
      "grad_norm": 7.487698078155518,
      "learning_rate": 4.543023255813954e-05,
      "loss": 0.928,
      "step": 1179
    },
    {
      "epoch": 4.573643410852713,
      "grad_norm": 1.1034786701202393,
      "learning_rate": 4.542635658914729e-05,
      "loss": 0.0075,
      "step": 1180
    },
    {
      "epoch": 4.577519379844961,
      "grad_norm": 0.5945596694946289,
      "learning_rate": 4.5422480620155036e-05,
      "loss": 0.0081,
      "step": 1181
    },
    {
      "epoch": 4.5813953488372094,
      "grad_norm": 18.376392364501953,
      "learning_rate": 4.5418604651162796e-05,
      "loss": 0.2155,
      "step": 1182
    },
    {
      "epoch": 4.5852713178294575,
      "grad_norm": 0.01345702726393938,
      "learning_rate": 4.541472868217054e-05,
      "loss": 0.0008,
      "step": 1183
    },
    {
      "epoch": 4.589147286821706,
      "grad_norm": 0.015561212785542011,
      "learning_rate": 4.54108527131783e-05,
      "loss": 0.0009,
      "step": 1184
    },
    {
      "epoch": 4.593023255813954,
      "grad_norm": 0.026096416637301445,
      "learning_rate": 4.5406976744186046e-05,
      "loss": 0.001,
      "step": 1185
    },
    {
      "epoch": 4.596899224806202,
      "grad_norm": 0.46136993169784546,
      "learning_rate": 4.5403100775193805e-05,
      "loss": 0.0143,
      "step": 1186
    },
    {
      "epoch": 4.60077519379845,
      "grad_norm": 0.11123890429735184,
      "learning_rate": 4.539922480620155e-05,
      "loss": 0.0024,
      "step": 1187
    },
    {
      "epoch": 4.604651162790698,
      "grad_norm": 0.007762348745018244,
      "learning_rate": 4.53953488372093e-05,
      "loss": 0.0007,
      "step": 1188
    },
    {
      "epoch": 4.608527131782946,
      "grad_norm": 0.017049873247742653,
      "learning_rate": 4.5391472868217056e-05,
      "loss": 0.001,
      "step": 1189
    },
    {
      "epoch": 4.612403100775194,
      "grad_norm": 0.02100023627281189,
      "learning_rate": 4.538759689922481e-05,
      "loss": 0.0011,
      "step": 1190
    },
    {
      "epoch": 4.616279069767442,
      "grad_norm": 0.008407075889408588,
      "learning_rate": 4.538372093023256e-05,
      "loss": 0.0006,
      "step": 1191
    },
    {
      "epoch": 4.62015503875969,
      "grad_norm": 0.04018907621502876,
      "learning_rate": 4.537984496124031e-05,
      "loss": 0.0017,
      "step": 1192
    },
    {
      "epoch": 4.624031007751938,
      "grad_norm": 0.8743556141853333,
      "learning_rate": 4.5375968992248065e-05,
      "loss": 0.0816,
      "step": 1193
    },
    {
      "epoch": 4.627906976744186,
      "grad_norm": 4.0126447677612305,
      "learning_rate": 4.537209302325582e-05,
      "loss": 0.3419,
      "step": 1194
    },
    {
      "epoch": 4.631782945736434,
      "grad_norm": 0.545745849609375,
      "learning_rate": 4.536821705426357e-05,
      "loss": 0.0109,
      "step": 1195
    },
    {
      "epoch": 4.635658914728682,
      "grad_norm": 0.01939813233911991,
      "learning_rate": 4.536434108527132e-05,
      "loss": 0.0008,
      "step": 1196
    },
    {
      "epoch": 4.6395348837209305,
      "grad_norm": 0.012806983664631844,
      "learning_rate": 4.5360465116279075e-05,
      "loss": 0.0006,
      "step": 1197
    },
    {
      "epoch": 4.6434108527131785,
      "grad_norm": 52.28273010253906,
      "learning_rate": 4.535658914728683e-05,
      "loss": 0.0455,
      "step": 1198
    },
    {
      "epoch": 4.647286821705427,
      "grad_norm": 12.03625774383545,
      "learning_rate": 4.535271317829457e-05,
      "loss": 0.0171,
      "step": 1199
    },
    {
      "epoch": 4.651162790697675,
      "grad_norm": 0.08517420291900635,
      "learning_rate": 4.5348837209302326e-05,
      "loss": 0.0034,
      "step": 1200
    },
    {
      "epoch": 4.655038759689923,
      "grad_norm": 0.0178392194211483,
      "learning_rate": 4.534496124031008e-05,
      "loss": 0.0009,
      "step": 1201
    },
    {
      "epoch": 4.658914728682171,
      "grad_norm": 0.016723783686757088,
      "learning_rate": 4.534108527131783e-05,
      "loss": 0.0011,
      "step": 1202
    },
    {
      "epoch": 4.662790697674419,
      "grad_norm": 0.00814063660800457,
      "learning_rate": 4.533720930232558e-05,
      "loss": 0.0006,
      "step": 1203
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 1.4347959756851196,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.0073,
      "step": 1204
    },
    {
      "epoch": 4.670542635658915,
      "grad_norm": 0.06343791633844376,
      "learning_rate": 4.532945736434109e-05,
      "loss": 0.001,
      "step": 1205
    },
    {
      "epoch": 4.674418604651163,
      "grad_norm": 0.2225809544324875,
      "learning_rate": 4.532558139534884e-05,
      "loss": 0.0017,
      "step": 1206
    },
    {
      "epoch": 4.678294573643411,
      "grad_norm": 0.020546434447169304,
      "learning_rate": 4.532170542635659e-05,
      "loss": 0.0012,
      "step": 1207
    },
    {
      "epoch": 4.682170542635659,
      "grad_norm": 0.008638286963105202,
      "learning_rate": 4.531782945736434e-05,
      "loss": 0.0007,
      "step": 1208
    },
    {
      "epoch": 4.686046511627907,
      "grad_norm": 3.1578261852264404,
      "learning_rate": 4.53139534883721e-05,
      "loss": 0.0313,
      "step": 1209
    },
    {
      "epoch": 4.689922480620155,
      "grad_norm": 0.17367875576019287,
      "learning_rate": 4.531007751937984e-05,
      "loss": 0.0063,
      "step": 1210
    },
    {
      "epoch": 4.6937984496124034,
      "grad_norm": 0.03135020285844803,
      "learning_rate": 4.53062015503876e-05,
      "loss": 0.001,
      "step": 1211
    },
    {
      "epoch": 4.6976744186046515,
      "grad_norm": 7.7399115562438965,
      "learning_rate": 4.530232558139535e-05,
      "loss": 0.051,
      "step": 1212
    },
    {
      "epoch": 4.7015503875969,
      "grad_norm": 0.6245802640914917,
      "learning_rate": 4.529844961240311e-05,
      "loss": 0.0069,
      "step": 1213
    },
    {
      "epoch": 4.705426356589148,
      "grad_norm": 8.584131240844727,
      "learning_rate": 4.529457364341085e-05,
      "loss": 0.2558,
      "step": 1214
    },
    {
      "epoch": 4.709302325581396,
      "grad_norm": 8.710187911987305,
      "learning_rate": 4.5290697674418605e-05,
      "loss": 0.2876,
      "step": 1215
    },
    {
      "epoch": 4.713178294573644,
      "grad_norm": 0.1718844175338745,
      "learning_rate": 4.528682170542636e-05,
      "loss": 0.0045,
      "step": 1216
    },
    {
      "epoch": 4.717054263565892,
      "grad_norm": 0.016909688711166382,
      "learning_rate": 4.528294573643411e-05,
      "loss": 0.0009,
      "step": 1217
    },
    {
      "epoch": 4.720930232558139,
      "grad_norm": 42.03895568847656,
      "learning_rate": 4.527906976744186e-05,
      "loss": 0.1889,
      "step": 1218
    },
    {
      "epoch": 4.724806201550388,
      "grad_norm": 21.95457649230957,
      "learning_rate": 4.5275193798449615e-05,
      "loss": 0.1007,
      "step": 1219
    },
    {
      "epoch": 4.728682170542635,
      "grad_norm": 5.783647537231445,
      "learning_rate": 4.527131782945737e-05,
      "loss": 0.601,
      "step": 1220
    },
    {
      "epoch": 4.732558139534884,
      "grad_norm": 0.4340720474720001,
      "learning_rate": 4.526744186046512e-05,
      "loss": 0.0038,
      "step": 1221
    },
    {
      "epoch": 4.736434108527131,
      "grad_norm": 12.287521362304688,
      "learning_rate": 4.526356589147287e-05,
      "loss": 0.5276,
      "step": 1222
    },
    {
      "epoch": 4.74031007751938,
      "grad_norm": 14.423761367797852,
      "learning_rate": 4.5259689922480624e-05,
      "loss": 1.1985,
      "step": 1223
    },
    {
      "epoch": 4.7441860465116275,
      "grad_norm": 0.019896402955055237,
      "learning_rate": 4.525581395348838e-05,
      "loss": 0.0013,
      "step": 1224
    },
    {
      "epoch": 4.748062015503876,
      "grad_norm": 0.01987285725772381,
      "learning_rate": 4.525193798449613e-05,
      "loss": 0.0007,
      "step": 1225
    },
    {
      "epoch": 4.751937984496124,
      "grad_norm": 22.06128692626953,
      "learning_rate": 4.5248062015503875e-05,
      "loss": 1.3826,
      "step": 1226
    },
    {
      "epoch": 4.7558139534883725,
      "grad_norm": 0.18740063905715942,
      "learning_rate": 4.524418604651163e-05,
      "loss": 0.004,
      "step": 1227
    },
    {
      "epoch": 4.75968992248062,
      "grad_norm": 14.176472663879395,
      "learning_rate": 4.524031007751938e-05,
      "loss": 0.4873,
      "step": 1228
    },
    {
      "epoch": 4.763565891472869,
      "grad_norm": 16.149295806884766,
      "learning_rate": 4.523643410852713e-05,
      "loss": 1.2281,
      "step": 1229
    },
    {
      "epoch": 4.767441860465116,
      "grad_norm": 0.5135505199432373,
      "learning_rate": 4.5232558139534885e-05,
      "loss": 0.0078,
      "step": 1230
    },
    {
      "epoch": 4.771317829457365,
      "grad_norm": 0.022835232317447662,
      "learning_rate": 4.522868217054264e-05,
      "loss": 0.0009,
      "step": 1231
    },
    {
      "epoch": 4.775193798449612,
      "grad_norm": 0.007927099242806435,
      "learning_rate": 4.522480620155039e-05,
      "loss": 0.0006,
      "step": 1232
    },
    {
      "epoch": 4.779069767441861,
      "grad_norm": 0.19437412917613983,
      "learning_rate": 4.522093023255814e-05,
      "loss": 0.0024,
      "step": 1233
    },
    {
      "epoch": 4.782945736434108,
      "grad_norm": 0.01853911392390728,
      "learning_rate": 4.5217054263565894e-05,
      "loss": 0.0009,
      "step": 1234
    },
    {
      "epoch": 4.786821705426356,
      "grad_norm": 0.8784440755844116,
      "learning_rate": 4.521317829457365e-05,
      "loss": 0.0108,
      "step": 1235
    },
    {
      "epoch": 4.790697674418604,
      "grad_norm": 0.324434369802475,
      "learning_rate": 4.52093023255814e-05,
      "loss": 0.0074,
      "step": 1236
    },
    {
      "epoch": 4.794573643410852,
      "grad_norm": 4.997407913208008,
      "learning_rate": 4.5205426356589145e-05,
      "loss": 0.0684,
      "step": 1237
    },
    {
      "epoch": 4.7984496124031,
      "grad_norm": 0.8867066502571106,
      "learning_rate": 4.5201550387596904e-05,
      "loss": 0.0582,
      "step": 1238
    },
    {
      "epoch": 4.8023255813953485,
      "grad_norm": 25.094097137451172,
      "learning_rate": 4.519767441860465e-05,
      "loss": 1.0706,
      "step": 1239
    },
    {
      "epoch": 4.8062015503875966,
      "grad_norm": 0.06396087259054184,
      "learning_rate": 4.519379844961241e-05,
      "loss": 0.0012,
      "step": 1240
    },
    {
      "epoch": 4.810077519379845,
      "grad_norm": 5.465383529663086,
      "learning_rate": 4.5189922480620155e-05,
      "loss": 0.1454,
      "step": 1241
    },
    {
      "epoch": 4.813953488372093,
      "grad_norm": 0.3992849588394165,
      "learning_rate": 4.5186046511627914e-05,
      "loss": 0.0036,
      "step": 1242
    },
    {
      "epoch": 4.817829457364341,
      "grad_norm": 0.027758965268731117,
      "learning_rate": 4.518217054263566e-05,
      "loss": 0.001,
      "step": 1243
    },
    {
      "epoch": 4.821705426356589,
      "grad_norm": 5.358992576599121,
      "learning_rate": 4.517829457364341e-05,
      "loss": 0.3803,
      "step": 1244
    },
    {
      "epoch": 4.825581395348837,
      "grad_norm": 0.014173745177686214,
      "learning_rate": 4.5174418604651164e-05,
      "loss": 0.0008,
      "step": 1245
    },
    {
      "epoch": 4.829457364341085,
      "grad_norm": 0.014088109135627747,
      "learning_rate": 4.517054263565892e-05,
      "loss": 0.0011,
      "step": 1246
    },
    {
      "epoch": 4.833333333333333,
      "grad_norm": 0.0944884866476059,
      "learning_rate": 4.516666666666667e-05,
      "loss": 0.0036,
      "step": 1247
    },
    {
      "epoch": 4.837209302325581,
      "grad_norm": 0.028421560302376747,
      "learning_rate": 4.516279069767442e-05,
      "loss": 0.001,
      "step": 1248
    },
    {
      "epoch": 4.841085271317829,
      "grad_norm": 0.017782561480998993,
      "learning_rate": 4.5158914728682174e-05,
      "loss": 0.001,
      "step": 1249
    },
    {
      "epoch": 4.844961240310077,
      "grad_norm": 0.04587782174348831,
      "learning_rate": 4.5155038759689926e-05,
      "loss": 0.0015,
      "step": 1250
    },
    {
      "epoch": 4.848837209302325,
      "grad_norm": 0.9229145050048828,
      "learning_rate": 4.515116279069768e-05,
      "loss": 0.0157,
      "step": 1251
    },
    {
      "epoch": 4.852713178294573,
      "grad_norm": 0.02153906598687172,
      "learning_rate": 4.514728682170543e-05,
      "loss": 0.001,
      "step": 1252
    },
    {
      "epoch": 4.8565891472868215,
      "grad_norm": 0.008853018283843994,
      "learning_rate": 4.5143410852713184e-05,
      "loss": 0.0007,
      "step": 1253
    },
    {
      "epoch": 4.8604651162790695,
      "grad_norm": 0.02971023879945278,
      "learning_rate": 4.513953488372093e-05,
      "loss": 0.001,
      "step": 1254
    },
    {
      "epoch": 4.864341085271318,
      "grad_norm": 7.565165996551514,
      "learning_rate": 4.513565891472868e-05,
      "loss": 0.0129,
      "step": 1255
    },
    {
      "epoch": 4.868217054263566,
      "grad_norm": 2.292336940765381,
      "learning_rate": 4.5131782945736434e-05,
      "loss": 0.1098,
      "step": 1256
    },
    {
      "epoch": 4.872093023255814,
      "grad_norm": 7.020546913146973,
      "learning_rate": 4.5127906976744186e-05,
      "loss": 0.2296,
      "step": 1257
    },
    {
      "epoch": 4.875968992248062,
      "grad_norm": 0.1399148404598236,
      "learning_rate": 4.512403100775194e-05,
      "loss": 0.0012,
      "step": 1258
    },
    {
      "epoch": 4.87984496124031,
      "grad_norm": 0.11154892295598984,
      "learning_rate": 4.512015503875969e-05,
      "loss": 0.0041,
      "step": 1259
    },
    {
      "epoch": 4.883720930232558,
      "grad_norm": 0.016406500712037086,
      "learning_rate": 4.5116279069767444e-05,
      "loss": 0.0012,
      "step": 1260
    },
    {
      "epoch": 4.887596899224806,
      "grad_norm": 0.00752595067024231,
      "learning_rate": 4.5112403100775196e-05,
      "loss": 0.0006,
      "step": 1261
    },
    {
      "epoch": 4.891472868217054,
      "grad_norm": 0.01429671235382557,
      "learning_rate": 4.510852713178295e-05,
      "loss": 0.0007,
      "step": 1262
    },
    {
      "epoch": 4.895348837209302,
      "grad_norm": 3.8496811389923096,
      "learning_rate": 4.51046511627907e-05,
      "loss": 0.0108,
      "step": 1263
    },
    {
      "epoch": 4.89922480620155,
      "grad_norm": 13.492164611816406,
      "learning_rate": 4.5100775193798453e-05,
      "loss": 1.6079,
      "step": 1264
    },
    {
      "epoch": 4.903100775193798,
      "grad_norm": 0.010765161365270615,
      "learning_rate": 4.5096899224806206e-05,
      "loss": 0.0006,
      "step": 1265
    },
    {
      "epoch": 4.906976744186046,
      "grad_norm": 0.00766825582832098,
      "learning_rate": 4.509302325581395e-05,
      "loss": 0.0006,
      "step": 1266
    },
    {
      "epoch": 4.910852713178294,
      "grad_norm": 0.016232116147875786,
      "learning_rate": 4.508914728682171e-05,
      "loss": 0.0011,
      "step": 1267
    },
    {
      "epoch": 4.9147286821705425,
      "grad_norm": 7.6975417137146,
      "learning_rate": 4.5085271317829456e-05,
      "loss": 0.5267,
      "step": 1268
    },
    {
      "epoch": 4.9186046511627906,
      "grad_norm": 0.41752153635025024,
      "learning_rate": 4.5081395348837216e-05,
      "loss": 0.0058,
      "step": 1269
    },
    {
      "epoch": 4.922480620155039,
      "grad_norm": 7.043054103851318,
      "learning_rate": 4.507751937984496e-05,
      "loss": 0.4469,
      "step": 1270
    },
    {
      "epoch": 4.926356589147287,
      "grad_norm": 12.842855453491211,
      "learning_rate": 4.507364341085272e-05,
      "loss": 0.128,
      "step": 1271
    },
    {
      "epoch": 4.930232558139535,
      "grad_norm": 0.006399604491889477,
      "learning_rate": 4.5069767441860466e-05,
      "loss": 0.0006,
      "step": 1272
    },
    {
      "epoch": 4.934108527131783,
      "grad_norm": 6.561689853668213,
      "learning_rate": 4.506589147286822e-05,
      "loss": 0.1153,
      "step": 1273
    },
    {
      "epoch": 4.937984496124031,
      "grad_norm": 0.032741665840148926,
      "learning_rate": 4.506201550387597e-05,
      "loss": 0.0008,
      "step": 1274
    },
    {
      "epoch": 4.941860465116279,
      "grad_norm": 7.021535396575928,
      "learning_rate": 4.505813953488372e-05,
      "loss": 0.2826,
      "step": 1275
    },
    {
      "epoch": 4.945736434108527,
      "grad_norm": 11.549324989318848,
      "learning_rate": 4.5054263565891476e-05,
      "loss": 0.7223,
      "step": 1276
    },
    {
      "epoch": 4.949612403100775,
      "grad_norm": 0.031641822308301926,
      "learning_rate": 4.505038759689923e-05,
      "loss": 0.0015,
      "step": 1277
    },
    {
      "epoch": 4.953488372093023,
      "grad_norm": 0.06524298340082169,
      "learning_rate": 4.504651162790698e-05,
      "loss": 0.0032,
      "step": 1278
    },
    {
      "epoch": 4.957364341085271,
      "grad_norm": 11.552719116210938,
      "learning_rate": 4.504263565891473e-05,
      "loss": 0.5583,
      "step": 1279
    },
    {
      "epoch": 4.961240310077519,
      "grad_norm": 8.065007209777832,
      "learning_rate": 4.5038759689922485e-05,
      "loss": 0.1123,
      "step": 1280
    },
    {
      "epoch": 4.965116279069767,
      "grad_norm": 0.6214047074317932,
      "learning_rate": 4.503488372093023e-05,
      "loss": 0.0033,
      "step": 1281
    },
    {
      "epoch": 4.9689922480620154,
      "grad_norm": 0.0456511564552784,
      "learning_rate": 4.503100775193799e-05,
      "loss": 0.0013,
      "step": 1282
    },
    {
      "epoch": 4.9728682170542635,
      "grad_norm": 5.965051651000977,
      "learning_rate": 4.5027131782945736e-05,
      "loss": 0.0948,
      "step": 1283
    },
    {
      "epoch": 4.976744186046512,
      "grad_norm": 0.05345815047621727,
      "learning_rate": 4.502325581395349e-05,
      "loss": 0.0013,
      "step": 1284
    },
    {
      "epoch": 4.98062015503876,
      "grad_norm": 0.5898309350013733,
      "learning_rate": 4.501937984496124e-05,
      "loss": 0.003,
      "step": 1285
    },
    {
      "epoch": 4.984496124031008,
      "grad_norm": 6.9654459953308105,
      "learning_rate": 4.501550387596899e-05,
      "loss": 0.1955,
      "step": 1286
    },
    {
      "epoch": 4.988372093023256,
      "grad_norm": 0.047413308173418045,
      "learning_rate": 4.5011627906976746e-05,
      "loss": 0.0015,
      "step": 1287
    },
    {
      "epoch": 4.992248062015504,
      "grad_norm": 0.016699369996786118,
      "learning_rate": 4.50077519379845e-05,
      "loss": 0.001,
      "step": 1288
    },
    {
      "epoch": 4.996124031007752,
      "grad_norm": 0.031053977087140083,
      "learning_rate": 4.500387596899225e-05,
      "loss": 0.0011,
      "step": 1289
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.1942397952079773,
      "learning_rate": 4.5e-05,
      "loss": 0.0035,
      "step": 1290
    },
    {
      "epoch": 5.003875968992248,
      "grad_norm": 0.34200406074523926,
      "learning_rate": 4.4996124031007755e-05,
      "loss": 0.0067,
      "step": 1291
    },
    {
      "epoch": 5.007751937984496,
      "grad_norm": 18.001014709472656,
      "learning_rate": 4.499224806201551e-05,
      "loss": 0.5249,
      "step": 1292
    },
    {
      "epoch": 5.011627906976744,
      "grad_norm": 4.688418388366699,
      "learning_rate": 4.498837209302325e-05,
      "loss": 0.014,
      "step": 1293
    },
    {
      "epoch": 5.015503875968992,
      "grad_norm": 4.514344692230225,
      "learning_rate": 4.498449612403101e-05,
      "loss": 0.1541,
      "step": 1294
    },
    {
      "epoch": 5.01937984496124,
      "grad_norm": 0.08215222507715225,
      "learning_rate": 4.498062015503876e-05,
      "loss": 0.0016,
      "step": 1295
    },
    {
      "epoch": 5.023255813953488,
      "grad_norm": 0.4966253638267517,
      "learning_rate": 4.497674418604652e-05,
      "loss": 0.0058,
      "step": 1296
    },
    {
      "epoch": 5.0271317829457365,
      "grad_norm": 0.07500040531158447,
      "learning_rate": 4.497286821705426e-05,
      "loss": 0.0013,
      "step": 1297
    },
    {
      "epoch": 5.0310077519379846,
      "grad_norm": 0.498862087726593,
      "learning_rate": 4.496899224806202e-05,
      "loss": 0.0024,
      "step": 1298
    },
    {
      "epoch": 5.034883720930233,
      "grad_norm": 0.018739420920610428,
      "learning_rate": 4.496511627906977e-05,
      "loss": 0.0009,
      "step": 1299
    },
    {
      "epoch": 5.038759689922481,
      "grad_norm": 0.013493496924638748,
      "learning_rate": 4.496124031007753e-05,
      "loss": 0.001,
      "step": 1300
    },
    {
      "epoch": 5.042635658914729,
      "grad_norm": 2.764885663986206,
      "learning_rate": 4.495736434108527e-05,
      "loss": 0.1331,
      "step": 1301
    },
    {
      "epoch": 5.046511627906977,
      "grad_norm": 0.04372461885213852,
      "learning_rate": 4.4953488372093025e-05,
      "loss": 0.0012,
      "step": 1302
    },
    {
      "epoch": 5.050387596899225,
      "grad_norm": 0.01925700530409813,
      "learning_rate": 4.494961240310078e-05,
      "loss": 0.001,
      "step": 1303
    },
    {
      "epoch": 5.054263565891473,
      "grad_norm": 0.010491735301911831,
      "learning_rate": 4.494573643410853e-05,
      "loss": 0.0007,
      "step": 1304
    },
    {
      "epoch": 5.058139534883721,
      "grad_norm": 0.8049984574317932,
      "learning_rate": 4.494186046511628e-05,
      "loss": 0.0209,
      "step": 1305
    },
    {
      "epoch": 5.062015503875969,
      "grad_norm": 1.4569488763809204,
      "learning_rate": 4.493798449612403e-05,
      "loss": 0.1128,
      "step": 1306
    },
    {
      "epoch": 5.065891472868217,
      "grad_norm": 0.9498559236526489,
      "learning_rate": 4.493410852713179e-05,
      "loss": 0.0127,
      "step": 1307
    },
    {
      "epoch": 5.069767441860465,
      "grad_norm": 0.03524663671851158,
      "learning_rate": 4.493023255813953e-05,
      "loss": 0.0017,
      "step": 1308
    },
    {
      "epoch": 5.073643410852713,
      "grad_norm": 0.09928351640701294,
      "learning_rate": 4.492635658914729e-05,
      "loss": 0.0042,
      "step": 1309
    },
    {
      "epoch": 5.077519379844961,
      "grad_norm": 0.030174575746059418,
      "learning_rate": 4.492248062015504e-05,
      "loss": 0.0009,
      "step": 1310
    },
    {
      "epoch": 5.0813953488372094,
      "grad_norm": 0.02239868976175785,
      "learning_rate": 4.491860465116279e-05,
      "loss": 0.0011,
      "step": 1311
    },
    {
      "epoch": 5.0852713178294575,
      "grad_norm": 0.6477254033088684,
      "learning_rate": 4.491472868217054e-05,
      "loss": 0.0517,
      "step": 1312
    },
    {
      "epoch": 5.089147286821706,
      "grad_norm": 0.008267616853117943,
      "learning_rate": 4.4910852713178295e-05,
      "loss": 0.0005,
      "step": 1313
    },
    {
      "epoch": 5.093023255813954,
      "grad_norm": 34.925994873046875,
      "learning_rate": 4.490697674418605e-05,
      "loss": 0.7149,
      "step": 1314
    },
    {
      "epoch": 5.096899224806202,
      "grad_norm": 0.005379367619752884,
      "learning_rate": 4.49031007751938e-05,
      "loss": 0.0006,
      "step": 1315
    },
    {
      "epoch": 5.10077519379845,
      "grad_norm": 0.021232735365629196,
      "learning_rate": 4.489922480620155e-05,
      "loss": 0.0009,
      "step": 1316
    },
    {
      "epoch": 5.104651162790698,
      "grad_norm": 0.006576905958354473,
      "learning_rate": 4.4895348837209305e-05,
      "loss": 0.0005,
      "step": 1317
    },
    {
      "epoch": 5.108527131782946,
      "grad_norm": 0.007021994795650244,
      "learning_rate": 4.489147286821706e-05,
      "loss": 0.0006,
      "step": 1318
    },
    {
      "epoch": 5.112403100775194,
      "grad_norm": 0.008192155510187149,
      "learning_rate": 4.488759689922481e-05,
      "loss": 0.0008,
      "step": 1319
    },
    {
      "epoch": 5.116279069767442,
      "grad_norm": 0.016782796010375023,
      "learning_rate": 4.488372093023256e-05,
      "loss": 0.0009,
      "step": 1320
    },
    {
      "epoch": 5.12015503875969,
      "grad_norm": 0.9796075224876404,
      "learning_rate": 4.4879844961240314e-05,
      "loss": 0.0329,
      "step": 1321
    },
    {
      "epoch": 5.124031007751938,
      "grad_norm": 0.16791090369224548,
      "learning_rate": 4.487596899224806e-05,
      "loss": 0.0077,
      "step": 1322
    },
    {
      "epoch": 5.127906976744186,
      "grad_norm": 0.015936492010951042,
      "learning_rate": 4.487209302325582e-05,
      "loss": 0.001,
      "step": 1323
    },
    {
      "epoch": 5.131782945736434,
      "grad_norm": 0.14394067227840424,
      "learning_rate": 4.4868217054263565e-05,
      "loss": 0.0053,
      "step": 1324
    },
    {
      "epoch": 5.135658914728682,
      "grad_norm": 8.639734268188477,
      "learning_rate": 4.4864341085271324e-05,
      "loss": 0.3728,
      "step": 1325
    },
    {
      "epoch": 5.1395348837209305,
      "grad_norm": 0.02075290121138096,
      "learning_rate": 4.486046511627907e-05,
      "loss": 0.001,
      "step": 1326
    },
    {
      "epoch": 5.1434108527131785,
      "grad_norm": 0.017706042155623436,
      "learning_rate": 4.485658914728683e-05,
      "loss": 0.0011,
      "step": 1327
    },
    {
      "epoch": 5.147286821705427,
      "grad_norm": 1.1078283786773682,
      "learning_rate": 4.4852713178294575e-05,
      "loss": 0.0603,
      "step": 1328
    },
    {
      "epoch": 5.151162790697675,
      "grad_norm": 10.776978492736816,
      "learning_rate": 4.484883720930233e-05,
      "loss": 0.2213,
      "step": 1329
    },
    {
      "epoch": 5.155038759689923,
      "grad_norm": 0.004976534750312567,
      "learning_rate": 4.484496124031008e-05,
      "loss": 0.0005,
      "step": 1330
    },
    {
      "epoch": 5.158914728682171,
      "grad_norm": 0.05195353552699089,
      "learning_rate": 4.484108527131783e-05,
      "loss": 0.0007,
      "step": 1331
    },
    {
      "epoch": 5.162790697674419,
      "grad_norm": 0.004375820979475975,
      "learning_rate": 4.4837209302325584e-05,
      "loss": 0.0004,
      "step": 1332
    },
    {
      "epoch": 5.166666666666667,
      "grad_norm": 5.78228235244751,
      "learning_rate": 4.483333333333333e-05,
      "loss": 0.3105,
      "step": 1333
    },
    {
      "epoch": 5.170542635658915,
      "grad_norm": 0.005038677714765072,
      "learning_rate": 4.482945736434109e-05,
      "loss": 0.0005,
      "step": 1334
    },
    {
      "epoch": 5.174418604651163,
      "grad_norm": 6.202718734741211,
      "learning_rate": 4.4825581395348835e-05,
      "loss": 0.1459,
      "step": 1335
    },
    {
      "epoch": 5.178294573643411,
      "grad_norm": 5.724531173706055,
      "learning_rate": 4.4821705426356594e-05,
      "loss": 0.2256,
      "step": 1336
    },
    {
      "epoch": 5.182170542635659,
      "grad_norm": 0.021144786849617958,
      "learning_rate": 4.481782945736434e-05,
      "loss": 0.001,
      "step": 1337
    },
    {
      "epoch": 5.186046511627907,
      "grad_norm": 0.15950128436088562,
      "learning_rate": 4.48139534883721e-05,
      "loss": 0.0038,
      "step": 1338
    },
    {
      "epoch": 5.189922480620155,
      "grad_norm": 19.974748611450195,
      "learning_rate": 4.4810077519379844e-05,
      "loss": 0.543,
      "step": 1339
    },
    {
      "epoch": 5.1937984496124034,
      "grad_norm": 1.5541507005691528,
      "learning_rate": 4.48062015503876e-05,
      "loss": 0.0048,
      "step": 1340
    },
    {
      "epoch": 5.1976744186046515,
      "grad_norm": 13.111135482788086,
      "learning_rate": 4.480232558139535e-05,
      "loss": 0.1759,
      "step": 1341
    },
    {
      "epoch": 5.2015503875969,
      "grad_norm": 1.310258150100708,
      "learning_rate": 4.47984496124031e-05,
      "loss": 0.0073,
      "step": 1342
    },
    {
      "epoch": 5.205426356589148,
      "grad_norm": 0.8453399538993835,
      "learning_rate": 4.4794573643410854e-05,
      "loss": 0.0113,
      "step": 1343
    },
    {
      "epoch": 5.209302325581396,
      "grad_norm": 2.4757843017578125,
      "learning_rate": 4.4790697674418606e-05,
      "loss": 0.0375,
      "step": 1344
    },
    {
      "epoch": 5.213178294573644,
      "grad_norm": 0.005823705345392227,
      "learning_rate": 4.478682170542636e-05,
      "loss": 0.0005,
      "step": 1345
    },
    {
      "epoch": 5.217054263565892,
      "grad_norm": 5.820004940032959,
      "learning_rate": 4.478294573643411e-05,
      "loss": 0.1364,
      "step": 1346
    },
    {
      "epoch": 5.22093023255814,
      "grad_norm": 0.055486783385276794,
      "learning_rate": 4.4779069767441864e-05,
      "loss": 0.0022,
      "step": 1347
    },
    {
      "epoch": 5.224806201550388,
      "grad_norm": 5.27716588973999,
      "learning_rate": 4.4775193798449616e-05,
      "loss": 0.0068,
      "step": 1348
    },
    {
      "epoch": 5.228682170542636,
      "grad_norm": 3.250591516494751,
      "learning_rate": 4.477131782945737e-05,
      "loss": 0.7183,
      "step": 1349
    },
    {
      "epoch": 5.232558139534884,
      "grad_norm": 0.9892454147338867,
      "learning_rate": 4.476744186046512e-05,
      "loss": 0.0046,
      "step": 1350
    },
    {
      "epoch": 5.236434108527132,
      "grad_norm": 0.23400649428367615,
      "learning_rate": 4.476356589147287e-05,
      "loss": 0.0052,
      "step": 1351
    },
    {
      "epoch": 5.24031007751938,
      "grad_norm": 1.8299827575683594,
      "learning_rate": 4.4759689922480626e-05,
      "loss": 0.004,
      "step": 1352
    },
    {
      "epoch": 5.2441860465116275,
      "grad_norm": 41.39711380004883,
      "learning_rate": 4.475581395348837e-05,
      "loss": 0.0912,
      "step": 1353
    },
    {
      "epoch": 5.248062015503876,
      "grad_norm": 0.016513517126441002,
      "learning_rate": 4.475193798449613e-05,
      "loss": 0.0008,
      "step": 1354
    },
    {
      "epoch": 5.251937984496124,
      "grad_norm": 29.21140480041504,
      "learning_rate": 4.4748062015503876e-05,
      "loss": 0.2031,
      "step": 1355
    },
    {
      "epoch": 5.2558139534883725,
      "grad_norm": 509.736572265625,
      "learning_rate": 4.4744186046511636e-05,
      "loss": 0.7483,
      "step": 1356
    },
    {
      "epoch": 5.25968992248062,
      "grad_norm": 3.480884552001953,
      "learning_rate": 4.474031007751938e-05,
      "loss": 0.0061,
      "step": 1357
    },
    {
      "epoch": 5.263565891472869,
      "grad_norm": 6.996702194213867,
      "learning_rate": 4.4736434108527134e-05,
      "loss": 0.3055,
      "step": 1358
    },
    {
      "epoch": 5.267441860465116,
      "grad_norm": 24.204030990600586,
      "learning_rate": 4.4732558139534886e-05,
      "loss": 0.3397,
      "step": 1359
    },
    {
      "epoch": 5.271317829457364,
      "grad_norm": 0.12915131449699402,
      "learning_rate": 4.472868217054264e-05,
      "loss": 0.0022,
      "step": 1360
    },
    {
      "epoch": 5.275193798449612,
      "grad_norm": 0.06964405626058578,
      "learning_rate": 4.472480620155039e-05,
      "loss": 0.0023,
      "step": 1361
    },
    {
      "epoch": 5.27906976744186,
      "grad_norm": 0.8995063900947571,
      "learning_rate": 4.4720930232558137e-05,
      "loss": 0.0729,
      "step": 1362
    },
    {
      "epoch": 5.282945736434108,
      "grad_norm": 4.23158073425293,
      "learning_rate": 4.4717054263565896e-05,
      "loss": 0.0243,
      "step": 1363
    },
    {
      "epoch": 5.286821705426356,
      "grad_norm": 0.06118960678577423,
      "learning_rate": 4.471317829457364e-05,
      "loss": 0.0023,
      "step": 1364
    },
    {
      "epoch": 5.290697674418604,
      "grad_norm": 0.05274708569049835,
      "learning_rate": 4.47093023255814e-05,
      "loss": 0.0019,
      "step": 1365
    },
    {
      "epoch": 5.294573643410852,
      "grad_norm": 12.893120765686035,
      "learning_rate": 4.4705426356589146e-05,
      "loss": 0.305,
      "step": 1366
    },
    {
      "epoch": 5.2984496124031,
      "grad_norm": 0.059778641909360886,
      "learning_rate": 4.4701550387596905e-05,
      "loss": 0.0024,
      "step": 1367
    },
    {
      "epoch": 5.3023255813953485,
      "grad_norm": 0.03370385617017746,
      "learning_rate": 4.469767441860465e-05,
      "loss": 0.0017,
      "step": 1368
    },
    {
      "epoch": 5.3062015503875966,
      "grad_norm": 8.150434494018555,
      "learning_rate": 4.4693798449612403e-05,
      "loss": 0.1219,
      "step": 1369
    },
    {
      "epoch": 5.310077519379845,
      "grad_norm": 89.39058685302734,
      "learning_rate": 4.4689922480620156e-05,
      "loss": 2.0447,
      "step": 1370
    },
    {
      "epoch": 5.313953488372093,
      "grad_norm": 2.7955007553100586,
      "learning_rate": 4.468604651162791e-05,
      "loss": 0.1223,
      "step": 1371
    },
    {
      "epoch": 5.317829457364341,
      "grad_norm": 37.41913986206055,
      "learning_rate": 4.468217054263566e-05,
      "loss": 0.2867,
      "step": 1372
    },
    {
      "epoch": 5.321705426356589,
      "grad_norm": 0.06453832983970642,
      "learning_rate": 4.467829457364341e-05,
      "loss": 0.0016,
      "step": 1373
    },
    {
      "epoch": 5.325581395348837,
      "grad_norm": 0.09898266941308975,
      "learning_rate": 4.4674418604651166e-05,
      "loss": 0.0025,
      "step": 1374
    },
    {
      "epoch": 5.329457364341085,
      "grad_norm": 32.148250579833984,
      "learning_rate": 4.467054263565892e-05,
      "loss": 0.2654,
      "step": 1375
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 0.0970664694905281,
      "learning_rate": 4.466666666666667e-05,
      "loss": 0.0039,
      "step": 1376
    },
    {
      "epoch": 5.337209302325581,
      "grad_norm": 0.014857611618936062,
      "learning_rate": 4.466279069767442e-05,
      "loss": 0.0007,
      "step": 1377
    },
    {
      "epoch": 5.341085271317829,
      "grad_norm": 5.293773174285889,
      "learning_rate": 4.465891472868217e-05,
      "loss": 0.4971,
      "step": 1378
    },
    {
      "epoch": 5.344961240310077,
      "grad_norm": 6.693552494049072,
      "learning_rate": 4.465503875968993e-05,
      "loss": 0.9455,
      "step": 1379
    },
    {
      "epoch": 5.348837209302325,
      "grad_norm": 5.992580413818359,
      "learning_rate": 4.465116279069767e-05,
      "loss": 0.4576,
      "step": 1380
    },
    {
      "epoch": 5.352713178294573,
      "grad_norm": 8.490097045898438,
      "learning_rate": 4.464728682170543e-05,
      "loss": 0.0433,
      "step": 1381
    },
    {
      "epoch": 5.3565891472868215,
      "grad_norm": 1.2690860033035278,
      "learning_rate": 4.464341085271318e-05,
      "loss": 0.0088,
      "step": 1382
    },
    {
      "epoch": 5.3604651162790695,
      "grad_norm": 0.021028272807598114,
      "learning_rate": 4.463953488372094e-05,
      "loss": 0.0014,
      "step": 1383
    },
    {
      "epoch": 5.364341085271318,
      "grad_norm": 1.657160758972168,
      "learning_rate": 4.463565891472868e-05,
      "loss": 0.0142,
      "step": 1384
    },
    {
      "epoch": 5.368217054263566,
      "grad_norm": 0.01528090052306652,
      "learning_rate": 4.463178294573644e-05,
      "loss": 0.0008,
      "step": 1385
    },
    {
      "epoch": 5.372093023255814,
      "grad_norm": 28.082677841186523,
      "learning_rate": 4.462790697674419e-05,
      "loss": 0.7586,
      "step": 1386
    },
    {
      "epoch": 5.375968992248062,
      "grad_norm": 0.024285096675157547,
      "learning_rate": 4.462403100775194e-05,
      "loss": 0.0014,
      "step": 1387
    },
    {
      "epoch": 5.37984496124031,
      "grad_norm": 0.011361544020473957,
      "learning_rate": 4.462015503875969e-05,
      "loss": 0.0008,
      "step": 1388
    },
    {
      "epoch": 5.383720930232558,
      "grad_norm": 0.1457073986530304,
      "learning_rate": 4.461627906976744e-05,
      "loss": 0.0011,
      "step": 1389
    },
    {
      "epoch": 5.387596899224806,
      "grad_norm": 4.849518775939941,
      "learning_rate": 4.46124031007752e-05,
      "loss": 0.0114,
      "step": 1390
    },
    {
      "epoch": 5.391472868217054,
      "grad_norm": 7.995645999908447,
      "learning_rate": 4.460852713178294e-05,
      "loss": 0.2388,
      "step": 1391
    },
    {
      "epoch": 5.395348837209302,
      "grad_norm": 0.07237579673528671,
      "learning_rate": 4.46046511627907e-05,
      "loss": 0.0028,
      "step": 1392
    },
    {
      "epoch": 5.39922480620155,
      "grad_norm": 35.49345779418945,
      "learning_rate": 4.460077519379845e-05,
      "loss": 0.6786,
      "step": 1393
    },
    {
      "epoch": 5.403100775193798,
      "grad_norm": 0.012666690163314342,
      "learning_rate": 4.459689922480621e-05,
      "loss": 0.001,
      "step": 1394
    },
    {
      "epoch": 5.406976744186046,
      "grad_norm": 0.15405070781707764,
      "learning_rate": 4.459302325581395e-05,
      "loss": 0.0016,
      "step": 1395
    },
    {
      "epoch": 5.410852713178294,
      "grad_norm": 0.028349535539746284,
      "learning_rate": 4.4589147286821705e-05,
      "loss": 0.0013,
      "step": 1396
    },
    {
      "epoch": 5.4147286821705425,
      "grad_norm": 0.01311793178319931,
      "learning_rate": 4.458527131782946e-05,
      "loss": 0.001,
      "step": 1397
    },
    {
      "epoch": 5.4186046511627906,
      "grad_norm": 0.010086769238114357,
      "learning_rate": 4.458139534883721e-05,
      "loss": 0.0008,
      "step": 1398
    },
    {
      "epoch": 5.422480620155039,
      "grad_norm": 0.3180950880050659,
      "learning_rate": 4.457751937984496e-05,
      "loss": 0.0068,
      "step": 1399
    },
    {
      "epoch": 5.426356589147287,
      "grad_norm": 0.0372048020362854,
      "learning_rate": 4.4573643410852715e-05,
      "loss": 0.0014,
      "step": 1400
    },
    {
      "epoch": 5.430232558139535,
      "grad_norm": 0.01830730400979519,
      "learning_rate": 4.456976744186047e-05,
      "loss": 0.0013,
      "step": 1401
    },
    {
      "epoch": 5.434108527131783,
      "grad_norm": 0.8808587789535522,
      "learning_rate": 4.456589147286822e-05,
      "loss": 0.022,
      "step": 1402
    },
    {
      "epoch": 5.437984496124031,
      "grad_norm": 0.01716483198106289,
      "learning_rate": 4.456201550387597e-05,
      "loss": 0.0011,
      "step": 1403
    },
    {
      "epoch": 5.441860465116279,
      "grad_norm": 0.012552670203149319,
      "learning_rate": 4.4558139534883725e-05,
      "loss": 0.0008,
      "step": 1404
    },
    {
      "epoch": 5.445736434108527,
      "grad_norm": 0.010891794227063656,
      "learning_rate": 4.455426356589148e-05,
      "loss": 0.0008,
      "step": 1405
    },
    {
      "epoch": 5.449612403100775,
      "grad_norm": 0.02966046892106533,
      "learning_rate": 4.455038759689923e-05,
      "loss": 0.0009,
      "step": 1406
    },
    {
      "epoch": 5.453488372093023,
      "grad_norm": 3.5709924697875977,
      "learning_rate": 4.4546511627906975e-05,
      "loss": 0.2393,
      "step": 1407
    },
    {
      "epoch": 5.457364341085271,
      "grad_norm": 0.06080130860209465,
      "learning_rate": 4.4542635658914734e-05,
      "loss": 0.0018,
      "step": 1408
    },
    {
      "epoch": 5.461240310077519,
      "grad_norm": 2.5758979320526123,
      "learning_rate": 4.453875968992248e-05,
      "loss": 0.0134,
      "step": 1409
    },
    {
      "epoch": 5.465116279069767,
      "grad_norm": 0.019849568605422974,
      "learning_rate": 4.453488372093024e-05,
      "loss": 0.0008,
      "step": 1410
    },
    {
      "epoch": 5.4689922480620154,
      "grad_norm": 15.036417961120605,
      "learning_rate": 4.4531007751937985e-05,
      "loss": 0.0844,
      "step": 1411
    },
    {
      "epoch": 5.4728682170542635,
      "grad_norm": 0.08003632724285126,
      "learning_rate": 4.4527131782945744e-05,
      "loss": 0.0011,
      "step": 1412
    },
    {
      "epoch": 5.476744186046512,
      "grad_norm": 0.012156816199421883,
      "learning_rate": 4.452325581395349e-05,
      "loss": 0.0008,
      "step": 1413
    },
    {
      "epoch": 5.48062015503876,
      "grad_norm": 0.08840329945087433,
      "learning_rate": 4.451937984496124e-05,
      "loss": 0.0014,
      "step": 1414
    },
    {
      "epoch": 5.484496124031008,
      "grad_norm": 0.027398383244872093,
      "learning_rate": 4.4515503875968995e-05,
      "loss": 0.0012,
      "step": 1415
    },
    {
      "epoch": 5.488372093023256,
      "grad_norm": 0.1668839156627655,
      "learning_rate": 4.451162790697675e-05,
      "loss": 0.0019,
      "step": 1416
    },
    {
      "epoch": 5.492248062015504,
      "grad_norm": 136.85482788085938,
      "learning_rate": 4.45077519379845e-05,
      "loss": 0.2999,
      "step": 1417
    },
    {
      "epoch": 5.496124031007752,
      "grad_norm": 0.007974183186888695,
      "learning_rate": 4.4503875968992245e-05,
      "loss": 0.0006,
      "step": 1418
    },
    {
      "epoch": 5.5,
      "grad_norm": 14.695301055908203,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.0215,
      "step": 1419
    },
    {
      "epoch": 5.503875968992248,
      "grad_norm": 3.9562747478485107,
      "learning_rate": 4.449612403100775e-05,
      "loss": 0.1211,
      "step": 1420
    },
    {
      "epoch": 5.507751937984496,
      "grad_norm": 0.014073039405047894,
      "learning_rate": 4.449224806201551e-05,
      "loss": 0.0009,
      "step": 1421
    },
    {
      "epoch": 5.511627906976744,
      "grad_norm": 0.07108070701360703,
      "learning_rate": 4.4488372093023255e-05,
      "loss": 0.0028,
      "step": 1422
    },
    {
      "epoch": 5.515503875968992,
      "grad_norm": 7.618606090545654,
      "learning_rate": 4.4484496124031014e-05,
      "loss": 0.7368,
      "step": 1423
    },
    {
      "epoch": 5.51937984496124,
      "grad_norm": 0.1869523823261261,
      "learning_rate": 4.448062015503876e-05,
      "loss": 0.0054,
      "step": 1424
    },
    {
      "epoch": 5.523255813953488,
      "grad_norm": 0.01209952961653471,
      "learning_rate": 4.447674418604651e-05,
      "loss": 0.0007,
      "step": 1425
    },
    {
      "epoch": 5.5271317829457365,
      "grad_norm": 0.02524396777153015,
      "learning_rate": 4.4472868217054264e-05,
      "loss": 0.0008,
      "step": 1426
    },
    {
      "epoch": 5.5310077519379846,
      "grad_norm": 0.14292538166046143,
      "learning_rate": 4.446899224806202e-05,
      "loss": 0.0018,
      "step": 1427
    },
    {
      "epoch": 5.534883720930233,
      "grad_norm": 0.007565431296825409,
      "learning_rate": 4.446511627906977e-05,
      "loss": 0.0007,
      "step": 1428
    },
    {
      "epoch": 5.538759689922481,
      "grad_norm": 0.3130309581756592,
      "learning_rate": 4.446124031007752e-05,
      "loss": 0.0082,
      "step": 1429
    },
    {
      "epoch": 5.542635658914729,
      "grad_norm": 0.034396953880786896,
      "learning_rate": 4.4457364341085274e-05,
      "loss": 0.0018,
      "step": 1430
    },
    {
      "epoch": 5.546511627906977,
      "grad_norm": 0.00834423303604126,
      "learning_rate": 4.4453488372093027e-05,
      "loss": 0.0006,
      "step": 1431
    },
    {
      "epoch": 5.550387596899225,
      "grad_norm": 10.876808166503906,
      "learning_rate": 4.444961240310078e-05,
      "loss": 0.361,
      "step": 1432
    },
    {
      "epoch": 5.554263565891473,
      "grad_norm": 0.17033587396144867,
      "learning_rate": 4.444573643410853e-05,
      "loss": 0.0042,
      "step": 1433
    },
    {
      "epoch": 5.558139534883721,
      "grad_norm": 0.03748609498143196,
      "learning_rate": 4.4441860465116284e-05,
      "loss": 0.0014,
      "step": 1434
    },
    {
      "epoch": 5.562015503875969,
      "grad_norm": 0.01967647299170494,
      "learning_rate": 4.4437984496124036e-05,
      "loss": 0.0009,
      "step": 1435
    },
    {
      "epoch": 5.565891472868217,
      "grad_norm": 0.1309690773487091,
      "learning_rate": 4.443410852713178e-05,
      "loss": 0.0021,
      "step": 1436
    },
    {
      "epoch": 5.569767441860465,
      "grad_norm": 0.1066252589225769,
      "learning_rate": 4.443023255813954e-05,
      "loss": 0.0017,
      "step": 1437
    },
    {
      "epoch": 5.573643410852713,
      "grad_norm": 0.19209930300712585,
      "learning_rate": 4.442635658914729e-05,
      "loss": 0.0028,
      "step": 1438
    },
    {
      "epoch": 5.577519379844961,
      "grad_norm": 0.014138536527752876,
      "learning_rate": 4.4422480620155046e-05,
      "loss": 0.0008,
      "step": 1439
    },
    {
      "epoch": 5.5813953488372094,
      "grad_norm": 0.06617684662342072,
      "learning_rate": 4.441860465116279e-05,
      "loss": 0.0019,
      "step": 1440
    },
    {
      "epoch": 5.5852713178294575,
      "grad_norm": 0.1621973216533661,
      "learning_rate": 4.4414728682170544e-05,
      "loss": 0.0034,
      "step": 1441
    },
    {
      "epoch": 5.589147286821706,
      "grad_norm": 0.081951804459095,
      "learning_rate": 4.4410852713178296e-05,
      "loss": 0.0024,
      "step": 1442
    },
    {
      "epoch": 5.593023255813954,
      "grad_norm": 0.020367849618196487,
      "learning_rate": 4.440697674418605e-05,
      "loss": 0.0011,
      "step": 1443
    },
    {
      "epoch": 5.596899224806202,
      "grad_norm": 0.05130889266729355,
      "learning_rate": 4.44031007751938e-05,
      "loss": 0.0015,
      "step": 1444
    },
    {
      "epoch": 5.60077519379845,
      "grad_norm": 12.784784317016602,
      "learning_rate": 4.4399224806201554e-05,
      "loss": 0.3717,
      "step": 1445
    },
    {
      "epoch": 5.604651162790698,
      "grad_norm": 0.019184833392500877,
      "learning_rate": 4.4395348837209306e-05,
      "loss": 0.0007,
      "step": 1446
    },
    {
      "epoch": 5.608527131782946,
      "grad_norm": 0.004906613379716873,
      "learning_rate": 4.439147286821705e-05,
      "loss": 0.0005,
      "step": 1447
    },
    {
      "epoch": 5.612403100775194,
      "grad_norm": 7.223426818847656,
      "learning_rate": 4.438759689922481e-05,
      "loss": 0.0155,
      "step": 1448
    },
    {
      "epoch": 5.616279069767442,
      "grad_norm": 1.8958755731582642,
      "learning_rate": 4.4383720930232557e-05,
      "loss": 0.0125,
      "step": 1449
    },
    {
      "epoch": 5.62015503875969,
      "grad_norm": 0.007702184375375509,
      "learning_rate": 4.4379844961240316e-05,
      "loss": 0.0006,
      "step": 1450
    },
    {
      "epoch": 5.624031007751938,
      "grad_norm": 0.46981343626976013,
      "learning_rate": 4.437596899224806e-05,
      "loss": 0.0041,
      "step": 1451
    },
    {
      "epoch": 5.627906976744186,
      "grad_norm": 0.025065431371331215,
      "learning_rate": 4.437209302325582e-05,
      "loss": 0.0016,
      "step": 1452
    },
    {
      "epoch": 5.631782945736434,
      "grad_norm": 0.05602670833468437,
      "learning_rate": 4.4368217054263566e-05,
      "loss": 0.0015,
      "step": 1453
    },
    {
      "epoch": 5.635658914728682,
      "grad_norm": 10.353178977966309,
      "learning_rate": 4.436434108527132e-05,
      "loss": 0.1145,
      "step": 1454
    },
    {
      "epoch": 5.6395348837209305,
      "grad_norm": 9.837740898132324,
      "learning_rate": 4.436046511627907e-05,
      "loss": 0.1014,
      "step": 1455
    },
    {
      "epoch": 5.6434108527131785,
      "grad_norm": 0.034359727054834366,
      "learning_rate": 4.4356589147286824e-05,
      "loss": 0.0013,
      "step": 1456
    },
    {
      "epoch": 5.647286821705427,
      "grad_norm": 0.17338880896568298,
      "learning_rate": 4.4352713178294576e-05,
      "loss": 0.0009,
      "step": 1457
    },
    {
      "epoch": 5.651162790697675,
      "grad_norm": 24.012649536132812,
      "learning_rate": 4.434883720930233e-05,
      "loss": 0.2811,
      "step": 1458
    },
    {
      "epoch": 5.655038759689923,
      "grad_norm": 0.005384684074670076,
      "learning_rate": 4.434496124031008e-05,
      "loss": 0.0005,
      "step": 1459
    },
    {
      "epoch": 5.658914728682171,
      "grad_norm": 0.006391972303390503,
      "learning_rate": 4.434108527131783e-05,
      "loss": 0.0006,
      "step": 1460
    },
    {
      "epoch": 5.662790697674419,
      "grad_norm": 11.837058067321777,
      "learning_rate": 4.4337209302325586e-05,
      "loss": 0.2917,
      "step": 1461
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 34.71455764770508,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.0404,
      "step": 1462
    },
    {
      "epoch": 5.670542635658915,
      "grad_norm": 0.005436965264379978,
      "learning_rate": 4.432945736434109e-05,
      "loss": 0.0005,
      "step": 1463
    },
    {
      "epoch": 5.674418604651163,
      "grad_norm": 12.186114311218262,
      "learning_rate": 4.432558139534884e-05,
      "loss": 0.382,
      "step": 1464
    },
    {
      "epoch": 5.678294573643411,
      "grad_norm": 0.17665211856365204,
      "learning_rate": 4.432170542635659e-05,
      "loss": 0.0037,
      "step": 1465
    },
    {
      "epoch": 5.682170542635659,
      "grad_norm": 0.31178945302963257,
      "learning_rate": 4.431782945736434e-05,
      "loss": 0.0107,
      "step": 1466
    },
    {
      "epoch": 5.686046511627907,
      "grad_norm": 0.005311474669724703,
      "learning_rate": 4.431395348837209e-05,
      "loss": 0.0005,
      "step": 1467
    },
    {
      "epoch": 5.689922480620155,
      "grad_norm": 6.747470855712891,
      "learning_rate": 4.4310077519379846e-05,
      "loss": 0.6655,
      "step": 1468
    },
    {
      "epoch": 5.6937984496124034,
      "grad_norm": 0.020922470837831497,
      "learning_rate": 4.43062015503876e-05,
      "loss": 0.0008,
      "step": 1469
    },
    {
      "epoch": 5.6976744186046515,
      "grad_norm": 2.6129889488220215,
      "learning_rate": 4.430232558139535e-05,
      "loss": 0.057,
      "step": 1470
    },
    {
      "epoch": 5.7015503875969,
      "grad_norm": 0.008923683315515518,
      "learning_rate": 4.42984496124031e-05,
      "loss": 0.0006,
      "step": 1471
    },
    {
      "epoch": 5.705426356589148,
      "grad_norm": 17.564645767211914,
      "learning_rate": 4.4294573643410855e-05,
      "loss": 0.2323,
      "step": 1472
    },
    {
      "epoch": 5.709302325581396,
      "grad_norm": 0.01651865616440773,
      "learning_rate": 4.429069767441861e-05,
      "loss": 0.001,
      "step": 1473
    },
    {
      "epoch": 5.713178294573644,
      "grad_norm": 8.791983604431152,
      "learning_rate": 4.4286821705426354e-05,
      "loss": 1.0339,
      "step": 1474
    },
    {
      "epoch": 5.717054263565892,
      "grad_norm": 16.698232650756836,
      "learning_rate": 4.428294573643411e-05,
      "loss": 0.0685,
      "step": 1475
    },
    {
      "epoch": 5.720930232558139,
      "grad_norm": 5.565361022949219,
      "learning_rate": 4.427906976744186e-05,
      "loss": 0.8927,
      "step": 1476
    },
    {
      "epoch": 5.724806201550388,
      "grad_norm": 0.8147204518318176,
      "learning_rate": 4.427519379844962e-05,
      "loss": 0.0527,
      "step": 1477
    },
    {
      "epoch": 5.728682170542635,
      "grad_norm": 0.008382149040699005,
      "learning_rate": 4.427131782945736e-05,
      "loss": 0.0007,
      "step": 1478
    },
    {
      "epoch": 5.732558139534884,
      "grad_norm": 3.2848551273345947,
      "learning_rate": 4.426744186046512e-05,
      "loss": 0.132,
      "step": 1479
    },
    {
      "epoch": 5.736434108527131,
      "grad_norm": 0.006728938780725002,
      "learning_rate": 4.426356589147287e-05,
      "loss": 0.0006,
      "step": 1480
    },
    {
      "epoch": 5.74031007751938,
      "grad_norm": 2.2058265209198,
      "learning_rate": 4.425968992248062e-05,
      "loss": 0.0237,
      "step": 1481
    },
    {
      "epoch": 5.7441860465116275,
      "grad_norm": 0.009001071564853191,
      "learning_rate": 4.425581395348837e-05,
      "loss": 0.0005,
      "step": 1482
    },
    {
      "epoch": 5.748062015503876,
      "grad_norm": 0.05116284638643265,
      "learning_rate": 4.4251937984496125e-05,
      "loss": 0.001,
      "step": 1483
    },
    {
      "epoch": 5.751937984496124,
      "grad_norm": 0.02120722457766533,
      "learning_rate": 4.424806201550388e-05,
      "loss": 0.0009,
      "step": 1484
    },
    {
      "epoch": 5.7558139534883725,
      "grad_norm": 8.520161628723145,
      "learning_rate": 4.424418604651163e-05,
      "loss": 0.0446,
      "step": 1485
    },
    {
      "epoch": 5.75968992248062,
      "grad_norm": 0.018363483250141144,
      "learning_rate": 4.424031007751938e-05,
      "loss": 0.0008,
      "step": 1486
    },
    {
      "epoch": 5.763565891472869,
      "grad_norm": 0.014772418886423111,
      "learning_rate": 4.4236434108527135e-05,
      "loss": 0.0007,
      "step": 1487
    },
    {
      "epoch": 5.767441860465116,
      "grad_norm": 0.05316206440329552,
      "learning_rate": 4.423255813953489e-05,
      "loss": 0.0011,
      "step": 1488
    },
    {
      "epoch": 5.771317829457365,
      "grad_norm": 4.400915622711182,
      "learning_rate": 4.422868217054264e-05,
      "loss": 0.0115,
      "step": 1489
    },
    {
      "epoch": 5.775193798449612,
      "grad_norm": 0.20613960921764374,
      "learning_rate": 4.422480620155039e-05,
      "loss": 0.002,
      "step": 1490
    },
    {
      "epoch": 5.779069767441861,
      "grad_norm": 0.043162763118743896,
      "learning_rate": 4.4220930232558145e-05,
      "loss": 0.0011,
      "step": 1491
    },
    {
      "epoch": 5.782945736434108,
      "grad_norm": 1.8117926120758057,
      "learning_rate": 4.421705426356589e-05,
      "loss": 0.059,
      "step": 1492
    },
    {
      "epoch": 5.786821705426356,
      "grad_norm": 0.01497545838356018,
      "learning_rate": 4.421317829457364e-05,
      "loss": 0.0006,
      "step": 1493
    },
    {
      "epoch": 5.790697674418604,
      "grad_norm": 0.023968011140823364,
      "learning_rate": 4.4209302325581395e-05,
      "loss": 0.0012,
      "step": 1494
    },
    {
      "epoch": 5.794573643410852,
      "grad_norm": 0.049604322761297226,
      "learning_rate": 4.420542635658915e-05,
      "loss": 0.0009,
      "step": 1495
    },
    {
      "epoch": 5.7984496124031,
      "grad_norm": 0.012966597452759743,
      "learning_rate": 4.42015503875969e-05,
      "loss": 0.0006,
      "step": 1496
    },
    {
      "epoch": 5.8023255813953485,
      "grad_norm": 27.828319549560547,
      "learning_rate": 4.419767441860465e-05,
      "loss": 0.9686,
      "step": 1497
    },
    {
      "epoch": 5.8062015503875966,
      "grad_norm": 0.008839328773319721,
      "learning_rate": 4.4193798449612405e-05,
      "loss": 0.0007,
      "step": 1498
    },
    {
      "epoch": 5.810077519379845,
      "grad_norm": 0.009619688615202904,
      "learning_rate": 4.418992248062016e-05,
      "loss": 0.0006,
      "step": 1499
    },
    {
      "epoch": 5.813953488372093,
      "grad_norm": 0.05657922476530075,
      "learning_rate": 4.418604651162791e-05,
      "loss": 0.0012,
      "step": 1500
    },
    {
      "epoch": 5.817829457364341,
      "grad_norm": 0.39735502004623413,
      "learning_rate": 4.418217054263566e-05,
      "loss": 0.0204,
      "step": 1501
    },
    {
      "epoch": 5.821705426356589,
      "grad_norm": 0.012667362578213215,
      "learning_rate": 4.4178294573643415e-05,
      "loss": 0.0009,
      "step": 1502
    },
    {
      "epoch": 5.825581395348837,
      "grad_norm": 0.05197812616825104,
      "learning_rate": 4.417441860465116e-05,
      "loss": 0.0009,
      "step": 1503
    },
    {
      "epoch": 5.829457364341085,
      "grad_norm": 0.004909557290375233,
      "learning_rate": 4.417054263565892e-05,
      "loss": 0.0005,
      "step": 1504
    },
    {
      "epoch": 5.833333333333333,
      "grad_norm": 0.014424686320126057,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 0.0009,
      "step": 1505
    },
    {
      "epoch": 5.837209302325581,
      "grad_norm": 0.005154761020094156,
      "learning_rate": 4.4162790697674424e-05,
      "loss": 0.0005,
      "step": 1506
    },
    {
      "epoch": 5.841085271317829,
      "grad_norm": 0.07945197075605392,
      "learning_rate": 4.415891472868217e-05,
      "loss": 0.003,
      "step": 1507
    },
    {
      "epoch": 5.844961240310077,
      "grad_norm": 0.014731013216078281,
      "learning_rate": 4.415503875968993e-05,
      "loss": 0.001,
      "step": 1508
    },
    {
      "epoch": 5.848837209302325,
      "grad_norm": 0.10944399982690811,
      "learning_rate": 4.4151162790697675e-05,
      "loss": 0.0048,
      "step": 1509
    },
    {
      "epoch": 5.852713178294573,
      "grad_norm": 0.550212562084198,
      "learning_rate": 4.414728682170543e-05,
      "loss": 0.0205,
      "step": 1510
    },
    {
      "epoch": 5.8565891472868215,
      "grad_norm": 0.0055612120777368546,
      "learning_rate": 4.414341085271318e-05,
      "loss": 0.0004,
      "step": 1511
    },
    {
      "epoch": 5.8604651162790695,
      "grad_norm": 12.337143898010254,
      "learning_rate": 4.413953488372093e-05,
      "loss": 0.1328,
      "step": 1512
    },
    {
      "epoch": 5.864341085271318,
      "grad_norm": 0.030352909117937088,
      "learning_rate": 4.4135658914728684e-05,
      "loss": 0.0016,
      "step": 1513
    },
    {
      "epoch": 5.868217054263566,
      "grad_norm": 0.02201160043478012,
      "learning_rate": 4.413178294573644e-05,
      "loss": 0.0008,
      "step": 1514
    },
    {
      "epoch": 5.872093023255814,
      "grad_norm": 4.652282238006592,
      "learning_rate": 4.412790697674419e-05,
      "loss": 0.5349,
      "step": 1515
    },
    {
      "epoch": 5.875968992248062,
      "grad_norm": 2.3989744186401367,
      "learning_rate": 4.412403100775194e-05,
      "loss": 0.3897,
      "step": 1516
    },
    {
      "epoch": 5.87984496124031,
      "grad_norm": 0.03686516359448433,
      "learning_rate": 4.4120155038759694e-05,
      "loss": 0.0012,
      "step": 1517
    },
    {
      "epoch": 5.883720930232558,
      "grad_norm": 0.2639995515346527,
      "learning_rate": 4.4116279069767447e-05,
      "loss": 0.0016,
      "step": 1518
    },
    {
      "epoch": 5.887596899224806,
      "grad_norm": 0.02848522551357746,
      "learning_rate": 4.41124031007752e-05,
      "loss": 0.0015,
      "step": 1519
    },
    {
      "epoch": 5.891472868217054,
      "grad_norm": 0.024770881980657578,
      "learning_rate": 4.4108527131782945e-05,
      "loss": 0.0012,
      "step": 1520
    },
    {
      "epoch": 5.895348837209302,
      "grad_norm": 12.366087913513184,
      "learning_rate": 4.41046511627907e-05,
      "loss": 0.2814,
      "step": 1521
    },
    {
      "epoch": 5.89922480620155,
      "grad_norm": 0.022626319900155067,
      "learning_rate": 4.410077519379845e-05,
      "loss": 0.0007,
      "step": 1522
    },
    {
      "epoch": 5.903100775193798,
      "grad_norm": 0.01374818105250597,
      "learning_rate": 4.40968992248062e-05,
      "loss": 0.0007,
      "step": 1523
    },
    {
      "epoch": 5.906976744186046,
      "grad_norm": 0.010637223720550537,
      "learning_rate": 4.4093023255813954e-05,
      "loss": 0.0006,
      "step": 1524
    },
    {
      "epoch": 5.910852713178294,
      "grad_norm": 0.012975117191672325,
      "learning_rate": 4.408914728682171e-05,
      "loss": 0.0009,
      "step": 1525
    },
    {
      "epoch": 5.9147286821705425,
      "grad_norm": 0.013307932764291763,
      "learning_rate": 4.408527131782946e-05,
      "loss": 0.0006,
      "step": 1526
    },
    {
      "epoch": 5.9186046511627906,
      "grad_norm": 0.022459406405687332,
      "learning_rate": 4.408139534883721e-05,
      "loss": 0.0009,
      "step": 1527
    },
    {
      "epoch": 5.922480620155039,
      "grad_norm": 0.005998828448355198,
      "learning_rate": 4.4077519379844964e-05,
      "loss": 0.0004,
      "step": 1528
    },
    {
      "epoch": 5.926356589147287,
      "grad_norm": 3.285226583480835,
      "learning_rate": 4.4073643410852716e-05,
      "loss": 0.0862,
      "step": 1529
    },
    {
      "epoch": 5.930232558139535,
      "grad_norm": 0.007945528253912926,
      "learning_rate": 4.406976744186047e-05,
      "loss": 0.0006,
      "step": 1530
    },
    {
      "epoch": 5.934108527131783,
      "grad_norm": 0.20516178011894226,
      "learning_rate": 4.406589147286822e-05,
      "loss": 0.0018,
      "step": 1531
    },
    {
      "epoch": 5.937984496124031,
      "grad_norm": 5.728280067443848,
      "learning_rate": 4.406201550387597e-05,
      "loss": 0.1946,
      "step": 1532
    },
    {
      "epoch": 5.941860465116279,
      "grad_norm": 18.96640968322754,
      "learning_rate": 4.4058139534883726e-05,
      "loss": 1.3957,
      "step": 1533
    },
    {
      "epoch": 5.945736434108527,
      "grad_norm": 24.756593704223633,
      "learning_rate": 4.405426356589147e-05,
      "loss": 0.5487,
      "step": 1534
    },
    {
      "epoch": 5.949612403100775,
      "grad_norm": 0.005034069996327162,
      "learning_rate": 4.405038759689923e-05,
      "loss": 0.0005,
      "step": 1535
    },
    {
      "epoch": 5.953488372093023,
      "grad_norm": 0.032644350081682205,
      "learning_rate": 4.4046511627906977e-05,
      "loss": 0.0011,
      "step": 1536
    },
    {
      "epoch": 5.957364341085271,
      "grad_norm": 0.006430202163755894,
      "learning_rate": 4.4042635658914736e-05,
      "loss": 0.0006,
      "step": 1537
    },
    {
      "epoch": 5.961240310077519,
      "grad_norm": 0.31712567806243896,
      "learning_rate": 4.403875968992248e-05,
      "loss": 0.0137,
      "step": 1538
    },
    {
      "epoch": 5.965116279069767,
      "grad_norm": 4.599237442016602,
      "learning_rate": 4.4034883720930234e-05,
      "loss": 0.1114,
      "step": 1539
    },
    {
      "epoch": 5.9689922480620154,
      "grad_norm": 0.0047249337658286095,
      "learning_rate": 4.4031007751937986e-05,
      "loss": 0.0004,
      "step": 1540
    },
    {
      "epoch": 5.9728682170542635,
      "grad_norm": 0.007097626104950905,
      "learning_rate": 4.402713178294574e-05,
      "loss": 0.0005,
      "step": 1541
    },
    {
      "epoch": 5.976744186046512,
      "grad_norm": 13.810590744018555,
      "learning_rate": 4.402325581395349e-05,
      "loss": 0.3091,
      "step": 1542
    },
    {
      "epoch": 5.98062015503876,
      "grad_norm": 4.3912458419799805,
      "learning_rate": 4.4019379844961244e-05,
      "loss": 0.0329,
      "step": 1543
    },
    {
      "epoch": 5.984496124031008,
      "grad_norm": 10.481522560119629,
      "learning_rate": 4.4015503875968996e-05,
      "loss": 0.6148,
      "step": 1544
    },
    {
      "epoch": 5.988372093023256,
      "grad_norm": 13.582225799560547,
      "learning_rate": 4.401162790697675e-05,
      "loss": 0.5549,
      "step": 1545
    },
    {
      "epoch": 5.992248062015504,
      "grad_norm": 11.75457763671875,
      "learning_rate": 4.40077519379845e-05,
      "loss": 0.3345,
      "step": 1546
    },
    {
      "epoch": 5.996124031007752,
      "grad_norm": 0.08702412247657776,
      "learning_rate": 4.4003875968992246e-05,
      "loss": 0.0044,
      "step": 1547
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.7670760750770569,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0077,
      "step": 1548
    },
    {
      "epoch": 6.003875968992248,
      "grad_norm": 0.22845366597175598,
      "learning_rate": 4.399612403100775e-05,
      "loss": 0.0101,
      "step": 1549
    },
    {
      "epoch": 6.007751937984496,
      "grad_norm": 0.013315762393176556,
      "learning_rate": 4.3992248062015504e-05,
      "loss": 0.0008,
      "step": 1550
    },
    {
      "epoch": 6.011627906976744,
      "grad_norm": 0.07485413551330566,
      "learning_rate": 4.3988372093023256e-05,
      "loss": 0.0019,
      "step": 1551
    },
    {
      "epoch": 6.015503875968992,
      "grad_norm": 0.653447151184082,
      "learning_rate": 4.398449612403101e-05,
      "loss": 0.0189,
      "step": 1552
    },
    {
      "epoch": 6.01937984496124,
      "grad_norm": 0.06888062506914139,
      "learning_rate": 4.398062015503876e-05,
      "loss": 0.0015,
      "step": 1553
    },
    {
      "epoch": 6.023255813953488,
      "grad_norm": 2.179124116897583,
      "learning_rate": 4.397674418604651e-05,
      "loss": 0.0296,
      "step": 1554
    },
    {
      "epoch": 6.0271317829457365,
      "grad_norm": 0.25000888109207153,
      "learning_rate": 4.3972868217054266e-05,
      "loss": 0.0031,
      "step": 1555
    },
    {
      "epoch": 6.0310077519379846,
      "grad_norm": 9.11559009552002,
      "learning_rate": 4.396899224806202e-05,
      "loss": 0.0938,
      "step": 1556
    },
    {
      "epoch": 6.034883720930233,
      "grad_norm": 54.425376892089844,
      "learning_rate": 4.396511627906977e-05,
      "loss": 0.1605,
      "step": 1557
    },
    {
      "epoch": 6.038759689922481,
      "grad_norm": 0.04637646675109863,
      "learning_rate": 4.396124031007752e-05,
      "loss": 0.0017,
      "step": 1558
    },
    {
      "epoch": 6.042635658914729,
      "grad_norm": 0.014015738852322102,
      "learning_rate": 4.395736434108527e-05,
      "loss": 0.0006,
      "step": 1559
    },
    {
      "epoch": 6.046511627906977,
      "grad_norm": 0.05157361179590225,
      "learning_rate": 4.395348837209303e-05,
      "loss": 0.0009,
      "step": 1560
    },
    {
      "epoch": 6.050387596899225,
      "grad_norm": 0.026209859177470207,
      "learning_rate": 4.3949612403100774e-05,
      "loss": 0.0007,
      "step": 1561
    },
    {
      "epoch": 6.054263565891473,
      "grad_norm": 0.14191584289073944,
      "learning_rate": 4.394573643410853e-05,
      "loss": 0.0059,
      "step": 1562
    },
    {
      "epoch": 6.058139534883721,
      "grad_norm": 0.10625725239515305,
      "learning_rate": 4.394186046511628e-05,
      "loss": 0.003,
      "step": 1563
    },
    {
      "epoch": 6.062015503875969,
      "grad_norm": 0.028763422742486,
      "learning_rate": 4.393798449612404e-05,
      "loss": 0.0009,
      "step": 1564
    },
    {
      "epoch": 6.065891472868217,
      "grad_norm": 1.351342797279358,
      "learning_rate": 4.393410852713178e-05,
      "loss": 0.0093,
      "step": 1565
    },
    {
      "epoch": 6.069767441860465,
      "grad_norm": 0.6253318190574646,
      "learning_rate": 4.393023255813954e-05,
      "loss": 0.0037,
      "step": 1566
    },
    {
      "epoch": 6.073643410852713,
      "grad_norm": 2.9361774921417236,
      "learning_rate": 4.392635658914729e-05,
      "loss": 0.4222,
      "step": 1567
    },
    {
      "epoch": 6.077519379844961,
      "grad_norm": 2.8335466384887695,
      "learning_rate": 4.392248062015504e-05,
      "loss": 0.0163,
      "step": 1568
    },
    {
      "epoch": 6.0813953488372094,
      "grad_norm": 0.05791892483830452,
      "learning_rate": 4.391860465116279e-05,
      "loss": 0.0025,
      "step": 1569
    },
    {
      "epoch": 6.0852713178294575,
      "grad_norm": 0.0712476372718811,
      "learning_rate": 4.3914728682170545e-05,
      "loss": 0.0009,
      "step": 1570
    },
    {
      "epoch": 6.089147286821706,
      "grad_norm": 0.015714988112449646,
      "learning_rate": 4.39108527131783e-05,
      "loss": 0.0006,
      "step": 1571
    },
    {
      "epoch": 6.093023255813954,
      "grad_norm": 0.01136528979986906,
      "learning_rate": 4.390697674418605e-05,
      "loss": 0.001,
      "step": 1572
    },
    {
      "epoch": 6.096899224806202,
      "grad_norm": 0.1617811769247055,
      "learning_rate": 4.39031007751938e-05,
      "loss": 0.0042,
      "step": 1573
    },
    {
      "epoch": 6.10077519379845,
      "grad_norm": 0.1814516931772232,
      "learning_rate": 4.389922480620155e-05,
      "loss": 0.0044,
      "step": 1574
    },
    {
      "epoch": 6.104651162790698,
      "grad_norm": 0.049944449216127396,
      "learning_rate": 4.389534883720931e-05,
      "loss": 0.0012,
      "step": 1575
    },
    {
      "epoch": 6.108527131782946,
      "grad_norm": 0.4572392404079437,
      "learning_rate": 4.389147286821705e-05,
      "loss": 0.005,
      "step": 1576
    },
    {
      "epoch": 6.112403100775194,
      "grad_norm": 4.657104015350342,
      "learning_rate": 4.3887596899224806e-05,
      "loss": 0.0416,
      "step": 1577
    },
    {
      "epoch": 6.116279069767442,
      "grad_norm": 32.003082275390625,
      "learning_rate": 4.388372093023256e-05,
      "loss": 1.0982,
      "step": 1578
    },
    {
      "epoch": 6.12015503875969,
      "grad_norm": 0.007665290962904692,
      "learning_rate": 4.387984496124031e-05,
      "loss": 0.0005,
      "step": 1579
    },
    {
      "epoch": 6.124031007751938,
      "grad_norm": 0.012348570860922337,
      "learning_rate": 4.387596899224806e-05,
      "loss": 0.0006,
      "step": 1580
    },
    {
      "epoch": 6.127906976744186,
      "grad_norm": 0.015459251590073109,
      "learning_rate": 4.3872093023255815e-05,
      "loss": 0.0007,
      "step": 1581
    },
    {
      "epoch": 6.131782945736434,
      "grad_norm": 0.006205687765032053,
      "learning_rate": 4.386821705426357e-05,
      "loss": 0.0005,
      "step": 1582
    },
    {
      "epoch": 6.135658914728682,
      "grad_norm": 0.024450816214084625,
      "learning_rate": 4.386434108527132e-05,
      "loss": 0.001,
      "step": 1583
    },
    {
      "epoch": 6.1395348837209305,
      "grad_norm": 0.02449733577668667,
      "learning_rate": 4.386046511627907e-05,
      "loss": 0.0008,
      "step": 1584
    },
    {
      "epoch": 6.1434108527131785,
      "grad_norm": 0.1798735409975052,
      "learning_rate": 4.3856589147286825e-05,
      "loss": 0.0014,
      "step": 1585
    },
    {
      "epoch": 6.147286821705427,
      "grad_norm": 0.020969541743397713,
      "learning_rate": 4.385271317829458e-05,
      "loss": 0.0009,
      "step": 1586
    },
    {
      "epoch": 6.151162790697675,
      "grad_norm": 0.04364040866494179,
      "learning_rate": 4.384883720930233e-05,
      "loss": 0.001,
      "step": 1587
    },
    {
      "epoch": 6.155038759689923,
      "grad_norm": 11.94217586517334,
      "learning_rate": 4.3844961240310075e-05,
      "loss": 0.0284,
      "step": 1588
    },
    {
      "epoch": 6.158914728682171,
      "grad_norm": 76.39641571044922,
      "learning_rate": 4.3841085271317835e-05,
      "loss": 0.5824,
      "step": 1589
    },
    {
      "epoch": 6.162790697674419,
      "grad_norm": 6.793403625488281,
      "learning_rate": 4.383720930232558e-05,
      "loss": 0.1245,
      "step": 1590
    },
    {
      "epoch": 6.166666666666667,
      "grad_norm": 0.08505560457706451,
      "learning_rate": 4.383333333333334e-05,
      "loss": 0.0024,
      "step": 1591
    },
    {
      "epoch": 6.170542635658915,
      "grad_norm": 0.006609700154513121,
      "learning_rate": 4.3829457364341085e-05,
      "loss": 0.0005,
      "step": 1592
    },
    {
      "epoch": 6.174418604651163,
      "grad_norm": 0.00735063012689352,
      "learning_rate": 4.3825581395348844e-05,
      "loss": 0.0006,
      "step": 1593
    },
    {
      "epoch": 6.178294573643411,
      "grad_norm": 9.137896537780762,
      "learning_rate": 4.382170542635659e-05,
      "loss": 0.0699,
      "step": 1594
    },
    {
      "epoch": 6.182170542635659,
      "grad_norm": 0.026484502479434013,
      "learning_rate": 4.381782945736434e-05,
      "loss": 0.0008,
      "step": 1595
    },
    {
      "epoch": 6.186046511627907,
      "grad_norm": 0.005307742860168219,
      "learning_rate": 4.3813953488372095e-05,
      "loss": 0.0005,
      "step": 1596
    },
    {
      "epoch": 6.189922480620155,
      "grad_norm": 0.006027930416166782,
      "learning_rate": 4.381007751937985e-05,
      "loss": 0.0005,
      "step": 1597
    },
    {
      "epoch": 6.1937984496124034,
      "grad_norm": 0.18368470668792725,
      "learning_rate": 4.38062015503876e-05,
      "loss": 0.0035,
      "step": 1598
    },
    {
      "epoch": 6.1976744186046515,
      "grad_norm": 0.005688642151653767,
      "learning_rate": 4.380232558139535e-05,
      "loss": 0.0005,
      "step": 1599
    },
    {
      "epoch": 6.2015503875969,
      "grad_norm": 1.7037385702133179,
      "learning_rate": 4.3798449612403104e-05,
      "loss": 0.2977,
      "step": 1600
    },
    {
      "epoch": 6.205426356589148,
      "grad_norm": 0.025758612900972366,
      "learning_rate": 4.379457364341085e-05,
      "loss": 0.0013,
      "step": 1601
    },
    {
      "epoch": 6.209302325581396,
      "grad_norm": 0.017656588926911354,
      "learning_rate": 4.379069767441861e-05,
      "loss": 0.0005,
      "step": 1602
    },
    {
      "epoch": 6.213178294573644,
      "grad_norm": 0.0059101334773004055,
      "learning_rate": 4.3786821705426355e-05,
      "loss": 0.0005,
      "step": 1603
    },
    {
      "epoch": 6.217054263565892,
      "grad_norm": 0.11143995821475983,
      "learning_rate": 4.3782945736434114e-05,
      "loss": 0.002,
      "step": 1604
    },
    {
      "epoch": 6.22093023255814,
      "grad_norm": 0.5146636366844177,
      "learning_rate": 4.377906976744186e-05,
      "loss": 0.0138,
      "step": 1605
    },
    {
      "epoch": 6.224806201550388,
      "grad_norm": 2.315492868423462,
      "learning_rate": 4.377519379844961e-05,
      "loss": 0.0116,
      "step": 1606
    },
    {
      "epoch": 6.228682170542636,
      "grad_norm": 0.006462306249886751,
      "learning_rate": 4.3771317829457365e-05,
      "loss": 0.0005,
      "step": 1607
    },
    {
      "epoch": 6.232558139534884,
      "grad_norm": 7.300225734710693,
      "learning_rate": 4.376744186046512e-05,
      "loss": 0.5627,
      "step": 1608
    },
    {
      "epoch": 6.236434108527132,
      "grad_norm": 0.05488152801990509,
      "learning_rate": 4.376356589147287e-05,
      "loss": 0.0016,
      "step": 1609
    },
    {
      "epoch": 6.24031007751938,
      "grad_norm": 0.3326055109500885,
      "learning_rate": 4.375968992248062e-05,
      "loss": 0.0074,
      "step": 1610
    },
    {
      "epoch": 6.2441860465116275,
      "grad_norm": 2.6667017936706543,
      "learning_rate": 4.3755813953488374e-05,
      "loss": 0.163,
      "step": 1611
    },
    {
      "epoch": 6.248062015503876,
      "grad_norm": 0.036419324576854706,
      "learning_rate": 4.375193798449613e-05,
      "loss": 0.002,
      "step": 1612
    },
    {
      "epoch": 6.251937984496124,
      "grad_norm": 0.008351302705705166,
      "learning_rate": 4.374806201550388e-05,
      "loss": 0.0006,
      "step": 1613
    },
    {
      "epoch": 6.2558139534883725,
      "grad_norm": 0.0076242731884121895,
      "learning_rate": 4.374418604651163e-05,
      "loss": 0.0006,
      "step": 1614
    },
    {
      "epoch": 6.25968992248062,
      "grad_norm": 0.005237560253590345,
      "learning_rate": 4.3740310077519384e-05,
      "loss": 0.0005,
      "step": 1615
    },
    {
      "epoch": 6.263565891472869,
      "grad_norm": 0.005987727083265781,
      "learning_rate": 4.3736434108527136e-05,
      "loss": 0.0005,
      "step": 1616
    },
    {
      "epoch": 6.267441860465116,
      "grad_norm": 0.007289975881576538,
      "learning_rate": 4.373255813953488e-05,
      "loss": 0.0005,
      "step": 1617
    },
    {
      "epoch": 6.271317829457364,
      "grad_norm": 25.91312599182129,
      "learning_rate": 4.372868217054264e-05,
      "loss": 0.9732,
      "step": 1618
    },
    {
      "epoch": 6.275193798449612,
      "grad_norm": 6.430647373199463,
      "learning_rate": 4.372480620155039e-05,
      "loss": 0.6998,
      "step": 1619
    },
    {
      "epoch": 6.27906976744186,
      "grad_norm": 5.709750175476074,
      "learning_rate": 4.3720930232558146e-05,
      "loss": 0.407,
      "step": 1620
    },
    {
      "epoch": 6.282945736434108,
      "grad_norm": 0.004843719303607941,
      "learning_rate": 4.371705426356589e-05,
      "loss": 0.0004,
      "step": 1621
    },
    {
      "epoch": 6.286821705426356,
      "grad_norm": 0.005880271550267935,
      "learning_rate": 4.371317829457365e-05,
      "loss": 0.0005,
      "step": 1622
    },
    {
      "epoch": 6.290697674418604,
      "grad_norm": 0.00521570211276412,
      "learning_rate": 4.3709302325581397e-05,
      "loss": 0.0005,
      "step": 1623
    },
    {
      "epoch": 6.294573643410852,
      "grad_norm": 0.07722742110490799,
      "learning_rate": 4.370542635658915e-05,
      "loss": 0.002,
      "step": 1624
    },
    {
      "epoch": 6.2984496124031,
      "grad_norm": 0.062214553356170654,
      "learning_rate": 4.37015503875969e-05,
      "loss": 0.0021,
      "step": 1625
    },
    {
      "epoch": 6.3023255813953485,
      "grad_norm": 3.926398277282715,
      "learning_rate": 4.3697674418604654e-05,
      "loss": 0.0243,
      "step": 1626
    },
    {
      "epoch": 6.3062015503875966,
      "grad_norm": 0.020399080589413643,
      "learning_rate": 4.3693798449612406e-05,
      "loss": 0.0009,
      "step": 1627
    },
    {
      "epoch": 6.310077519379845,
      "grad_norm": 0.027207151055336,
      "learning_rate": 4.368992248062015e-05,
      "loss": 0.0009,
      "step": 1628
    },
    {
      "epoch": 6.313953488372093,
      "grad_norm": 0.08611191064119339,
      "learning_rate": 4.368604651162791e-05,
      "loss": 0.0018,
      "step": 1629
    },
    {
      "epoch": 6.317829457364341,
      "grad_norm": 31.282819747924805,
      "learning_rate": 4.368217054263566e-05,
      "loss": 0.1264,
      "step": 1630
    },
    {
      "epoch": 6.321705426356589,
      "grad_norm": 0.02008633501827717,
      "learning_rate": 4.3678294573643416e-05,
      "loss": 0.0009,
      "step": 1631
    },
    {
      "epoch": 6.325581395348837,
      "grad_norm": 0.022361844778060913,
      "learning_rate": 4.367441860465116e-05,
      "loss": 0.0009,
      "step": 1632
    },
    {
      "epoch": 6.329457364341085,
      "grad_norm": 0.10536081343889236,
      "learning_rate": 4.367054263565892e-05,
      "loss": 0.0018,
      "step": 1633
    },
    {
      "epoch": 6.333333333333333,
      "grad_norm": 0.01679675653576851,
      "learning_rate": 4.3666666666666666e-05,
      "loss": 0.0008,
      "step": 1634
    },
    {
      "epoch": 6.337209302325581,
      "grad_norm": 1.9508920907974243,
      "learning_rate": 4.366279069767442e-05,
      "loss": 0.0571,
      "step": 1635
    },
    {
      "epoch": 6.341085271317829,
      "grad_norm": 0.023839015513658524,
      "learning_rate": 4.365891472868217e-05,
      "loss": 0.0011,
      "step": 1636
    },
    {
      "epoch": 6.344961240310077,
      "grad_norm": 0.05586991086602211,
      "learning_rate": 4.3655038759689924e-05,
      "loss": 0.0023,
      "step": 1637
    },
    {
      "epoch": 6.348837209302325,
      "grad_norm": 0.2049880474805832,
      "learning_rate": 4.3651162790697676e-05,
      "loss": 0.0066,
      "step": 1638
    },
    {
      "epoch": 6.352713178294573,
      "grad_norm": 0.008388746529817581,
      "learning_rate": 4.364728682170543e-05,
      "loss": 0.0006,
      "step": 1639
    },
    {
      "epoch": 6.3565891472868215,
      "grad_norm": 0.01068540196865797,
      "learning_rate": 4.364341085271318e-05,
      "loss": 0.0008,
      "step": 1640
    },
    {
      "epoch": 6.3604651162790695,
      "grad_norm": 18.119550704956055,
      "learning_rate": 4.3639534883720933e-05,
      "loss": 0.0844,
      "step": 1641
    },
    {
      "epoch": 6.364341085271318,
      "grad_norm": 100.76809692382812,
      "learning_rate": 4.3635658914728686e-05,
      "loss": 0.2255,
      "step": 1642
    },
    {
      "epoch": 6.368217054263566,
      "grad_norm": 1.0883182287216187,
      "learning_rate": 4.363178294573644e-05,
      "loss": 0.012,
      "step": 1643
    },
    {
      "epoch": 6.372093023255814,
      "grad_norm": 0.005941372364759445,
      "learning_rate": 4.3627906976744184e-05,
      "loss": 0.0005,
      "step": 1644
    },
    {
      "epoch": 6.375968992248062,
      "grad_norm": 0.10430321097373962,
      "learning_rate": 4.362403100775194e-05,
      "loss": 0.0043,
      "step": 1645
    },
    {
      "epoch": 6.37984496124031,
      "grad_norm": 0.04422376677393913,
      "learning_rate": 4.362015503875969e-05,
      "loss": 0.0016,
      "step": 1646
    },
    {
      "epoch": 6.383720930232558,
      "grad_norm": 0.0057784635573625565,
      "learning_rate": 4.361627906976745e-05,
      "loss": 0.0005,
      "step": 1647
    },
    {
      "epoch": 6.387596899224806,
      "grad_norm": 12.277888298034668,
      "learning_rate": 4.3612403100775194e-05,
      "loss": 0.0249,
      "step": 1648
    },
    {
      "epoch": 6.391472868217054,
      "grad_norm": 0.18426169455051422,
      "learning_rate": 4.360852713178295e-05,
      "loss": 0.0038,
      "step": 1649
    },
    {
      "epoch": 6.395348837209302,
      "grad_norm": 14.497314453125,
      "learning_rate": 4.36046511627907e-05,
      "loss": 0.0747,
      "step": 1650
    },
    {
      "epoch": 6.39922480620155,
      "grad_norm": 2.1894266605377197,
      "learning_rate": 4.360077519379846e-05,
      "loss": 0.0744,
      "step": 1651
    },
    {
      "epoch": 6.403100775193798,
      "grad_norm": 0.00954180397093296,
      "learning_rate": 4.35968992248062e-05,
      "loss": 0.0007,
      "step": 1652
    },
    {
      "epoch": 6.406976744186046,
      "grad_norm": 0.01782972924411297,
      "learning_rate": 4.3593023255813956e-05,
      "loss": 0.0012,
      "step": 1653
    },
    {
      "epoch": 6.410852713178294,
      "grad_norm": 0.005836197175085545,
      "learning_rate": 4.358914728682171e-05,
      "loss": 0.0004,
      "step": 1654
    },
    {
      "epoch": 6.4147286821705425,
      "grad_norm": 0.004808580037206411,
      "learning_rate": 4.3585271317829454e-05,
      "loss": 0.0004,
      "step": 1655
    },
    {
      "epoch": 6.4186046511627906,
      "grad_norm": 12.018321990966797,
      "learning_rate": 4.358139534883721e-05,
      "loss": 0.1343,
      "step": 1656
    },
    {
      "epoch": 6.422480620155039,
      "grad_norm": 0.024859506636857986,
      "learning_rate": 4.357751937984496e-05,
      "loss": 0.0012,
      "step": 1657
    },
    {
      "epoch": 6.426356589147287,
      "grad_norm": 6.382434368133545,
      "learning_rate": 4.357364341085272e-05,
      "loss": 0.4465,
      "step": 1658
    },
    {
      "epoch": 6.430232558139535,
      "grad_norm": 20.0987548828125,
      "learning_rate": 4.3569767441860463e-05,
      "loss": 0.4813,
      "step": 1659
    },
    {
      "epoch": 6.434108527131783,
      "grad_norm": 6.826282024383545,
      "learning_rate": 4.356589147286822e-05,
      "loss": 1.4248,
      "step": 1660
    },
    {
      "epoch": 6.437984496124031,
      "grad_norm": 0.014050308614969254,
      "learning_rate": 4.356201550387597e-05,
      "loss": 0.001,
      "step": 1661
    },
    {
      "epoch": 6.441860465116279,
      "grad_norm": 0.02071620337665081,
      "learning_rate": 4.355813953488372e-05,
      "loss": 0.0008,
      "step": 1662
    },
    {
      "epoch": 6.445736434108527,
      "grad_norm": 8.67272663116455,
      "learning_rate": 4.355426356589147e-05,
      "loss": 0.6486,
      "step": 1663
    },
    {
      "epoch": 6.449612403100775,
      "grad_norm": 0.071993887424469,
      "learning_rate": 4.3550387596899226e-05,
      "loss": 0.0012,
      "step": 1664
    },
    {
      "epoch": 6.453488372093023,
      "grad_norm": 0.08539337664842606,
      "learning_rate": 4.354651162790698e-05,
      "loss": 0.0013,
      "step": 1665
    },
    {
      "epoch": 6.457364341085271,
      "grad_norm": 0.09992192685604095,
      "learning_rate": 4.354263565891473e-05,
      "loss": 0.0013,
      "step": 1666
    },
    {
      "epoch": 6.461240310077519,
      "grad_norm": 0.010547506622970104,
      "learning_rate": 4.353875968992248e-05,
      "loss": 0.0006,
      "step": 1667
    },
    {
      "epoch": 6.465116279069767,
      "grad_norm": 0.07671081274747849,
      "learning_rate": 4.3534883720930235e-05,
      "loss": 0.0036,
      "step": 1668
    },
    {
      "epoch": 6.4689922480620154,
      "grad_norm": 0.011163495481014252,
      "learning_rate": 4.353100775193799e-05,
      "loss": 0.0006,
      "step": 1669
    },
    {
      "epoch": 6.4728682170542635,
      "grad_norm": 0.025419598445296288,
      "learning_rate": 4.352713178294574e-05,
      "loss": 0.0011,
      "step": 1670
    },
    {
      "epoch": 6.476744186046512,
      "grad_norm": 6.814326763153076,
      "learning_rate": 4.352325581395349e-05,
      "loss": 0.3633,
      "step": 1671
    },
    {
      "epoch": 6.48062015503876,
      "grad_norm": 0.16977214813232422,
      "learning_rate": 4.3519379844961245e-05,
      "loss": 0.0047,
      "step": 1672
    },
    {
      "epoch": 6.484496124031008,
      "grad_norm": 4.738224029541016,
      "learning_rate": 4.351550387596899e-05,
      "loss": 0.0218,
      "step": 1673
    },
    {
      "epoch": 6.488372093023256,
      "grad_norm": 0.023979976773262024,
      "learning_rate": 4.351162790697675e-05,
      "loss": 0.0014,
      "step": 1674
    },
    {
      "epoch": 6.492248062015504,
      "grad_norm": 0.14160050451755524,
      "learning_rate": 4.3507751937984495e-05,
      "loss": 0.0019,
      "step": 1675
    },
    {
      "epoch": 6.496124031007752,
      "grad_norm": 0.06177226081490517,
      "learning_rate": 4.3503875968992255e-05,
      "loss": 0.0014,
      "step": 1676
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.37360814213752747,
      "learning_rate": 4.35e-05,
      "loss": 0.0113,
      "step": 1677
    },
    {
      "epoch": 6.503875968992248,
      "grad_norm": 0.5117859840393066,
      "learning_rate": 4.349612403100776e-05,
      "loss": 0.0049,
      "step": 1678
    },
    {
      "epoch": 6.507751937984496,
      "grad_norm": 0.009590880014002323,
      "learning_rate": 4.3492248062015505e-05,
      "loss": 0.0006,
      "step": 1679
    },
    {
      "epoch": 6.511627906976744,
      "grad_norm": 0.8660042881965637,
      "learning_rate": 4.348837209302326e-05,
      "loss": 0.0046,
      "step": 1680
    },
    {
      "epoch": 6.515503875968992,
      "grad_norm": 0.013975930400192738,
      "learning_rate": 4.348449612403101e-05,
      "loss": 0.0007,
      "step": 1681
    },
    {
      "epoch": 6.51937984496124,
      "grad_norm": 0.9718985557556152,
      "learning_rate": 4.348062015503876e-05,
      "loss": 0.0077,
      "step": 1682
    },
    {
      "epoch": 6.523255813953488,
      "grad_norm": 0.035666003823280334,
      "learning_rate": 4.3476744186046515e-05,
      "loss": 0.0013,
      "step": 1683
    },
    {
      "epoch": 6.5271317829457365,
      "grad_norm": 19.65916633605957,
      "learning_rate": 4.347286821705426e-05,
      "loss": 0.6155,
      "step": 1684
    },
    {
      "epoch": 6.5310077519379846,
      "grad_norm": 0.009287613444030285,
      "learning_rate": 4.346899224806202e-05,
      "loss": 0.0007,
      "step": 1685
    },
    {
      "epoch": 6.534883720930233,
      "grad_norm": 2.2980833053588867,
      "learning_rate": 4.3465116279069765e-05,
      "loss": 0.6089,
      "step": 1686
    },
    {
      "epoch": 6.538759689922481,
      "grad_norm": 0.008139562793076038,
      "learning_rate": 4.3461240310077524e-05,
      "loss": 0.0006,
      "step": 1687
    },
    {
      "epoch": 6.542635658914729,
      "grad_norm": 18.30001449584961,
      "learning_rate": 4.345736434108527e-05,
      "loss": 0.5302,
      "step": 1688
    },
    {
      "epoch": 6.546511627906977,
      "grad_norm": 7.874816417694092,
      "learning_rate": 4.345348837209303e-05,
      "loss": 0.6192,
      "step": 1689
    },
    {
      "epoch": 6.550387596899225,
      "grad_norm": 0.010592468082904816,
      "learning_rate": 4.3449612403100775e-05,
      "loss": 0.0008,
      "step": 1690
    },
    {
      "epoch": 6.554263565891473,
      "grad_norm": 0.023740705102682114,
      "learning_rate": 4.344573643410853e-05,
      "loss": 0.0013,
      "step": 1691
    },
    {
      "epoch": 6.558139534883721,
      "grad_norm": 0.023621229454874992,
      "learning_rate": 4.344186046511628e-05,
      "loss": 0.0014,
      "step": 1692
    },
    {
      "epoch": 6.562015503875969,
      "grad_norm": 5.233460903167725,
      "learning_rate": 4.343798449612403e-05,
      "loss": 0.8808,
      "step": 1693
    },
    {
      "epoch": 6.565891472868217,
      "grad_norm": 0.08689919114112854,
      "learning_rate": 4.3434108527131785e-05,
      "loss": 0.0027,
      "step": 1694
    },
    {
      "epoch": 6.569767441860465,
      "grad_norm": 0.04253338277339935,
      "learning_rate": 4.343023255813954e-05,
      "loss": 0.0022,
      "step": 1695
    },
    {
      "epoch": 6.573643410852713,
      "grad_norm": 0.2111477553844452,
      "learning_rate": 4.342635658914729e-05,
      "loss": 0.0039,
      "step": 1696
    },
    {
      "epoch": 6.577519379844961,
      "grad_norm": 0.17364303767681122,
      "learning_rate": 4.342248062015504e-05,
      "loss": 0.0049,
      "step": 1697
    },
    {
      "epoch": 6.5813953488372094,
      "grad_norm": 0.020941855385899544,
      "learning_rate": 4.3418604651162794e-05,
      "loss": 0.0012,
      "step": 1698
    },
    {
      "epoch": 6.5852713178294575,
      "grad_norm": 0.08957143872976303,
      "learning_rate": 4.341472868217055e-05,
      "loss": 0.0036,
      "step": 1699
    },
    {
      "epoch": 6.589147286821706,
      "grad_norm": 7.8955817222595215,
      "learning_rate": 4.34108527131783e-05,
      "loss": 0.3519,
      "step": 1700
    },
    {
      "epoch": 6.593023255813954,
      "grad_norm": 0.06674555689096451,
      "learning_rate": 4.340697674418605e-05,
      "loss": 0.0036,
      "step": 1701
    },
    {
      "epoch": 6.596899224806202,
      "grad_norm": 0.12286937236785889,
      "learning_rate": 4.34031007751938e-05,
      "loss": 0.0057,
      "step": 1702
    },
    {
      "epoch": 6.60077519379845,
      "grad_norm": 0.05234666168689728,
      "learning_rate": 4.3399224806201556e-05,
      "loss": 0.0028,
      "step": 1703
    },
    {
      "epoch": 6.604651162790698,
      "grad_norm": 0.1478240042924881,
      "learning_rate": 4.33953488372093e-05,
      "loss": 0.0061,
      "step": 1704
    },
    {
      "epoch": 6.608527131782946,
      "grad_norm": 0.025307534262537956,
      "learning_rate": 4.339147286821706e-05,
      "loss": 0.0015,
      "step": 1705
    },
    {
      "epoch": 6.612403100775194,
      "grad_norm": 4.5377092361450195,
      "learning_rate": 4.338759689922481e-05,
      "loss": 0.3195,
      "step": 1706
    },
    {
      "epoch": 6.616279069767442,
      "grad_norm": 2.3878798484802246,
      "learning_rate": 4.338372093023256e-05,
      "loss": 0.2006,
      "step": 1707
    },
    {
      "epoch": 6.62015503875969,
      "grad_norm": 0.5196555256843567,
      "learning_rate": 4.337984496124031e-05,
      "loss": 0.012,
      "step": 1708
    },
    {
      "epoch": 6.624031007751938,
      "grad_norm": 0.014726282097399235,
      "learning_rate": 4.3375968992248064e-05,
      "loss": 0.001,
      "step": 1709
    },
    {
      "epoch": 6.627906976744186,
      "grad_norm": 0.01700529456138611,
      "learning_rate": 4.337209302325582e-05,
      "loss": 0.0006,
      "step": 1710
    },
    {
      "epoch": 6.631782945736434,
      "grad_norm": 0.49082639813423157,
      "learning_rate": 4.336821705426357e-05,
      "loss": 0.0058,
      "step": 1711
    },
    {
      "epoch": 6.635658914728682,
      "grad_norm": 0.023108450695872307,
      "learning_rate": 4.336434108527132e-05,
      "loss": 0.0015,
      "step": 1712
    },
    {
      "epoch": 6.6395348837209305,
      "grad_norm": 0.01152961328625679,
      "learning_rate": 4.336046511627907e-05,
      "loss": 0.0009,
      "step": 1713
    },
    {
      "epoch": 6.6434108527131785,
      "grad_norm": 0.01841123215854168,
      "learning_rate": 4.3356589147286826e-05,
      "loss": 0.001,
      "step": 1714
    },
    {
      "epoch": 6.647286821705427,
      "grad_norm": 0.01466432586312294,
      "learning_rate": 4.335271317829457e-05,
      "loss": 0.0011,
      "step": 1715
    },
    {
      "epoch": 6.651162790697675,
      "grad_norm": 0.009059406816959381,
      "learning_rate": 4.334883720930233e-05,
      "loss": 0.0007,
      "step": 1716
    },
    {
      "epoch": 6.655038759689923,
      "grad_norm": 0.010131101123988628,
      "learning_rate": 4.334496124031008e-05,
      "loss": 0.0008,
      "step": 1717
    },
    {
      "epoch": 6.658914728682171,
      "grad_norm": 0.14765292406082153,
      "learning_rate": 4.3341085271317836e-05,
      "loss": 0.0029,
      "step": 1718
    },
    {
      "epoch": 6.662790697674419,
      "grad_norm": 0.03171733021736145,
      "learning_rate": 4.333720930232558e-05,
      "loss": 0.0011,
      "step": 1719
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 2.1198291778564453,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.2708,
      "step": 1720
    },
    {
      "epoch": 6.670542635658915,
      "grad_norm": 0.015157965011894703,
      "learning_rate": 4.3329457364341086e-05,
      "loss": 0.001,
      "step": 1721
    },
    {
      "epoch": 6.674418604651163,
      "grad_norm": 7.513802528381348,
      "learning_rate": 4.332558139534884e-05,
      "loss": 0.5709,
      "step": 1722
    },
    {
      "epoch": 6.678294573643411,
      "grad_norm": 9.881648063659668,
      "learning_rate": 4.332170542635659e-05,
      "loss": 0.1338,
      "step": 1723
    },
    {
      "epoch": 6.682170542635659,
      "grad_norm": 1.4879165887832642,
      "learning_rate": 4.3317829457364344e-05,
      "loss": 0.0031,
      "step": 1724
    },
    {
      "epoch": 6.686046511627907,
      "grad_norm": 0.0084071084856987,
      "learning_rate": 4.3313953488372096e-05,
      "loss": 0.0007,
      "step": 1725
    },
    {
      "epoch": 6.689922480620155,
      "grad_norm": 0.006151200272142887,
      "learning_rate": 4.331007751937985e-05,
      "loss": 0.0006,
      "step": 1726
    },
    {
      "epoch": 6.6937984496124034,
      "grad_norm": 0.007509453222155571,
      "learning_rate": 4.33062015503876e-05,
      "loss": 0.0006,
      "step": 1727
    },
    {
      "epoch": 6.6976744186046515,
      "grad_norm": 0.019967932254076004,
      "learning_rate": 4.3302325581395353e-05,
      "loss": 0.001,
      "step": 1728
    },
    {
      "epoch": 6.7015503875969,
      "grad_norm": 9.803192138671875,
      "learning_rate": 4.3298449612403106e-05,
      "loss": 0.7387,
      "step": 1729
    },
    {
      "epoch": 6.705426356589148,
      "grad_norm": 29.04199981689453,
      "learning_rate": 4.329457364341086e-05,
      "loss": 0.1976,
      "step": 1730
    },
    {
      "epoch": 6.709302325581396,
      "grad_norm": 3.6718335151672363,
      "learning_rate": 4.3290697674418604e-05,
      "loss": 0.631,
      "step": 1731
    },
    {
      "epoch": 6.713178294573644,
      "grad_norm": 3.2977397441864014,
      "learning_rate": 4.328682170542636e-05,
      "loss": 0.058,
      "step": 1732
    },
    {
      "epoch": 6.717054263565892,
      "grad_norm": 0.00799041148275137,
      "learning_rate": 4.328294573643411e-05,
      "loss": 0.0007,
      "step": 1733
    },
    {
      "epoch": 6.720930232558139,
      "grad_norm": 0.006152160931378603,
      "learning_rate": 4.327906976744186e-05,
      "loss": 0.0005,
      "step": 1734
    },
    {
      "epoch": 6.724806201550388,
      "grad_norm": 0.5616798400878906,
      "learning_rate": 4.3275193798449614e-05,
      "loss": 0.0153,
      "step": 1735
    },
    {
      "epoch": 6.728682170542635,
      "grad_norm": 35.73627471923828,
      "learning_rate": 4.3271317829457366e-05,
      "loss": 0.7912,
      "step": 1736
    },
    {
      "epoch": 6.732558139534884,
      "grad_norm": 2.824256658554077,
      "learning_rate": 4.326744186046512e-05,
      "loss": 0.0469,
      "step": 1737
    },
    {
      "epoch": 6.736434108527131,
      "grad_norm": 0.013253483921289444,
      "learning_rate": 4.326356589147287e-05,
      "loss": 0.0007,
      "step": 1738
    },
    {
      "epoch": 6.74031007751938,
      "grad_norm": 2.268691301345825,
      "learning_rate": 4.325968992248062e-05,
      "loss": 0.1143,
      "step": 1739
    },
    {
      "epoch": 6.7441860465116275,
      "grad_norm": 0.025993183255195618,
      "learning_rate": 4.325581395348837e-05,
      "loss": 0.0008,
      "step": 1740
    },
    {
      "epoch": 6.748062015503876,
      "grad_norm": 0.016838904470205307,
      "learning_rate": 4.325193798449613e-05,
      "loss": 0.0008,
      "step": 1741
    },
    {
      "epoch": 6.751937984496124,
      "grad_norm": 3.687051296234131,
      "learning_rate": 4.3248062015503874e-05,
      "loss": 0.0089,
      "step": 1742
    },
    {
      "epoch": 6.7558139534883725,
      "grad_norm": 0.014651147648692131,
      "learning_rate": 4.324418604651163e-05,
      "loss": 0.001,
      "step": 1743
    },
    {
      "epoch": 6.75968992248062,
      "grad_norm": 17.411436080932617,
      "learning_rate": 4.324031007751938e-05,
      "loss": 0.5447,
      "step": 1744
    },
    {
      "epoch": 6.763565891472869,
      "grad_norm": 3.405569553375244,
      "learning_rate": 4.323643410852714e-05,
      "loss": 0.2654,
      "step": 1745
    },
    {
      "epoch": 6.767441860465116,
      "grad_norm": 0.012188314460217953,
      "learning_rate": 4.3232558139534883e-05,
      "loss": 0.0007,
      "step": 1746
    },
    {
      "epoch": 6.771317829457365,
      "grad_norm": 0.028950145468115807,
      "learning_rate": 4.3228682170542636e-05,
      "loss": 0.001,
      "step": 1747
    },
    {
      "epoch": 6.775193798449612,
      "grad_norm": 0.01599884405732155,
      "learning_rate": 4.322480620155039e-05,
      "loss": 0.001,
      "step": 1748
    },
    {
      "epoch": 6.779069767441861,
      "grad_norm": 15.75410270690918,
      "learning_rate": 4.322093023255814e-05,
      "loss": 0.231,
      "step": 1749
    },
    {
      "epoch": 6.782945736434108,
      "grad_norm": 0.05770217627286911,
      "learning_rate": 4.321705426356589e-05,
      "loss": 0.0028,
      "step": 1750
    },
    {
      "epoch": 6.786821705426356,
      "grad_norm": 2.3018012046813965,
      "learning_rate": 4.3213178294573646e-05,
      "loss": 0.0132,
      "step": 1751
    },
    {
      "epoch": 6.790697674418604,
      "grad_norm": 0.009308857843279839,
      "learning_rate": 4.32093023255814e-05,
      "loss": 0.0006,
      "step": 1752
    },
    {
      "epoch": 6.794573643410852,
      "grad_norm": 0.0147776547819376,
      "learning_rate": 4.320542635658915e-05,
      "loss": 0.0009,
      "step": 1753
    },
    {
      "epoch": 6.7984496124031,
      "grad_norm": 0.01017157081514597,
      "learning_rate": 4.32015503875969e-05,
      "loss": 0.0008,
      "step": 1754
    },
    {
      "epoch": 6.8023255813953485,
      "grad_norm": 13.46155834197998,
      "learning_rate": 4.3197674418604655e-05,
      "loss": 0.4314,
      "step": 1755
    },
    {
      "epoch": 6.8062015503875966,
      "grad_norm": 0.22165805101394653,
      "learning_rate": 4.319379844961241e-05,
      "loss": 0.0045,
      "step": 1756
    },
    {
      "epoch": 6.810077519379845,
      "grad_norm": 4.129817962646484,
      "learning_rate": 4.318992248062016e-05,
      "loss": 0.4622,
      "step": 1757
    },
    {
      "epoch": 6.813953488372093,
      "grad_norm": 25.69038963317871,
      "learning_rate": 4.3186046511627906e-05,
      "loss": 0.3178,
      "step": 1758
    },
    {
      "epoch": 6.817829457364341,
      "grad_norm": 5.545557498931885,
      "learning_rate": 4.3182170542635665e-05,
      "loss": 0.2947,
      "step": 1759
    },
    {
      "epoch": 6.821705426356589,
      "grad_norm": 8.301566123962402,
      "learning_rate": 4.317829457364341e-05,
      "loss": 0.3529,
      "step": 1760
    },
    {
      "epoch": 6.825581395348837,
      "grad_norm": 0.011340516619384289,
      "learning_rate": 4.317441860465116e-05,
      "loss": 0.0008,
      "step": 1761
    },
    {
      "epoch": 6.829457364341085,
      "grad_norm": 0.01402317825704813,
      "learning_rate": 4.3170542635658915e-05,
      "loss": 0.0009,
      "step": 1762
    },
    {
      "epoch": 6.833333333333333,
      "grad_norm": 0.0344047024846077,
      "learning_rate": 4.316666666666667e-05,
      "loss": 0.0009,
      "step": 1763
    },
    {
      "epoch": 6.837209302325581,
      "grad_norm": 9.656603813171387,
      "learning_rate": 4.316279069767442e-05,
      "loss": 0.653,
      "step": 1764
    },
    {
      "epoch": 6.841085271317829,
      "grad_norm": 5.703432559967041,
      "learning_rate": 4.315891472868217e-05,
      "loss": 0.0088,
      "step": 1765
    },
    {
      "epoch": 6.844961240310077,
      "grad_norm": 0.028816260397434235,
      "learning_rate": 4.3155038759689925e-05,
      "loss": 0.0015,
      "step": 1766
    },
    {
      "epoch": 6.848837209302325,
      "grad_norm": 0.013740426860749722,
      "learning_rate": 4.315116279069768e-05,
      "loss": 0.0009,
      "step": 1767
    },
    {
      "epoch": 6.852713178294573,
      "grad_norm": 0.01858776994049549,
      "learning_rate": 4.314728682170543e-05,
      "loss": 0.0009,
      "step": 1768
    },
    {
      "epoch": 6.8565891472868215,
      "grad_norm": 0.04375887289643288,
      "learning_rate": 4.3143410852713176e-05,
      "loss": 0.0012,
      "step": 1769
    },
    {
      "epoch": 6.8604651162790695,
      "grad_norm": 0.25930503010749817,
      "learning_rate": 4.3139534883720935e-05,
      "loss": 0.0096,
      "step": 1770
    },
    {
      "epoch": 6.864341085271318,
      "grad_norm": 0.12012751400470734,
      "learning_rate": 4.313565891472868e-05,
      "loss": 0.001,
      "step": 1771
    },
    {
      "epoch": 6.868217054263566,
      "grad_norm": 0.04564422369003296,
      "learning_rate": 4.313178294573644e-05,
      "loss": 0.0008,
      "step": 1772
    },
    {
      "epoch": 6.872093023255814,
      "grad_norm": 3.473588705062866,
      "learning_rate": 4.3127906976744185e-05,
      "loss": 0.0086,
      "step": 1773
    },
    {
      "epoch": 6.875968992248062,
      "grad_norm": 0.17585714161396027,
      "learning_rate": 4.3124031007751944e-05,
      "loss": 0.0043,
      "step": 1774
    },
    {
      "epoch": 6.87984496124031,
      "grad_norm": 0.06523965299129486,
      "learning_rate": 4.312015503875969e-05,
      "loss": 0.0013,
      "step": 1775
    },
    {
      "epoch": 6.883720930232558,
      "grad_norm": 7.200600624084473,
      "learning_rate": 4.311627906976744e-05,
      "loss": 0.3928,
      "step": 1776
    },
    {
      "epoch": 6.887596899224806,
      "grad_norm": 0.028423914685845375,
      "learning_rate": 4.3112403100775195e-05,
      "loss": 0.0015,
      "step": 1777
    },
    {
      "epoch": 6.891472868217054,
      "grad_norm": 0.009806414134800434,
      "learning_rate": 4.310852713178295e-05,
      "loss": 0.0006,
      "step": 1778
    },
    {
      "epoch": 6.895348837209302,
      "grad_norm": 0.049222253262996674,
      "learning_rate": 4.31046511627907e-05,
      "loss": 0.002,
      "step": 1779
    },
    {
      "epoch": 6.89922480620155,
      "grad_norm": 0.5536571145057678,
      "learning_rate": 4.310077519379845e-05,
      "loss": 0.015,
      "step": 1780
    },
    {
      "epoch": 6.903100775193798,
      "grad_norm": 0.20893114805221558,
      "learning_rate": 4.3096899224806205e-05,
      "loss": 0.0069,
      "step": 1781
    },
    {
      "epoch": 6.906976744186046,
      "grad_norm": 1.0802998542785645,
      "learning_rate": 4.309302325581396e-05,
      "loss": 0.0121,
      "step": 1782
    },
    {
      "epoch": 6.910852713178294,
      "grad_norm": 15.93996810913086,
      "learning_rate": 4.308914728682171e-05,
      "loss": 0.4466,
      "step": 1783
    },
    {
      "epoch": 6.9147286821705425,
      "grad_norm": 0.007712472230195999,
      "learning_rate": 4.308527131782946e-05,
      "loss": 0.0006,
      "step": 1784
    },
    {
      "epoch": 6.9186046511627906,
      "grad_norm": 7.640051364898682,
      "learning_rate": 4.3081395348837214e-05,
      "loss": 0.1501,
      "step": 1785
    },
    {
      "epoch": 6.922480620155039,
      "grad_norm": 0.761229932308197,
      "learning_rate": 4.307751937984496e-05,
      "loss": 0.0109,
      "step": 1786
    },
    {
      "epoch": 6.926356589147287,
      "grad_norm": 0.03533373773097992,
      "learning_rate": 4.307364341085271e-05,
      "loss": 0.0013,
      "step": 1787
    },
    {
      "epoch": 6.930232558139535,
      "grad_norm": 0.12021872401237488,
      "learning_rate": 4.3069767441860465e-05,
      "loss": 0.0043,
      "step": 1788
    },
    {
      "epoch": 6.934108527131783,
      "grad_norm": 10.477635383605957,
      "learning_rate": 4.306589147286822e-05,
      "loss": 0.2272,
      "step": 1789
    },
    {
      "epoch": 6.937984496124031,
      "grad_norm": 0.005133496131747961,
      "learning_rate": 4.306201550387597e-05,
      "loss": 0.0005,
      "step": 1790
    },
    {
      "epoch": 6.941860465116279,
      "grad_norm": 1.8032877445220947,
      "learning_rate": 4.305813953488372e-05,
      "loss": 0.0486,
      "step": 1791
    },
    {
      "epoch": 6.945736434108527,
      "grad_norm": 9.181465148925781,
      "learning_rate": 4.3054263565891475e-05,
      "loss": 0.6672,
      "step": 1792
    },
    {
      "epoch": 6.949612403100775,
      "grad_norm": 0.0216832235455513,
      "learning_rate": 4.305038759689923e-05,
      "loss": 0.0005,
      "step": 1793
    },
    {
      "epoch": 6.953488372093023,
      "grad_norm": 0.07624001801013947,
      "learning_rate": 4.304651162790698e-05,
      "loss": 0.0027,
      "step": 1794
    },
    {
      "epoch": 6.957364341085271,
      "grad_norm": 4.852664947509766,
      "learning_rate": 4.304263565891473e-05,
      "loss": 0.1528,
      "step": 1795
    },
    {
      "epoch": 6.961240310077519,
      "grad_norm": 0.05872361734509468,
      "learning_rate": 4.3038759689922484e-05,
      "loss": 0.0017,
      "step": 1796
    },
    {
      "epoch": 6.965116279069767,
      "grad_norm": 0.06453900039196014,
      "learning_rate": 4.303488372093024e-05,
      "loss": 0.0034,
      "step": 1797
    },
    {
      "epoch": 6.9689922480620154,
      "grad_norm": 0.01751544326543808,
      "learning_rate": 4.303100775193798e-05,
      "loss": 0.0009,
      "step": 1798
    },
    {
      "epoch": 6.9728682170542635,
      "grad_norm": 0.1274942308664322,
      "learning_rate": 4.302713178294574e-05,
      "loss": 0.0052,
      "step": 1799
    },
    {
      "epoch": 6.976744186046512,
      "grad_norm": 0.04048217460513115,
      "learning_rate": 4.302325581395349e-05,
      "loss": 0.0012,
      "step": 1800
    },
    {
      "epoch": 6.98062015503876,
      "grad_norm": 0.014998859725892544,
      "learning_rate": 4.3019379844961246e-05,
      "loss": 0.0007,
      "step": 1801
    },
    {
      "epoch": 6.984496124031008,
      "grad_norm": 2.838615655899048,
      "learning_rate": 4.301550387596899e-05,
      "loss": 0.2481,
      "step": 1802
    },
    {
      "epoch": 6.988372093023256,
      "grad_norm": 9.439242362976074,
      "learning_rate": 4.301162790697675e-05,
      "loss": 0.0465,
      "step": 1803
    },
    {
      "epoch": 6.992248062015504,
      "grad_norm": 0.020366385579109192,
      "learning_rate": 4.30077519379845e-05,
      "loss": 0.001,
      "step": 1804
    },
    {
      "epoch": 6.996124031007752,
      "grad_norm": 9.166168212890625,
      "learning_rate": 4.300387596899225e-05,
      "loss": 0.0791,
      "step": 1805
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.02152193710207939,
      "learning_rate": 4.3e-05,
      "loss": 0.0009,
      "step": 1806
    },
    {
      "epoch": 7.003875968992248,
      "grad_norm": 0.09081056714057922,
      "learning_rate": 4.2996124031007754e-05,
      "loss": 0.0022,
      "step": 1807
    },
    {
      "epoch": 7.007751937984496,
      "grad_norm": 433.1405334472656,
      "learning_rate": 4.2992248062015506e-05,
      "loss": 0.115,
      "step": 1808
    },
    {
      "epoch": 7.011627906976744,
      "grad_norm": 0.26416000723838806,
      "learning_rate": 4.298837209302326e-05,
      "loss": 0.0302,
      "step": 1809
    },
    {
      "epoch": 7.015503875968992,
      "grad_norm": 8.487624168395996,
      "learning_rate": 4.298449612403101e-05,
      "loss": 0.1723,
      "step": 1810
    },
    {
      "epoch": 7.01937984496124,
      "grad_norm": 0.34188976883888245,
      "learning_rate": 4.2980620155038764e-05,
      "loss": 0.0064,
      "step": 1811
    },
    {
      "epoch": 7.023255813953488,
      "grad_norm": 1.5512598752975464,
      "learning_rate": 4.2976744186046516e-05,
      "loss": 0.0414,
      "step": 1812
    },
    {
      "epoch": 7.0271317829457365,
      "grad_norm": 0.02680552378296852,
      "learning_rate": 4.297286821705426e-05,
      "loss": 0.001,
      "step": 1813
    },
    {
      "epoch": 7.0310077519379846,
      "grad_norm": 5.9531049728393555,
      "learning_rate": 4.296899224806202e-05,
      "loss": 0.0552,
      "step": 1814
    },
    {
      "epoch": 7.034883720930233,
      "grad_norm": 1.852746844291687,
      "learning_rate": 4.296511627906977e-05,
      "loss": 0.0101,
      "step": 1815
    },
    {
      "epoch": 7.038759689922481,
      "grad_norm": 5.193187713623047,
      "learning_rate": 4.296124031007752e-05,
      "loss": 0.2226,
      "step": 1816
    },
    {
      "epoch": 7.042635658914729,
      "grad_norm": 0.2093942016363144,
      "learning_rate": 4.295736434108527e-05,
      "loss": 0.0024,
      "step": 1817
    },
    {
      "epoch": 7.046511627906977,
      "grad_norm": 0.933756411075592,
      "learning_rate": 4.2953488372093024e-05,
      "loss": 0.0036,
      "step": 1818
    },
    {
      "epoch": 7.050387596899225,
      "grad_norm": 0.1569899320602417,
      "learning_rate": 4.2949612403100776e-05,
      "loss": 0.0027,
      "step": 1819
    },
    {
      "epoch": 7.054263565891473,
      "grad_norm": 0.03841518983244896,
      "learning_rate": 4.294573643410853e-05,
      "loss": 0.0009,
      "step": 1820
    },
    {
      "epoch": 7.058139534883721,
      "grad_norm": 0.05013461410999298,
      "learning_rate": 4.294186046511628e-05,
      "loss": 0.0014,
      "step": 1821
    },
    {
      "epoch": 7.062015503875969,
      "grad_norm": 0.01968563348054886,
      "learning_rate": 4.2937984496124034e-05,
      "loss": 0.0012,
      "step": 1822
    },
    {
      "epoch": 7.065891472868217,
      "grad_norm": 3.9917423725128174,
      "learning_rate": 4.2934108527131786e-05,
      "loss": 0.0127,
      "step": 1823
    },
    {
      "epoch": 7.069767441860465,
      "grad_norm": 0.060033366084098816,
      "learning_rate": 4.293023255813954e-05,
      "loss": 0.0014,
      "step": 1824
    },
    {
      "epoch": 7.073643410852713,
      "grad_norm": 0.017285963520407677,
      "learning_rate": 4.2926356589147284e-05,
      "loss": 0.0011,
      "step": 1825
    },
    {
      "epoch": 7.077519379844961,
      "grad_norm": 0.021763620898127556,
      "learning_rate": 4.292248062015504e-05,
      "loss": 0.0013,
      "step": 1826
    },
    {
      "epoch": 7.0813953488372094,
      "grad_norm": 0.008363185450434685,
      "learning_rate": 4.291860465116279e-05,
      "loss": 0.0005,
      "step": 1827
    },
    {
      "epoch": 7.0852713178294575,
      "grad_norm": 0.030340921133756638,
      "learning_rate": 4.291472868217055e-05,
      "loss": 0.0013,
      "step": 1828
    },
    {
      "epoch": 7.089147286821706,
      "grad_norm": 0.005416502710431814,
      "learning_rate": 4.2910852713178294e-05,
      "loss": 0.0005,
      "step": 1829
    },
    {
      "epoch": 7.093023255813954,
      "grad_norm": 0.0073573533445596695,
      "learning_rate": 4.290697674418605e-05,
      "loss": 0.0005,
      "step": 1830
    },
    {
      "epoch": 7.096899224806202,
      "grad_norm": 0.02270209975540638,
      "learning_rate": 4.29031007751938e-05,
      "loss": 0.0006,
      "step": 1831
    },
    {
      "epoch": 7.10077519379845,
      "grad_norm": 2.5672872066497803,
      "learning_rate": 4.289922480620156e-05,
      "loss": 0.0922,
      "step": 1832
    },
    {
      "epoch": 7.104651162790698,
      "grad_norm": 0.004274152684956789,
      "learning_rate": 4.2895348837209303e-05,
      "loss": 0.0004,
      "step": 1833
    },
    {
      "epoch": 7.108527131782946,
      "grad_norm": 0.19447168707847595,
      "learning_rate": 4.2891472868217056e-05,
      "loss": 0.0014,
      "step": 1834
    },
    {
      "epoch": 7.112403100775194,
      "grad_norm": 0.036501817405223846,
      "learning_rate": 4.288759689922481e-05,
      "loss": 0.0018,
      "step": 1835
    },
    {
      "epoch": 7.116279069767442,
      "grad_norm": 0.00439439294859767,
      "learning_rate": 4.288372093023256e-05,
      "loss": 0.0004,
      "step": 1836
    },
    {
      "epoch": 7.12015503875969,
      "grad_norm": 0.0072438400238752365,
      "learning_rate": 4.287984496124031e-05,
      "loss": 0.0004,
      "step": 1837
    },
    {
      "epoch": 7.124031007751938,
      "grad_norm": 0.007453013677150011,
      "learning_rate": 4.2875968992248066e-05,
      "loss": 0.0006,
      "step": 1838
    },
    {
      "epoch": 7.127906976744186,
      "grad_norm": 0.3161320090293884,
      "learning_rate": 4.287209302325582e-05,
      "loss": 0.007,
      "step": 1839
    },
    {
      "epoch": 7.131782945736434,
      "grad_norm": 0.6336498856544495,
      "learning_rate": 4.2868217054263564e-05,
      "loss": 0.0212,
      "step": 1840
    },
    {
      "epoch": 7.135658914728682,
      "grad_norm": 0.004498183727264404,
      "learning_rate": 4.286434108527132e-05,
      "loss": 0.0004,
      "step": 1841
    },
    {
      "epoch": 7.1395348837209305,
      "grad_norm": 0.0045209163799881935,
      "learning_rate": 4.286046511627907e-05,
      "loss": 0.0004,
      "step": 1842
    },
    {
      "epoch": 7.1434108527131785,
      "grad_norm": 0.005359662231057882,
      "learning_rate": 4.285658914728682e-05,
      "loss": 0.0004,
      "step": 1843
    },
    {
      "epoch": 7.147286821705427,
      "grad_norm": 0.5849736332893372,
      "learning_rate": 4.285271317829457e-05,
      "loss": 0.0169,
      "step": 1844
    },
    {
      "epoch": 7.151162790697675,
      "grad_norm": 21.865922927856445,
      "learning_rate": 4.2848837209302326e-05,
      "loss": 0.4562,
      "step": 1845
    },
    {
      "epoch": 7.155038759689923,
      "grad_norm": 22.07731056213379,
      "learning_rate": 4.284496124031008e-05,
      "loss": 0.1955,
      "step": 1846
    },
    {
      "epoch": 7.158914728682171,
      "grad_norm": 0.004577313549816608,
      "learning_rate": 4.284108527131783e-05,
      "loss": 0.0004,
      "step": 1847
    },
    {
      "epoch": 7.162790697674419,
      "grad_norm": 0.02041509933769703,
      "learning_rate": 4.283720930232558e-05,
      "loss": 0.0006,
      "step": 1848
    },
    {
      "epoch": 7.166666666666667,
      "grad_norm": 446.9481201171875,
      "learning_rate": 4.2833333333333335e-05,
      "loss": 0.1507,
      "step": 1849
    },
    {
      "epoch": 7.170542635658915,
      "grad_norm": 0.030773837119340897,
      "learning_rate": 4.282945736434109e-05,
      "loss": 0.0015,
      "step": 1850
    },
    {
      "epoch": 7.174418604651163,
      "grad_norm": 0.46899181604385376,
      "learning_rate": 4.282558139534884e-05,
      "loss": 0.0123,
      "step": 1851
    },
    {
      "epoch": 7.178294573643411,
      "grad_norm": 0.06880602985620499,
      "learning_rate": 4.282170542635659e-05,
      "loss": 0.0011,
      "step": 1852
    },
    {
      "epoch": 7.182170542635659,
      "grad_norm": 3.0585670471191406,
      "learning_rate": 4.2817829457364345e-05,
      "loss": 0.0393,
      "step": 1853
    },
    {
      "epoch": 7.186046511627907,
      "grad_norm": 0.00565049983561039,
      "learning_rate": 4.281395348837209e-05,
      "loss": 0.0006,
      "step": 1854
    },
    {
      "epoch": 7.189922480620155,
      "grad_norm": 0.1689748764038086,
      "learning_rate": 4.281007751937985e-05,
      "loss": 0.0055,
      "step": 1855
    },
    {
      "epoch": 7.1937984496124034,
      "grad_norm": 0.00627137953415513,
      "learning_rate": 4.2806201550387596e-05,
      "loss": 0.0005,
      "step": 1856
    },
    {
      "epoch": 7.1976744186046515,
      "grad_norm": 0.0033919999841600657,
      "learning_rate": 4.2802325581395355e-05,
      "loss": 0.0004,
      "step": 1857
    },
    {
      "epoch": 7.2015503875969,
      "grad_norm": 0.005624535959213972,
      "learning_rate": 4.27984496124031e-05,
      "loss": 0.0004,
      "step": 1858
    },
    {
      "epoch": 7.205426356589148,
      "grad_norm": 0.006959049962460995,
      "learning_rate": 4.279457364341086e-05,
      "loss": 0.0006,
      "step": 1859
    },
    {
      "epoch": 7.209302325581396,
      "grad_norm": 0.0059258779510855675,
      "learning_rate": 4.2790697674418605e-05,
      "loss": 0.0005,
      "step": 1860
    },
    {
      "epoch": 7.213178294573644,
      "grad_norm": 0.006384370382875204,
      "learning_rate": 4.278682170542636e-05,
      "loss": 0.0003,
      "step": 1861
    },
    {
      "epoch": 7.217054263565892,
      "grad_norm": 0.0053165568970143795,
      "learning_rate": 4.278294573643411e-05,
      "loss": 0.0004,
      "step": 1862
    },
    {
      "epoch": 7.22093023255814,
      "grad_norm": 0.0032966083381325006,
      "learning_rate": 4.277906976744186e-05,
      "loss": 0.0003,
      "step": 1863
    },
    {
      "epoch": 7.224806201550388,
      "grad_norm": 0.006631670985370874,
      "learning_rate": 4.2775193798449615e-05,
      "loss": 0.0005,
      "step": 1864
    },
    {
      "epoch": 7.228682170542636,
      "grad_norm": 0.07542551308870316,
      "learning_rate": 4.277131782945737e-05,
      "loss": 0.0005,
      "step": 1865
    },
    {
      "epoch": 7.232558139534884,
      "grad_norm": 0.14301510155200958,
      "learning_rate": 4.276744186046512e-05,
      "loss": 0.0009,
      "step": 1866
    },
    {
      "epoch": 7.236434108527132,
      "grad_norm": 0.0103020453825593,
      "learning_rate": 4.2763565891472865e-05,
      "loss": 0.0005,
      "step": 1867
    },
    {
      "epoch": 7.24031007751938,
      "grad_norm": 0.023908238857984543,
      "learning_rate": 4.2759689922480625e-05,
      "loss": 0.0011,
      "step": 1868
    },
    {
      "epoch": 7.2441860465116275,
      "grad_norm": 0.007051454856991768,
      "learning_rate": 4.275581395348837e-05,
      "loss": 0.0005,
      "step": 1869
    },
    {
      "epoch": 7.248062015503876,
      "grad_norm": 13.886063575744629,
      "learning_rate": 4.275193798449613e-05,
      "loss": 0.4461,
      "step": 1870
    },
    {
      "epoch": 7.251937984496124,
      "grad_norm": 0.0046254536136984825,
      "learning_rate": 4.2748062015503875e-05,
      "loss": 0.0004,
      "step": 1871
    },
    {
      "epoch": 7.2558139534883725,
      "grad_norm": 0.004348414018750191,
      "learning_rate": 4.274418604651163e-05,
      "loss": 0.0004,
      "step": 1872
    },
    {
      "epoch": 7.25968992248062,
      "grad_norm": 0.003460152307525277,
      "learning_rate": 4.274031007751938e-05,
      "loss": 0.0004,
      "step": 1873
    },
    {
      "epoch": 7.263565891472869,
      "grad_norm": 0.008649359457194805,
      "learning_rate": 4.273643410852713e-05,
      "loss": 0.0007,
      "step": 1874
    },
    {
      "epoch": 7.267441860465116,
      "grad_norm": 0.07854648679494858,
      "learning_rate": 4.2732558139534885e-05,
      "loss": 0.0008,
      "step": 1875
    },
    {
      "epoch": 7.271317829457364,
      "grad_norm": 0.004251391626894474,
      "learning_rate": 4.272868217054264e-05,
      "loss": 0.0004,
      "step": 1876
    },
    {
      "epoch": 7.275193798449612,
      "grad_norm": 0.003671634243801236,
      "learning_rate": 4.272480620155039e-05,
      "loss": 0.0004,
      "step": 1877
    },
    {
      "epoch": 7.27906976744186,
      "grad_norm": 0.0036311878357082605,
      "learning_rate": 4.272093023255814e-05,
      "loss": 0.0004,
      "step": 1878
    },
    {
      "epoch": 7.282945736434108,
      "grad_norm": 0.003575132228434086,
      "learning_rate": 4.2717054263565895e-05,
      "loss": 0.0004,
      "step": 1879
    },
    {
      "epoch": 7.286821705426356,
      "grad_norm": 0.005465866532176733,
      "learning_rate": 4.271317829457365e-05,
      "loss": 0.0003,
      "step": 1880
    },
    {
      "epoch": 7.290697674418604,
      "grad_norm": 0.029949525371193886,
      "learning_rate": 4.27093023255814e-05,
      "loss": 0.0009,
      "step": 1881
    },
    {
      "epoch": 7.294573643410852,
      "grad_norm": 0.011478353291749954,
      "learning_rate": 4.270542635658915e-05,
      "loss": 0.0008,
      "step": 1882
    },
    {
      "epoch": 7.2984496124031,
      "grad_norm": 0.006180129945278168,
      "learning_rate": 4.27015503875969e-05,
      "loss": 0.0004,
      "step": 1883
    },
    {
      "epoch": 7.3023255813953485,
      "grad_norm": 0.009275078773498535,
      "learning_rate": 4.269767441860466e-05,
      "loss": 0.0005,
      "step": 1884
    },
    {
      "epoch": 7.3062015503875966,
      "grad_norm": 1.0395983457565308,
      "learning_rate": 4.26937984496124e-05,
      "loss": 0.0034,
      "step": 1885
    },
    {
      "epoch": 7.310077519379845,
      "grad_norm": 0.002989670494571328,
      "learning_rate": 4.268992248062016e-05,
      "loss": 0.0003,
      "step": 1886
    },
    {
      "epoch": 7.313953488372093,
      "grad_norm": 40.33494567871094,
      "learning_rate": 4.268604651162791e-05,
      "loss": 1.1246,
      "step": 1887
    },
    {
      "epoch": 7.317829457364341,
      "grad_norm": 3.380491018295288,
      "learning_rate": 4.2682170542635666e-05,
      "loss": 0.0149,
      "step": 1888
    },
    {
      "epoch": 7.321705426356589,
      "grad_norm": 0.004014768172055483,
      "learning_rate": 4.267829457364341e-05,
      "loss": 0.0004,
      "step": 1889
    },
    {
      "epoch": 7.325581395348837,
      "grad_norm": 0.013663101010024548,
      "learning_rate": 4.2674418604651164e-05,
      "loss": 0.0006,
      "step": 1890
    },
    {
      "epoch": 7.329457364341085,
      "grad_norm": 0.004090943839401007,
      "learning_rate": 4.267054263565892e-05,
      "loss": 0.0004,
      "step": 1891
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 9.722476959228516,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.6608,
      "step": 1892
    },
    {
      "epoch": 7.337209302325581,
      "grad_norm": 0.0254447590559721,
      "learning_rate": 4.266279069767442e-05,
      "loss": 0.0014,
      "step": 1893
    },
    {
      "epoch": 7.341085271317829,
      "grad_norm": 8.580565452575684,
      "learning_rate": 4.265891472868217e-05,
      "loss": 0.3937,
      "step": 1894
    },
    {
      "epoch": 7.344961240310077,
      "grad_norm": 0.003125095972791314,
      "learning_rate": 4.2655038759689927e-05,
      "loss": 0.0003,
      "step": 1895
    },
    {
      "epoch": 7.348837209302325,
      "grad_norm": 0.01247380767017603,
      "learning_rate": 4.265116279069767e-05,
      "loss": 0.0008,
      "step": 1896
    },
    {
      "epoch": 7.352713178294573,
      "grad_norm": 0.0032731506507843733,
      "learning_rate": 4.264728682170543e-05,
      "loss": 0.0003,
      "step": 1897
    },
    {
      "epoch": 7.3565891472868215,
      "grad_norm": 0.0035258824937045574,
      "learning_rate": 4.264341085271318e-05,
      "loss": 0.0003,
      "step": 1898
    },
    {
      "epoch": 7.3604651162790695,
      "grad_norm": 0.02296878769993782,
      "learning_rate": 4.2639534883720936e-05,
      "loss": 0.0013,
      "step": 1899
    },
    {
      "epoch": 7.364341085271318,
      "grad_norm": 0.004084452521055937,
      "learning_rate": 4.263565891472868e-05,
      "loss": 0.0004,
      "step": 1900
    },
    {
      "epoch": 7.368217054263566,
      "grad_norm": 6.466978073120117,
      "learning_rate": 4.2631782945736434e-05,
      "loss": 0.4719,
      "step": 1901
    },
    {
      "epoch": 7.372093023255814,
      "grad_norm": 25.77958106994629,
      "learning_rate": 4.262790697674419e-05,
      "loss": 0.4093,
      "step": 1902
    },
    {
      "epoch": 7.375968992248062,
      "grad_norm": 0.5718680620193481,
      "learning_rate": 4.262403100775194e-05,
      "loss": 0.0187,
      "step": 1903
    },
    {
      "epoch": 7.37984496124031,
      "grad_norm": 0.05745602771639824,
      "learning_rate": 4.262015503875969e-05,
      "loss": 0.0009,
      "step": 1904
    },
    {
      "epoch": 7.383720930232558,
      "grad_norm": 74.18173217773438,
      "learning_rate": 4.2616279069767444e-05,
      "loss": 0.111,
      "step": 1905
    },
    {
      "epoch": 7.387596899224806,
      "grad_norm": 0.0032720998860895634,
      "learning_rate": 4.2612403100775196e-05,
      "loss": 0.0003,
      "step": 1906
    },
    {
      "epoch": 7.391472868217054,
      "grad_norm": 0.011212368495762348,
      "learning_rate": 4.260852713178295e-05,
      "loss": 0.0005,
      "step": 1907
    },
    {
      "epoch": 7.395348837209302,
      "grad_norm": 6.302685260772705,
      "learning_rate": 4.26046511627907e-05,
      "loss": 0.3353,
      "step": 1908
    },
    {
      "epoch": 7.39922480620155,
      "grad_norm": 0.03317414969205856,
      "learning_rate": 4.2600775193798454e-05,
      "loss": 0.0011,
      "step": 1909
    },
    {
      "epoch": 7.403100775193798,
      "grad_norm": 0.008385533466935158,
      "learning_rate": 4.25968992248062e-05,
      "loss": 0.0007,
      "step": 1910
    },
    {
      "epoch": 7.406976744186046,
      "grad_norm": 2.3406832218170166,
      "learning_rate": 4.259302325581396e-05,
      "loss": 0.0286,
      "step": 1911
    },
    {
      "epoch": 7.410852713178294,
      "grad_norm": 0.005287069361656904,
      "learning_rate": 4.2589147286821704e-05,
      "loss": 0.0004,
      "step": 1912
    },
    {
      "epoch": 7.4147286821705425,
      "grad_norm": 7.6311821937561035,
      "learning_rate": 4.258527131782946e-05,
      "loss": 0.713,
      "step": 1913
    },
    {
      "epoch": 7.4186046511627906,
      "grad_norm": 0.006828185636550188,
      "learning_rate": 4.258139534883721e-05,
      "loss": 0.0005,
      "step": 1914
    },
    {
      "epoch": 7.422480620155039,
      "grad_norm": 4.809767246246338,
      "learning_rate": 4.257751937984497e-05,
      "loss": 0.5948,
      "step": 1915
    },
    {
      "epoch": 7.426356589147287,
      "grad_norm": 61.722564697265625,
      "learning_rate": 4.2573643410852714e-05,
      "loss": 0.0365,
      "step": 1916
    },
    {
      "epoch": 7.430232558139535,
      "grad_norm": 0.03773270919919014,
      "learning_rate": 4.256976744186047e-05,
      "loss": 0.0019,
      "step": 1917
    },
    {
      "epoch": 7.434108527131783,
      "grad_norm": 0.4952932894229889,
      "learning_rate": 4.256589147286822e-05,
      "loss": 0.0006,
      "step": 1918
    },
    {
      "epoch": 7.437984496124031,
      "grad_norm": 0.012926694005727768,
      "learning_rate": 4.256201550387597e-05,
      "loss": 0.0007,
      "step": 1919
    },
    {
      "epoch": 7.441860465116279,
      "grad_norm": 1.7675584554672241,
      "learning_rate": 4.2558139534883724e-05,
      "loss": 0.1369,
      "step": 1920
    },
    {
      "epoch": 7.445736434108527,
      "grad_norm": 0.02492048218846321,
      "learning_rate": 4.255426356589147e-05,
      "loss": 0.0011,
      "step": 1921
    },
    {
      "epoch": 7.449612403100775,
      "grad_norm": 0.09966430068016052,
      "learning_rate": 4.255038759689923e-05,
      "loss": 0.0024,
      "step": 1922
    },
    {
      "epoch": 7.453488372093023,
      "grad_norm": 0.04236404225230217,
      "learning_rate": 4.2546511627906974e-05,
      "loss": 0.0022,
      "step": 1923
    },
    {
      "epoch": 7.457364341085271,
      "grad_norm": 0.025714822113513947,
      "learning_rate": 4.254263565891473e-05,
      "loss": 0.0011,
      "step": 1924
    },
    {
      "epoch": 7.461240310077519,
      "grad_norm": 27.543245315551758,
      "learning_rate": 4.253875968992248e-05,
      "loss": 0.7869,
      "step": 1925
    },
    {
      "epoch": 7.465116279069767,
      "grad_norm": 0.02056194841861725,
      "learning_rate": 4.253488372093024e-05,
      "loss": 0.001,
      "step": 1926
    },
    {
      "epoch": 7.4689922480620154,
      "grad_norm": 0.04710543528199196,
      "learning_rate": 4.2531007751937984e-05,
      "loss": 0.0013,
      "step": 1927
    },
    {
      "epoch": 7.4728682170542635,
      "grad_norm": 0.043921176344156265,
      "learning_rate": 4.2527131782945736e-05,
      "loss": 0.0014,
      "step": 1928
    },
    {
      "epoch": 7.476744186046512,
      "grad_norm": 18.46927261352539,
      "learning_rate": 4.252325581395349e-05,
      "loss": 1.3494,
      "step": 1929
    },
    {
      "epoch": 7.48062015503876,
      "grad_norm": 0.1559264212846756,
      "learning_rate": 4.251937984496124e-05,
      "loss": 0.0047,
      "step": 1930
    },
    {
      "epoch": 7.484496124031008,
      "grad_norm": 29.675891876220703,
      "learning_rate": 4.251550387596899e-05,
      "loss": 1.2947,
      "step": 1931
    },
    {
      "epoch": 7.488372093023256,
      "grad_norm": 70.10235595703125,
      "learning_rate": 4.2511627906976746e-05,
      "loss": 0.4165,
      "step": 1932
    },
    {
      "epoch": 7.492248062015504,
      "grad_norm": 0.21276766061782837,
      "learning_rate": 4.25077519379845e-05,
      "loss": 0.0028,
      "step": 1933
    },
    {
      "epoch": 7.496124031007752,
      "grad_norm": 0.003755307989194989,
      "learning_rate": 4.250387596899225e-05,
      "loss": 0.0002,
      "step": 1934
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.060313113033771515,
      "learning_rate": 4.25e-05,
      "loss": 0.0026,
      "step": 1935
    },
    {
      "epoch": 7.503875968992248,
      "grad_norm": 0.6612603664398193,
      "learning_rate": 4.2496124031007755e-05,
      "loss": 0.0032,
      "step": 1936
    },
    {
      "epoch": 7.507751937984496,
      "grad_norm": 0.035159364342689514,
      "learning_rate": 4.249224806201551e-05,
      "loss": 0.0013,
      "step": 1937
    },
    {
      "epoch": 7.511627906976744,
      "grad_norm": 0.017219500616192818,
      "learning_rate": 4.248837209302326e-05,
      "loss": 0.0008,
      "step": 1938
    },
    {
      "epoch": 7.515503875968992,
      "grad_norm": 0.013412210159003735,
      "learning_rate": 4.2484496124031006e-05,
      "loss": 0.0008,
      "step": 1939
    },
    {
      "epoch": 7.51937984496124,
      "grad_norm": 0.3852372467517853,
      "learning_rate": 4.2480620155038765e-05,
      "loss": 0.0027,
      "step": 1940
    },
    {
      "epoch": 7.523255813953488,
      "grad_norm": 0.011537576094269753,
      "learning_rate": 4.247674418604651e-05,
      "loss": 0.0006,
      "step": 1941
    },
    {
      "epoch": 7.5271317829457365,
      "grad_norm": 14.458141326904297,
      "learning_rate": 4.247286821705427e-05,
      "loss": 0.491,
      "step": 1942
    },
    {
      "epoch": 7.5310077519379846,
      "grad_norm": 2.510606288909912,
      "learning_rate": 4.2468992248062016e-05,
      "loss": 0.1802,
      "step": 1943
    },
    {
      "epoch": 7.534883720930233,
      "grad_norm": 0.031873296946287155,
      "learning_rate": 4.2465116279069775e-05,
      "loss": 0.0007,
      "step": 1944
    },
    {
      "epoch": 7.538759689922481,
      "grad_norm": 0.015578338876366615,
      "learning_rate": 4.246124031007752e-05,
      "loss": 0.0008,
      "step": 1945
    },
    {
      "epoch": 7.542635658914729,
      "grad_norm": 0.03353764861822128,
      "learning_rate": 4.245736434108527e-05,
      "loss": 0.0016,
      "step": 1946
    },
    {
      "epoch": 7.546511627906977,
      "grad_norm": 0.0147934565320611,
      "learning_rate": 4.2453488372093025e-05,
      "loss": 0.0007,
      "step": 1947
    },
    {
      "epoch": 7.550387596899225,
      "grad_norm": 0.005659435875713825,
      "learning_rate": 4.244961240310078e-05,
      "loss": 0.0004,
      "step": 1948
    },
    {
      "epoch": 7.554263565891473,
      "grad_norm": 0.02492494322359562,
      "learning_rate": 4.244573643410853e-05,
      "loss": 0.0008,
      "step": 1949
    },
    {
      "epoch": 7.558139534883721,
      "grad_norm": 0.43307074904441833,
      "learning_rate": 4.2441860465116276e-05,
      "loss": 0.0081,
      "step": 1950
    },
    {
      "epoch": 7.562015503875969,
      "grad_norm": 4.17905855178833,
      "learning_rate": 4.2437984496124035e-05,
      "loss": 0.2488,
      "step": 1951
    },
    {
      "epoch": 7.565891472868217,
      "grad_norm": 0.05068434402346611,
      "learning_rate": 4.243410852713178e-05,
      "loss": 0.0018,
      "step": 1952
    },
    {
      "epoch": 7.569767441860465,
      "grad_norm": 0.006025331560522318,
      "learning_rate": 4.243023255813954e-05,
      "loss": 0.0005,
      "step": 1953
    },
    {
      "epoch": 7.573643410852713,
      "grad_norm": 0.13171713054180145,
      "learning_rate": 4.2426356589147286e-05,
      "loss": 0.0046,
      "step": 1954
    },
    {
      "epoch": 7.577519379844961,
      "grad_norm": 0.08223778009414673,
      "learning_rate": 4.2422480620155045e-05,
      "loss": 0.002,
      "step": 1955
    },
    {
      "epoch": 7.5813953488372094,
      "grad_norm": 9.392705917358398,
      "learning_rate": 4.241860465116279e-05,
      "loss": 1.8076,
      "step": 1956
    },
    {
      "epoch": 7.5852713178294575,
      "grad_norm": 8.00631046295166,
      "learning_rate": 4.241472868217054e-05,
      "loss": 0.5888,
      "step": 1957
    },
    {
      "epoch": 7.589147286821706,
      "grad_norm": 10.77144718170166,
      "learning_rate": 4.2410852713178295e-05,
      "loss": 0.6751,
      "step": 1958
    },
    {
      "epoch": 7.593023255813954,
      "grad_norm": 0.01564416103065014,
      "learning_rate": 4.240697674418605e-05,
      "loss": 0.0007,
      "step": 1959
    },
    {
      "epoch": 7.596899224806202,
      "grad_norm": 0.01873135380446911,
      "learning_rate": 4.24031007751938e-05,
      "loss": 0.0011,
      "step": 1960
    },
    {
      "epoch": 7.60077519379845,
      "grad_norm": 20.76999855041504,
      "learning_rate": 4.239922480620155e-05,
      "loss": 0.6543,
      "step": 1961
    },
    {
      "epoch": 7.604651162790698,
      "grad_norm": 1069.2916259765625,
      "learning_rate": 4.2395348837209305e-05,
      "loss": 0.4954,
      "step": 1962
    },
    {
      "epoch": 7.608527131782946,
      "grad_norm": 0.09320177882909775,
      "learning_rate": 4.239147286821706e-05,
      "loss": 0.0021,
      "step": 1963
    },
    {
      "epoch": 7.612403100775194,
      "grad_norm": 0.019468484446406364,
      "learning_rate": 4.238759689922481e-05,
      "loss": 0.0008,
      "step": 1964
    },
    {
      "epoch": 7.616279069767442,
      "grad_norm": 0.4431433379650116,
      "learning_rate": 4.238372093023256e-05,
      "loss": 0.0017,
      "step": 1965
    },
    {
      "epoch": 7.62015503875969,
      "grad_norm": 0.4541206955909729,
      "learning_rate": 4.2379844961240315e-05,
      "loss": 0.0037,
      "step": 1966
    },
    {
      "epoch": 7.624031007751938,
      "grad_norm": 0.016896434128284454,
      "learning_rate": 4.237596899224807e-05,
      "loss": 0.0007,
      "step": 1967
    },
    {
      "epoch": 7.627906976744186,
      "grad_norm": 0.17663463950157166,
      "learning_rate": 4.237209302325581e-05,
      "loss": 0.0019,
      "step": 1968
    },
    {
      "epoch": 7.631782945736434,
      "grad_norm": 15.001388549804688,
      "learning_rate": 4.236821705426357e-05,
      "loss": 0.2651,
      "step": 1969
    },
    {
      "epoch": 7.635658914728682,
      "grad_norm": 0.3076203465461731,
      "learning_rate": 4.236434108527132e-05,
      "loss": 0.0015,
      "step": 1970
    },
    {
      "epoch": 7.6395348837209305,
      "grad_norm": 1.5219570398330688,
      "learning_rate": 4.236046511627908e-05,
      "loss": 0.0229,
      "step": 1971
    },
    {
      "epoch": 7.6434108527131785,
      "grad_norm": 0.1277475208044052,
      "learning_rate": 4.235658914728682e-05,
      "loss": 0.0041,
      "step": 1972
    },
    {
      "epoch": 7.647286821705427,
      "grad_norm": 68.23664855957031,
      "learning_rate": 4.2352713178294575e-05,
      "loss": 0.1669,
      "step": 1973
    },
    {
      "epoch": 7.651162790697675,
      "grad_norm": 0.017612040042877197,
      "learning_rate": 4.234883720930233e-05,
      "loss": 0.0008,
      "step": 1974
    },
    {
      "epoch": 7.655038759689923,
      "grad_norm": 0.02655027061700821,
      "learning_rate": 4.234496124031008e-05,
      "loss": 0.0011,
      "step": 1975
    },
    {
      "epoch": 7.658914728682171,
      "grad_norm": 0.033276259899139404,
      "learning_rate": 4.234108527131783e-05,
      "loss": 0.0015,
      "step": 1976
    },
    {
      "epoch": 7.662790697674419,
      "grad_norm": 0.011651608161628246,
      "learning_rate": 4.2337209302325584e-05,
      "loss": 0.0007,
      "step": 1977
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 0.03673011064529419,
      "learning_rate": 4.233333333333334e-05,
      "loss": 0.001,
      "step": 1978
    },
    {
      "epoch": 7.670542635658915,
      "grad_norm": 9.647449493408203,
      "learning_rate": 4.232945736434108e-05,
      "loss": 0.8704,
      "step": 1979
    },
    {
      "epoch": 7.674418604651163,
      "grad_norm": 0.029780982062220573,
      "learning_rate": 4.232558139534884e-05,
      "loss": 0.0008,
      "step": 1980
    },
    {
      "epoch": 7.678294573643411,
      "grad_norm": 0.07805328071117401,
      "learning_rate": 4.232170542635659e-05,
      "loss": 0.001,
      "step": 1981
    },
    {
      "epoch": 7.682170542635659,
      "grad_norm": 0.30538201332092285,
      "learning_rate": 4.2317829457364347e-05,
      "loss": 0.0018,
      "step": 1982
    },
    {
      "epoch": 7.686046511627907,
      "grad_norm": 13.570895195007324,
      "learning_rate": 4.231395348837209e-05,
      "loss": 0.2008,
      "step": 1983
    },
    {
      "epoch": 7.689922480620155,
      "grad_norm": 0.0078118108212947845,
      "learning_rate": 4.231007751937985e-05,
      "loss": 0.0006,
      "step": 1984
    },
    {
      "epoch": 7.6937984496124034,
      "grad_norm": 0.0342894084751606,
      "learning_rate": 4.23062015503876e-05,
      "loss": 0.0009,
      "step": 1985
    },
    {
      "epoch": 7.6976744186046515,
      "grad_norm": 0.018067659810185432,
      "learning_rate": 4.230232558139535e-05,
      "loss": 0.0007,
      "step": 1986
    },
    {
      "epoch": 7.7015503875969,
      "grad_norm": 0.007904843427240849,
      "learning_rate": 4.22984496124031e-05,
      "loss": 0.0006,
      "step": 1987
    },
    {
      "epoch": 7.705426356589148,
      "grad_norm": 0.015632670372724533,
      "learning_rate": 4.2294573643410854e-05,
      "loss": 0.0008,
      "step": 1988
    },
    {
      "epoch": 7.709302325581396,
      "grad_norm": 10.517763137817383,
      "learning_rate": 4.229069767441861e-05,
      "loss": 0.445,
      "step": 1989
    },
    {
      "epoch": 7.713178294573644,
      "grad_norm": 0.009655613452196121,
      "learning_rate": 4.228682170542636e-05,
      "loss": 0.0006,
      "step": 1990
    },
    {
      "epoch": 7.717054263565892,
      "grad_norm": 0.9830512404441833,
      "learning_rate": 4.228294573643411e-05,
      "loss": 0.0667,
      "step": 1991
    },
    {
      "epoch": 7.720930232558139,
      "grad_norm": 18.062427520751953,
      "learning_rate": 4.2279069767441864e-05,
      "loss": 0.1581,
      "step": 1992
    },
    {
      "epoch": 7.724806201550388,
      "grad_norm": 0.009927220642566681,
      "learning_rate": 4.2275193798449616e-05,
      "loss": 0.0008,
      "step": 1993
    },
    {
      "epoch": 7.728682170542635,
      "grad_norm": 0.018160931766033173,
      "learning_rate": 4.227131782945737e-05,
      "loss": 0.0011,
      "step": 1994
    },
    {
      "epoch": 7.732558139534884,
      "grad_norm": 0.008454883471131325,
      "learning_rate": 4.226744186046512e-05,
      "loss": 0.0004,
      "step": 1995
    },
    {
      "epoch": 7.736434108527131,
      "grad_norm": 0.03382003307342529,
      "learning_rate": 4.2263565891472874e-05,
      "loss": 0.0008,
      "step": 1996
    },
    {
      "epoch": 7.74031007751938,
      "grad_norm": 1.5405371189117432,
      "learning_rate": 4.225968992248062e-05,
      "loss": 0.0174,
      "step": 1997
    },
    {
      "epoch": 7.7441860465116275,
      "grad_norm": 0.5842568278312683,
      "learning_rate": 4.225581395348838e-05,
      "loss": 0.0016,
      "step": 1998
    },
    {
      "epoch": 7.748062015503876,
      "grad_norm": 0.020159564912319183,
      "learning_rate": 4.2251937984496124e-05,
      "loss": 0.0008,
      "step": 1999
    },
    {
      "epoch": 7.751937984496124,
      "grad_norm": 0.014928296208381653,
      "learning_rate": 4.2248062015503877e-05,
      "loss": 0.0009,
      "step": 2000
    },
    {
      "epoch": 7.7558139534883725,
      "grad_norm": 0.026167090982198715,
      "learning_rate": 4.224418604651163e-05,
      "loss": 0.0015,
      "step": 2001
    },
    {
      "epoch": 7.75968992248062,
      "grad_norm": 7.382959842681885,
      "learning_rate": 4.224031007751938e-05,
      "loss": 0.3418,
      "step": 2002
    },
    {
      "epoch": 7.763565891472869,
      "grad_norm": 11.030719757080078,
      "learning_rate": 4.2236434108527134e-05,
      "loss": 0.5,
      "step": 2003
    },
    {
      "epoch": 7.767441860465116,
      "grad_norm": 11.955709457397461,
      "learning_rate": 4.2232558139534886e-05,
      "loss": 0.4061,
      "step": 2004
    },
    {
      "epoch": 7.771317829457365,
      "grad_norm": 0.014432338997721672,
      "learning_rate": 4.222868217054264e-05,
      "loss": 0.0007,
      "step": 2005
    },
    {
      "epoch": 7.775193798449612,
      "grad_norm": 0.020470362156629562,
      "learning_rate": 4.2224806201550384e-05,
      "loss": 0.0008,
      "step": 2006
    },
    {
      "epoch": 7.779069767441861,
      "grad_norm": 15.873922348022461,
      "learning_rate": 4.2220930232558144e-05,
      "loss": 0.3473,
      "step": 2007
    },
    {
      "epoch": 7.782945736434108,
      "grad_norm": 7.823634624481201,
      "learning_rate": 4.221705426356589e-05,
      "loss": 0.4462,
      "step": 2008
    },
    {
      "epoch": 7.786821705426356,
      "grad_norm": 0.04366070777177811,
      "learning_rate": 4.221317829457365e-05,
      "loss": 0.0012,
      "step": 2009
    },
    {
      "epoch": 7.790697674418604,
      "grad_norm": 3.337299346923828,
      "learning_rate": 4.2209302325581394e-05,
      "loss": 0.1441,
      "step": 2010
    },
    {
      "epoch": 7.794573643410852,
      "grad_norm": 2.2420079708099365,
      "learning_rate": 4.220542635658915e-05,
      "loss": 0.0823,
      "step": 2011
    },
    {
      "epoch": 7.7984496124031,
      "grad_norm": 0.03467074781656265,
      "learning_rate": 4.22015503875969e-05,
      "loss": 0.0011,
      "step": 2012
    },
    {
      "epoch": 7.8023255813953485,
      "grad_norm": 0.01737317256629467,
      "learning_rate": 4.219767441860465e-05,
      "loss": 0.0009,
      "step": 2013
    },
    {
      "epoch": 7.8062015503875966,
      "grad_norm": 0.01405436173081398,
      "learning_rate": 4.2193798449612404e-05,
      "loss": 0.0008,
      "step": 2014
    },
    {
      "epoch": 7.810077519379845,
      "grad_norm": 3.904209613800049,
      "learning_rate": 4.2189922480620156e-05,
      "loss": 0.0631,
      "step": 2015
    },
    {
      "epoch": 7.813953488372093,
      "grad_norm": 0.04565656930208206,
      "learning_rate": 4.218604651162791e-05,
      "loss": 0.0015,
      "step": 2016
    },
    {
      "epoch": 7.817829457364341,
      "grad_norm": 0.2993079125881195,
      "learning_rate": 4.218217054263566e-05,
      "loss": 0.0049,
      "step": 2017
    },
    {
      "epoch": 7.821705426356589,
      "grad_norm": 0.03155721351504326,
      "learning_rate": 4.217829457364341e-05,
      "loss": 0.0008,
      "step": 2018
    },
    {
      "epoch": 7.825581395348837,
      "grad_norm": 3.612337350845337,
      "learning_rate": 4.2174418604651166e-05,
      "loss": 0.1516,
      "step": 2019
    },
    {
      "epoch": 7.829457364341085,
      "grad_norm": 0.008501200005412102,
      "learning_rate": 4.217054263565892e-05,
      "loss": 0.0006,
      "step": 2020
    },
    {
      "epoch": 7.833333333333333,
      "grad_norm": 0.3437580466270447,
      "learning_rate": 4.216666666666667e-05,
      "loss": 0.0045,
      "step": 2021
    },
    {
      "epoch": 7.837209302325581,
      "grad_norm": 22.20844078063965,
      "learning_rate": 4.216279069767442e-05,
      "loss": 0.2745,
      "step": 2022
    },
    {
      "epoch": 7.841085271317829,
      "grad_norm": 41.9776725769043,
      "learning_rate": 4.2158914728682175e-05,
      "loss": 0.6731,
      "step": 2023
    },
    {
      "epoch": 7.844961240310077,
      "grad_norm": 0.04624129459261894,
      "learning_rate": 4.215503875968992e-05,
      "loss": 0.0016,
      "step": 2024
    },
    {
      "epoch": 7.848837209302325,
      "grad_norm": 7.582355976104736,
      "learning_rate": 4.215116279069768e-05,
      "loss": 0.5561,
      "step": 2025
    },
    {
      "epoch": 7.852713178294573,
      "grad_norm": 4.694869041442871,
      "learning_rate": 4.2147286821705426e-05,
      "loss": 0.2782,
      "step": 2026
    },
    {
      "epoch": 7.8565891472868215,
      "grad_norm": 0.01205902174115181,
      "learning_rate": 4.214341085271318e-05,
      "loss": 0.0007,
      "step": 2027
    },
    {
      "epoch": 7.8604651162790695,
      "grad_norm": 0.12577901780605316,
      "learning_rate": 4.213953488372093e-05,
      "loss": 0.0006,
      "step": 2028
    },
    {
      "epoch": 7.864341085271318,
      "grad_norm": 2.0418057441711426,
      "learning_rate": 4.213565891472868e-05,
      "loss": 0.0144,
      "step": 2029
    },
    {
      "epoch": 7.868217054263566,
      "grad_norm": 0.010489169508218765,
      "learning_rate": 4.2131782945736436e-05,
      "loss": 0.0006,
      "step": 2030
    },
    {
      "epoch": 7.872093023255814,
      "grad_norm": 0.3211085796356201,
      "learning_rate": 4.212790697674419e-05,
      "loss": 0.0112,
      "step": 2031
    },
    {
      "epoch": 7.875968992248062,
      "grad_norm": 0.014711538329720497,
      "learning_rate": 4.212403100775194e-05,
      "loss": 0.0009,
      "step": 2032
    },
    {
      "epoch": 7.87984496124031,
      "grad_norm": 0.014546814374625683,
      "learning_rate": 4.212015503875969e-05,
      "loss": 0.0006,
      "step": 2033
    },
    {
      "epoch": 7.883720930232558,
      "grad_norm": 0.006350143346935511,
      "learning_rate": 4.2116279069767445e-05,
      "loss": 0.0005,
      "step": 2034
    },
    {
      "epoch": 7.887596899224806,
      "grad_norm": 0.10773459076881409,
      "learning_rate": 4.211240310077519e-05,
      "loss": 0.0009,
      "step": 2035
    },
    {
      "epoch": 7.891472868217054,
      "grad_norm": 0.028650464490056038,
      "learning_rate": 4.210852713178295e-05,
      "loss": 0.0014,
      "step": 2036
    },
    {
      "epoch": 7.895348837209302,
      "grad_norm": 0.008520598523318768,
      "learning_rate": 4.2104651162790696e-05,
      "loss": 0.0006,
      "step": 2037
    },
    {
      "epoch": 7.89922480620155,
      "grad_norm": 0.07210948318243027,
      "learning_rate": 4.2100775193798455e-05,
      "loss": 0.0012,
      "step": 2038
    },
    {
      "epoch": 7.903100775193798,
      "grad_norm": 5.92887020111084,
      "learning_rate": 4.20968992248062e-05,
      "loss": 0.2623,
      "step": 2039
    },
    {
      "epoch": 7.906976744186046,
      "grad_norm": 0.014574007131159306,
      "learning_rate": 4.209302325581396e-05,
      "loss": 0.0006,
      "step": 2040
    },
    {
      "epoch": 7.910852713178294,
      "grad_norm": 0.00803972128778696,
      "learning_rate": 4.2089147286821706e-05,
      "loss": 0.0005,
      "step": 2041
    },
    {
      "epoch": 7.9147286821705425,
      "grad_norm": 0.014555913396179676,
      "learning_rate": 4.208527131782946e-05,
      "loss": 0.0011,
      "step": 2042
    },
    {
      "epoch": 7.9186046511627906,
      "grad_norm": 0.13530319929122925,
      "learning_rate": 4.208139534883721e-05,
      "loss": 0.0025,
      "step": 2043
    },
    {
      "epoch": 7.922480620155039,
      "grad_norm": 4.744659900665283,
      "learning_rate": 4.207751937984496e-05,
      "loss": 0.052,
      "step": 2044
    },
    {
      "epoch": 7.926356589147287,
      "grad_norm": 0.011144747026264668,
      "learning_rate": 4.2073643410852715e-05,
      "loss": 0.0005,
      "step": 2045
    },
    {
      "epoch": 7.930232558139535,
      "grad_norm": 0.005907234735786915,
      "learning_rate": 4.206976744186047e-05,
      "loss": 0.0004,
      "step": 2046
    },
    {
      "epoch": 7.934108527131783,
      "grad_norm": 5.930568695068359,
      "learning_rate": 4.206589147286822e-05,
      "loss": 0.1409,
      "step": 2047
    },
    {
      "epoch": 7.937984496124031,
      "grad_norm": 0.013606976717710495,
      "learning_rate": 4.206201550387597e-05,
      "loss": 0.0006,
      "step": 2048
    },
    {
      "epoch": 7.941860465116279,
      "grad_norm": 0.01245839986950159,
      "learning_rate": 4.2058139534883725e-05,
      "loss": 0.0006,
      "step": 2049
    },
    {
      "epoch": 7.945736434108527,
      "grad_norm": 0.010079528205096722,
      "learning_rate": 4.205426356589148e-05,
      "loss": 0.0006,
      "step": 2050
    },
    {
      "epoch": 7.949612403100775,
      "grad_norm": 64.09381103515625,
      "learning_rate": 4.205038759689923e-05,
      "loss": 0.3868,
      "step": 2051
    },
    {
      "epoch": 7.953488372093023,
      "grad_norm": 0.039787210524082184,
      "learning_rate": 4.204651162790698e-05,
      "loss": 0.0008,
      "step": 2052
    },
    {
      "epoch": 7.957364341085271,
      "grad_norm": 0.006945712026208639,
      "learning_rate": 4.204263565891473e-05,
      "loss": 0.0006,
      "step": 2053
    },
    {
      "epoch": 7.961240310077519,
      "grad_norm": 6.9988322257995605,
      "learning_rate": 4.203875968992248e-05,
      "loss": 0.3329,
      "step": 2054
    },
    {
      "epoch": 7.965116279069767,
      "grad_norm": 0.010498383082449436,
      "learning_rate": 4.203488372093023e-05,
      "loss": 0.0007,
      "step": 2055
    },
    {
      "epoch": 7.9689922480620154,
      "grad_norm": 0.005581095814704895,
      "learning_rate": 4.2031007751937985e-05,
      "loss": 0.0005,
      "step": 2056
    },
    {
      "epoch": 7.9728682170542635,
      "grad_norm": 0.04911697655916214,
      "learning_rate": 4.202713178294574e-05,
      "loss": 0.0022,
      "step": 2057
    },
    {
      "epoch": 7.976744186046512,
      "grad_norm": 0.011915895156562328,
      "learning_rate": 4.202325581395349e-05,
      "loss": 0.0006,
      "step": 2058
    },
    {
      "epoch": 7.98062015503876,
      "grad_norm": 0.019462987780570984,
      "learning_rate": 4.201937984496124e-05,
      "loss": 0.0009,
      "step": 2059
    },
    {
      "epoch": 7.984496124031008,
      "grad_norm": 0.059253424406051636,
      "learning_rate": 4.2015503875968995e-05,
      "loss": 0.001,
      "step": 2060
    },
    {
      "epoch": 7.988372093023256,
      "grad_norm": 0.02703937701880932,
      "learning_rate": 4.201162790697675e-05,
      "loss": 0.0009,
      "step": 2061
    },
    {
      "epoch": 7.992248062015504,
      "grad_norm": 10.139163970947266,
      "learning_rate": 4.20077519379845e-05,
      "loss": 0.0722,
      "step": 2062
    },
    {
      "epoch": 7.996124031007752,
      "grad_norm": 0.42188358306884766,
      "learning_rate": 4.200387596899225e-05,
      "loss": 0.0045,
      "step": 2063
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.02188870497047901,
      "learning_rate": 4.2e-05,
      "loss": 0.0008,
      "step": 2064
    },
    {
      "epoch": 8.003875968992247,
      "grad_norm": 5.390852928161621,
      "learning_rate": 4.199612403100776e-05,
      "loss": 0.1457,
      "step": 2065
    },
    {
      "epoch": 8.007751937984496,
      "grad_norm": 0.021308796480298042,
      "learning_rate": 4.19922480620155e-05,
      "loss": 0.0006,
      "step": 2066
    },
    {
      "epoch": 8.011627906976743,
      "grad_norm": 10.123281478881836,
      "learning_rate": 4.198837209302326e-05,
      "loss": 0.3911,
      "step": 2067
    },
    {
      "epoch": 8.015503875968992,
      "grad_norm": 3.7859277725219727,
      "learning_rate": 4.198449612403101e-05,
      "loss": 0.0715,
      "step": 2068
    },
    {
      "epoch": 8.01937984496124,
      "grad_norm": 0.5841412544250488,
      "learning_rate": 4.1980620155038767e-05,
      "loss": 0.015,
      "step": 2069
    },
    {
      "epoch": 8.023255813953488,
      "grad_norm": 0.17782163619995117,
      "learning_rate": 4.197674418604651e-05,
      "loss": 0.0014,
      "step": 2070
    },
    {
      "epoch": 8.027131782945736,
      "grad_norm": 0.02847057767212391,
      "learning_rate": 4.1972868217054265e-05,
      "loss": 0.0008,
      "step": 2071
    },
    {
      "epoch": 8.031007751937985,
      "grad_norm": 1.6252470016479492,
      "learning_rate": 4.196899224806202e-05,
      "loss": 0.0057,
      "step": 2072
    },
    {
      "epoch": 8.034883720930232,
      "grad_norm": 3.7936439514160156,
      "learning_rate": 4.196511627906977e-05,
      "loss": 0.2289,
      "step": 2073
    },
    {
      "epoch": 8.03875968992248,
      "grad_norm": 0.02085821144282818,
      "learning_rate": 4.196124031007752e-05,
      "loss": 0.0007,
      "step": 2074
    },
    {
      "epoch": 8.042635658914728,
      "grad_norm": 0.007742187008261681,
      "learning_rate": 4.1957364341085274e-05,
      "loss": 0.0005,
      "step": 2075
    },
    {
      "epoch": 8.046511627906977,
      "grad_norm": 0.1321735829114914,
      "learning_rate": 4.195348837209303e-05,
      "loss": 0.0043,
      "step": 2076
    },
    {
      "epoch": 8.050387596899224,
      "grad_norm": 0.01964070461690426,
      "learning_rate": 4.194961240310078e-05,
      "loss": 0.0006,
      "step": 2077
    },
    {
      "epoch": 8.054263565891473,
      "grad_norm": 4.9683709144592285,
      "learning_rate": 4.194573643410853e-05,
      "loss": 0.1203,
      "step": 2078
    },
    {
      "epoch": 8.05813953488372,
      "grad_norm": 2.944995641708374,
      "learning_rate": 4.194186046511628e-05,
      "loss": 0.0757,
      "step": 2079
    },
    {
      "epoch": 8.062015503875969,
      "grad_norm": 0.004127658437937498,
      "learning_rate": 4.1937984496124036e-05,
      "loss": 0.0004,
      "step": 2080
    },
    {
      "epoch": 8.065891472868216,
      "grad_norm": 0.0036159197334200144,
      "learning_rate": 4.193410852713178e-05,
      "loss": 0.0004,
      "step": 2081
    },
    {
      "epoch": 8.069767441860465,
      "grad_norm": 0.006879325956106186,
      "learning_rate": 4.1930232558139534e-05,
      "loss": 0.0005,
      "step": 2082
    },
    {
      "epoch": 8.073643410852712,
      "grad_norm": 0.3520568311214447,
      "learning_rate": 4.192635658914729e-05,
      "loss": 0.0045,
      "step": 2083
    },
    {
      "epoch": 8.077519379844961,
      "grad_norm": 0.006974601652473211,
      "learning_rate": 4.192248062015504e-05,
      "loss": 0.0004,
      "step": 2084
    },
    {
      "epoch": 8.081395348837209,
      "grad_norm": 0.007505007553845644,
      "learning_rate": 4.191860465116279e-05,
      "loss": 0.0004,
      "step": 2085
    },
    {
      "epoch": 8.085271317829458,
      "grad_norm": 7.812551498413086,
      "learning_rate": 4.1914728682170544e-05,
      "loss": 0.1782,
      "step": 2086
    },
    {
      "epoch": 8.089147286821705,
      "grad_norm": 34.1986083984375,
      "learning_rate": 4.1910852713178297e-05,
      "loss": 0.1272,
      "step": 2087
    },
    {
      "epoch": 8.093023255813954,
      "grad_norm": 0.005395416636019945,
      "learning_rate": 4.190697674418605e-05,
      "loss": 0.0005,
      "step": 2088
    },
    {
      "epoch": 8.0968992248062,
      "grad_norm": 0.006978081539273262,
      "learning_rate": 4.19031007751938e-05,
      "loss": 0.0006,
      "step": 2089
    },
    {
      "epoch": 8.10077519379845,
      "grad_norm": 0.007959098555147648,
      "learning_rate": 4.1899224806201554e-05,
      "loss": 0.0005,
      "step": 2090
    },
    {
      "epoch": 8.104651162790697,
      "grad_norm": 0.09565921872854233,
      "learning_rate": 4.18953488372093e-05,
      "loss": 0.0014,
      "step": 2091
    },
    {
      "epoch": 8.108527131782946,
      "grad_norm": 1.8049423694610596,
      "learning_rate": 4.189147286821706e-05,
      "loss": 0.0361,
      "step": 2092
    },
    {
      "epoch": 8.112403100775193,
      "grad_norm": 0.006797692272812128,
      "learning_rate": 4.1887596899224804e-05,
      "loss": 0.0004,
      "step": 2093
    },
    {
      "epoch": 8.116279069767442,
      "grad_norm": 0.006144984625279903,
      "learning_rate": 4.1883720930232564e-05,
      "loss": 0.0004,
      "step": 2094
    },
    {
      "epoch": 8.12015503875969,
      "grad_norm": 0.010759739205241203,
      "learning_rate": 4.187984496124031e-05,
      "loss": 0.0005,
      "step": 2095
    },
    {
      "epoch": 8.124031007751938,
      "grad_norm": 2.3554768562316895,
      "learning_rate": 4.187596899224807e-05,
      "loss": 0.0096,
      "step": 2096
    },
    {
      "epoch": 8.127906976744185,
      "grad_norm": 0.007169964723289013,
      "learning_rate": 4.1872093023255814e-05,
      "loss": 0.0005,
      "step": 2097
    },
    {
      "epoch": 8.131782945736434,
      "grad_norm": 0.004215601831674576,
      "learning_rate": 4.186821705426357e-05,
      "loss": 0.0003,
      "step": 2098
    },
    {
      "epoch": 8.135658914728682,
      "grad_norm": 0.7797970771789551,
      "learning_rate": 4.186434108527132e-05,
      "loss": 0.0007,
      "step": 2099
    },
    {
      "epoch": 8.13953488372093,
      "grad_norm": 0.00429282383993268,
      "learning_rate": 4.186046511627907e-05,
      "loss": 0.0003,
      "step": 2100
    },
    {
      "epoch": 8.143410852713178,
      "grad_norm": 0.01027678418904543,
      "learning_rate": 4.1856589147286824e-05,
      "loss": 0.0007,
      "step": 2101
    },
    {
      "epoch": 8.147286821705427,
      "grad_norm": 7.4171671867370605,
      "learning_rate": 4.1852713178294576e-05,
      "loss": 0.6045,
      "step": 2102
    },
    {
      "epoch": 8.151162790697674,
      "grad_norm": 0.004156087059527636,
      "learning_rate": 4.184883720930233e-05,
      "loss": 0.0004,
      "step": 2103
    },
    {
      "epoch": 8.155038759689923,
      "grad_norm": 0.00417931517586112,
      "learning_rate": 4.184496124031008e-05,
      "loss": 0.0004,
      "step": 2104
    },
    {
      "epoch": 8.15891472868217,
      "grad_norm": 11.812246322631836,
      "learning_rate": 4.1841085271317833e-05,
      "loss": 0.1293,
      "step": 2105
    },
    {
      "epoch": 8.162790697674419,
      "grad_norm": 0.004240015055984259,
      "learning_rate": 4.183720930232558e-05,
      "loss": 0.0004,
      "step": 2106
    },
    {
      "epoch": 8.166666666666666,
      "grad_norm": 8.237197875976562,
      "learning_rate": 4.183333333333334e-05,
      "loss": 0.1701,
      "step": 2107
    },
    {
      "epoch": 8.170542635658915,
      "grad_norm": 0.0047450559213757515,
      "learning_rate": 4.1829457364341084e-05,
      "loss": 0.0004,
      "step": 2108
    },
    {
      "epoch": 8.174418604651162,
      "grad_norm": 1.828791856765747,
      "learning_rate": 4.1825581395348836e-05,
      "loss": 0.1636,
      "step": 2109
    },
    {
      "epoch": 8.178294573643411,
      "grad_norm": 5.097359657287598,
      "learning_rate": 4.182170542635659e-05,
      "loss": 0.6819,
      "step": 2110
    },
    {
      "epoch": 8.182170542635658,
      "grad_norm": 0.5397505760192871,
      "learning_rate": 4.181782945736434e-05,
      "loss": 0.0062,
      "step": 2111
    },
    {
      "epoch": 8.186046511627907,
      "grad_norm": 0.009431460872292519,
      "learning_rate": 4.1813953488372094e-05,
      "loss": 0.0005,
      "step": 2112
    },
    {
      "epoch": 8.189922480620154,
      "grad_norm": 0.01358834933489561,
      "learning_rate": 4.1810077519379846e-05,
      "loss": 0.0006,
      "step": 2113
    },
    {
      "epoch": 8.193798449612403,
      "grad_norm": 0.009709457866847515,
      "learning_rate": 4.18062015503876e-05,
      "loss": 0.0006,
      "step": 2114
    },
    {
      "epoch": 8.19767441860465,
      "grad_norm": 6.450516223907471,
      "learning_rate": 4.180232558139535e-05,
      "loss": 0.6167,
      "step": 2115
    },
    {
      "epoch": 8.2015503875969,
      "grad_norm": 17.76137924194336,
      "learning_rate": 4.17984496124031e-05,
      "loss": 0.1894,
      "step": 2116
    },
    {
      "epoch": 8.205426356589147,
      "grad_norm": 0.014945916831493378,
      "learning_rate": 4.1794573643410856e-05,
      "loss": 0.0006,
      "step": 2117
    },
    {
      "epoch": 8.209302325581396,
      "grad_norm": 0.21367189288139343,
      "learning_rate": 4.179069767441861e-05,
      "loss": 0.0008,
      "step": 2118
    },
    {
      "epoch": 8.213178294573643,
      "grad_norm": 0.017059287056326866,
      "learning_rate": 4.178682170542636e-05,
      "loss": 0.0008,
      "step": 2119
    },
    {
      "epoch": 8.217054263565892,
      "grad_norm": 5.650616645812988,
      "learning_rate": 4.1782945736434106e-05,
      "loss": 0.1939,
      "step": 2120
    },
    {
      "epoch": 8.220930232558139,
      "grad_norm": 0.10344761610031128,
      "learning_rate": 4.1779069767441865e-05,
      "loss": 0.0024,
      "step": 2121
    },
    {
      "epoch": 8.224806201550388,
      "grad_norm": 7.424156665802002,
      "learning_rate": 4.177519379844961e-05,
      "loss": 0.0116,
      "step": 2122
    },
    {
      "epoch": 8.228682170542635,
      "grad_norm": 0.015928102657198906,
      "learning_rate": 4.177131782945737e-05,
      "loss": 0.0006,
      "step": 2123
    },
    {
      "epoch": 8.232558139534884,
      "grad_norm": 0.1401061862707138,
      "learning_rate": 4.1767441860465116e-05,
      "loss": 0.0032,
      "step": 2124
    },
    {
      "epoch": 8.236434108527131,
      "grad_norm": 0.014289015904068947,
      "learning_rate": 4.1763565891472875e-05,
      "loss": 0.0006,
      "step": 2125
    },
    {
      "epoch": 8.24031007751938,
      "grad_norm": 3.6721158027648926,
      "learning_rate": 4.175968992248062e-05,
      "loss": 0.0175,
      "step": 2126
    },
    {
      "epoch": 8.244186046511627,
      "grad_norm": 4.824480056762695,
      "learning_rate": 4.175581395348837e-05,
      "loss": 0.0093,
      "step": 2127
    },
    {
      "epoch": 8.248062015503876,
      "grad_norm": 0.024176448583602905,
      "learning_rate": 4.1751937984496126e-05,
      "loss": 0.0005,
      "step": 2128
    },
    {
      "epoch": 8.251937984496124,
      "grad_norm": 11.337885856628418,
      "learning_rate": 4.174806201550388e-05,
      "loss": 1.455,
      "step": 2129
    },
    {
      "epoch": 8.255813953488373,
      "grad_norm": 1.3291091918945312,
      "learning_rate": 4.174418604651163e-05,
      "loss": 0.1047,
      "step": 2130
    },
    {
      "epoch": 8.25968992248062,
      "grad_norm": 0.04975865036249161,
      "learning_rate": 4.174031007751938e-05,
      "loss": 0.0007,
      "step": 2131
    },
    {
      "epoch": 8.263565891472869,
      "grad_norm": 0.014630166813731194,
      "learning_rate": 4.1736434108527135e-05,
      "loss": 0.0006,
      "step": 2132
    },
    {
      "epoch": 8.267441860465116,
      "grad_norm": 0.17166337370872498,
      "learning_rate": 4.173255813953488e-05,
      "loss": 0.0007,
      "step": 2133
    },
    {
      "epoch": 8.271317829457365,
      "grad_norm": 0.0202817153185606,
      "learning_rate": 4.172868217054264e-05,
      "loss": 0.0007,
      "step": 2134
    },
    {
      "epoch": 8.275193798449612,
      "grad_norm": 0.007516390644013882,
      "learning_rate": 4.1724806201550386e-05,
      "loss": 0.0005,
      "step": 2135
    },
    {
      "epoch": 8.279069767441861,
      "grad_norm": 0.016524450853466988,
      "learning_rate": 4.1720930232558145e-05,
      "loss": 0.0008,
      "step": 2136
    },
    {
      "epoch": 8.282945736434108,
      "grad_norm": 0.35186856985092163,
      "learning_rate": 4.171705426356589e-05,
      "loss": 0.0095,
      "step": 2137
    },
    {
      "epoch": 8.286821705426357,
      "grad_norm": 0.007050840649753809,
      "learning_rate": 4.171317829457364e-05,
      "loss": 0.0005,
      "step": 2138
    },
    {
      "epoch": 8.290697674418604,
      "grad_norm": 3.7753639221191406,
      "learning_rate": 4.1709302325581395e-05,
      "loss": 0.1895,
      "step": 2139
    },
    {
      "epoch": 8.294573643410853,
      "grad_norm": 0.4574139714241028,
      "learning_rate": 4.170542635658915e-05,
      "loss": 0.0029,
      "step": 2140
    },
    {
      "epoch": 8.2984496124031,
      "grad_norm": 0.004181283991783857,
      "learning_rate": 4.17015503875969e-05,
      "loss": 0.0004,
      "step": 2141
    },
    {
      "epoch": 8.30232558139535,
      "grad_norm": 0.005254798103123903,
      "learning_rate": 4.169767441860465e-05,
      "loss": 0.0005,
      "step": 2142
    },
    {
      "epoch": 8.306201550387597,
      "grad_norm": 0.004380848724395037,
      "learning_rate": 4.1693798449612405e-05,
      "loss": 0.0004,
      "step": 2143
    },
    {
      "epoch": 8.310077519379846,
      "grad_norm": 5.141875267028809,
      "learning_rate": 4.168992248062016e-05,
      "loss": 0.2558,
      "step": 2144
    },
    {
      "epoch": 8.313953488372093,
      "grad_norm": 0.15287378430366516,
      "learning_rate": 4.168604651162791e-05,
      "loss": 0.0031,
      "step": 2145
    },
    {
      "epoch": 8.317829457364342,
      "grad_norm": 0.010833974927663803,
      "learning_rate": 4.168217054263566e-05,
      "loss": 0.0007,
      "step": 2146
    },
    {
      "epoch": 8.321705426356589,
      "grad_norm": 0.09236114472150803,
      "learning_rate": 4.1678294573643415e-05,
      "loss": 0.0013,
      "step": 2147
    },
    {
      "epoch": 8.325581395348838,
      "grad_norm": 0.004718315321952105,
      "learning_rate": 4.167441860465117e-05,
      "loss": 0.0005,
      "step": 2148
    },
    {
      "epoch": 8.329457364341085,
      "grad_norm": 0.005310478620231152,
      "learning_rate": 4.167054263565891e-05,
      "loss": 0.0004,
      "step": 2149
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.007017044350504875,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.0005,
      "step": 2150
    },
    {
      "epoch": 8.337209302325581,
      "grad_norm": 0.11516743153333664,
      "learning_rate": 4.166279069767442e-05,
      "loss": 0.0023,
      "step": 2151
    },
    {
      "epoch": 8.34108527131783,
      "grad_norm": 8.964855194091797,
      "learning_rate": 4.165891472868218e-05,
      "loss": 0.412,
      "step": 2152
    },
    {
      "epoch": 8.344961240310077,
      "grad_norm": 0.4528346657752991,
      "learning_rate": 4.165503875968992e-05,
      "loss": 0.0159,
      "step": 2153
    },
    {
      "epoch": 8.348837209302326,
      "grad_norm": 4.36591100692749,
      "learning_rate": 4.165116279069768e-05,
      "loss": 0.3816,
      "step": 2154
    },
    {
      "epoch": 8.352713178294573,
      "grad_norm": 0.005155051127076149,
      "learning_rate": 4.164728682170543e-05,
      "loss": 0.0005,
      "step": 2155
    },
    {
      "epoch": 8.356589147286822,
      "grad_norm": 0.6165624260902405,
      "learning_rate": 4.164341085271318e-05,
      "loss": 0.0015,
      "step": 2156
    },
    {
      "epoch": 8.36046511627907,
      "grad_norm": 0.3306502103805542,
      "learning_rate": 4.163953488372093e-05,
      "loss": 0.0031,
      "step": 2157
    },
    {
      "epoch": 8.364341085271318,
      "grad_norm": 0.013289133086800575,
      "learning_rate": 4.1635658914728685e-05,
      "loss": 0.0005,
      "step": 2158
    },
    {
      "epoch": 8.368217054263566,
      "grad_norm": 0.012680401094257832,
      "learning_rate": 4.163178294573644e-05,
      "loss": 0.0006,
      "step": 2159
    },
    {
      "epoch": 8.372093023255815,
      "grad_norm": 0.012730063870549202,
      "learning_rate": 4.162790697674418e-05,
      "loss": 0.0005,
      "step": 2160
    },
    {
      "epoch": 8.375968992248062,
      "grad_norm": 3.694819688796997,
      "learning_rate": 4.162403100775194e-05,
      "loss": 0.3759,
      "step": 2161
    },
    {
      "epoch": 8.37984496124031,
      "grad_norm": 0.01579517126083374,
      "learning_rate": 4.162015503875969e-05,
      "loss": 0.0007,
      "step": 2162
    },
    {
      "epoch": 8.383720930232558,
      "grad_norm": 0.5589797496795654,
      "learning_rate": 4.161627906976745e-05,
      "loss": 0.0054,
      "step": 2163
    },
    {
      "epoch": 8.387596899224807,
      "grad_norm": 0.2644144296646118,
      "learning_rate": 4.161240310077519e-05,
      "loss": 0.0036,
      "step": 2164
    },
    {
      "epoch": 8.391472868217054,
      "grad_norm": 0.29314443469047546,
      "learning_rate": 4.160852713178295e-05,
      "loss": 0.0042,
      "step": 2165
    },
    {
      "epoch": 8.395348837209303,
      "grad_norm": 0.034035712480545044,
      "learning_rate": 4.16046511627907e-05,
      "loss": 0.0014,
      "step": 2166
    },
    {
      "epoch": 8.39922480620155,
      "grad_norm": 0.04378318414092064,
      "learning_rate": 4.160077519379845e-05,
      "loss": 0.0019,
      "step": 2167
    },
    {
      "epoch": 8.4031007751938,
      "grad_norm": 0.10528018325567245,
      "learning_rate": 4.15968992248062e-05,
      "loss": 0.003,
      "step": 2168
    },
    {
      "epoch": 8.406976744186046,
      "grad_norm": 0.14286349713802338,
      "learning_rate": 4.1593023255813955e-05,
      "loss": 0.0033,
      "step": 2169
    },
    {
      "epoch": 8.410852713178295,
      "grad_norm": 0.017833152785897255,
      "learning_rate": 4.158914728682171e-05,
      "loss": 0.0007,
      "step": 2170
    },
    {
      "epoch": 8.414728682170542,
      "grad_norm": 3.0766072273254395,
      "learning_rate": 4.158527131782946e-05,
      "loss": 0.0984,
      "step": 2171
    },
    {
      "epoch": 8.418604651162791,
      "grad_norm": 1.8869966268539429,
      "learning_rate": 4.158139534883721e-05,
      "loss": 0.0797,
      "step": 2172
    },
    {
      "epoch": 8.422480620155039,
      "grad_norm": 0.0202595517039299,
      "learning_rate": 4.1577519379844964e-05,
      "loss": 0.0007,
      "step": 2173
    },
    {
      "epoch": 8.426356589147288,
      "grad_norm": 0.018747955560684204,
      "learning_rate": 4.157364341085272e-05,
      "loss": 0.0006,
      "step": 2174
    },
    {
      "epoch": 8.430232558139535,
      "grad_norm": 18.039052963256836,
      "learning_rate": 4.156976744186047e-05,
      "loss": 0.223,
      "step": 2175
    },
    {
      "epoch": 8.434108527131784,
      "grad_norm": 0.009777388535439968,
      "learning_rate": 4.1565891472868215e-05,
      "loss": 0.0006,
      "step": 2176
    },
    {
      "epoch": 8.437984496124031,
      "grad_norm": 0.2559664249420166,
      "learning_rate": 4.1562015503875974e-05,
      "loss": 0.006,
      "step": 2177
    },
    {
      "epoch": 8.44186046511628,
      "grad_norm": 0.013772851787507534,
      "learning_rate": 4.155813953488372e-05,
      "loss": 0.0007,
      "step": 2178
    },
    {
      "epoch": 8.445736434108527,
      "grad_norm": 0.46105602383613586,
      "learning_rate": 4.155426356589148e-05,
      "loss": 0.008,
      "step": 2179
    },
    {
      "epoch": 8.449612403100776,
      "grad_norm": 12.54270076751709,
      "learning_rate": 4.1550387596899224e-05,
      "loss": 1.2952,
      "step": 2180
    },
    {
      "epoch": 8.453488372093023,
      "grad_norm": 4.2500081062316895,
      "learning_rate": 4.1546511627906984e-05,
      "loss": 0.0685,
      "step": 2181
    },
    {
      "epoch": 8.457364341085272,
      "grad_norm": 0.014134187251329422,
      "learning_rate": 4.154263565891473e-05,
      "loss": 0.0007,
      "step": 2182
    },
    {
      "epoch": 8.46124031007752,
      "grad_norm": 0.013550718314945698,
      "learning_rate": 4.153875968992249e-05,
      "loss": 0.0006,
      "step": 2183
    },
    {
      "epoch": 8.465116279069768,
      "grad_norm": 0.007175405044108629,
      "learning_rate": 4.1534883720930234e-05,
      "loss": 0.0005,
      "step": 2184
    },
    {
      "epoch": 8.468992248062015,
      "grad_norm": 0.0044679464772343636,
      "learning_rate": 4.1531007751937986e-05,
      "loss": 0.0004,
      "step": 2185
    },
    {
      "epoch": 8.472868217054264,
      "grad_norm": 2.6151440143585205,
      "learning_rate": 4.152713178294574e-05,
      "loss": 0.0167,
      "step": 2186
    },
    {
      "epoch": 8.476744186046512,
      "grad_norm": 0.22843363881111145,
      "learning_rate": 4.1523255813953485e-05,
      "loss": 0.002,
      "step": 2187
    },
    {
      "epoch": 8.48062015503876,
      "grad_norm": 0.0074163940735161304,
      "learning_rate": 4.1519379844961244e-05,
      "loss": 0.0006,
      "step": 2188
    },
    {
      "epoch": 8.484496124031008,
      "grad_norm": 0.008641377091407776,
      "learning_rate": 4.151550387596899e-05,
      "loss": 0.0005,
      "step": 2189
    },
    {
      "epoch": 8.488372093023255,
      "grad_norm": 0.012688159942626953,
      "learning_rate": 4.151162790697675e-05,
      "loss": 0.0006,
      "step": 2190
    },
    {
      "epoch": 8.492248062015504,
      "grad_norm": 0.026760218665003777,
      "learning_rate": 4.1507751937984494e-05,
      "loss": 0.0007,
      "step": 2191
    },
    {
      "epoch": 8.496124031007753,
      "grad_norm": 0.01122229639440775,
      "learning_rate": 4.1503875968992253e-05,
      "loss": 0.0005,
      "step": 2192
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.00517061073333025,
      "learning_rate": 4.15e-05,
      "loss": 0.0004,
      "step": 2193
    },
    {
      "epoch": 8.503875968992247,
      "grad_norm": 0.052976228296756744,
      "learning_rate": 4.149612403100775e-05,
      "loss": 0.0006,
      "step": 2194
    },
    {
      "epoch": 8.507751937984496,
      "grad_norm": 0.0066903503611683846,
      "learning_rate": 4.1492248062015504e-05,
      "loss": 0.0005,
      "step": 2195
    },
    {
      "epoch": 8.511627906976745,
      "grad_norm": 0.00927189365029335,
      "learning_rate": 4.1488372093023256e-05,
      "loss": 0.0005,
      "step": 2196
    },
    {
      "epoch": 8.515503875968992,
      "grad_norm": 0.006890392396599054,
      "learning_rate": 4.148449612403101e-05,
      "loss": 0.0005,
      "step": 2197
    },
    {
      "epoch": 8.51937984496124,
      "grad_norm": 0.007622011937201023,
      "learning_rate": 4.148062015503876e-05,
      "loss": 0.0005,
      "step": 2198
    },
    {
      "epoch": 8.523255813953488,
      "grad_norm": 0.006541016977280378,
      "learning_rate": 4.1476744186046514e-05,
      "loss": 0.0005,
      "step": 2199
    },
    {
      "epoch": 8.527131782945737,
      "grad_norm": 0.04482730105519295,
      "learning_rate": 4.1472868217054266e-05,
      "loss": 0.0012,
      "step": 2200
    },
    {
      "epoch": 8.531007751937985,
      "grad_norm": 0.0036992577370256186,
      "learning_rate": 4.146899224806202e-05,
      "loss": 0.0004,
      "step": 2201
    },
    {
      "epoch": 8.534883720930232,
      "grad_norm": 0.12448330223560333,
      "learning_rate": 4.146511627906977e-05,
      "loss": 0.0023,
      "step": 2202
    },
    {
      "epoch": 8.53875968992248,
      "grad_norm": 0.14147277176380157,
      "learning_rate": 4.146124031007752e-05,
      "loss": 0.0025,
      "step": 2203
    },
    {
      "epoch": 8.542635658914728,
      "grad_norm": 0.008991374634206295,
      "learning_rate": 4.1457364341085276e-05,
      "loss": 0.0004,
      "step": 2204
    },
    {
      "epoch": 8.546511627906977,
      "grad_norm": 0.00702277198433876,
      "learning_rate": 4.145348837209302e-05,
      "loss": 0.0005,
      "step": 2205
    },
    {
      "epoch": 8.550387596899224,
      "grad_norm": 0.0034738953690975904,
      "learning_rate": 4.144961240310078e-05,
      "loss": 0.0004,
      "step": 2206
    },
    {
      "epoch": 8.554263565891473,
      "grad_norm": 0.024641050025820732,
      "learning_rate": 4.1445736434108526e-05,
      "loss": 0.001,
      "step": 2207
    },
    {
      "epoch": 8.55813953488372,
      "grad_norm": 0.0049558342434465885,
      "learning_rate": 4.1441860465116285e-05,
      "loss": 0.0004,
      "step": 2208
    },
    {
      "epoch": 8.562015503875969,
      "grad_norm": 5.303011894226074,
      "learning_rate": 4.143798449612403e-05,
      "loss": 0.0477,
      "step": 2209
    },
    {
      "epoch": 8.565891472868216,
      "grad_norm": 0.003320693038403988,
      "learning_rate": 4.143410852713179e-05,
      "loss": 0.0003,
      "step": 2210
    },
    {
      "epoch": 8.569767441860465,
      "grad_norm": 0.0031450630631297827,
      "learning_rate": 4.1430232558139536e-05,
      "loss": 0.0004,
      "step": 2211
    },
    {
      "epoch": 8.573643410852712,
      "grad_norm": 0.0035389484837651253,
      "learning_rate": 4.142635658914729e-05,
      "loss": 0.0003,
      "step": 2212
    },
    {
      "epoch": 8.577519379844961,
      "grad_norm": 0.004090895410627127,
      "learning_rate": 4.142248062015504e-05,
      "loss": 0.0004,
      "step": 2213
    },
    {
      "epoch": 8.581395348837209,
      "grad_norm": 3.9463579654693604,
      "learning_rate": 4.141860465116279e-05,
      "loss": 0.5626,
      "step": 2214
    },
    {
      "epoch": 8.585271317829458,
      "grad_norm": 0.0026908889412879944,
      "learning_rate": 4.1414728682170546e-05,
      "loss": 0.0003,
      "step": 2215
    },
    {
      "epoch": 8.589147286821705,
      "grad_norm": 2.128228187561035,
      "learning_rate": 4.141085271317829e-05,
      "loss": 0.0149,
      "step": 2216
    },
    {
      "epoch": 8.593023255813954,
      "grad_norm": 1.0918114185333252,
      "learning_rate": 4.140697674418605e-05,
      "loss": 0.0032,
      "step": 2217
    },
    {
      "epoch": 8.5968992248062,
      "grad_norm": 0.058217789977788925,
      "learning_rate": 4.1403100775193796e-05,
      "loss": 0.0021,
      "step": 2218
    },
    {
      "epoch": 8.60077519379845,
      "grad_norm": 4.008884906768799,
      "learning_rate": 4.1399224806201555e-05,
      "loss": 0.6698,
      "step": 2219
    },
    {
      "epoch": 8.604651162790697,
      "grad_norm": 0.06571760773658752,
      "learning_rate": 4.13953488372093e-05,
      "loss": 0.0017,
      "step": 2220
    },
    {
      "epoch": 8.608527131782946,
      "grad_norm": 0.03637261316180229,
      "learning_rate": 4.139147286821706e-05,
      "loss": 0.0013,
      "step": 2221
    },
    {
      "epoch": 8.612403100775193,
      "grad_norm": 0.13364197313785553,
      "learning_rate": 4.1387596899224806e-05,
      "loss": 0.0036,
      "step": 2222
    },
    {
      "epoch": 8.616279069767442,
      "grad_norm": 7.54118013381958,
      "learning_rate": 4.138372093023256e-05,
      "loss": 0.1748,
      "step": 2223
    },
    {
      "epoch": 8.62015503875969,
      "grad_norm": 0.1177525669336319,
      "learning_rate": 4.137984496124031e-05,
      "loss": 0.0042,
      "step": 2224
    },
    {
      "epoch": 8.624031007751938,
      "grad_norm": 0.06539884209632874,
      "learning_rate": 4.137596899224806e-05,
      "loss": 0.0026,
      "step": 2225
    },
    {
      "epoch": 8.627906976744185,
      "grad_norm": 19.657180786132812,
      "learning_rate": 4.1372093023255815e-05,
      "loss": 0.1645,
      "step": 2226
    },
    {
      "epoch": 8.631782945736434,
      "grad_norm": 0.13459111750125885,
      "learning_rate": 4.136821705426357e-05,
      "loss": 0.0048,
      "step": 2227
    },
    {
      "epoch": 8.635658914728682,
      "grad_norm": 0.2255195826292038,
      "learning_rate": 4.136434108527132e-05,
      "loss": 0.0067,
      "step": 2228
    },
    {
      "epoch": 8.63953488372093,
      "grad_norm": 0.1590510606765747,
      "learning_rate": 4.136046511627907e-05,
      "loss": 0.0056,
      "step": 2229
    },
    {
      "epoch": 8.643410852713178,
      "grad_norm": 5.727565288543701,
      "learning_rate": 4.1356589147286825e-05,
      "loss": 0.0495,
      "step": 2230
    },
    {
      "epoch": 8.647286821705427,
      "grad_norm": 0.584728479385376,
      "learning_rate": 4.135271317829458e-05,
      "loss": 0.0102,
      "step": 2231
    },
    {
      "epoch": 8.651162790697674,
      "grad_norm": 0.053976744413375854,
      "learning_rate": 4.134883720930233e-05,
      "loss": 0.0023,
      "step": 2232
    },
    {
      "epoch": 8.655038759689923,
      "grad_norm": 0.05157429352402687,
      "learning_rate": 4.134496124031008e-05,
      "loss": 0.0025,
      "step": 2233
    },
    {
      "epoch": 8.65891472868217,
      "grad_norm": 0.26677173376083374,
      "learning_rate": 4.134108527131783e-05,
      "loss": 0.0087,
      "step": 2234
    },
    {
      "epoch": 8.662790697674419,
      "grad_norm": 0.16932661831378937,
      "learning_rate": 4.133720930232559e-05,
      "loss": 0.0075,
      "step": 2235
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 0.028571993112564087,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.0015,
      "step": 2236
    },
    {
      "epoch": 8.670542635658915,
      "grad_norm": 0.010010075755417347,
      "learning_rate": 4.132945736434109e-05,
      "loss": 0.0007,
      "step": 2237
    },
    {
      "epoch": 8.674418604651162,
      "grad_norm": 0.004511511884629726,
      "learning_rate": 4.132558139534884e-05,
      "loss": 0.0004,
      "step": 2238
    },
    {
      "epoch": 8.678294573643411,
      "grad_norm": 5.8639020919799805,
      "learning_rate": 4.132170542635659e-05,
      "loss": 0.2163,
      "step": 2239
    },
    {
      "epoch": 8.682170542635658,
      "grad_norm": 0.020985808223485947,
      "learning_rate": 4.131782945736434e-05,
      "loss": 0.001,
      "step": 2240
    },
    {
      "epoch": 8.686046511627907,
      "grad_norm": 0.007827157154679298,
      "learning_rate": 4.1313953488372095e-05,
      "loss": 0.0006,
      "step": 2241
    },
    {
      "epoch": 8.689922480620154,
      "grad_norm": 0.006389638874679804,
      "learning_rate": 4.131007751937985e-05,
      "loss": 0.0004,
      "step": 2242
    },
    {
      "epoch": 8.693798449612403,
      "grad_norm": 0.025228984653949738,
      "learning_rate": 4.13062015503876e-05,
      "loss": 0.0006,
      "step": 2243
    },
    {
      "epoch": 8.69767441860465,
      "grad_norm": 0.004461333621293306,
      "learning_rate": 4.130232558139535e-05,
      "loss": 0.0004,
      "step": 2244
    },
    {
      "epoch": 8.7015503875969,
      "grad_norm": 0.009369973093271255,
      "learning_rate": 4.12984496124031e-05,
      "loss": 0.0006,
      "step": 2245
    },
    {
      "epoch": 8.705426356589147,
      "grad_norm": 0.0047730556689202785,
      "learning_rate": 4.129457364341086e-05,
      "loss": 0.0005,
      "step": 2246
    },
    {
      "epoch": 8.709302325581396,
      "grad_norm": 0.02103741653263569,
      "learning_rate": 4.12906976744186e-05,
      "loss": 0.0007,
      "step": 2247
    },
    {
      "epoch": 8.713178294573643,
      "grad_norm": 0.005157564766705036,
      "learning_rate": 4.128682170542636e-05,
      "loss": 0.0004,
      "step": 2248
    },
    {
      "epoch": 8.717054263565892,
      "grad_norm": 10.164780616760254,
      "learning_rate": 4.128294573643411e-05,
      "loss": 1.2916,
      "step": 2249
    },
    {
      "epoch": 8.720930232558139,
      "grad_norm": 0.026436999440193176,
      "learning_rate": 4.127906976744187e-05,
      "loss": 0.0015,
      "step": 2250
    },
    {
      "epoch": 8.724806201550388,
      "grad_norm": 0.010201849043369293,
      "learning_rate": 4.127519379844961e-05,
      "loss": 0.0006,
      "step": 2251
    },
    {
      "epoch": 8.728682170542635,
      "grad_norm": 0.0054172975942492485,
      "learning_rate": 4.1271317829457365e-05,
      "loss": 0.0005,
      "step": 2252
    },
    {
      "epoch": 8.732558139534884,
      "grad_norm": 4.158089637756348,
      "learning_rate": 4.126744186046512e-05,
      "loss": 0.0838,
      "step": 2253
    },
    {
      "epoch": 8.736434108527131,
      "grad_norm": 0.006747355684638023,
      "learning_rate": 4.126356589147287e-05,
      "loss": 0.0005,
      "step": 2254
    },
    {
      "epoch": 8.74031007751938,
      "grad_norm": 0.007805991917848587,
      "learning_rate": 4.125968992248062e-05,
      "loss": 0.0004,
      "step": 2255
    },
    {
      "epoch": 8.744186046511627,
      "grad_norm": 0.010422834195196629,
      "learning_rate": 4.1255813953488375e-05,
      "loss": 0.0005,
      "step": 2256
    },
    {
      "epoch": 8.748062015503876,
      "grad_norm": 0.08350770175457001,
      "learning_rate": 4.125193798449613e-05,
      "loss": 0.0028,
      "step": 2257
    },
    {
      "epoch": 8.751937984496124,
      "grad_norm": 0.00270456844009459,
      "learning_rate": 4.124806201550388e-05,
      "loss": 0.0003,
      "step": 2258
    },
    {
      "epoch": 8.755813953488373,
      "grad_norm": 0.004045773297548294,
      "learning_rate": 4.124418604651163e-05,
      "loss": 0.0004,
      "step": 2259
    },
    {
      "epoch": 8.75968992248062,
      "grad_norm": 7.251124382019043,
      "learning_rate": 4.1240310077519384e-05,
      "loss": 0.9239,
      "step": 2260
    },
    {
      "epoch": 8.763565891472869,
      "grad_norm": 0.06193578988313675,
      "learning_rate": 4.123643410852714e-05,
      "loss": 0.0023,
      "step": 2261
    },
    {
      "epoch": 8.767441860465116,
      "grad_norm": 0.005105944350361824,
      "learning_rate": 4.123255813953489e-05,
      "loss": 0.0004,
      "step": 2262
    },
    {
      "epoch": 8.771317829457365,
      "grad_norm": 0.04864969849586487,
      "learning_rate": 4.1228682170542635e-05,
      "loss": 0.0016,
      "step": 2263
    },
    {
      "epoch": 8.775193798449612,
      "grad_norm": 0.0648670494556427,
      "learning_rate": 4.1224806201550394e-05,
      "loss": 0.0028,
      "step": 2264
    },
    {
      "epoch": 8.779069767441861,
      "grad_norm": 4.80949068069458,
      "learning_rate": 4.122093023255814e-05,
      "loss": 0.2042,
      "step": 2265
    },
    {
      "epoch": 8.782945736434108,
      "grad_norm": 1.4035698175430298,
      "learning_rate": 4.121705426356589e-05,
      "loss": 0.0301,
      "step": 2266
    },
    {
      "epoch": 8.786821705426357,
      "grad_norm": 5.174834251403809,
      "learning_rate": 4.1213178294573644e-05,
      "loss": 0.6789,
      "step": 2267
    },
    {
      "epoch": 8.790697674418604,
      "grad_norm": 9.246126174926758,
      "learning_rate": 4.12093023255814e-05,
      "loss": 1.309,
      "step": 2268
    },
    {
      "epoch": 8.794573643410853,
      "grad_norm": 0.11768032610416412,
      "learning_rate": 4.120542635658915e-05,
      "loss": 0.0046,
      "step": 2269
    },
    {
      "epoch": 8.7984496124031,
      "grad_norm": 0.004502554889768362,
      "learning_rate": 4.12015503875969e-05,
      "loss": 0.0004,
      "step": 2270
    },
    {
      "epoch": 8.80232558139535,
      "grad_norm": 0.011247732676565647,
      "learning_rate": 4.1197674418604654e-05,
      "loss": 0.0005,
      "step": 2271
    },
    {
      "epoch": 8.806201550387597,
      "grad_norm": 5.497025966644287,
      "learning_rate": 4.11937984496124e-05,
      "loss": 0.3248,
      "step": 2272
    },
    {
      "epoch": 8.810077519379846,
      "grad_norm": 0.0061996676959097385,
      "learning_rate": 4.118992248062016e-05,
      "loss": 0.0004,
      "step": 2273
    },
    {
      "epoch": 8.813953488372093,
      "grad_norm": 0.009152804501354694,
      "learning_rate": 4.1186046511627905e-05,
      "loss": 0.0005,
      "step": 2274
    },
    {
      "epoch": 8.817829457364342,
      "grad_norm": 0.15723712742328644,
      "learning_rate": 4.1182170542635664e-05,
      "loss": 0.0016,
      "step": 2275
    },
    {
      "epoch": 8.821705426356589,
      "grad_norm": 0.008834057487547398,
      "learning_rate": 4.117829457364341e-05,
      "loss": 0.0006,
      "step": 2276
    },
    {
      "epoch": 8.825581395348838,
      "grad_norm": 0.07035808265209198,
      "learning_rate": 4.117441860465117e-05,
      "loss": 0.0006,
      "step": 2277
    },
    {
      "epoch": 8.829457364341085,
      "grad_norm": 0.005851836409419775,
      "learning_rate": 4.1170542635658914e-05,
      "loss": 0.0004,
      "step": 2278
    },
    {
      "epoch": 8.833333333333334,
      "grad_norm": 0.13220007717609406,
      "learning_rate": 4.116666666666667e-05,
      "loss": 0.0016,
      "step": 2279
    },
    {
      "epoch": 8.837209302325581,
      "grad_norm": 0.0829235091805458,
      "learning_rate": 4.116279069767442e-05,
      "loss": 0.0029,
      "step": 2280
    },
    {
      "epoch": 8.84108527131783,
      "grad_norm": 29.445541381835938,
      "learning_rate": 4.115891472868217e-05,
      "loss": 0.3857,
      "step": 2281
    },
    {
      "epoch": 8.844961240310077,
      "grad_norm": 15.162932395935059,
      "learning_rate": 4.1155038759689924e-05,
      "loss": 0.2447,
      "step": 2282
    },
    {
      "epoch": 8.848837209302326,
      "grad_norm": 2.2109851837158203,
      "learning_rate": 4.1151162790697676e-05,
      "loss": 0.0595,
      "step": 2283
    },
    {
      "epoch": 8.852713178294573,
      "grad_norm": 0.011676257476210594,
      "learning_rate": 4.114728682170543e-05,
      "loss": 0.0005,
      "step": 2284
    },
    {
      "epoch": 8.856589147286822,
      "grad_norm": 6.616861343383789,
      "learning_rate": 4.114341085271318e-05,
      "loss": 0.0393,
      "step": 2285
    },
    {
      "epoch": 8.86046511627907,
      "grad_norm": 0.32448089122772217,
      "learning_rate": 4.1139534883720934e-05,
      "loss": 0.0068,
      "step": 2286
    },
    {
      "epoch": 8.864341085271318,
      "grad_norm": 0.02912978082895279,
      "learning_rate": 4.1135658914728686e-05,
      "loss": 0.0007,
      "step": 2287
    },
    {
      "epoch": 8.868217054263566,
      "grad_norm": 0.02514810673892498,
      "learning_rate": 4.113178294573644e-05,
      "loss": 0.0005,
      "step": 2288
    },
    {
      "epoch": 8.872093023255815,
      "grad_norm": 0.004969557747244835,
      "learning_rate": 4.112790697674419e-05,
      "loss": 0.0004,
      "step": 2289
    },
    {
      "epoch": 8.875968992248062,
      "grad_norm": 2.333404779434204,
      "learning_rate": 4.1124031007751937e-05,
      "loss": 0.0725,
      "step": 2290
    },
    {
      "epoch": 8.87984496124031,
      "grad_norm": 0.3112739622592926,
      "learning_rate": 4.1120155038759696e-05,
      "loss": 0.0066,
      "step": 2291
    },
    {
      "epoch": 8.883720930232558,
      "grad_norm": 0.18166333436965942,
      "learning_rate": 4.111627906976744e-05,
      "loss": 0.0041,
      "step": 2292
    },
    {
      "epoch": 8.887596899224807,
      "grad_norm": 0.005054153501987457,
      "learning_rate": 4.1112403100775194e-05,
      "loss": 0.0004,
      "step": 2293
    },
    {
      "epoch": 8.891472868217054,
      "grad_norm": 17.46519660949707,
      "learning_rate": 4.1108527131782946e-05,
      "loss": 0.1034,
      "step": 2294
    },
    {
      "epoch": 8.895348837209303,
      "grad_norm": 0.010070652700960636,
      "learning_rate": 4.11046511627907e-05,
      "loss": 0.0005,
      "step": 2295
    },
    {
      "epoch": 8.89922480620155,
      "grad_norm": 0.003995065577328205,
      "learning_rate": 4.110077519379845e-05,
      "loss": 0.0004,
      "step": 2296
    },
    {
      "epoch": 8.9031007751938,
      "grad_norm": 0.10569413006305695,
      "learning_rate": 4.1096899224806203e-05,
      "loss": 0.0009,
      "step": 2297
    },
    {
      "epoch": 8.906976744186046,
      "grad_norm": 0.004326337482780218,
      "learning_rate": 4.1093023255813956e-05,
      "loss": 0.0004,
      "step": 2298
    },
    {
      "epoch": 8.910852713178295,
      "grad_norm": 0.00697681400924921,
      "learning_rate": 4.108914728682171e-05,
      "loss": 0.0004,
      "step": 2299
    },
    {
      "epoch": 8.914728682170542,
      "grad_norm": 0.009603253565728664,
      "learning_rate": 4.108527131782946e-05,
      "loss": 0.0005,
      "step": 2300
    },
    {
      "epoch": 8.918604651162791,
      "grad_norm": 0.004835238680243492,
      "learning_rate": 4.1081395348837206e-05,
      "loss": 0.0004,
      "step": 2301
    },
    {
      "epoch": 8.922480620155039,
      "grad_norm": 0.0029710589442402124,
      "learning_rate": 4.1077519379844966e-05,
      "loss": 0.0003,
      "step": 2302
    },
    {
      "epoch": 8.926356589147288,
      "grad_norm": 0.0033992815297096968,
      "learning_rate": 4.107364341085271e-05,
      "loss": 0.0003,
      "step": 2303
    },
    {
      "epoch": 8.930232558139535,
      "grad_norm": 11.115822792053223,
      "learning_rate": 4.106976744186047e-05,
      "loss": 0.5208,
      "step": 2304
    },
    {
      "epoch": 8.934108527131784,
      "grad_norm": 0.00866057351231575,
      "learning_rate": 4.1065891472868216e-05,
      "loss": 0.0005,
      "step": 2305
    },
    {
      "epoch": 8.937984496124031,
      "grad_norm": 0.003978240769356489,
      "learning_rate": 4.1062015503875975e-05,
      "loss": 0.0004,
      "step": 2306
    },
    {
      "epoch": 8.94186046511628,
      "grad_norm": 0.004215882625430822,
      "learning_rate": 4.105813953488372e-05,
      "loss": 0.0004,
      "step": 2307
    },
    {
      "epoch": 8.945736434108527,
      "grad_norm": 0.0030422897543758154,
      "learning_rate": 4.105426356589147e-05,
      "loss": 0.0003,
      "step": 2308
    },
    {
      "epoch": 8.949612403100776,
      "grad_norm": 0.04571003094315529,
      "learning_rate": 4.1050387596899226e-05,
      "loss": 0.0011,
      "step": 2309
    },
    {
      "epoch": 8.953488372093023,
      "grad_norm": 1.1608270406723022,
      "learning_rate": 4.104651162790698e-05,
      "loss": 0.0236,
      "step": 2310
    },
    {
      "epoch": 8.957364341085272,
      "grad_norm": 0.005466429051011801,
      "learning_rate": 4.104263565891473e-05,
      "loss": 0.0004,
      "step": 2311
    },
    {
      "epoch": 8.96124031007752,
      "grad_norm": 0.0035476088523864746,
      "learning_rate": 4.103875968992248e-05,
      "loss": 0.0003,
      "step": 2312
    },
    {
      "epoch": 8.965116279069768,
      "grad_norm": 0.0036417546216398478,
      "learning_rate": 4.1034883720930235e-05,
      "loss": 0.0003,
      "step": 2313
    },
    {
      "epoch": 8.968992248062015,
      "grad_norm": 0.0039500403217971325,
      "learning_rate": 4.103100775193799e-05,
      "loss": 0.0004,
      "step": 2314
    },
    {
      "epoch": 8.972868217054263,
      "grad_norm": 0.017709823325276375,
      "learning_rate": 4.102713178294574e-05,
      "loss": 0.0005,
      "step": 2315
    },
    {
      "epoch": 8.976744186046512,
      "grad_norm": 0.020424729213118553,
      "learning_rate": 4.102325581395349e-05,
      "loss": 0.0005,
      "step": 2316
    },
    {
      "epoch": 8.98062015503876,
      "grad_norm": 0.010011234320700169,
      "learning_rate": 4.1019379844961245e-05,
      "loss": 0.0005,
      "step": 2317
    },
    {
      "epoch": 8.984496124031008,
      "grad_norm": 0.003742735367268324,
      "learning_rate": 4.1015503875969e-05,
      "loss": 0.0003,
      "step": 2318
    },
    {
      "epoch": 8.988372093023255,
      "grad_norm": 5.23189115524292,
      "learning_rate": 4.101162790697674e-05,
      "loss": 0.0417,
      "step": 2319
    },
    {
      "epoch": 8.992248062015504,
      "grad_norm": 0.003999792039394379,
      "learning_rate": 4.1007751937984496e-05,
      "loss": 0.0004,
      "step": 2320
    },
    {
      "epoch": 8.996124031007753,
      "grad_norm": 0.020714638754725456,
      "learning_rate": 4.100387596899225e-05,
      "loss": 0.0008,
      "step": 2321
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.0036941904108971357,
      "learning_rate": 4.1e-05,
      "loss": 0.0003,
      "step": 2322
    },
    {
      "epoch": 9.003875968992247,
      "grad_norm": 0.004739097785204649,
      "learning_rate": 4.099612403100775e-05,
      "loss": 0.0004,
      "step": 2323
    },
    {
      "epoch": 9.007751937984496,
      "grad_norm": 0.38666781783103943,
      "learning_rate": 4.0992248062015505e-05,
      "loss": 0.0121,
      "step": 2324
    },
    {
      "epoch": 9.011627906976743,
      "grad_norm": 0.012470862828195095,
      "learning_rate": 4.098837209302326e-05,
      "loss": 0.0004,
      "step": 2325
    },
    {
      "epoch": 9.015503875968992,
      "grad_norm": 1.0933603048324585,
      "learning_rate": 4.098449612403101e-05,
      "loss": 0.0703,
      "step": 2326
    },
    {
      "epoch": 9.01937984496124,
      "grad_norm": 0.004690925125032663,
      "learning_rate": 4.098062015503876e-05,
      "loss": 0.0004,
      "step": 2327
    },
    {
      "epoch": 9.023255813953488,
      "grad_norm": 0.09907562285661697,
      "learning_rate": 4.0976744186046515e-05,
      "loss": 0.0009,
      "step": 2328
    },
    {
      "epoch": 9.027131782945736,
      "grad_norm": 0.033366646617650986,
      "learning_rate": 4.097286821705427e-05,
      "loss": 0.0007,
      "step": 2329
    },
    {
      "epoch": 9.031007751937985,
      "grad_norm": 5.047917366027832,
      "learning_rate": 4.096899224806201e-05,
      "loss": 0.3376,
      "step": 2330
    },
    {
      "epoch": 9.034883720930232,
      "grad_norm": 12.706570625305176,
      "learning_rate": 4.096511627906977e-05,
      "loss": 0.8998,
      "step": 2331
    },
    {
      "epoch": 9.03875968992248,
      "grad_norm": 0.0064910175278782845,
      "learning_rate": 4.096124031007752e-05,
      "loss": 0.0004,
      "step": 2332
    },
    {
      "epoch": 9.042635658914728,
      "grad_norm": 0.19526924192905426,
      "learning_rate": 4.095736434108528e-05,
      "loss": 0.0033,
      "step": 2333
    },
    {
      "epoch": 9.046511627906977,
      "grad_norm": 4.578052043914795,
      "learning_rate": 4.095348837209302e-05,
      "loss": 0.1449,
      "step": 2334
    },
    {
      "epoch": 9.050387596899224,
      "grad_norm": 0.4754490554332733,
      "learning_rate": 4.094961240310078e-05,
      "loss": 0.0058,
      "step": 2335
    },
    {
      "epoch": 9.054263565891473,
      "grad_norm": 0.005179039668291807,
      "learning_rate": 4.094573643410853e-05,
      "loss": 0.0004,
      "step": 2336
    },
    {
      "epoch": 9.05813953488372,
      "grad_norm": 0.026782331988215446,
      "learning_rate": 4.094186046511628e-05,
      "loss": 0.0012,
      "step": 2337
    },
    {
      "epoch": 9.062015503875969,
      "grad_norm": 0.01763194426894188,
      "learning_rate": 4.093798449612403e-05,
      "loss": 0.001,
      "step": 2338
    },
    {
      "epoch": 9.065891472868216,
      "grad_norm": 0.06930485367774963,
      "learning_rate": 4.0934108527131785e-05,
      "loss": 0.002,
      "step": 2339
    },
    {
      "epoch": 9.069767441860465,
      "grad_norm": 0.032351572066545486,
      "learning_rate": 4.093023255813954e-05,
      "loss": 0.0013,
      "step": 2340
    },
    {
      "epoch": 9.073643410852712,
      "grad_norm": 0.279205322265625,
      "learning_rate": 4.092635658914729e-05,
      "loss": 0.0011,
      "step": 2341
    },
    {
      "epoch": 9.077519379844961,
      "grad_norm": 0.00525198969990015,
      "learning_rate": 4.092248062015504e-05,
      "loss": 0.0005,
      "step": 2342
    },
    {
      "epoch": 9.081395348837209,
      "grad_norm": 0.0029401620849967003,
      "learning_rate": 4.0918604651162795e-05,
      "loss": 0.0003,
      "step": 2343
    },
    {
      "epoch": 9.085271317829458,
      "grad_norm": 2.14936900138855,
      "learning_rate": 4.091472868217055e-05,
      "loss": 0.0909,
      "step": 2344
    },
    {
      "epoch": 9.089147286821705,
      "grad_norm": 0.003664974356070161,
      "learning_rate": 4.09108527131783e-05,
      "loss": 0.0003,
      "step": 2345
    },
    {
      "epoch": 9.093023255813954,
      "grad_norm": 0.22425681352615356,
      "learning_rate": 4.090697674418605e-05,
      "loss": 0.0053,
      "step": 2346
    },
    {
      "epoch": 9.0968992248062,
      "grad_norm": 0.6644719839096069,
      "learning_rate": 4.09031007751938e-05,
      "loss": 0.0144,
      "step": 2347
    },
    {
      "epoch": 9.10077519379845,
      "grad_norm": 0.04084780439734459,
      "learning_rate": 4.089922480620155e-05,
      "loss": 0.0015,
      "step": 2348
    },
    {
      "epoch": 9.104651162790697,
      "grad_norm": 0.013756933622062206,
      "learning_rate": 4.08953488372093e-05,
      "loss": 0.0005,
      "step": 2349
    },
    {
      "epoch": 9.108527131782946,
      "grad_norm": 0.002684419509023428,
      "learning_rate": 4.0891472868217055e-05,
      "loss": 0.0003,
      "step": 2350
    },
    {
      "epoch": 9.112403100775193,
      "grad_norm": 0.1263248473405838,
      "learning_rate": 4.088759689922481e-05,
      "loss": 0.0049,
      "step": 2351
    },
    {
      "epoch": 9.116279069767442,
      "grad_norm": 0.30922213196754456,
      "learning_rate": 4.088372093023256e-05,
      "loss": 0.0032,
      "step": 2352
    },
    {
      "epoch": 9.12015503875969,
      "grad_norm": 0.003290625521913171,
      "learning_rate": 4.087984496124031e-05,
      "loss": 0.0003,
      "step": 2353
    },
    {
      "epoch": 9.124031007751938,
      "grad_norm": 0.004158067051321268,
      "learning_rate": 4.0875968992248064e-05,
      "loss": 0.0004,
      "step": 2354
    },
    {
      "epoch": 9.127906976744185,
      "grad_norm": 0.0037962181959301233,
      "learning_rate": 4.087209302325582e-05,
      "loss": 0.0002,
      "step": 2355
    },
    {
      "epoch": 9.131782945736434,
      "grad_norm": 0.005472241435199976,
      "learning_rate": 4.086821705426357e-05,
      "loss": 0.0003,
      "step": 2356
    },
    {
      "epoch": 9.135658914728682,
      "grad_norm": 0.3645908236503601,
      "learning_rate": 4.0864341085271315e-05,
      "loss": 0.006,
      "step": 2357
    },
    {
      "epoch": 9.13953488372093,
      "grad_norm": 0.08822418004274368,
      "learning_rate": 4.0860465116279074e-05,
      "loss": 0.0015,
      "step": 2358
    },
    {
      "epoch": 9.143410852713178,
      "grad_norm": 6.4990434646606445,
      "learning_rate": 4.085658914728682e-05,
      "loss": 0.1768,
      "step": 2359
    },
    {
      "epoch": 9.147286821705427,
      "grad_norm": 0.07043777406215668,
      "learning_rate": 4.085271317829458e-05,
      "loss": 0.0025,
      "step": 2360
    },
    {
      "epoch": 9.151162790697674,
      "grad_norm": 0.009108053520321846,
      "learning_rate": 4.0848837209302325e-05,
      "loss": 0.0005,
      "step": 2361
    },
    {
      "epoch": 9.155038759689923,
      "grad_norm": 0.002551210578531027,
      "learning_rate": 4.0844961240310084e-05,
      "loss": 0.0003,
      "step": 2362
    },
    {
      "epoch": 9.15891472868217,
      "grad_norm": 11.15645694732666,
      "learning_rate": 4.084108527131783e-05,
      "loss": 0.0081,
      "step": 2363
    },
    {
      "epoch": 9.162790697674419,
      "grad_norm": 0.4373389780521393,
      "learning_rate": 4.083720930232559e-05,
      "loss": 0.0092,
      "step": 2364
    },
    {
      "epoch": 9.166666666666666,
      "grad_norm": 0.027487359941005707,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.0017,
      "step": 2365
    },
    {
      "epoch": 9.170542635658915,
      "grad_norm": 5.93092155456543,
      "learning_rate": 4.082945736434109e-05,
      "loss": 0.0972,
      "step": 2366
    },
    {
      "epoch": 9.174418604651162,
      "grad_norm": 2.588704824447632,
      "learning_rate": 4.082558139534884e-05,
      "loss": 0.546,
      "step": 2367
    },
    {
      "epoch": 9.178294573643411,
      "grad_norm": 13.063700675964355,
      "learning_rate": 4.082170542635659e-05,
      "loss": 1.0316,
      "step": 2368
    },
    {
      "epoch": 9.182170542635658,
      "grad_norm": 0.0075753419660031796,
      "learning_rate": 4.0817829457364344e-05,
      "loss": 0.0006,
      "step": 2369
    },
    {
      "epoch": 9.186046511627907,
      "grad_norm": 0.6967372298240662,
      "learning_rate": 4.0813953488372096e-05,
      "loss": 0.0091,
      "step": 2370
    },
    {
      "epoch": 9.189922480620154,
      "grad_norm": 0.06461881846189499,
      "learning_rate": 4.081007751937985e-05,
      "loss": 0.0026,
      "step": 2371
    },
    {
      "epoch": 9.193798449612403,
      "grad_norm": 0.002726250560954213,
      "learning_rate": 4.08062015503876e-05,
      "loss": 0.0003,
      "step": 2372
    },
    {
      "epoch": 9.19767441860465,
      "grad_norm": 0.10638564825057983,
      "learning_rate": 4.0802325581395354e-05,
      "loss": 0.0018,
      "step": 2373
    },
    {
      "epoch": 9.2015503875969,
      "grad_norm": 6.257823944091797,
      "learning_rate": 4.07984496124031e-05,
      "loss": 0.4508,
      "step": 2374
    },
    {
      "epoch": 9.205426356589147,
      "grad_norm": 0.004155017901211977,
      "learning_rate": 4.079457364341085e-05,
      "loss": 0.0004,
      "step": 2375
    },
    {
      "epoch": 9.209302325581396,
      "grad_norm": 0.0050760796293616295,
      "learning_rate": 4.0790697674418604e-05,
      "loss": 0.0004,
      "step": 2376
    },
    {
      "epoch": 9.213178294573643,
      "grad_norm": 6.047593593597412,
      "learning_rate": 4.0786821705426357e-05,
      "loss": 0.0784,
      "step": 2377
    },
    {
      "epoch": 9.217054263565892,
      "grad_norm": 0.00504877557978034,
      "learning_rate": 4.078294573643411e-05,
      "loss": 0.0003,
      "step": 2378
    },
    {
      "epoch": 9.220930232558139,
      "grad_norm": 0.004097519442439079,
      "learning_rate": 4.077906976744186e-05,
      "loss": 0.0003,
      "step": 2379
    },
    {
      "epoch": 9.224806201550388,
      "grad_norm": 0.006531450431793928,
      "learning_rate": 4.0775193798449614e-05,
      "loss": 0.0004,
      "step": 2380
    },
    {
      "epoch": 9.228682170542635,
      "grad_norm": 0.0034612342715263367,
      "learning_rate": 4.0771317829457366e-05,
      "loss": 0.0003,
      "step": 2381
    },
    {
      "epoch": 9.232558139534884,
      "grad_norm": 0.00446447916328907,
      "learning_rate": 4.076744186046512e-05,
      "loss": 0.0004,
      "step": 2382
    },
    {
      "epoch": 9.236434108527131,
      "grad_norm": 0.007259467151015997,
      "learning_rate": 4.076356589147287e-05,
      "loss": 0.0004,
      "step": 2383
    },
    {
      "epoch": 9.24031007751938,
      "grad_norm": 2.594099521636963,
      "learning_rate": 4.0759689922480624e-05,
      "loss": 0.3568,
      "step": 2384
    },
    {
      "epoch": 9.244186046511627,
      "grad_norm": 0.3426472544670105,
      "learning_rate": 4.0755813953488376e-05,
      "loss": 0.0079,
      "step": 2385
    },
    {
      "epoch": 9.248062015503876,
      "grad_norm": 0.05463055893778801,
      "learning_rate": 4.075193798449612e-05,
      "loss": 0.002,
      "step": 2386
    },
    {
      "epoch": 9.251937984496124,
      "grad_norm": 0.007850437425076962,
      "learning_rate": 4.074806201550388e-05,
      "loss": 0.0005,
      "step": 2387
    },
    {
      "epoch": 9.255813953488373,
      "grad_norm": 0.003962532617151737,
      "learning_rate": 4.0744186046511626e-05,
      "loss": 0.0003,
      "step": 2388
    },
    {
      "epoch": 9.25968992248062,
      "grad_norm": 0.0042407638393342495,
      "learning_rate": 4.0740310077519386e-05,
      "loss": 0.0004,
      "step": 2389
    },
    {
      "epoch": 9.263565891472869,
      "grad_norm": 0.06055140495300293,
      "learning_rate": 4.073643410852713e-05,
      "loss": 0.0023,
      "step": 2390
    },
    {
      "epoch": 9.267441860465116,
      "grad_norm": 0.1882878541946411,
      "learning_rate": 4.073255813953489e-05,
      "loss": 0.0063,
      "step": 2391
    },
    {
      "epoch": 9.271317829457365,
      "grad_norm": 0.09344352781772614,
      "learning_rate": 4.0728682170542636e-05,
      "loss": 0.0018,
      "step": 2392
    },
    {
      "epoch": 9.275193798449612,
      "grad_norm": 0.008562063798308372,
      "learning_rate": 4.072480620155039e-05,
      "loss": 0.0004,
      "step": 2393
    },
    {
      "epoch": 9.279069767441861,
      "grad_norm": 0.0036353145260363817,
      "learning_rate": 4.072093023255814e-05,
      "loss": 0.0004,
      "step": 2394
    },
    {
      "epoch": 9.282945736434108,
      "grad_norm": 0.036496080458164215,
      "learning_rate": 4.071705426356589e-05,
      "loss": 0.0012,
      "step": 2395
    },
    {
      "epoch": 9.286821705426357,
      "grad_norm": 3.759678602218628,
      "learning_rate": 4.0713178294573646e-05,
      "loss": 0.1305,
      "step": 2396
    },
    {
      "epoch": 9.290697674418604,
      "grad_norm": 0.002955447882413864,
      "learning_rate": 4.07093023255814e-05,
      "loss": 0.0003,
      "step": 2397
    },
    {
      "epoch": 9.294573643410853,
      "grad_norm": 0.0060864463448524475,
      "learning_rate": 4.070542635658915e-05,
      "loss": 0.0004,
      "step": 2398
    },
    {
      "epoch": 9.2984496124031,
      "grad_norm": 1.1174592971801758,
      "learning_rate": 4.0701550387596896e-05,
      "loss": 0.1147,
      "step": 2399
    },
    {
      "epoch": 9.30232558139535,
      "grad_norm": 0.0033629420213401318,
      "learning_rate": 4.0697674418604655e-05,
      "loss": 0.0003,
      "step": 2400
    },
    {
      "epoch": 9.306201550387597,
      "grad_norm": 0.027879588305950165,
      "learning_rate": 4.06937984496124e-05,
      "loss": 0.0011,
      "step": 2401
    },
    {
      "epoch": 9.310077519379846,
      "grad_norm": 0.03581904247403145,
      "learning_rate": 4.068992248062016e-05,
      "loss": 0.0009,
      "step": 2402
    },
    {
      "epoch": 9.313953488372093,
      "grad_norm": 2.675809621810913,
      "learning_rate": 4.0686046511627906e-05,
      "loss": 0.3475,
      "step": 2403
    },
    {
      "epoch": 9.317829457364342,
      "grad_norm": 0.005306364968419075,
      "learning_rate": 4.068217054263566e-05,
      "loss": 0.0004,
      "step": 2404
    },
    {
      "epoch": 9.321705426356589,
      "grad_norm": 0.019802488386631012,
      "learning_rate": 4.067829457364341e-05,
      "loss": 0.0007,
      "step": 2405
    },
    {
      "epoch": 9.325581395348838,
      "grad_norm": 0.005259770434349775,
      "learning_rate": 4.067441860465116e-05,
      "loss": 0.0004,
      "step": 2406
    },
    {
      "epoch": 9.329457364341085,
      "grad_norm": 18.97382164001465,
      "learning_rate": 4.0670542635658916e-05,
      "loss": 0.697,
      "step": 2407
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 0.05850699916481972,
      "learning_rate": 4.066666666666667e-05,
      "loss": 0.002,
      "step": 2408
    },
    {
      "epoch": 9.337209302325581,
      "grad_norm": 0.005928289145231247,
      "learning_rate": 4.066279069767442e-05,
      "loss": 0.0005,
      "step": 2409
    },
    {
      "epoch": 9.34108527131783,
      "grad_norm": 0.005499551072716713,
      "learning_rate": 4.065891472868217e-05,
      "loss": 0.0005,
      "step": 2410
    },
    {
      "epoch": 9.344961240310077,
      "grad_norm": 0.0675964206457138,
      "learning_rate": 4.0655038759689925e-05,
      "loss": 0.0015,
      "step": 2411
    },
    {
      "epoch": 9.348837209302326,
      "grad_norm": 0.1046648621559143,
      "learning_rate": 4.065116279069768e-05,
      "loss": 0.0031,
      "step": 2412
    },
    {
      "epoch": 9.352713178294573,
      "grad_norm": 0.023077605292201042,
      "learning_rate": 4.064728682170543e-05,
      "loss": 0.0012,
      "step": 2413
    },
    {
      "epoch": 9.356589147286822,
      "grad_norm": 0.5126010775566101,
      "learning_rate": 4.064341085271318e-05,
      "loss": 0.0064,
      "step": 2414
    },
    {
      "epoch": 9.36046511627907,
      "grad_norm": 0.02857118286192417,
      "learning_rate": 4.063953488372093e-05,
      "loss": 0.0017,
      "step": 2415
    },
    {
      "epoch": 9.364341085271318,
      "grad_norm": 9.296662330627441,
      "learning_rate": 4.063565891472869e-05,
      "loss": 0.0977,
      "step": 2416
    },
    {
      "epoch": 9.368217054263566,
      "grad_norm": 0.6615537405014038,
      "learning_rate": 4.063178294573643e-05,
      "loss": 0.0081,
      "step": 2417
    },
    {
      "epoch": 9.372093023255815,
      "grad_norm": 0.02054399438202381,
      "learning_rate": 4.062790697674419e-05,
      "loss": 0.0008,
      "step": 2418
    },
    {
      "epoch": 9.375968992248062,
      "grad_norm": 15.93452262878418,
      "learning_rate": 4.062403100775194e-05,
      "loss": 0.5915,
      "step": 2419
    },
    {
      "epoch": 9.37984496124031,
      "grad_norm": 0.007599148899316788,
      "learning_rate": 4.06201550387597e-05,
      "loss": 0.0005,
      "step": 2420
    },
    {
      "epoch": 9.383720930232558,
      "grad_norm": 0.5251009464263916,
      "learning_rate": 4.061627906976744e-05,
      "loss": 0.0023,
      "step": 2421
    },
    {
      "epoch": 9.387596899224807,
      "grad_norm": 11.962272644042969,
      "learning_rate": 4.0612403100775195e-05,
      "loss": 0.2047,
      "step": 2422
    },
    {
      "epoch": 9.391472868217054,
      "grad_norm": 0.07134465128183365,
      "learning_rate": 4.060852713178295e-05,
      "loss": 0.0032,
      "step": 2423
    },
    {
      "epoch": 9.395348837209303,
      "grad_norm": 0.026805829256772995,
      "learning_rate": 4.06046511627907e-05,
      "loss": 0.0008,
      "step": 2424
    },
    {
      "epoch": 9.39922480620155,
      "grad_norm": 0.015652744099497795,
      "learning_rate": 4.060077519379845e-05,
      "loss": 0.0006,
      "step": 2425
    },
    {
      "epoch": 9.4031007751938,
      "grad_norm": 0.007124816533178091,
      "learning_rate": 4.05968992248062e-05,
      "loss": 0.0005,
      "step": 2426
    },
    {
      "epoch": 9.406976744186046,
      "grad_norm": 1.0051765441894531,
      "learning_rate": 4.059302325581396e-05,
      "loss": 0.0033,
      "step": 2427
    },
    {
      "epoch": 9.410852713178295,
      "grad_norm": 0.03344995900988579,
      "learning_rate": 4.05891472868217e-05,
      "loss": 0.0008,
      "step": 2428
    },
    {
      "epoch": 9.414728682170542,
      "grad_norm": 0.010867123492062092,
      "learning_rate": 4.058527131782946e-05,
      "loss": 0.0005,
      "step": 2429
    },
    {
      "epoch": 9.418604651162791,
      "grad_norm": 0.01801939494907856,
      "learning_rate": 4.058139534883721e-05,
      "loss": 0.0007,
      "step": 2430
    },
    {
      "epoch": 9.422480620155039,
      "grad_norm": 0.031903646886348724,
      "learning_rate": 4.057751937984497e-05,
      "loss": 0.0007,
      "step": 2431
    },
    {
      "epoch": 9.426356589147288,
      "grad_norm": 0.007827629335224628,
      "learning_rate": 4.057364341085271e-05,
      "loss": 0.0006,
      "step": 2432
    },
    {
      "epoch": 9.430232558139535,
      "grad_norm": 0.6685842871665955,
      "learning_rate": 4.0569767441860465e-05,
      "loss": 0.002,
      "step": 2433
    },
    {
      "epoch": 9.434108527131784,
      "grad_norm": 0.2836572825908661,
      "learning_rate": 4.056589147286822e-05,
      "loss": 0.005,
      "step": 2434
    },
    {
      "epoch": 9.437984496124031,
      "grad_norm": 0.007155685219913721,
      "learning_rate": 4.056201550387597e-05,
      "loss": 0.0005,
      "step": 2435
    },
    {
      "epoch": 9.44186046511628,
      "grad_norm": 0.03649084270000458,
      "learning_rate": 4.055813953488372e-05,
      "loss": 0.0009,
      "step": 2436
    },
    {
      "epoch": 9.445736434108527,
      "grad_norm": 0.004824531730264425,
      "learning_rate": 4.0554263565891475e-05,
      "loss": 0.0003,
      "step": 2437
    },
    {
      "epoch": 9.449612403100776,
      "grad_norm": 7.747375965118408,
      "learning_rate": 4.055038759689923e-05,
      "loss": 0.0209,
      "step": 2438
    },
    {
      "epoch": 9.453488372093023,
      "grad_norm": 28.83196258544922,
      "learning_rate": 4.054651162790698e-05,
      "loss": 0.1246,
      "step": 2439
    },
    {
      "epoch": 9.457364341085272,
      "grad_norm": 0.003584308549761772,
      "learning_rate": 4.054263565891473e-05,
      "loss": 0.0003,
      "step": 2440
    },
    {
      "epoch": 9.46124031007752,
      "grad_norm": 0.003985351882874966,
      "learning_rate": 4.0538759689922484e-05,
      "loss": 0.0003,
      "step": 2441
    },
    {
      "epoch": 9.465116279069768,
      "grad_norm": 0.0035237011034041643,
      "learning_rate": 4.053488372093023e-05,
      "loss": 0.0003,
      "step": 2442
    },
    {
      "epoch": 9.468992248062015,
      "grad_norm": 19.568445205688477,
      "learning_rate": 4.053100775193799e-05,
      "loss": 0.1381,
      "step": 2443
    },
    {
      "epoch": 9.472868217054264,
      "grad_norm": 1.3160345554351807,
      "learning_rate": 4.0527131782945735e-05,
      "loss": 0.0015,
      "step": 2444
    },
    {
      "epoch": 9.476744186046512,
      "grad_norm": 0.004877156112343073,
      "learning_rate": 4.0523255813953494e-05,
      "loss": 0.0004,
      "step": 2445
    },
    {
      "epoch": 9.48062015503876,
      "grad_norm": 4.054227828979492,
      "learning_rate": 4.051937984496124e-05,
      "loss": 0.1674,
      "step": 2446
    },
    {
      "epoch": 9.484496124031008,
      "grad_norm": 0.7959255576133728,
      "learning_rate": 4.0515503875969e-05,
      "loss": 0.0069,
      "step": 2447
    },
    {
      "epoch": 9.488372093023255,
      "grad_norm": 0.0061254012398421764,
      "learning_rate": 4.0511627906976745e-05,
      "loss": 0.0004,
      "step": 2448
    },
    {
      "epoch": 9.492248062015504,
      "grad_norm": 0.0027558503206819296,
      "learning_rate": 4.0507751937984504e-05,
      "loss": 0.0003,
      "step": 2449
    },
    {
      "epoch": 9.496124031007753,
      "grad_norm": 0.00803679320961237,
      "learning_rate": 4.050387596899225e-05,
      "loss": 0.0004,
      "step": 2450
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.017362719401717186,
      "learning_rate": 4.05e-05,
      "loss": 0.0007,
      "step": 2451
    },
    {
      "epoch": 9.503875968992247,
      "grad_norm": 0.0099403765052557,
      "learning_rate": 4.0496124031007754e-05,
      "loss": 0.0006,
      "step": 2452
    },
    {
      "epoch": 9.507751937984496,
      "grad_norm": 0.017680054530501366,
      "learning_rate": 4.04922480620155e-05,
      "loss": 0.0005,
      "step": 2453
    },
    {
      "epoch": 9.511627906976745,
      "grad_norm": 0.015376096591353416,
      "learning_rate": 4.048837209302326e-05,
      "loss": 0.0005,
      "step": 2454
    },
    {
      "epoch": 9.515503875968992,
      "grad_norm": 0.005245292093604803,
      "learning_rate": 4.0484496124031005e-05,
      "loss": 0.0004,
      "step": 2455
    },
    {
      "epoch": 9.51937984496124,
      "grad_norm": 0.009333343245089054,
      "learning_rate": 4.0480620155038764e-05,
      "loss": 0.0006,
      "step": 2456
    },
    {
      "epoch": 9.523255813953488,
      "grad_norm": 0.007953187450766563,
      "learning_rate": 4.047674418604651e-05,
      "loss": 0.0004,
      "step": 2457
    },
    {
      "epoch": 9.527131782945737,
      "grad_norm": 1.4783653020858765,
      "learning_rate": 4.047286821705427e-05,
      "loss": 0.3873,
      "step": 2458
    },
    {
      "epoch": 9.531007751937985,
      "grad_norm": 0.2612697184085846,
      "learning_rate": 4.0468992248062014e-05,
      "loss": 0.0009,
      "step": 2459
    },
    {
      "epoch": 9.534883720930232,
      "grad_norm": 0.07459448277950287,
      "learning_rate": 4.046511627906977e-05,
      "loss": 0.003,
      "step": 2460
    },
    {
      "epoch": 9.53875968992248,
      "grad_norm": 2.8212974071502686,
      "learning_rate": 4.046124031007752e-05,
      "loss": 0.2129,
      "step": 2461
    },
    {
      "epoch": 9.542635658914728,
      "grad_norm": 0.5251181125640869,
      "learning_rate": 4.045736434108527e-05,
      "loss": 0.0033,
      "step": 2462
    },
    {
      "epoch": 9.546511627906977,
      "grad_norm": 0.014923001639544964,
      "learning_rate": 4.0453488372093024e-05,
      "loss": 0.0008,
      "step": 2463
    },
    {
      "epoch": 9.550387596899224,
      "grad_norm": 0.07767440378665924,
      "learning_rate": 4.0449612403100777e-05,
      "loss": 0.0029,
      "step": 2464
    },
    {
      "epoch": 9.554263565891473,
      "grad_norm": 0.025406088680028915,
      "learning_rate": 4.044573643410853e-05,
      "loss": 0.0011,
      "step": 2465
    },
    {
      "epoch": 9.55813953488372,
      "grad_norm": 0.010838571935892105,
      "learning_rate": 4.044186046511628e-05,
      "loss": 0.0006,
      "step": 2466
    },
    {
      "epoch": 9.562015503875969,
      "grad_norm": 0.08689091354608536,
      "learning_rate": 4.0437984496124034e-05,
      "loss": 0.003,
      "step": 2467
    },
    {
      "epoch": 9.565891472868216,
      "grad_norm": 0.020375864580273628,
      "learning_rate": 4.0434108527131786e-05,
      "loss": 0.001,
      "step": 2468
    },
    {
      "epoch": 9.569767441860465,
      "grad_norm": 0.21998371183872223,
      "learning_rate": 4.043023255813954e-05,
      "loss": 0.0067,
      "step": 2469
    },
    {
      "epoch": 9.573643410852712,
      "grad_norm": 0.07029923796653748,
      "learning_rate": 4.042635658914729e-05,
      "loss": 0.0027,
      "step": 2470
    },
    {
      "epoch": 9.577519379844961,
      "grad_norm": 2.6931984424591064,
      "learning_rate": 4.042248062015504e-05,
      "loss": 0.3028,
      "step": 2471
    },
    {
      "epoch": 9.581395348837209,
      "grad_norm": 0.061891570687294006,
      "learning_rate": 4.0418604651162796e-05,
      "loss": 0.0024,
      "step": 2472
    },
    {
      "epoch": 9.585271317829458,
      "grad_norm": 0.09558314830064774,
      "learning_rate": 4.041472868217054e-05,
      "loss": 0.0036,
      "step": 2473
    },
    {
      "epoch": 9.589147286821705,
      "grad_norm": 7.353628158569336,
      "learning_rate": 4.04108527131783e-05,
      "loss": 0.5136,
      "step": 2474
    },
    {
      "epoch": 9.593023255813954,
      "grad_norm": 3.8679065704345703,
      "learning_rate": 4.0406976744186046e-05,
      "loss": 0.2812,
      "step": 2475
    },
    {
      "epoch": 9.5968992248062,
      "grad_norm": 0.2680727541446686,
      "learning_rate": 4.0403100775193806e-05,
      "loss": 0.0068,
      "step": 2476
    },
    {
      "epoch": 9.60077519379845,
      "grad_norm": 7.061981678009033,
      "learning_rate": 4.039922480620155e-05,
      "loss": 0.0396,
      "step": 2477
    },
    {
      "epoch": 9.604651162790697,
      "grad_norm": 0.11398157477378845,
      "learning_rate": 4.0395348837209304e-05,
      "loss": 0.0042,
      "step": 2478
    },
    {
      "epoch": 9.608527131782946,
      "grad_norm": 2.2673423290252686,
      "learning_rate": 4.0391472868217056e-05,
      "loss": 0.0057,
      "step": 2479
    },
    {
      "epoch": 9.612403100775193,
      "grad_norm": 3.7859914302825928,
      "learning_rate": 4.038759689922481e-05,
      "loss": 0.6037,
      "step": 2480
    },
    {
      "epoch": 9.616279069767442,
      "grad_norm": 5.139975547790527,
      "learning_rate": 4.038372093023256e-05,
      "loss": 0.2198,
      "step": 2481
    },
    {
      "epoch": 9.62015503875969,
      "grad_norm": 0.04437239468097687,
      "learning_rate": 4.037984496124031e-05,
      "loss": 0.0023,
      "step": 2482
    },
    {
      "epoch": 9.624031007751938,
      "grad_norm": 0.01979842782020569,
      "learning_rate": 4.0375968992248066e-05,
      "loss": 0.001,
      "step": 2483
    },
    {
      "epoch": 9.627906976744185,
      "grad_norm": 3.57851505279541,
      "learning_rate": 4.037209302325581e-05,
      "loss": 0.0159,
      "step": 2484
    },
    {
      "epoch": 9.631782945736434,
      "grad_norm": 0.014366121962666512,
      "learning_rate": 4.036821705426357e-05,
      "loss": 0.0008,
      "step": 2485
    },
    {
      "epoch": 9.635658914728682,
      "grad_norm": 0.6744204759597778,
      "learning_rate": 4.0364341085271316e-05,
      "loss": 0.0093,
      "step": 2486
    },
    {
      "epoch": 9.63953488372093,
      "grad_norm": 0.02446695603430271,
      "learning_rate": 4.0360465116279075e-05,
      "loss": 0.0013,
      "step": 2487
    },
    {
      "epoch": 9.643410852713178,
      "grad_norm": 0.154814213514328,
      "learning_rate": 4.035658914728682e-05,
      "loss": 0.0027,
      "step": 2488
    },
    {
      "epoch": 9.647286821705427,
      "grad_norm": 0.008097374811768532,
      "learning_rate": 4.0352713178294574e-05,
      "loss": 0.0006,
      "step": 2489
    },
    {
      "epoch": 9.651162790697674,
      "grad_norm": 1.4396370649337769,
      "learning_rate": 4.0348837209302326e-05,
      "loss": 0.1853,
      "step": 2490
    },
    {
      "epoch": 9.655038759689923,
      "grad_norm": 0.008376882411539555,
      "learning_rate": 4.034496124031008e-05,
      "loss": 0.0006,
      "step": 2491
    },
    {
      "epoch": 9.65891472868217,
      "grad_norm": 0.01144031248986721,
      "learning_rate": 4.034108527131783e-05,
      "loss": 0.0007,
      "step": 2492
    },
    {
      "epoch": 9.662790697674419,
      "grad_norm": 0.24705031514167786,
      "learning_rate": 4.033720930232558e-05,
      "loss": 0.0034,
      "step": 2493
    },
    {
      "epoch": 9.666666666666666,
      "grad_norm": 0.03761594370007515,
      "learning_rate": 4.0333333333333336e-05,
      "loss": 0.0021,
      "step": 2494
    },
    {
      "epoch": 9.670542635658915,
      "grad_norm": 0.022366706281900406,
      "learning_rate": 4.032945736434109e-05,
      "loss": 0.0012,
      "step": 2495
    },
    {
      "epoch": 9.674418604651162,
      "grad_norm": 0.06279899179935455,
      "learning_rate": 4.032558139534884e-05,
      "loss": 0.003,
      "step": 2496
    },
    {
      "epoch": 9.678294573643411,
      "grad_norm": 0.03398852050304413,
      "learning_rate": 4.032170542635659e-05,
      "loss": 0.0019,
      "step": 2497
    },
    {
      "epoch": 9.682170542635658,
      "grad_norm": 0.048972997814416885,
      "learning_rate": 4.0317829457364345e-05,
      "loss": 0.0028,
      "step": 2498
    },
    {
      "epoch": 9.686046511627907,
      "grad_norm": 0.017891775816679,
      "learning_rate": 4.03139534883721e-05,
      "loss": 0.0009,
      "step": 2499
    },
    {
      "epoch": 9.689922480620154,
      "grad_norm": 0.022013140842318535,
      "learning_rate": 4.0310077519379843e-05,
      "loss": 0.001,
      "step": 2500
    },
    {
      "epoch": 9.693798449612403,
      "grad_norm": 0.03208606690168381,
      "learning_rate": 4.03062015503876e-05,
      "loss": 0.0014,
      "step": 2501
    },
    {
      "epoch": 9.69767441860465,
      "grad_norm": 0.030380966141819954,
      "learning_rate": 4.030232558139535e-05,
      "loss": 0.0014,
      "step": 2502
    },
    {
      "epoch": 9.7015503875969,
      "grad_norm": 0.024485057219862938,
      "learning_rate": 4.029844961240311e-05,
      "loss": 0.0012,
      "step": 2503
    },
    {
      "epoch": 9.705426356589147,
      "grad_norm": 0.05549720674753189,
      "learning_rate": 4.029457364341085e-05,
      "loss": 0.0027,
      "step": 2504
    },
    {
      "epoch": 9.709302325581396,
      "grad_norm": 0.009361263364553452,
      "learning_rate": 4.029069767441861e-05,
      "loss": 0.0006,
      "step": 2505
    },
    {
      "epoch": 9.713178294573643,
      "grad_norm": 0.03062581829726696,
      "learning_rate": 4.028682170542636e-05,
      "loss": 0.002,
      "step": 2506
    },
    {
      "epoch": 9.717054263565892,
      "grad_norm": 0.04984287917613983,
      "learning_rate": 4.028294573643411e-05,
      "loss": 0.0026,
      "step": 2507
    },
    {
      "epoch": 9.720930232558139,
      "grad_norm": 0.0082707479596138,
      "learning_rate": 4.027906976744186e-05,
      "loss": 0.0007,
      "step": 2508
    },
    {
      "epoch": 9.724806201550388,
      "grad_norm": 0.015162274241447449,
      "learning_rate": 4.0275193798449615e-05,
      "loss": 0.0008,
      "step": 2509
    },
    {
      "epoch": 9.728682170542635,
      "grad_norm": 0.008253761567175388,
      "learning_rate": 4.027131782945737e-05,
      "loss": 0.0005,
      "step": 2510
    },
    {
      "epoch": 9.732558139534884,
      "grad_norm": 0.01872478425502777,
      "learning_rate": 4.026744186046511e-05,
      "loss": 0.0009,
      "step": 2511
    },
    {
      "epoch": 9.736434108527131,
      "grad_norm": 0.009802115149796009,
      "learning_rate": 4.026356589147287e-05,
      "loss": 0.0006,
      "step": 2512
    },
    {
      "epoch": 9.74031007751938,
      "grad_norm": 0.014448558911681175,
      "learning_rate": 4.025968992248062e-05,
      "loss": 0.0008,
      "step": 2513
    },
    {
      "epoch": 9.744186046511627,
      "grad_norm": 0.009775823913514614,
      "learning_rate": 4.025581395348838e-05,
      "loss": 0.0006,
      "step": 2514
    },
    {
      "epoch": 9.748062015503876,
      "grad_norm": 0.01511809229850769,
      "learning_rate": 4.025193798449612e-05,
      "loss": 0.0008,
      "step": 2515
    },
    {
      "epoch": 9.751937984496124,
      "grad_norm": 0.7680473327636719,
      "learning_rate": 4.024806201550388e-05,
      "loss": 0.1663,
      "step": 2516
    },
    {
      "epoch": 9.755813953488373,
      "grad_norm": 0.017984546720981598,
      "learning_rate": 4.024418604651163e-05,
      "loss": 0.001,
      "step": 2517
    },
    {
      "epoch": 9.75968992248062,
      "grad_norm": 8.315197944641113,
      "learning_rate": 4.024031007751938e-05,
      "loss": 0.4532,
      "step": 2518
    },
    {
      "epoch": 9.763565891472869,
      "grad_norm": 0.012603399343788624,
      "learning_rate": 4.023643410852713e-05,
      "loss": 0.0007,
      "step": 2519
    },
    {
      "epoch": 9.767441860465116,
      "grad_norm": 0.035700466483831406,
      "learning_rate": 4.0232558139534885e-05,
      "loss": 0.0015,
      "step": 2520
    },
    {
      "epoch": 9.771317829457365,
      "grad_norm": 0.007656719069927931,
      "learning_rate": 4.022868217054264e-05,
      "loss": 0.0006,
      "step": 2521
    },
    {
      "epoch": 9.775193798449612,
      "grad_norm": 0.7655630707740784,
      "learning_rate": 4.022480620155039e-05,
      "loss": 0.0013,
      "step": 2522
    },
    {
      "epoch": 9.779069767441861,
      "grad_norm": 0.017574211582541466,
      "learning_rate": 4.022093023255814e-05,
      "loss": 0.0012,
      "step": 2523
    },
    {
      "epoch": 9.782945736434108,
      "grad_norm": 0.013933500275015831,
      "learning_rate": 4.0217054263565895e-05,
      "loss": 0.0008,
      "step": 2524
    },
    {
      "epoch": 9.786821705426357,
      "grad_norm": 0.006555201485753059,
      "learning_rate": 4.021317829457365e-05,
      "loss": 0.0005,
      "step": 2525
    },
    {
      "epoch": 9.790697674418604,
      "grad_norm": 42.42512130737305,
      "learning_rate": 4.02093023255814e-05,
      "loss": 0.0673,
      "step": 2526
    },
    {
      "epoch": 9.794573643410853,
      "grad_norm": 0.014761321246623993,
      "learning_rate": 4.020542635658915e-05,
      "loss": 0.0009,
      "step": 2527
    },
    {
      "epoch": 9.7984496124031,
      "grad_norm": 0.0069092088378965855,
      "learning_rate": 4.0201550387596904e-05,
      "loss": 0.0005,
      "step": 2528
    },
    {
      "epoch": 9.80232558139535,
      "grad_norm": 0.10976076126098633,
      "learning_rate": 4.019767441860465e-05,
      "loss": 0.0019,
      "step": 2529
    },
    {
      "epoch": 9.806201550387597,
      "grad_norm": 0.006065277382731438,
      "learning_rate": 4.019379844961241e-05,
      "loss": 0.0005,
      "step": 2530
    },
    {
      "epoch": 9.810077519379846,
      "grad_norm": 0.022446243092417717,
      "learning_rate": 4.0189922480620155e-05,
      "loss": 0.0006,
      "step": 2531
    },
    {
      "epoch": 9.813953488372093,
      "grad_norm": 0.005165623966604471,
      "learning_rate": 4.0186046511627914e-05,
      "loss": 0.0004,
      "step": 2532
    },
    {
      "epoch": 9.817829457364342,
      "grad_norm": 0.005187676753848791,
      "learning_rate": 4.018217054263566e-05,
      "loss": 0.0005,
      "step": 2533
    },
    {
      "epoch": 9.821705426356589,
      "grad_norm": 1.5544464588165283,
      "learning_rate": 4.017829457364341e-05,
      "loss": 0.2395,
      "step": 2534
    },
    {
      "epoch": 9.825581395348838,
      "grad_norm": 0.0031997491605579853,
      "learning_rate": 4.0174418604651165e-05,
      "loss": 0.0003,
      "step": 2535
    },
    {
      "epoch": 9.829457364341085,
      "grad_norm": 0.004671177826821804,
      "learning_rate": 4.017054263565892e-05,
      "loss": 0.0004,
      "step": 2536
    },
    {
      "epoch": 9.833333333333334,
      "grad_norm": 0.04844488948583603,
      "learning_rate": 4.016666666666667e-05,
      "loss": 0.0021,
      "step": 2537
    },
    {
      "epoch": 9.837209302325581,
      "grad_norm": 0.0062229628674685955,
      "learning_rate": 4.0162790697674415e-05,
      "loss": 0.0005,
      "step": 2538
    },
    {
      "epoch": 9.84108527131783,
      "grad_norm": 0.7932204604148865,
      "learning_rate": 4.0158914728682174e-05,
      "loss": 0.0107,
      "step": 2539
    },
    {
      "epoch": 9.844961240310077,
      "grad_norm": 6.349276065826416,
      "learning_rate": 4.015503875968992e-05,
      "loss": 0.0054,
      "step": 2540
    },
    {
      "epoch": 9.848837209302326,
      "grad_norm": 0.0062073590233922005,
      "learning_rate": 4.015116279069768e-05,
      "loss": 0.0004,
      "step": 2541
    },
    {
      "epoch": 9.852713178294573,
      "grad_norm": 0.00363391381688416,
      "learning_rate": 4.0147286821705425e-05,
      "loss": 0.0004,
      "step": 2542
    },
    {
      "epoch": 9.856589147286822,
      "grad_norm": 3.903385877609253,
      "learning_rate": 4.0143410852713184e-05,
      "loss": 0.0541,
      "step": 2543
    },
    {
      "epoch": 9.86046511627907,
      "grad_norm": 0.0070495703257620335,
      "learning_rate": 4.013953488372093e-05,
      "loss": 0.0005,
      "step": 2544
    },
    {
      "epoch": 9.864341085271318,
      "grad_norm": 0.0047705224715173244,
      "learning_rate": 4.013565891472868e-05,
      "loss": 0.0004,
      "step": 2545
    },
    {
      "epoch": 9.868217054263566,
      "grad_norm": 6.191888809204102,
      "learning_rate": 4.0131782945736434e-05,
      "loss": 0.9484,
      "step": 2546
    },
    {
      "epoch": 9.872093023255815,
      "grad_norm": 0.004315820522606373,
      "learning_rate": 4.012790697674419e-05,
      "loss": 0.0004,
      "step": 2547
    },
    {
      "epoch": 9.875968992248062,
      "grad_norm": 1.4899771213531494,
      "learning_rate": 4.012403100775194e-05,
      "loss": 0.064,
      "step": 2548
    },
    {
      "epoch": 9.87984496124031,
      "grad_norm": 0.008598756976425648,
      "learning_rate": 4.012015503875969e-05,
      "loss": 0.0006,
      "step": 2549
    },
    {
      "epoch": 9.883720930232558,
      "grad_norm": 0.011130349710583687,
      "learning_rate": 4.0116279069767444e-05,
      "loss": 0.0006,
      "step": 2550
    },
    {
      "epoch": 9.887596899224807,
      "grad_norm": 0.05988526716828346,
      "learning_rate": 4.0112403100775197e-05,
      "loss": 0.0017,
      "step": 2551
    },
    {
      "epoch": 9.891472868217054,
      "grad_norm": 0.03959708660840988,
      "learning_rate": 4.010852713178295e-05,
      "loss": 0.0012,
      "step": 2552
    },
    {
      "epoch": 9.895348837209303,
      "grad_norm": 1.7061303853988647,
      "learning_rate": 4.01046511627907e-05,
      "loss": 0.292,
      "step": 2553
    },
    {
      "epoch": 9.89922480620155,
      "grad_norm": 0.05813700333237648,
      "learning_rate": 4.0100775193798454e-05,
      "loss": 0.0029,
      "step": 2554
    },
    {
      "epoch": 9.9031007751938,
      "grad_norm": 0.019380172714591026,
      "learning_rate": 4.0096899224806206e-05,
      "loss": 0.0007,
      "step": 2555
    },
    {
      "epoch": 9.906976744186046,
      "grad_norm": 0.07039369642734528,
      "learning_rate": 4.009302325581395e-05,
      "loss": 0.001,
      "step": 2556
    },
    {
      "epoch": 9.910852713178295,
      "grad_norm": 2.4298086166381836,
      "learning_rate": 4.008914728682171e-05,
      "loss": 0.0747,
      "step": 2557
    },
    {
      "epoch": 9.914728682170542,
      "grad_norm": 0.004822771064937115,
      "learning_rate": 4.008527131782946e-05,
      "loss": 0.0004,
      "step": 2558
    },
    {
      "epoch": 9.918604651162791,
      "grad_norm": 4.856729030609131,
      "learning_rate": 4.008139534883721e-05,
      "loss": 0.1882,
      "step": 2559
    },
    {
      "epoch": 9.922480620155039,
      "grad_norm": 0.005574026145040989,
      "learning_rate": 4.007751937984496e-05,
      "loss": 0.0005,
      "step": 2560
    },
    {
      "epoch": 9.926356589147288,
      "grad_norm": 0.008697735145688057,
      "learning_rate": 4.0073643410852714e-05,
      "loss": 0.0005,
      "step": 2561
    },
    {
      "epoch": 9.930232558139535,
      "grad_norm": 0.13218437135219574,
      "learning_rate": 4.0069767441860466e-05,
      "loss": 0.0043,
      "step": 2562
    },
    {
      "epoch": 9.934108527131784,
      "grad_norm": 4.859640121459961,
      "learning_rate": 4.006589147286822e-05,
      "loss": 0.643,
      "step": 2563
    },
    {
      "epoch": 9.937984496124031,
      "grad_norm": 0.005047151818871498,
      "learning_rate": 4.006201550387597e-05,
      "loss": 0.0004,
      "step": 2564
    },
    {
      "epoch": 9.94186046511628,
      "grad_norm": 0.004315908998250961,
      "learning_rate": 4.0058139534883724e-05,
      "loss": 0.0004,
      "step": 2565
    },
    {
      "epoch": 9.945736434108527,
      "grad_norm": 0.01057848334312439,
      "learning_rate": 4.0054263565891476e-05,
      "loss": 0.0006,
      "step": 2566
    },
    {
      "epoch": 9.949612403100776,
      "grad_norm": 3.788719892501831,
      "learning_rate": 4.005038759689922e-05,
      "loss": 0.4611,
      "step": 2567
    },
    {
      "epoch": 9.953488372093023,
      "grad_norm": 0.004926189314574003,
      "learning_rate": 4.004651162790698e-05,
      "loss": 0.0004,
      "step": 2568
    },
    {
      "epoch": 9.957364341085272,
      "grad_norm": 7.020047187805176,
      "learning_rate": 4.004263565891473e-05,
      "loss": 0.1938,
      "step": 2569
    },
    {
      "epoch": 9.96124031007752,
      "grad_norm": 5.186419486999512,
      "learning_rate": 4.0038759689922486e-05,
      "loss": 0.0491,
      "step": 2570
    },
    {
      "epoch": 9.965116279069768,
      "grad_norm": 0.11247900873422623,
      "learning_rate": 4.003488372093023e-05,
      "loss": 0.0023,
      "step": 2571
    },
    {
      "epoch": 9.968992248062015,
      "grad_norm": 16.773597717285156,
      "learning_rate": 4.003100775193799e-05,
      "loss": 0.7801,
      "step": 2572
    },
    {
      "epoch": 9.972868217054263,
      "grad_norm": 0.8935234546661377,
      "learning_rate": 4.0027131782945736e-05,
      "loss": 0.0192,
      "step": 2573
    },
    {
      "epoch": 9.976744186046512,
      "grad_norm": 0.01727299578487873,
      "learning_rate": 4.002325581395349e-05,
      "loss": 0.0007,
      "step": 2574
    },
    {
      "epoch": 9.98062015503876,
      "grad_norm": 8.434207916259766,
      "learning_rate": 4.001937984496124e-05,
      "loss": 0.6767,
      "step": 2575
    },
    {
      "epoch": 9.984496124031008,
      "grad_norm": 0.011001971550285816,
      "learning_rate": 4.0015503875968994e-05,
      "loss": 0.0005,
      "step": 2576
    },
    {
      "epoch": 9.988372093023255,
      "grad_norm": 0.027374183759093285,
      "learning_rate": 4.0011627906976746e-05,
      "loss": 0.0006,
      "step": 2577
    },
    {
      "epoch": 9.992248062015504,
      "grad_norm": 0.010985719040036201,
      "learning_rate": 4.00077519379845e-05,
      "loss": 0.0006,
      "step": 2578
    },
    {
      "epoch": 9.996124031007753,
      "grad_norm": 0.006535537540912628,
      "learning_rate": 4.000387596899225e-05,
      "loss": 0.0005,
      "step": 2579
    },
    {
      "epoch": 10.0,
      "grad_norm": 5.273244380950928,
      "learning_rate": 4e-05,
      "loss": 0.4282,
      "step": 2580
    },
    {
      "epoch": 10.003875968992247,
      "grad_norm": 0.5287800431251526,
      "learning_rate": 3.9996124031007756e-05,
      "loss": 0.0205,
      "step": 2581
    },
    {
      "epoch": 10.007751937984496,
      "grad_norm": 0.6325193643569946,
      "learning_rate": 3.999224806201551e-05,
      "loss": 0.0229,
      "step": 2582
    },
    {
      "epoch": 10.011627906976743,
      "grad_norm": 1.9068502187728882,
      "learning_rate": 3.998837209302326e-05,
      "loss": 0.0917,
      "step": 2583
    },
    {
      "epoch": 10.015503875968992,
      "grad_norm": 1.17949378490448,
      "learning_rate": 3.998449612403101e-05,
      "loss": 0.0353,
      "step": 2584
    },
    {
      "epoch": 10.01937984496124,
      "grad_norm": 0.6997100710868835,
      "learning_rate": 3.998062015503876e-05,
      "loss": 0.0019,
      "step": 2585
    },
    {
      "epoch": 10.023255813953488,
      "grad_norm": 6.2195563316345215,
      "learning_rate": 3.997674418604651e-05,
      "loss": 0.0135,
      "step": 2586
    },
    {
      "epoch": 10.027131782945736,
      "grad_norm": 0.008806596510112286,
      "learning_rate": 3.9972868217054263e-05,
      "loss": 0.0005,
      "step": 2587
    },
    {
      "epoch": 10.031007751937985,
      "grad_norm": 0.008227881975471973,
      "learning_rate": 3.9968992248062016e-05,
      "loss": 0.0005,
      "step": 2588
    },
    {
      "epoch": 10.034883720930232,
      "grad_norm": 0.010169381275773048,
      "learning_rate": 3.996511627906977e-05,
      "loss": 0.0006,
      "step": 2589
    },
    {
      "epoch": 10.03875968992248,
      "grad_norm": 0.004115777555853128,
      "learning_rate": 3.996124031007752e-05,
      "loss": 0.0004,
      "step": 2590
    },
    {
      "epoch": 10.042635658914728,
      "grad_norm": 4.3804931640625,
      "learning_rate": 3.995736434108527e-05,
      "loss": 0.0414,
      "step": 2591
    },
    {
      "epoch": 10.046511627906977,
      "grad_norm": 0.004695409443229437,
      "learning_rate": 3.9953488372093026e-05,
      "loss": 0.0004,
      "step": 2592
    },
    {
      "epoch": 10.050387596899224,
      "grad_norm": 0.0845203846693039,
      "learning_rate": 3.994961240310078e-05,
      "loss": 0.0036,
      "step": 2593
    },
    {
      "epoch": 10.054263565891473,
      "grad_norm": 0.0050210775807499886,
      "learning_rate": 3.994573643410853e-05,
      "loss": 0.0004,
      "step": 2594
    },
    {
      "epoch": 10.05813953488372,
      "grad_norm": 0.8405905961990356,
      "learning_rate": 3.994186046511628e-05,
      "loss": 0.0303,
      "step": 2595
    },
    {
      "epoch": 10.062015503875969,
      "grad_norm": 13.166402816772461,
      "learning_rate": 3.993798449612403e-05,
      "loss": 0.0335,
      "step": 2596
    },
    {
      "epoch": 10.065891472868216,
      "grad_norm": 0.109820157289505,
      "learning_rate": 3.993410852713179e-05,
      "loss": 0.0064,
      "step": 2597
    },
    {
      "epoch": 10.069767441860465,
      "grad_norm": 0.005000387318432331,
      "learning_rate": 3.993023255813953e-05,
      "loss": 0.0004,
      "step": 2598
    },
    {
      "epoch": 10.073643410852712,
      "grad_norm": 0.006428289692848921,
      "learning_rate": 3.992635658914729e-05,
      "loss": 0.0005,
      "step": 2599
    },
    {
      "epoch": 10.077519379844961,
      "grad_norm": 0.004522035829722881,
      "learning_rate": 3.992248062015504e-05,
      "loss": 0.0003,
      "step": 2600
    },
    {
      "epoch": 10.081395348837209,
      "grad_norm": 7.020468711853027,
      "learning_rate": 3.99186046511628e-05,
      "loss": 0.8798,
      "step": 2601
    },
    {
      "epoch": 10.085271317829458,
      "grad_norm": 1.3170160055160522,
      "learning_rate": 3.991472868217054e-05,
      "loss": 0.091,
      "step": 2602
    },
    {
      "epoch": 10.089147286821705,
      "grad_norm": 0.013078694231808186,
      "learning_rate": 3.9910852713178295e-05,
      "loss": 0.0006,
      "step": 2603
    },
    {
      "epoch": 10.093023255813954,
      "grad_norm": 0.004332537297159433,
      "learning_rate": 3.990697674418605e-05,
      "loss": 0.0004,
      "step": 2604
    },
    {
      "epoch": 10.0968992248062,
      "grad_norm": 0.004313135053962469,
      "learning_rate": 3.99031007751938e-05,
      "loss": 0.0004,
      "step": 2605
    },
    {
      "epoch": 10.10077519379845,
      "grad_norm": 0.00602753134444356,
      "learning_rate": 3.989922480620155e-05,
      "loss": 0.0005,
      "step": 2606
    },
    {
      "epoch": 10.104651162790697,
      "grad_norm": 0.02400231547653675,
      "learning_rate": 3.9895348837209305e-05,
      "loss": 0.0013,
      "step": 2607
    },
    {
      "epoch": 10.108527131782946,
      "grad_norm": 2.959104537963867,
      "learning_rate": 3.989147286821706e-05,
      "loss": 0.0217,
      "step": 2608
    },
    {
      "epoch": 10.112403100775193,
      "grad_norm": 10.577183723449707,
      "learning_rate": 3.988759689922481e-05,
      "loss": 0.0481,
      "step": 2609
    },
    {
      "epoch": 10.116279069767442,
      "grad_norm": 0.010952341370284557,
      "learning_rate": 3.988372093023256e-05,
      "loss": 0.0008,
      "step": 2610
    },
    {
      "epoch": 10.12015503875969,
      "grad_norm": 0.03144826367497444,
      "learning_rate": 3.9879844961240315e-05,
      "loss": 0.001,
      "step": 2611
    },
    {
      "epoch": 10.124031007751938,
      "grad_norm": 0.07828235626220703,
      "learning_rate": 3.987596899224807e-05,
      "loss": 0.001,
      "step": 2612
    },
    {
      "epoch": 10.127906976744185,
      "grad_norm": 64.35100555419922,
      "learning_rate": 3.987209302325581e-05,
      "loss": 0.6703,
      "step": 2613
    },
    {
      "epoch": 10.131782945736434,
      "grad_norm": 0.02801317162811756,
      "learning_rate": 3.9868217054263565e-05,
      "loss": 0.0009,
      "step": 2614
    },
    {
      "epoch": 10.135658914728682,
      "grad_norm": 0.024721231311559677,
      "learning_rate": 3.986434108527132e-05,
      "loss": 0.0014,
      "step": 2615
    },
    {
      "epoch": 10.13953488372093,
      "grad_norm": 0.007022373378276825,
      "learning_rate": 3.986046511627907e-05,
      "loss": 0.0005,
      "step": 2616
    },
    {
      "epoch": 10.143410852713178,
      "grad_norm": 0.0055554877035319805,
      "learning_rate": 3.985658914728682e-05,
      "loss": 0.0005,
      "step": 2617
    },
    {
      "epoch": 10.147286821705427,
      "grad_norm": 4.003116130828857,
      "learning_rate": 3.9852713178294575e-05,
      "loss": 0.511,
      "step": 2618
    },
    {
      "epoch": 10.151162790697674,
      "grad_norm": 0.04068518057465553,
      "learning_rate": 3.984883720930233e-05,
      "loss": 0.0009,
      "step": 2619
    },
    {
      "epoch": 10.155038759689923,
      "grad_norm": 0.005765130743384361,
      "learning_rate": 3.984496124031008e-05,
      "loss": 0.0004,
      "step": 2620
    },
    {
      "epoch": 10.15891472868217,
      "grad_norm": 0.01943746581673622,
      "learning_rate": 3.984108527131783e-05,
      "loss": 0.0012,
      "step": 2621
    },
    {
      "epoch": 10.162790697674419,
      "grad_norm": 8.574198722839355,
      "learning_rate": 3.9837209302325585e-05,
      "loss": 0.1556,
      "step": 2622
    },
    {
      "epoch": 10.166666666666666,
      "grad_norm": 6.767190933227539,
      "learning_rate": 3.983333333333333e-05,
      "loss": 0.0495,
      "step": 2623
    },
    {
      "epoch": 10.170542635658915,
      "grad_norm": 0.004405423533171415,
      "learning_rate": 3.982945736434109e-05,
      "loss": 0.0004,
      "step": 2624
    },
    {
      "epoch": 10.174418604651162,
      "grad_norm": 0.004003413021564484,
      "learning_rate": 3.9825581395348835e-05,
      "loss": 0.0004,
      "step": 2625
    },
    {
      "epoch": 10.178294573643411,
      "grad_norm": 1.4077938795089722,
      "learning_rate": 3.9821705426356594e-05,
      "loss": 0.1915,
      "step": 2626
    },
    {
      "epoch": 10.182170542635658,
      "grad_norm": 0.0055928826332092285,
      "learning_rate": 3.981782945736434e-05,
      "loss": 0.0004,
      "step": 2627
    },
    {
      "epoch": 10.186046511627907,
      "grad_norm": 0.33838340640068054,
      "learning_rate": 3.98139534883721e-05,
      "loss": 0.011,
      "step": 2628
    },
    {
      "epoch": 10.189922480620154,
      "grad_norm": 0.03859255835413933,
      "learning_rate": 3.9810077519379845e-05,
      "loss": 0.0005,
      "step": 2629
    },
    {
      "epoch": 10.193798449612403,
      "grad_norm": 0.007043729070574045,
      "learning_rate": 3.9806201550387604e-05,
      "loss": 0.0005,
      "step": 2630
    },
    {
      "epoch": 10.19767441860465,
      "grad_norm": 0.004330147989094257,
      "learning_rate": 3.980232558139535e-05,
      "loss": 0.0004,
      "step": 2631
    },
    {
      "epoch": 10.2015503875969,
      "grad_norm": 0.010857619345188141,
      "learning_rate": 3.97984496124031e-05,
      "loss": 0.0005,
      "step": 2632
    },
    {
      "epoch": 10.205426356589147,
      "grad_norm": 1.2384192943572998,
      "learning_rate": 3.9794573643410855e-05,
      "loss": 0.0037,
      "step": 2633
    },
    {
      "epoch": 10.209302325581396,
      "grad_norm": 0.005416967440396547,
      "learning_rate": 3.979069767441861e-05,
      "loss": 0.0005,
      "step": 2634
    },
    {
      "epoch": 10.213178294573643,
      "grad_norm": 0.0030242339707911015,
      "learning_rate": 3.978682170542636e-05,
      "loss": 0.0003,
      "step": 2635
    },
    {
      "epoch": 10.217054263565892,
      "grad_norm": 0.004120446741580963,
      "learning_rate": 3.978294573643411e-05,
      "loss": 0.0003,
      "step": 2636
    },
    {
      "epoch": 10.220930232558139,
      "grad_norm": 0.03484432026743889,
      "learning_rate": 3.9779069767441864e-05,
      "loss": 0.0008,
      "step": 2637
    },
    {
      "epoch": 10.224806201550388,
      "grad_norm": 0.18659839034080505,
      "learning_rate": 3.977519379844962e-05,
      "loss": 0.0032,
      "step": 2638
    },
    {
      "epoch": 10.228682170542635,
      "grad_norm": 0.0032613633666187525,
      "learning_rate": 3.977131782945737e-05,
      "loss": 0.0004,
      "step": 2639
    },
    {
      "epoch": 10.232558139534884,
      "grad_norm": 18.001554489135742,
      "learning_rate": 3.9767441860465115e-05,
      "loss": 0.4777,
      "step": 2640
    },
    {
      "epoch": 10.236434108527131,
      "grad_norm": 4.183264255523682,
      "learning_rate": 3.976356589147287e-05,
      "loss": 0.4856,
      "step": 2641
    },
    {
      "epoch": 10.24031007751938,
      "grad_norm": 0.1263601928949356,
      "learning_rate": 3.975968992248062e-05,
      "loss": 0.0052,
      "step": 2642
    },
    {
      "epoch": 10.244186046511627,
      "grad_norm": 0.013442138209939003,
      "learning_rate": 3.975581395348837e-05,
      "loss": 0.0005,
      "step": 2643
    },
    {
      "epoch": 10.248062015503876,
      "grad_norm": 0.004261034540832043,
      "learning_rate": 3.9751937984496124e-05,
      "loss": 0.0004,
      "step": 2644
    },
    {
      "epoch": 10.251937984496124,
      "grad_norm": 1.0234527587890625,
      "learning_rate": 3.974806201550388e-05,
      "loss": 0.0085,
      "step": 2645
    },
    {
      "epoch": 10.255813953488373,
      "grad_norm": 0.017460118979215622,
      "learning_rate": 3.974418604651163e-05,
      "loss": 0.0007,
      "step": 2646
    },
    {
      "epoch": 10.25968992248062,
      "grad_norm": 0.004234710242599249,
      "learning_rate": 3.974031007751938e-05,
      "loss": 0.0004,
      "step": 2647
    },
    {
      "epoch": 10.263565891472869,
      "grad_norm": 0.01856476068496704,
      "learning_rate": 3.9736434108527134e-05,
      "loss": 0.0009,
      "step": 2648
    },
    {
      "epoch": 10.267441860465116,
      "grad_norm": 0.010460160672664642,
      "learning_rate": 3.9732558139534886e-05,
      "loss": 0.0004,
      "step": 2649
    },
    {
      "epoch": 10.271317829457365,
      "grad_norm": 0.0031707847956568003,
      "learning_rate": 3.972868217054264e-05,
      "loss": 0.0003,
      "step": 2650
    },
    {
      "epoch": 10.275193798449612,
      "grad_norm": 0.00518007529899478,
      "learning_rate": 3.972480620155039e-05,
      "loss": 0.0004,
      "step": 2651
    },
    {
      "epoch": 10.279069767441861,
      "grad_norm": 0.0736464187502861,
      "learning_rate": 3.972093023255814e-05,
      "loss": 0.0012,
      "step": 2652
    },
    {
      "epoch": 10.282945736434108,
      "grad_norm": 0.0037865263875573874,
      "learning_rate": 3.9717054263565896e-05,
      "loss": 0.0004,
      "step": 2653
    },
    {
      "epoch": 10.286821705426357,
      "grad_norm": 8.905710220336914,
      "learning_rate": 3.971317829457364e-05,
      "loss": 0.3673,
      "step": 2654
    },
    {
      "epoch": 10.290697674418604,
      "grad_norm": 0.07125319540500641,
      "learning_rate": 3.97093023255814e-05,
      "loss": 0.0027,
      "step": 2655
    },
    {
      "epoch": 10.294573643410853,
      "grad_norm": 0.13281014561653137,
      "learning_rate": 3.970542635658915e-05,
      "loss": 0.0019,
      "step": 2656
    },
    {
      "epoch": 10.2984496124031,
      "grad_norm": 0.12534382939338684,
      "learning_rate": 3.9701550387596906e-05,
      "loss": 0.0008,
      "step": 2657
    },
    {
      "epoch": 10.30232558139535,
      "grad_norm": 0.0041323076002299786,
      "learning_rate": 3.969767441860465e-05,
      "loss": 0.0004,
      "step": 2658
    },
    {
      "epoch": 10.306201550387597,
      "grad_norm": 49.647159576416016,
      "learning_rate": 3.9693798449612404e-05,
      "loss": 0.2065,
      "step": 2659
    },
    {
      "epoch": 10.310077519379846,
      "grad_norm": 0.13738000392913818,
      "learning_rate": 3.9689922480620156e-05,
      "loss": 0.0047,
      "step": 2660
    },
    {
      "epoch": 10.313953488372093,
      "grad_norm": 2.5464444160461426,
      "learning_rate": 3.968604651162791e-05,
      "loss": 0.0078,
      "step": 2661
    },
    {
      "epoch": 10.317829457364342,
      "grad_norm": 0.0037119239568710327,
      "learning_rate": 3.968217054263566e-05,
      "loss": 0.0003,
      "step": 2662
    },
    {
      "epoch": 10.321705426356589,
      "grad_norm": 0.8587335348129272,
      "learning_rate": 3.9678294573643414e-05,
      "loss": 0.0105,
      "step": 2663
    },
    {
      "epoch": 10.325581395348838,
      "grad_norm": 0.0035649477504193783,
      "learning_rate": 3.9674418604651166e-05,
      "loss": 0.0003,
      "step": 2664
    },
    {
      "epoch": 10.329457364341085,
      "grad_norm": 4.6409149169921875,
      "learning_rate": 3.967054263565892e-05,
      "loss": 0.5117,
      "step": 2665
    },
    {
      "epoch": 10.333333333333334,
      "grad_norm": 3.566155433654785,
      "learning_rate": 3.966666666666667e-05,
      "loss": 0.0893,
      "step": 2666
    },
    {
      "epoch": 10.337209302325581,
      "grad_norm": 0.15584948658943176,
      "learning_rate": 3.9662790697674417e-05,
      "loss": 0.0062,
      "step": 2667
    },
    {
      "epoch": 10.34108527131783,
      "grad_norm": 4.063591003417969,
      "learning_rate": 3.9658914728682176e-05,
      "loss": 0.5773,
      "step": 2668
    },
    {
      "epoch": 10.344961240310077,
      "grad_norm": 0.3412152826786041,
      "learning_rate": 3.965503875968992e-05,
      "loss": 0.0016,
      "step": 2669
    },
    {
      "epoch": 10.348837209302326,
      "grad_norm": 27.583826065063477,
      "learning_rate": 3.9651162790697674e-05,
      "loss": 0.115,
      "step": 2670
    },
    {
      "epoch": 10.352713178294573,
      "grad_norm": 76.62554168701172,
      "learning_rate": 3.9647286821705426e-05,
      "loss": 0.0907,
      "step": 2671
    },
    {
      "epoch": 10.356589147286822,
      "grad_norm": 0.003358457237482071,
      "learning_rate": 3.964341085271318e-05,
      "loss": 0.0003,
      "step": 2672
    },
    {
      "epoch": 10.36046511627907,
      "grad_norm": 0.03179151192307472,
      "learning_rate": 3.963953488372093e-05,
      "loss": 0.0014,
      "step": 2673
    },
    {
      "epoch": 10.364341085271318,
      "grad_norm": 0.004082505125552416,
      "learning_rate": 3.9635658914728683e-05,
      "loss": 0.0004,
      "step": 2674
    },
    {
      "epoch": 10.368217054263566,
      "grad_norm": 0.25796860456466675,
      "learning_rate": 3.9631782945736436e-05,
      "loss": 0.0125,
      "step": 2675
    },
    {
      "epoch": 10.372093023255815,
      "grad_norm": 0.00335452938452363,
      "learning_rate": 3.962790697674419e-05,
      "loss": 0.0003,
      "step": 2676
    },
    {
      "epoch": 10.375968992248062,
      "grad_norm": 1.6531119346618652,
      "learning_rate": 3.962403100775194e-05,
      "loss": 0.0295,
      "step": 2677
    },
    {
      "epoch": 10.37984496124031,
      "grad_norm": 0.019408490508794785,
      "learning_rate": 3.962015503875969e-05,
      "loss": 0.0009,
      "step": 2678
    },
    {
      "epoch": 10.383720930232558,
      "grad_norm": 0.006661783903837204,
      "learning_rate": 3.9616279069767446e-05,
      "loss": 0.0004,
      "step": 2679
    },
    {
      "epoch": 10.387596899224807,
      "grad_norm": 0.009592597372829914,
      "learning_rate": 3.96124031007752e-05,
      "loss": 0.0004,
      "step": 2680
    },
    {
      "epoch": 10.391472868217054,
      "grad_norm": 0.00355898542329669,
      "learning_rate": 3.9608527131782944e-05,
      "loss": 0.0003,
      "step": 2681
    },
    {
      "epoch": 10.395348837209303,
      "grad_norm": 9.451028823852539,
      "learning_rate": 3.96046511627907e-05,
      "loss": 0.3331,
      "step": 2682
    },
    {
      "epoch": 10.39922480620155,
      "grad_norm": 3.667018413543701,
      "learning_rate": 3.960077519379845e-05,
      "loss": 0.5251,
      "step": 2683
    },
    {
      "epoch": 10.4031007751938,
      "grad_norm": 2.939528703689575,
      "learning_rate": 3.959689922480621e-05,
      "loss": 0.3241,
      "step": 2684
    },
    {
      "epoch": 10.406976744186046,
      "grad_norm": 0.00493701221421361,
      "learning_rate": 3.959302325581395e-05,
      "loss": 0.0004,
      "step": 2685
    },
    {
      "epoch": 10.410852713178295,
      "grad_norm": 0.08342862129211426,
      "learning_rate": 3.958914728682171e-05,
      "loss": 0.0008,
      "step": 2686
    },
    {
      "epoch": 10.414728682170542,
      "grad_norm": 0.015808427706360817,
      "learning_rate": 3.958527131782946e-05,
      "loss": 0.0005,
      "step": 2687
    },
    {
      "epoch": 10.418604651162791,
      "grad_norm": 0.012852986343204975,
      "learning_rate": 3.958139534883721e-05,
      "loss": 0.0006,
      "step": 2688
    },
    {
      "epoch": 10.422480620155039,
      "grad_norm": 13.155427932739258,
      "learning_rate": 3.957751937984496e-05,
      "loss": 0.07,
      "step": 2689
    },
    {
      "epoch": 10.426356589147288,
      "grad_norm": 38.61341857910156,
      "learning_rate": 3.9573643410852715e-05,
      "loss": 0.0097,
      "step": 2690
    },
    {
      "epoch": 10.430232558139535,
      "grad_norm": 0.02510249987244606,
      "learning_rate": 3.956976744186047e-05,
      "loss": 0.0012,
      "step": 2691
    },
    {
      "epoch": 10.434108527131784,
      "grad_norm": 5.690104961395264,
      "learning_rate": 3.9565891472868214e-05,
      "loss": 0.0983,
      "step": 2692
    },
    {
      "epoch": 10.437984496124031,
      "grad_norm": 0.02240573987364769,
      "learning_rate": 3.956201550387597e-05,
      "loss": 0.0011,
      "step": 2693
    },
    {
      "epoch": 10.44186046511628,
      "grad_norm": 0.012539940886199474,
      "learning_rate": 3.955813953488372e-05,
      "loss": 0.0005,
      "step": 2694
    },
    {
      "epoch": 10.445736434108527,
      "grad_norm": 0.008023930713534355,
      "learning_rate": 3.955426356589148e-05,
      "loss": 0.0005,
      "step": 2695
    },
    {
      "epoch": 10.449612403100776,
      "grad_norm": 0.023525867611169815,
      "learning_rate": 3.955038759689922e-05,
      "loss": 0.0007,
      "step": 2696
    },
    {
      "epoch": 10.453488372093023,
      "grad_norm": 1.186490535736084,
      "learning_rate": 3.954651162790698e-05,
      "loss": 0.0201,
      "step": 2697
    },
    {
      "epoch": 10.457364341085272,
      "grad_norm": 0.0074848453514277935,
      "learning_rate": 3.954263565891473e-05,
      "loss": 0.0004,
      "step": 2698
    },
    {
      "epoch": 10.46124031007752,
      "grad_norm": 0.010942984372377396,
      "learning_rate": 3.953875968992248e-05,
      "loss": 0.0005,
      "step": 2699
    },
    {
      "epoch": 10.465116279069768,
      "grad_norm": 0.019988011568784714,
      "learning_rate": 3.953488372093023e-05,
      "loss": 0.0007,
      "step": 2700
    },
    {
      "epoch": 10.468992248062015,
      "grad_norm": 6.105616569519043,
      "learning_rate": 3.9531007751937985e-05,
      "loss": 0.0483,
      "step": 2701
    },
    {
      "epoch": 10.472868217054264,
      "grad_norm": 0.021817775443196297,
      "learning_rate": 3.952713178294574e-05,
      "loss": 0.0006,
      "step": 2702
    },
    {
      "epoch": 10.476744186046512,
      "grad_norm": 3.437922239303589,
      "learning_rate": 3.952325581395349e-05,
      "loss": 0.0613,
      "step": 2703
    },
    {
      "epoch": 10.48062015503876,
      "grad_norm": 0.0505857840180397,
      "learning_rate": 3.951937984496124e-05,
      "loss": 0.0014,
      "step": 2704
    },
    {
      "epoch": 10.484496124031008,
      "grad_norm": 0.006991355214267969,
      "learning_rate": 3.9515503875968995e-05,
      "loss": 0.0004,
      "step": 2705
    },
    {
      "epoch": 10.488372093023255,
      "grad_norm": 0.007869289256632328,
      "learning_rate": 3.951162790697675e-05,
      "loss": 0.0005,
      "step": 2706
    },
    {
      "epoch": 10.492248062015504,
      "grad_norm": 0.06399209052324295,
      "learning_rate": 3.95077519379845e-05,
      "loss": 0.001,
      "step": 2707
    },
    {
      "epoch": 10.496124031007753,
      "grad_norm": 0.016473637893795967,
      "learning_rate": 3.9503875968992245e-05,
      "loss": 0.0006,
      "step": 2708
    },
    {
      "epoch": 10.5,
      "grad_norm": 5.559440612792969,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.0078,
      "step": 2709
    },
    {
      "epoch": 10.503875968992247,
      "grad_norm": 15.343094825744629,
      "learning_rate": 3.949612403100775e-05,
      "loss": 0.0107,
      "step": 2710
    },
    {
      "epoch": 10.507751937984496,
      "grad_norm": 0.008557884953916073,
      "learning_rate": 3.949224806201551e-05,
      "loss": 0.0005,
      "step": 2711
    },
    {
      "epoch": 10.511627906976745,
      "grad_norm": 0.09088398516178131,
      "learning_rate": 3.9488372093023255e-05,
      "loss": 0.002,
      "step": 2712
    },
    {
      "epoch": 10.515503875968992,
      "grad_norm": 0.1650407910346985,
      "learning_rate": 3.9484496124031014e-05,
      "loss": 0.002,
      "step": 2713
    },
    {
      "epoch": 10.51937984496124,
      "grad_norm": 0.013262621127068996,
      "learning_rate": 3.948062015503876e-05,
      "loss": 0.0004,
      "step": 2714
    },
    {
      "epoch": 10.523255813953488,
      "grad_norm": 0.015606852248311043,
      "learning_rate": 3.947674418604652e-05,
      "loss": 0.0004,
      "step": 2715
    },
    {
      "epoch": 10.527131782945737,
      "grad_norm": 0.015319672413170338,
      "learning_rate": 3.9472868217054265e-05,
      "loss": 0.0009,
      "step": 2716
    },
    {
      "epoch": 10.531007751937985,
      "grad_norm": 0.031310707330703735,
      "learning_rate": 3.946899224806202e-05,
      "loss": 0.0015,
      "step": 2717
    },
    {
      "epoch": 10.534883720930232,
      "grad_norm": 9.060384750366211,
      "learning_rate": 3.946511627906977e-05,
      "loss": 0.229,
      "step": 2718
    },
    {
      "epoch": 10.53875968992248,
      "grad_norm": 0.013765087351202965,
      "learning_rate": 3.9461240310077515e-05,
      "loss": 0.0005,
      "step": 2719
    },
    {
      "epoch": 10.542635658914728,
      "grad_norm": 9.612208366394043,
      "learning_rate": 3.9457364341085275e-05,
      "loss": 0.1275,
      "step": 2720
    },
    {
      "epoch": 10.546511627906977,
      "grad_norm": 0.1690616011619568,
      "learning_rate": 3.945348837209302e-05,
      "loss": 0.0054,
      "step": 2721
    },
    {
      "epoch": 10.550387596899224,
      "grad_norm": 0.005350411869585514,
      "learning_rate": 3.944961240310078e-05,
      "loss": 0.0003,
      "step": 2722
    },
    {
      "epoch": 10.554263565891473,
      "grad_norm": 0.009058795869350433,
      "learning_rate": 3.9445736434108525e-05,
      "loss": 0.0004,
      "step": 2723
    },
    {
      "epoch": 10.55813953488372,
      "grad_norm": 0.004059935919940472,
      "learning_rate": 3.9441860465116284e-05,
      "loss": 0.0004,
      "step": 2724
    },
    {
      "epoch": 10.562015503875969,
      "grad_norm": 0.005591082386672497,
      "learning_rate": 3.943798449612403e-05,
      "loss": 0.0004,
      "step": 2725
    },
    {
      "epoch": 10.565891472868216,
      "grad_norm": 0.014429021626710892,
      "learning_rate": 3.943410852713178e-05,
      "loss": 0.0008,
      "step": 2726
    },
    {
      "epoch": 10.569767441860465,
      "grad_norm": 0.008985401131212711,
      "learning_rate": 3.9430232558139535e-05,
      "loss": 0.0004,
      "step": 2727
    },
    {
      "epoch": 10.573643410852712,
      "grad_norm": 4.7111053466796875,
      "learning_rate": 3.942635658914729e-05,
      "loss": 0.1732,
      "step": 2728
    },
    {
      "epoch": 10.577519379844961,
      "grad_norm": 8.137678146362305,
      "learning_rate": 3.942248062015504e-05,
      "loss": 0.6423,
      "step": 2729
    },
    {
      "epoch": 10.581395348837209,
      "grad_norm": 0.004435082897543907,
      "learning_rate": 3.941860465116279e-05,
      "loss": 0.0004,
      "step": 2730
    },
    {
      "epoch": 10.585271317829458,
      "grad_norm": 1.246840476989746,
      "learning_rate": 3.9414728682170544e-05,
      "loss": 0.0248,
      "step": 2731
    },
    {
      "epoch": 10.589147286821705,
      "grad_norm": 0.14291638135910034,
      "learning_rate": 3.94108527131783e-05,
      "loss": 0.0006,
      "step": 2732
    },
    {
      "epoch": 10.593023255813954,
      "grad_norm": 0.006877920590341091,
      "learning_rate": 3.940697674418605e-05,
      "loss": 0.0004,
      "step": 2733
    },
    {
      "epoch": 10.5968992248062,
      "grad_norm": 0.06506320834159851,
      "learning_rate": 3.94031007751938e-05,
      "loss": 0.0005,
      "step": 2734
    },
    {
      "epoch": 10.60077519379845,
      "grad_norm": 0.0639796108007431,
      "learning_rate": 3.9399224806201554e-05,
      "loss": 0.0006,
      "step": 2735
    },
    {
      "epoch": 10.604651162790697,
      "grad_norm": 0.015477967448532581,
      "learning_rate": 3.9395348837209307e-05,
      "loss": 0.0004,
      "step": 2736
    },
    {
      "epoch": 10.608527131782946,
      "grad_norm": 0.18467070162296295,
      "learning_rate": 3.939147286821705e-05,
      "loss": 0.0018,
      "step": 2737
    },
    {
      "epoch": 10.612403100775193,
      "grad_norm": 0.005671133287250996,
      "learning_rate": 3.938759689922481e-05,
      "loss": 0.0004,
      "step": 2738
    },
    {
      "epoch": 10.616279069767442,
      "grad_norm": 0.04321691021323204,
      "learning_rate": 3.938372093023256e-05,
      "loss": 0.0026,
      "step": 2739
    },
    {
      "epoch": 10.62015503875969,
      "grad_norm": 0.031115271151065826,
      "learning_rate": 3.9379844961240316e-05,
      "loss": 0.0007,
      "step": 2740
    },
    {
      "epoch": 10.624031007751938,
      "grad_norm": 0.017493776977062225,
      "learning_rate": 3.937596899224806e-05,
      "loss": 0.0005,
      "step": 2741
    },
    {
      "epoch": 10.627906976744185,
      "grad_norm": 0.02010909467935562,
      "learning_rate": 3.937209302325582e-05,
      "loss": 0.0005,
      "step": 2742
    },
    {
      "epoch": 10.631782945736434,
      "grad_norm": 0.02616518922150135,
      "learning_rate": 3.936821705426357e-05,
      "loss": 0.0005,
      "step": 2743
    },
    {
      "epoch": 10.635658914728682,
      "grad_norm": 0.6501860022544861,
      "learning_rate": 3.936434108527132e-05,
      "loss": 0.1358,
      "step": 2744
    },
    {
      "epoch": 10.63953488372093,
      "grad_norm": 1.005845546722412,
      "learning_rate": 3.936046511627907e-05,
      "loss": 0.0014,
      "step": 2745
    },
    {
      "epoch": 10.643410852713178,
      "grad_norm": 0.012314769439399242,
      "learning_rate": 3.9356589147286824e-05,
      "loss": 0.0005,
      "step": 2746
    },
    {
      "epoch": 10.647286821705427,
      "grad_norm": 3.8840925693511963,
      "learning_rate": 3.9352713178294576e-05,
      "loss": 0.2913,
      "step": 2747
    },
    {
      "epoch": 10.651162790697674,
      "grad_norm": 2.3646585941314697,
      "learning_rate": 3.934883720930232e-05,
      "loss": 0.165,
      "step": 2748
    },
    {
      "epoch": 10.655038759689923,
      "grad_norm": 0.16469672322273254,
      "learning_rate": 3.934496124031008e-05,
      "loss": 0.0017,
      "step": 2749
    },
    {
      "epoch": 10.65891472868217,
      "grad_norm": 24.256837844848633,
      "learning_rate": 3.934108527131783e-05,
      "loss": 0.4482,
      "step": 2750
    },
    {
      "epoch": 10.662790697674419,
      "grad_norm": 0.008148416876792908,
      "learning_rate": 3.9337209302325586e-05,
      "loss": 0.0005,
      "step": 2751
    },
    {
      "epoch": 10.666666666666666,
      "grad_norm": 0.034571100026369095,
      "learning_rate": 3.933333333333333e-05,
      "loss": 0.0007,
      "step": 2752
    },
    {
      "epoch": 10.670542635658915,
      "grad_norm": 0.03213825076818466,
      "learning_rate": 3.932945736434109e-05,
      "loss": 0.0009,
      "step": 2753
    },
    {
      "epoch": 10.674418604651162,
      "grad_norm": 0.08623325824737549,
      "learning_rate": 3.9325581395348837e-05,
      "loss": 0.0008,
      "step": 2754
    },
    {
      "epoch": 10.678294573643411,
      "grad_norm": 0.02639639936387539,
      "learning_rate": 3.932170542635659e-05,
      "loss": 0.001,
      "step": 2755
    },
    {
      "epoch": 10.682170542635658,
      "grad_norm": 0.02177111804485321,
      "learning_rate": 3.931782945736434e-05,
      "loss": 0.001,
      "step": 2756
    },
    {
      "epoch": 10.686046511627907,
      "grad_norm": 0.028167059645056725,
      "learning_rate": 3.9313953488372094e-05,
      "loss": 0.0007,
      "step": 2757
    },
    {
      "epoch": 10.689922480620154,
      "grad_norm": 0.039794377982616425,
      "learning_rate": 3.9310077519379846e-05,
      "loss": 0.001,
      "step": 2758
    },
    {
      "epoch": 10.693798449612403,
      "grad_norm": 0.04829878732562065,
      "learning_rate": 3.93062015503876e-05,
      "loss": 0.0013,
      "step": 2759
    },
    {
      "epoch": 10.69767441860465,
      "grad_norm": 0.019811490550637245,
      "learning_rate": 3.930232558139535e-05,
      "loss": 0.0009,
      "step": 2760
    },
    {
      "epoch": 10.7015503875969,
      "grad_norm": 0.015364330261945724,
      "learning_rate": 3.9298449612403103e-05,
      "loss": 0.0005,
      "step": 2761
    },
    {
      "epoch": 10.705426356589147,
      "grad_norm": 0.012880722992122173,
      "learning_rate": 3.9294573643410856e-05,
      "loss": 0.0006,
      "step": 2762
    },
    {
      "epoch": 10.709302325581396,
      "grad_norm": 0.018118461593985558,
      "learning_rate": 3.929069767441861e-05,
      "loss": 0.0008,
      "step": 2763
    },
    {
      "epoch": 10.713178294573643,
      "grad_norm": 2.9109244346618652,
      "learning_rate": 3.928682170542636e-05,
      "loss": 0.1397,
      "step": 2764
    },
    {
      "epoch": 10.717054263565892,
      "grad_norm": 0.00819450244307518,
      "learning_rate": 3.928294573643411e-05,
      "loss": 0.0004,
      "step": 2765
    },
    {
      "epoch": 10.720930232558139,
      "grad_norm": 0.005143531132489443,
      "learning_rate": 3.927906976744186e-05,
      "loss": 0.0004,
      "step": 2766
    },
    {
      "epoch": 10.724806201550388,
      "grad_norm": 0.007099504582583904,
      "learning_rate": 3.927519379844962e-05,
      "loss": 0.0005,
      "step": 2767
    },
    {
      "epoch": 10.728682170542635,
      "grad_norm": 0.038804031908512115,
      "learning_rate": 3.9271317829457364e-05,
      "loss": 0.0019,
      "step": 2768
    },
    {
      "epoch": 10.732558139534884,
      "grad_norm": 0.005340935662388802,
      "learning_rate": 3.926744186046512e-05,
      "loss": 0.0004,
      "step": 2769
    },
    {
      "epoch": 10.736434108527131,
      "grad_norm": 0.004205161705613136,
      "learning_rate": 3.926356589147287e-05,
      "loss": 0.0004,
      "step": 2770
    },
    {
      "epoch": 10.74031007751938,
      "grad_norm": 0.690696656703949,
      "learning_rate": 3.925968992248063e-05,
      "loss": 0.0032,
      "step": 2771
    },
    {
      "epoch": 10.744186046511627,
      "grad_norm": 0.015962347388267517,
      "learning_rate": 3.925581395348837e-05,
      "loss": 0.0007,
      "step": 2772
    },
    {
      "epoch": 10.748062015503876,
      "grad_norm": 0.02316133677959442,
      "learning_rate": 3.9251937984496126e-05,
      "loss": 0.0014,
      "step": 2773
    },
    {
      "epoch": 10.751937984496124,
      "grad_norm": 0.0056764353066682816,
      "learning_rate": 3.924806201550388e-05,
      "loss": 0.0004,
      "step": 2774
    },
    {
      "epoch": 10.755813953488373,
      "grad_norm": 0.018321393057703972,
      "learning_rate": 3.924418604651163e-05,
      "loss": 0.0006,
      "step": 2775
    },
    {
      "epoch": 10.75968992248062,
      "grad_norm": 0.008307546377182007,
      "learning_rate": 3.924031007751938e-05,
      "loss": 0.0006,
      "step": 2776
    },
    {
      "epoch": 10.763565891472869,
      "grad_norm": 0.5862525701522827,
      "learning_rate": 3.923643410852713e-05,
      "loss": 0.0048,
      "step": 2777
    },
    {
      "epoch": 10.767441860465116,
      "grad_norm": 0.003665079129859805,
      "learning_rate": 3.923255813953489e-05,
      "loss": 0.0004,
      "step": 2778
    },
    {
      "epoch": 10.771317829457365,
      "grad_norm": 1.2686777114868164,
      "learning_rate": 3.9228682170542634e-05,
      "loss": 0.0257,
      "step": 2779
    },
    {
      "epoch": 10.775193798449612,
      "grad_norm": 0.010520205833017826,
      "learning_rate": 3.922480620155039e-05,
      "loss": 0.0007,
      "step": 2780
    },
    {
      "epoch": 10.779069767441861,
      "grad_norm": 0.0070669986307621,
      "learning_rate": 3.922093023255814e-05,
      "loss": 0.0004,
      "step": 2781
    },
    {
      "epoch": 10.782945736434108,
      "grad_norm": 5.777082443237305,
      "learning_rate": 3.92170542635659e-05,
      "loss": 0.387,
      "step": 2782
    },
    {
      "epoch": 10.786821705426357,
      "grad_norm": 16.542346954345703,
      "learning_rate": 3.921317829457364e-05,
      "loss": 0.6904,
      "step": 2783
    },
    {
      "epoch": 10.790697674418604,
      "grad_norm": 6.875450611114502,
      "learning_rate": 3.9209302325581396e-05,
      "loss": 0.1235,
      "step": 2784
    },
    {
      "epoch": 10.794573643410853,
      "grad_norm": 0.009050467982888222,
      "learning_rate": 3.920542635658915e-05,
      "loss": 0.0007,
      "step": 2785
    },
    {
      "epoch": 10.7984496124031,
      "grad_norm": 0.011042197234928608,
      "learning_rate": 3.92015503875969e-05,
      "loss": 0.0005,
      "step": 2786
    },
    {
      "epoch": 10.80232558139535,
      "grad_norm": 0.003917527385056019,
      "learning_rate": 3.919767441860465e-05,
      "loss": 0.0003,
      "step": 2787
    },
    {
      "epoch": 10.806201550387597,
      "grad_norm": 0.005879889242351055,
      "learning_rate": 3.9193798449612405e-05,
      "loss": 0.0004,
      "step": 2788
    },
    {
      "epoch": 10.810077519379846,
      "grad_norm": 8.919726371765137,
      "learning_rate": 3.918992248062016e-05,
      "loss": 0.0854,
      "step": 2789
    },
    {
      "epoch": 10.813953488372093,
      "grad_norm": 0.006214144639670849,
      "learning_rate": 3.918604651162791e-05,
      "loss": 0.0004,
      "step": 2790
    },
    {
      "epoch": 10.817829457364342,
      "grad_norm": 2.558061361312866,
      "learning_rate": 3.918217054263566e-05,
      "loss": 0.5123,
      "step": 2791
    },
    {
      "epoch": 10.821705426356589,
      "grad_norm": 0.28413283824920654,
      "learning_rate": 3.9178294573643415e-05,
      "loss": 0.0011,
      "step": 2792
    },
    {
      "epoch": 10.825581395348838,
      "grad_norm": 13.144060134887695,
      "learning_rate": 3.917441860465117e-05,
      "loss": 0.0786,
      "step": 2793
    },
    {
      "epoch": 10.829457364341085,
      "grad_norm": 3.5703582763671875,
      "learning_rate": 3.917054263565892e-05,
      "loss": 0.0553,
      "step": 2794
    },
    {
      "epoch": 10.833333333333334,
      "grad_norm": 0.005906582344323397,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 0.0004,
      "step": 2795
    },
    {
      "epoch": 10.837209302325581,
      "grad_norm": 0.008730947971343994,
      "learning_rate": 3.9162790697674425e-05,
      "loss": 0.0006,
      "step": 2796
    },
    {
      "epoch": 10.84108527131783,
      "grad_norm": 1.6943981647491455,
      "learning_rate": 3.915891472868217e-05,
      "loss": 0.0029,
      "step": 2797
    },
    {
      "epoch": 10.844961240310077,
      "grad_norm": 25.29318618774414,
      "learning_rate": 3.915503875968993e-05,
      "loss": 0.0141,
      "step": 2798
    },
    {
      "epoch": 10.848837209302326,
      "grad_norm": 5.37031888961792,
      "learning_rate": 3.9151162790697675e-05,
      "loss": 0.0402,
      "step": 2799
    },
    {
      "epoch": 10.852713178294573,
      "grad_norm": 0.009562632068991661,
      "learning_rate": 3.914728682170543e-05,
      "loss": 0.0004,
      "step": 2800
    },
    {
      "epoch": 10.856589147286822,
      "grad_norm": 0.006137666292488575,
      "learning_rate": 3.914341085271318e-05,
      "loss": 0.0005,
      "step": 2801
    },
    {
      "epoch": 10.86046511627907,
      "grad_norm": 0.009161999449133873,
      "learning_rate": 3.913953488372093e-05,
      "loss": 0.0005,
      "step": 2802
    },
    {
      "epoch": 10.864341085271318,
      "grad_norm": 0.01145117450505495,
      "learning_rate": 3.9135658914728685e-05,
      "loss": 0.0004,
      "step": 2803
    },
    {
      "epoch": 10.868217054263566,
      "grad_norm": 4.6120076179504395,
      "learning_rate": 3.913178294573643e-05,
      "loss": 0.002,
      "step": 2804
    },
    {
      "epoch": 10.872093023255815,
      "grad_norm": 0.11787156015634537,
      "learning_rate": 3.912790697674419e-05,
      "loss": 0.003,
      "step": 2805
    },
    {
      "epoch": 10.875968992248062,
      "grad_norm": 0.00913221389055252,
      "learning_rate": 3.9124031007751935e-05,
      "loss": 0.0005,
      "step": 2806
    },
    {
      "epoch": 10.87984496124031,
      "grad_norm": 0.005533130839467049,
      "learning_rate": 3.9120155038759695e-05,
      "loss": 0.0004,
      "step": 2807
    },
    {
      "epoch": 10.883720930232558,
      "grad_norm": 2.333383560180664,
      "learning_rate": 3.911627906976744e-05,
      "loss": 0.2679,
      "step": 2808
    },
    {
      "epoch": 10.887596899224807,
      "grad_norm": 0.007845929823815823,
      "learning_rate": 3.91124031007752e-05,
      "loss": 0.0005,
      "step": 2809
    },
    {
      "epoch": 10.891472868217054,
      "grad_norm": 66.79978942871094,
      "learning_rate": 3.9108527131782945e-05,
      "loss": 0.2705,
      "step": 2810
    },
    {
      "epoch": 10.895348837209303,
      "grad_norm": 0.008988725021481514,
      "learning_rate": 3.91046511627907e-05,
      "loss": 0.0005,
      "step": 2811
    },
    {
      "epoch": 10.89922480620155,
      "grad_norm": 0.008018485270440578,
      "learning_rate": 3.910077519379845e-05,
      "loss": 0.0005,
      "step": 2812
    },
    {
      "epoch": 10.9031007751938,
      "grad_norm": 16.47627830505371,
      "learning_rate": 3.90968992248062e-05,
      "loss": 0.2845,
      "step": 2813
    },
    {
      "epoch": 10.906976744186046,
      "grad_norm": 0.13317859172821045,
      "learning_rate": 3.9093023255813955e-05,
      "loss": 0.0055,
      "step": 2814
    },
    {
      "epoch": 10.910852713178295,
      "grad_norm": 1.4661097526550293,
      "learning_rate": 3.908914728682171e-05,
      "loss": 0.2605,
      "step": 2815
    },
    {
      "epoch": 10.914728682170542,
      "grad_norm": 0.03625112771987915,
      "learning_rate": 3.908527131782946e-05,
      "loss": 0.0018,
      "step": 2816
    },
    {
      "epoch": 10.918604651162791,
      "grad_norm": 0.03221503272652626,
      "learning_rate": 3.908139534883721e-05,
      "loss": 0.0018,
      "step": 2817
    },
    {
      "epoch": 10.922480620155039,
      "grad_norm": 0.07957984507083893,
      "learning_rate": 3.9077519379844964e-05,
      "loss": 0.0027,
      "step": 2818
    },
    {
      "epoch": 10.926356589147288,
      "grad_norm": 0.14634259045124054,
      "learning_rate": 3.907364341085272e-05,
      "loss": 0.0018,
      "step": 2819
    },
    {
      "epoch": 10.930232558139535,
      "grad_norm": 2.555234432220459,
      "learning_rate": 3.906976744186047e-05,
      "loss": 0.0091,
      "step": 2820
    },
    {
      "epoch": 10.934108527131784,
      "grad_norm": 0.054871946573257446,
      "learning_rate": 3.906589147286822e-05,
      "loss": 0.0012,
      "step": 2821
    },
    {
      "epoch": 10.937984496124031,
      "grad_norm": 2.6654911041259766,
      "learning_rate": 3.906201550387597e-05,
      "loss": 0.0935,
      "step": 2822
    },
    {
      "epoch": 10.94186046511628,
      "grad_norm": 0.07010510563850403,
      "learning_rate": 3.9058139534883727e-05,
      "loss": 0.0034,
      "step": 2823
    },
    {
      "epoch": 10.945736434108527,
      "grad_norm": 0.014081803150475025,
      "learning_rate": 3.905426356589147e-05,
      "loss": 0.0006,
      "step": 2824
    },
    {
      "epoch": 10.949612403100776,
      "grad_norm": 0.05850708484649658,
      "learning_rate": 3.905038759689923e-05,
      "loss": 0.001,
      "step": 2825
    },
    {
      "epoch": 10.953488372093023,
      "grad_norm": 0.010397600941359997,
      "learning_rate": 3.904651162790698e-05,
      "loss": 0.0005,
      "step": 2826
    },
    {
      "epoch": 10.957364341085272,
      "grad_norm": 20.62050437927246,
      "learning_rate": 3.904263565891473e-05,
      "loss": 0.5916,
      "step": 2827
    },
    {
      "epoch": 10.96124031007752,
      "grad_norm": 55.28083038330078,
      "learning_rate": 3.903875968992248e-05,
      "loss": 0.495,
      "step": 2828
    },
    {
      "epoch": 10.965116279069768,
      "grad_norm": 0.014141157269477844,
      "learning_rate": 3.9034883720930234e-05,
      "loss": 0.0006,
      "step": 2829
    },
    {
      "epoch": 10.968992248062015,
      "grad_norm": 15.832354545593262,
      "learning_rate": 3.903100775193799e-05,
      "loss": 0.6736,
      "step": 2830
    },
    {
      "epoch": 10.972868217054263,
      "grad_norm": 36.525604248046875,
      "learning_rate": 3.902713178294574e-05,
      "loss": 0.2961,
      "step": 2831
    },
    {
      "epoch": 10.976744186046512,
      "grad_norm": 0.4029116928577423,
      "learning_rate": 3.902325581395349e-05,
      "loss": 0.0088,
      "step": 2832
    },
    {
      "epoch": 10.98062015503876,
      "grad_norm": 0.05314408242702484,
      "learning_rate": 3.901937984496124e-05,
      "loss": 0.0008,
      "step": 2833
    },
    {
      "epoch": 10.984496124031008,
      "grad_norm": 0.589893639087677,
      "learning_rate": 3.9015503875968996e-05,
      "loss": 0.0044,
      "step": 2834
    },
    {
      "epoch": 10.988372093023255,
      "grad_norm": 0.012506590224802494,
      "learning_rate": 3.901162790697674e-05,
      "loss": 0.0005,
      "step": 2835
    },
    {
      "epoch": 10.992248062015504,
      "grad_norm": 37.35103225708008,
      "learning_rate": 3.90077519379845e-05,
      "loss": 0.658,
      "step": 2836
    },
    {
      "epoch": 10.996124031007753,
      "grad_norm": 0.0921604111790657,
      "learning_rate": 3.900387596899225e-05,
      "loss": 0.0024,
      "step": 2837
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.046541739255189896,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0022,
      "step": 2838
    },
    {
      "epoch": 11.003875968992247,
      "grad_norm": 4.020561218261719,
      "learning_rate": 3.899612403100775e-05,
      "loss": 0.2201,
      "step": 2839
    },
    {
      "epoch": 11.007751937984496,
      "grad_norm": 1.4268656969070435,
      "learning_rate": 3.8992248062015504e-05,
      "loss": 0.2139,
      "step": 2840
    },
    {
      "epoch": 11.011627906976743,
      "grad_norm": 1.0248615741729736,
      "learning_rate": 3.8988372093023257e-05,
      "loss": 0.2417,
      "step": 2841
    },
    {
      "epoch": 11.015503875968992,
      "grad_norm": 0.008321152999997139,
      "learning_rate": 3.898449612403101e-05,
      "loss": 0.0005,
      "step": 2842
    },
    {
      "epoch": 11.01937984496124,
      "grad_norm": 0.01577521115541458,
      "learning_rate": 3.898062015503876e-05,
      "loss": 0.0007,
      "step": 2843
    },
    {
      "epoch": 11.023255813953488,
      "grad_norm": 0.013899089768528938,
      "learning_rate": 3.8976744186046514e-05,
      "loss": 0.0006,
      "step": 2844
    },
    {
      "epoch": 11.027131782945736,
      "grad_norm": 1.5437244176864624,
      "learning_rate": 3.8972868217054266e-05,
      "loss": 0.115,
      "step": 2845
    },
    {
      "epoch": 11.031007751937985,
      "grad_norm": 162.57723999023438,
      "learning_rate": 3.896899224806202e-05,
      "loss": 0.2945,
      "step": 2846
    },
    {
      "epoch": 11.034883720930232,
      "grad_norm": 0.1053781658411026,
      "learning_rate": 3.896511627906977e-05,
      "loss": 0.0026,
      "step": 2847
    },
    {
      "epoch": 11.03875968992248,
      "grad_norm": 0.202859029173851,
      "learning_rate": 3.8961240310077524e-05,
      "loss": 0.0073,
      "step": 2848
    },
    {
      "epoch": 11.042635658914728,
      "grad_norm": 1.130731463432312,
      "learning_rate": 3.8957364341085276e-05,
      "loss": 0.0211,
      "step": 2849
    },
    {
      "epoch": 11.046511627906977,
      "grad_norm": 0.6374572515487671,
      "learning_rate": 3.895348837209303e-05,
      "loss": 0.0091,
      "step": 2850
    },
    {
      "epoch": 11.050387596899224,
      "grad_norm": 0.11776868253946304,
      "learning_rate": 3.8949612403100774e-05,
      "loss": 0.0011,
      "step": 2851
    },
    {
      "epoch": 11.054263565891473,
      "grad_norm": 4.067689418792725,
      "learning_rate": 3.8945736434108526e-05,
      "loss": 0.6582,
      "step": 2852
    },
    {
      "epoch": 11.05813953488372,
      "grad_norm": 0.1324453502893448,
      "learning_rate": 3.894186046511628e-05,
      "loss": 0.002,
      "step": 2853
    },
    {
      "epoch": 11.062015503875969,
      "grad_norm": 0.14208830893039703,
      "learning_rate": 3.893798449612403e-05,
      "loss": 0.0038,
      "step": 2854
    },
    {
      "epoch": 11.065891472868216,
      "grad_norm": 0.031192293390631676,
      "learning_rate": 3.8934108527131784e-05,
      "loss": 0.0008,
      "step": 2855
    },
    {
      "epoch": 11.069767441860465,
      "grad_norm": 21.285551071166992,
      "learning_rate": 3.8930232558139536e-05,
      "loss": 0.2592,
      "step": 2856
    },
    {
      "epoch": 11.073643410852712,
      "grad_norm": 0.027622666209936142,
      "learning_rate": 3.892635658914729e-05,
      "loss": 0.0006,
      "step": 2857
    },
    {
      "epoch": 11.077519379844961,
      "grad_norm": 0.018652239814400673,
      "learning_rate": 3.892248062015504e-05,
      "loss": 0.0006,
      "step": 2858
    },
    {
      "epoch": 11.081395348837209,
      "grad_norm": 135.17288208007812,
      "learning_rate": 3.891860465116279e-05,
      "loss": 0.0963,
      "step": 2859
    },
    {
      "epoch": 11.085271317829458,
      "grad_norm": 3.9172768592834473,
      "learning_rate": 3.8914728682170546e-05,
      "loss": 0.0105,
      "step": 2860
    },
    {
      "epoch": 11.089147286821705,
      "grad_norm": 0.014396218582987785,
      "learning_rate": 3.89108527131783e-05,
      "loss": 0.0006,
      "step": 2861
    },
    {
      "epoch": 11.093023255813954,
      "grad_norm": 0.4923705756664276,
      "learning_rate": 3.8906976744186044e-05,
      "loss": 0.0071,
      "step": 2862
    },
    {
      "epoch": 11.0968992248062,
      "grad_norm": 0.1664954572916031,
      "learning_rate": 3.89031007751938e-05,
      "loss": 0.0013,
      "step": 2863
    },
    {
      "epoch": 11.10077519379845,
      "grad_norm": 0.005707411095499992,
      "learning_rate": 3.889922480620155e-05,
      "loss": 0.0004,
      "step": 2864
    },
    {
      "epoch": 11.104651162790697,
      "grad_norm": 6.0828351974487305,
      "learning_rate": 3.889534883720931e-05,
      "loss": 0.159,
      "step": 2865
    },
    {
      "epoch": 11.108527131782946,
      "grad_norm": 4.3944621086120605,
      "learning_rate": 3.8891472868217054e-05,
      "loss": 0.1828,
      "step": 2866
    },
    {
      "epoch": 11.112403100775193,
      "grad_norm": 0.3111974596977234,
      "learning_rate": 3.888759689922481e-05,
      "loss": 0.0125,
      "step": 2867
    },
    {
      "epoch": 11.116279069767442,
      "grad_norm": 0.08055625110864639,
      "learning_rate": 3.888372093023256e-05,
      "loss": 0.0036,
      "step": 2868
    },
    {
      "epoch": 11.12015503875969,
      "grad_norm": 4.986270904541016,
      "learning_rate": 3.887984496124031e-05,
      "loss": 0.7623,
      "step": 2869
    },
    {
      "epoch": 11.124031007751938,
      "grad_norm": 9.107908248901367,
      "learning_rate": 3.887596899224806e-05,
      "loss": 0.2165,
      "step": 2870
    },
    {
      "epoch": 11.127906976744185,
      "grad_norm": 4.4488677978515625,
      "learning_rate": 3.8872093023255816e-05,
      "loss": 0.0667,
      "step": 2871
    },
    {
      "epoch": 11.131782945736434,
      "grad_norm": 0.009356184862554073,
      "learning_rate": 3.886821705426357e-05,
      "loss": 0.0005,
      "step": 2872
    },
    {
      "epoch": 11.135658914728682,
      "grad_norm": 0.07174645364284515,
      "learning_rate": 3.886434108527132e-05,
      "loss": 0.0032,
      "step": 2873
    },
    {
      "epoch": 11.13953488372093,
      "grad_norm": 0.029711246490478516,
      "learning_rate": 3.886046511627907e-05,
      "loss": 0.0008,
      "step": 2874
    },
    {
      "epoch": 11.143410852713178,
      "grad_norm": 0.03855271264910698,
      "learning_rate": 3.8856589147286825e-05,
      "loss": 0.002,
      "step": 2875
    },
    {
      "epoch": 11.147286821705427,
      "grad_norm": 0.0030369083397090435,
      "learning_rate": 3.885271317829458e-05,
      "loss": 0.0003,
      "step": 2876
    },
    {
      "epoch": 11.151162790697674,
      "grad_norm": 35.2591667175293,
      "learning_rate": 3.884883720930233e-05,
      "loss": 0.1625,
      "step": 2877
    },
    {
      "epoch": 11.155038759689923,
      "grad_norm": 0.4906655251979828,
      "learning_rate": 3.884496124031008e-05,
      "loss": 0.0076,
      "step": 2878
    },
    {
      "epoch": 11.15891472868217,
      "grad_norm": 52.30552673339844,
      "learning_rate": 3.884108527131783e-05,
      "loss": 0.0452,
      "step": 2879
    },
    {
      "epoch": 11.162790697674419,
      "grad_norm": 6.452603816986084,
      "learning_rate": 3.883720930232558e-05,
      "loss": 0.0887,
      "step": 2880
    },
    {
      "epoch": 11.166666666666666,
      "grad_norm": 0.0055723111145198345,
      "learning_rate": 3.883333333333333e-05,
      "loss": 0.0005,
      "step": 2881
    },
    {
      "epoch": 11.170542635658915,
      "grad_norm": 9.708573341369629,
      "learning_rate": 3.8829457364341086e-05,
      "loss": 0.1533,
      "step": 2882
    },
    {
      "epoch": 11.174418604651162,
      "grad_norm": 0.00453147990629077,
      "learning_rate": 3.882558139534884e-05,
      "loss": 0.0004,
      "step": 2883
    },
    {
      "epoch": 11.178294573643411,
      "grad_norm": 0.013216786086559296,
      "learning_rate": 3.882170542635659e-05,
      "loss": 0.0006,
      "step": 2884
    },
    {
      "epoch": 11.182170542635658,
      "grad_norm": 0.00952330231666565,
      "learning_rate": 3.881782945736434e-05,
      "loss": 0.0006,
      "step": 2885
    },
    {
      "epoch": 11.186046511627907,
      "grad_norm": 0.005899857729673386,
      "learning_rate": 3.8813953488372095e-05,
      "loss": 0.0004,
      "step": 2886
    },
    {
      "epoch": 11.189922480620154,
      "grad_norm": 0.007754971273243427,
      "learning_rate": 3.881007751937985e-05,
      "loss": 0.0004,
      "step": 2887
    },
    {
      "epoch": 11.193798449612403,
      "grad_norm": 0.028846625238656998,
      "learning_rate": 3.88062015503876e-05,
      "loss": 0.0016,
      "step": 2888
    },
    {
      "epoch": 11.19767441860465,
      "grad_norm": 0.006024232599884272,
      "learning_rate": 3.8802325581395346e-05,
      "loss": 0.0004,
      "step": 2889
    },
    {
      "epoch": 11.2015503875969,
      "grad_norm": 0.005757782142609358,
      "learning_rate": 3.8798449612403105e-05,
      "loss": 0.0004,
      "step": 2890
    },
    {
      "epoch": 11.205426356589147,
      "grad_norm": 0.007322059944272041,
      "learning_rate": 3.879457364341085e-05,
      "loss": 0.0006,
      "step": 2891
    },
    {
      "epoch": 11.209302325581396,
      "grad_norm": 0.05105777084827423,
      "learning_rate": 3.879069767441861e-05,
      "loss": 0.0015,
      "step": 2892
    },
    {
      "epoch": 11.213178294573643,
      "grad_norm": 0.0039900424890220165,
      "learning_rate": 3.8786821705426355e-05,
      "loss": 0.0004,
      "step": 2893
    },
    {
      "epoch": 11.217054263565892,
      "grad_norm": 0.00817472580820322,
      "learning_rate": 3.8782945736434115e-05,
      "loss": 0.0005,
      "step": 2894
    },
    {
      "epoch": 11.220930232558139,
      "grad_norm": 0.0032819437328726053,
      "learning_rate": 3.877906976744186e-05,
      "loss": 0.0003,
      "step": 2895
    },
    {
      "epoch": 11.224806201550388,
      "grad_norm": 0.009608667343854904,
      "learning_rate": 3.877519379844962e-05,
      "loss": 0.0006,
      "step": 2896
    },
    {
      "epoch": 11.228682170542635,
      "grad_norm": 9.118528366088867,
      "learning_rate": 3.8771317829457365e-05,
      "loss": 0.4725,
      "step": 2897
    },
    {
      "epoch": 11.232558139534884,
      "grad_norm": 0.4566085934638977,
      "learning_rate": 3.876744186046512e-05,
      "loss": 0.0141,
      "step": 2898
    },
    {
      "epoch": 11.236434108527131,
      "grad_norm": 0.012179478071630001,
      "learning_rate": 3.876356589147287e-05,
      "loss": 0.0005,
      "step": 2899
    },
    {
      "epoch": 11.24031007751938,
      "grad_norm": 0.020344292744994164,
      "learning_rate": 3.875968992248062e-05,
      "loss": 0.0013,
      "step": 2900
    },
    {
      "epoch": 11.244186046511627,
      "grad_norm": 0.022358598187565804,
      "learning_rate": 3.8755813953488375e-05,
      "loss": 0.0012,
      "step": 2901
    },
    {
      "epoch": 11.248062015503876,
      "grad_norm": 0.004915740340948105,
      "learning_rate": 3.875193798449613e-05,
      "loss": 0.0004,
      "step": 2902
    },
    {
      "epoch": 11.251937984496124,
      "grad_norm": 0.15990769863128662,
      "learning_rate": 3.874806201550388e-05,
      "loss": 0.0017,
      "step": 2903
    },
    {
      "epoch": 11.255813953488373,
      "grad_norm": 0.004031629301607609,
      "learning_rate": 3.874418604651163e-05,
      "loss": 0.0004,
      "step": 2904
    },
    {
      "epoch": 11.25968992248062,
      "grad_norm": 0.01972454972565174,
      "learning_rate": 3.8740310077519384e-05,
      "loss": 0.0006,
      "step": 2905
    },
    {
      "epoch": 11.263565891472869,
      "grad_norm": 0.9779803156852722,
      "learning_rate": 3.873643410852713e-05,
      "loss": 0.099,
      "step": 2906
    },
    {
      "epoch": 11.267441860465116,
      "grad_norm": 0.0075011528097093105,
      "learning_rate": 3.873255813953488e-05,
      "loss": 0.0005,
      "step": 2907
    },
    {
      "epoch": 11.271317829457365,
      "grad_norm": 0.006043184082955122,
      "learning_rate": 3.8728682170542635e-05,
      "loss": 0.0004,
      "step": 2908
    },
    {
      "epoch": 11.275193798449612,
      "grad_norm": 0.00458343792706728,
      "learning_rate": 3.872480620155039e-05,
      "loss": 0.0004,
      "step": 2909
    },
    {
      "epoch": 11.279069767441861,
      "grad_norm": 0.0224424097687006,
      "learning_rate": 3.872093023255814e-05,
      "loss": 0.0008,
      "step": 2910
    },
    {
      "epoch": 11.282945736434108,
      "grad_norm": 0.009214029647409916,
      "learning_rate": 3.871705426356589e-05,
      "loss": 0.0005,
      "step": 2911
    },
    {
      "epoch": 11.286821705426357,
      "grad_norm": 0.02682815119624138,
      "learning_rate": 3.8713178294573645e-05,
      "loss": 0.0005,
      "step": 2912
    },
    {
      "epoch": 11.290697674418604,
      "grad_norm": 0.9408054947853088,
      "learning_rate": 3.87093023255814e-05,
      "loss": 0.0095,
      "step": 2913
    },
    {
      "epoch": 11.294573643410853,
      "grad_norm": 0.008084309287369251,
      "learning_rate": 3.870542635658915e-05,
      "loss": 0.0005,
      "step": 2914
    },
    {
      "epoch": 11.2984496124031,
      "grad_norm": 0.004670226015150547,
      "learning_rate": 3.87015503875969e-05,
      "loss": 0.0004,
      "step": 2915
    },
    {
      "epoch": 11.30232558139535,
      "grad_norm": 10.44019603729248,
      "learning_rate": 3.8697674418604654e-05,
      "loss": 0.3261,
      "step": 2916
    },
    {
      "epoch": 11.306201550387597,
      "grad_norm": 0.004379187244921923,
      "learning_rate": 3.869379844961241e-05,
      "loss": 0.0004,
      "step": 2917
    },
    {
      "epoch": 11.310077519379846,
      "grad_norm": 2.8328194618225098,
      "learning_rate": 3.868992248062015e-05,
      "loss": 0.1849,
      "step": 2918
    },
    {
      "epoch": 11.313953488372093,
      "grad_norm": 0.006486351136118174,
      "learning_rate": 3.868604651162791e-05,
      "loss": 0.0004,
      "step": 2919
    },
    {
      "epoch": 11.317829457364342,
      "grad_norm": 0.019945846870541573,
      "learning_rate": 3.868217054263566e-05,
      "loss": 0.0006,
      "step": 2920
    },
    {
      "epoch": 11.321705426356589,
      "grad_norm": 0.003514876589179039,
      "learning_rate": 3.8678294573643416e-05,
      "loss": 0.0004,
      "step": 2921
    },
    {
      "epoch": 11.325581395348838,
      "grad_norm": 1.9022451639175415,
      "learning_rate": 3.867441860465116e-05,
      "loss": 0.1436,
      "step": 2922
    },
    {
      "epoch": 11.329457364341085,
      "grad_norm": 19.15462303161621,
      "learning_rate": 3.867054263565892e-05,
      "loss": 0.0144,
      "step": 2923
    },
    {
      "epoch": 11.333333333333334,
      "grad_norm": 0.0044580670073628426,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.0004,
      "step": 2924
    },
    {
      "epoch": 11.337209302325581,
      "grad_norm": 0.004949895665049553,
      "learning_rate": 3.866279069767442e-05,
      "loss": 0.0003,
      "step": 2925
    },
    {
      "epoch": 11.34108527131783,
      "grad_norm": 5.417495250701904,
      "learning_rate": 3.865891472868217e-05,
      "loss": 0.3948,
      "step": 2926
    },
    {
      "epoch": 11.344961240310077,
      "grad_norm": 0.006745288614183664,
      "learning_rate": 3.8655038759689924e-05,
      "loss": 0.0005,
      "step": 2927
    },
    {
      "epoch": 11.348837209302326,
      "grad_norm": 0.0657723918557167,
      "learning_rate": 3.8651162790697677e-05,
      "loss": 0.0004,
      "step": 2928
    },
    {
      "epoch": 11.352713178294573,
      "grad_norm": 21.568391799926758,
      "learning_rate": 3.864728682170543e-05,
      "loss": 0.6687,
      "step": 2929
    },
    {
      "epoch": 11.356589147286822,
      "grad_norm": 0.009067499078810215,
      "learning_rate": 3.864341085271318e-05,
      "loss": 0.0005,
      "step": 2930
    },
    {
      "epoch": 11.36046511627907,
      "grad_norm": 0.09155591577291489,
      "learning_rate": 3.8639534883720934e-05,
      "loss": 0.0009,
      "step": 2931
    },
    {
      "epoch": 11.364341085271318,
      "grad_norm": 0.022929256781935692,
      "learning_rate": 3.8635658914728686e-05,
      "loss": 0.0006,
      "step": 2932
    },
    {
      "epoch": 11.368217054263566,
      "grad_norm": 0.006669028662145138,
      "learning_rate": 3.863178294573643e-05,
      "loss": 0.0004,
      "step": 2933
    },
    {
      "epoch": 11.372093023255815,
      "grad_norm": 7.865344524383545,
      "learning_rate": 3.862790697674419e-05,
      "loss": 0.074,
      "step": 2934
    },
    {
      "epoch": 11.375968992248062,
      "grad_norm": 0.008178338408470154,
      "learning_rate": 3.862403100775194e-05,
      "loss": 0.0004,
      "step": 2935
    },
    {
      "epoch": 11.37984496124031,
      "grad_norm": 0.14601273834705353,
      "learning_rate": 3.862015503875969e-05,
      "loss": 0.0039,
      "step": 2936
    },
    {
      "epoch": 11.383720930232558,
      "grad_norm": 2.350076913833618,
      "learning_rate": 3.861627906976744e-05,
      "loss": 0.096,
      "step": 2937
    },
    {
      "epoch": 11.387596899224807,
      "grad_norm": 11.520697593688965,
      "learning_rate": 3.8612403100775194e-05,
      "loss": 0.0041,
      "step": 2938
    },
    {
      "epoch": 11.391472868217054,
      "grad_norm": 0.010653160512447357,
      "learning_rate": 3.8608527131782946e-05,
      "loss": 0.0008,
      "step": 2939
    },
    {
      "epoch": 11.395348837209303,
      "grad_norm": 5.848133563995361,
      "learning_rate": 3.86046511627907e-05,
      "loss": 0.6054,
      "step": 2940
    },
    {
      "epoch": 11.39922480620155,
      "grad_norm": 0.02578621730208397,
      "learning_rate": 3.860077519379845e-05,
      "loss": 0.0006,
      "step": 2941
    },
    {
      "epoch": 11.4031007751938,
      "grad_norm": 0.037246014922857285,
      "learning_rate": 3.8596899224806204e-05,
      "loss": 0.0008,
      "step": 2942
    },
    {
      "epoch": 11.406976744186046,
      "grad_norm": 3.3200109004974365,
      "learning_rate": 3.8593023255813956e-05,
      "loss": 0.2195,
      "step": 2943
    },
    {
      "epoch": 11.410852713178295,
      "grad_norm": 0.010516313835978508,
      "learning_rate": 3.858914728682171e-05,
      "loss": 0.0005,
      "step": 2944
    },
    {
      "epoch": 11.414728682170542,
      "grad_norm": 2.1105780601501465,
      "learning_rate": 3.858527131782946e-05,
      "loss": 0.0912,
      "step": 2945
    },
    {
      "epoch": 11.418604651162791,
      "grad_norm": 0.006844224873930216,
      "learning_rate": 3.8581395348837213e-05,
      "loss": 0.0005,
      "step": 2946
    },
    {
      "epoch": 11.422480620155039,
      "grad_norm": 0.07168411463499069,
      "learning_rate": 3.857751937984496e-05,
      "loss": 0.0007,
      "step": 2947
    },
    {
      "epoch": 11.426356589147288,
      "grad_norm": 1.3189308643341064,
      "learning_rate": 3.857364341085272e-05,
      "loss": 0.0279,
      "step": 2948
    },
    {
      "epoch": 11.430232558139535,
      "grad_norm": 0.007341380231082439,
      "learning_rate": 3.8569767441860464e-05,
      "loss": 0.0005,
      "step": 2949
    },
    {
      "epoch": 11.434108527131784,
      "grad_norm": 0.028636867180466652,
      "learning_rate": 3.856589147286822e-05,
      "loss": 0.0008,
      "step": 2950
    },
    {
      "epoch": 11.437984496124031,
      "grad_norm": 0.3881906270980835,
      "learning_rate": 3.856201550387597e-05,
      "loss": 0.0154,
      "step": 2951
    },
    {
      "epoch": 11.44186046511628,
      "grad_norm": 0.019912129268050194,
      "learning_rate": 3.855813953488373e-05,
      "loss": 0.0008,
      "step": 2952
    },
    {
      "epoch": 11.445736434108527,
      "grad_norm": 0.050317104905843735,
      "learning_rate": 3.8554263565891474e-05,
      "loss": 0.0023,
      "step": 2953
    },
    {
      "epoch": 11.449612403100776,
      "grad_norm": 24.759021759033203,
      "learning_rate": 3.8550387596899226e-05,
      "loss": 0.061,
      "step": 2954
    },
    {
      "epoch": 11.453488372093023,
      "grad_norm": 0.024547932669520378,
      "learning_rate": 3.854651162790698e-05,
      "loss": 0.0009,
      "step": 2955
    },
    {
      "epoch": 11.457364341085272,
      "grad_norm": 0.01681259460747242,
      "learning_rate": 3.854263565891473e-05,
      "loss": 0.0007,
      "step": 2956
    },
    {
      "epoch": 11.46124031007752,
      "grad_norm": 0.020682526752352715,
      "learning_rate": 3.853875968992248e-05,
      "loss": 0.0008,
      "step": 2957
    },
    {
      "epoch": 11.465116279069768,
      "grad_norm": 2.1140544414520264,
      "learning_rate": 3.8534883720930236e-05,
      "loss": 0.2512,
      "step": 2958
    },
    {
      "epoch": 11.468992248062015,
      "grad_norm": 0.037934236228466034,
      "learning_rate": 3.853100775193799e-05,
      "loss": 0.0007,
      "step": 2959
    },
    {
      "epoch": 11.472868217054264,
      "grad_norm": 2.4884979724884033,
      "learning_rate": 3.8527131782945734e-05,
      "loss": 0.0125,
      "step": 2960
    },
    {
      "epoch": 11.476744186046512,
      "grad_norm": 0.012625271454453468,
      "learning_rate": 3.852325581395349e-05,
      "loss": 0.0006,
      "step": 2961
    },
    {
      "epoch": 11.48062015503876,
      "grad_norm": 0.012951758690178394,
      "learning_rate": 3.851937984496124e-05,
      "loss": 0.0008,
      "step": 2962
    },
    {
      "epoch": 11.484496124031008,
      "grad_norm": 0.08980759978294373,
      "learning_rate": 3.8515503875969e-05,
      "loss": 0.0044,
      "step": 2963
    },
    {
      "epoch": 11.488372093023255,
      "grad_norm": 0.023885414004325867,
      "learning_rate": 3.8511627906976743e-05,
      "loss": 0.0007,
      "step": 2964
    },
    {
      "epoch": 11.492248062015504,
      "grad_norm": 0.01706061325967312,
      "learning_rate": 3.8507751937984496e-05,
      "loss": 0.0011,
      "step": 2965
    },
    {
      "epoch": 11.496124031007753,
      "grad_norm": 8.898860931396484,
      "learning_rate": 3.850387596899225e-05,
      "loss": 0.5946,
      "step": 2966
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.03541336581110954,
      "learning_rate": 3.85e-05,
      "loss": 0.0008,
      "step": 2967
    },
    {
      "epoch": 11.503875968992247,
      "grad_norm": 0.019050000235438347,
      "learning_rate": 3.849612403100775e-05,
      "loss": 0.0007,
      "step": 2968
    },
    {
      "epoch": 11.507751937984496,
      "grad_norm": 0.362885981798172,
      "learning_rate": 3.8492248062015506e-05,
      "loss": 0.0008,
      "step": 2969
    },
    {
      "epoch": 11.511627906976745,
      "grad_norm": 2.1579155921936035,
      "learning_rate": 3.848837209302326e-05,
      "loss": 0.1272,
      "step": 2970
    },
    {
      "epoch": 11.515503875968992,
      "grad_norm": 0.010178654454648495,
      "learning_rate": 3.848449612403101e-05,
      "loss": 0.0006,
      "step": 2971
    },
    {
      "epoch": 11.51937984496124,
      "grad_norm": 40.741912841796875,
      "learning_rate": 3.848062015503876e-05,
      "loss": 0.8748,
      "step": 2972
    },
    {
      "epoch": 11.523255813953488,
      "grad_norm": 0.01808450184762478,
      "learning_rate": 3.8476744186046515e-05,
      "loss": 0.0004,
      "step": 2973
    },
    {
      "epoch": 11.527131782945737,
      "grad_norm": 0.06378022581338882,
      "learning_rate": 3.847286821705426e-05,
      "loss": 0.0007,
      "step": 2974
    },
    {
      "epoch": 11.531007751937985,
      "grad_norm": 0.1377212107181549,
      "learning_rate": 3.846899224806202e-05,
      "loss": 0.0045,
      "step": 2975
    },
    {
      "epoch": 11.534883720930232,
      "grad_norm": 0.08607697486877441,
      "learning_rate": 3.8465116279069766e-05,
      "loss": 0.0045,
      "step": 2976
    },
    {
      "epoch": 11.53875968992248,
      "grad_norm": 0.011141665279865265,
      "learning_rate": 3.8461240310077525e-05,
      "loss": 0.0005,
      "step": 2977
    },
    {
      "epoch": 11.542635658914728,
      "grad_norm": 5.398012161254883,
      "learning_rate": 3.845736434108527e-05,
      "loss": 0.0035,
      "step": 2978
    },
    {
      "epoch": 11.546511627906977,
      "grad_norm": 0.005237166304141283,
      "learning_rate": 3.845348837209303e-05,
      "loss": 0.0004,
      "step": 2979
    },
    {
      "epoch": 11.550387596899224,
      "grad_norm": 0.029766136780381203,
      "learning_rate": 3.8449612403100775e-05,
      "loss": 0.0008,
      "step": 2980
    },
    {
      "epoch": 11.554263565891473,
      "grad_norm": 1.1109784841537476,
      "learning_rate": 3.8445736434108535e-05,
      "loss": 0.1063,
      "step": 2981
    },
    {
      "epoch": 11.55813953488372,
      "grad_norm": 0.31613418459892273,
      "learning_rate": 3.844186046511628e-05,
      "loss": 0.0007,
      "step": 2982
    },
    {
      "epoch": 11.562015503875969,
      "grad_norm": 0.0047982060350477695,
      "learning_rate": 3.843798449612403e-05,
      "loss": 0.0003,
      "step": 2983
    },
    {
      "epoch": 11.565891472868216,
      "grad_norm": 1.3304704427719116,
      "learning_rate": 3.8434108527131785e-05,
      "loss": 0.2535,
      "step": 2984
    },
    {
      "epoch": 11.569767441860465,
      "grad_norm": 0.005959640257060528,
      "learning_rate": 3.843023255813954e-05,
      "loss": 0.0005,
      "step": 2985
    },
    {
      "epoch": 11.573643410852712,
      "grad_norm": 0.02975921705365181,
      "learning_rate": 3.842635658914729e-05,
      "loss": 0.0013,
      "step": 2986
    },
    {
      "epoch": 11.577519379844961,
      "grad_norm": 0.1383276879787445,
      "learning_rate": 3.8422480620155036e-05,
      "loss": 0.0074,
      "step": 2987
    },
    {
      "epoch": 11.581395348837209,
      "grad_norm": 0.01393163949251175,
      "learning_rate": 3.8418604651162795e-05,
      "loss": 0.0006,
      "step": 2988
    },
    {
      "epoch": 11.585271317829458,
      "grad_norm": 5.461515426635742,
      "learning_rate": 3.841472868217054e-05,
      "loss": 0.0077,
      "step": 2989
    },
    {
      "epoch": 11.589147286821705,
      "grad_norm": 0.004966794978827238,
      "learning_rate": 3.84108527131783e-05,
      "loss": 0.0004,
      "step": 2990
    },
    {
      "epoch": 11.593023255813954,
      "grad_norm": 0.09220006316900253,
      "learning_rate": 3.8406976744186045e-05,
      "loss": 0.0007,
      "step": 2991
    },
    {
      "epoch": 11.5968992248062,
      "grad_norm": 14.671512603759766,
      "learning_rate": 3.84031007751938e-05,
      "loss": 0.1248,
      "step": 2992
    },
    {
      "epoch": 11.60077519379845,
      "grad_norm": 0.004681294318288565,
      "learning_rate": 3.839922480620155e-05,
      "loss": 0.0004,
      "step": 2993
    },
    {
      "epoch": 11.604651162790697,
      "grad_norm": 11.647906303405762,
      "learning_rate": 3.83953488372093e-05,
      "loss": 0.2691,
      "step": 2994
    },
    {
      "epoch": 11.608527131782946,
      "grad_norm": 0.040877122431993484,
      "learning_rate": 3.8391472868217055e-05,
      "loss": 0.0006,
      "step": 2995
    },
    {
      "epoch": 11.612403100775193,
      "grad_norm": 0.7224862575531006,
      "learning_rate": 3.838759689922481e-05,
      "loss": 0.0726,
      "step": 2996
    },
    {
      "epoch": 11.616279069767442,
      "grad_norm": 0.15444210171699524,
      "learning_rate": 3.838372093023256e-05,
      "loss": 0.008,
      "step": 2997
    },
    {
      "epoch": 11.62015503875969,
      "grad_norm": 0.03316468745470047,
      "learning_rate": 3.837984496124031e-05,
      "loss": 0.0008,
      "step": 2998
    },
    {
      "epoch": 11.624031007751938,
      "grad_norm": 0.006099021062254906,
      "learning_rate": 3.8375968992248065e-05,
      "loss": 0.0005,
      "step": 2999
    },
    {
      "epoch": 11.627906976744185,
      "grad_norm": 0.03791099786758423,
      "learning_rate": 3.837209302325582e-05,
      "loss": 0.0013,
      "step": 3000
    },
    {
      "epoch": 11.631782945736434,
      "grad_norm": 0.009595264680683613,
      "learning_rate": 3.836821705426357e-05,
      "loss": 0.0005,
      "step": 3001
    },
    {
      "epoch": 11.635658914728682,
      "grad_norm": 0.006534471642225981,
      "learning_rate": 3.836434108527132e-05,
      "loss": 0.0005,
      "step": 3002
    },
    {
      "epoch": 11.63953488372093,
      "grad_norm": 0.06768274307250977,
      "learning_rate": 3.836046511627907e-05,
      "loss": 0.0011,
      "step": 3003
    },
    {
      "epoch": 11.643410852713178,
      "grad_norm": 0.008961633779108524,
      "learning_rate": 3.835658914728683e-05,
      "loss": 0.0005,
      "step": 3004
    },
    {
      "epoch": 11.647286821705427,
      "grad_norm": 0.7209216952323914,
      "learning_rate": 3.835271317829457e-05,
      "loss": 0.0143,
      "step": 3005
    },
    {
      "epoch": 11.651162790697674,
      "grad_norm": 13.093568801879883,
      "learning_rate": 3.834883720930233e-05,
      "loss": 0.3856,
      "step": 3006
    },
    {
      "epoch": 11.655038759689923,
      "grad_norm": 0.55748450756073,
      "learning_rate": 3.834496124031008e-05,
      "loss": 0.0057,
      "step": 3007
    },
    {
      "epoch": 11.65891472868217,
      "grad_norm": 0.0981559306383133,
      "learning_rate": 3.8341085271317836e-05,
      "loss": 0.0042,
      "step": 3008
    },
    {
      "epoch": 11.662790697674419,
      "grad_norm": 0.016297785565257072,
      "learning_rate": 3.833720930232558e-05,
      "loss": 0.0011,
      "step": 3009
    },
    {
      "epoch": 11.666666666666666,
      "grad_norm": 0.006925245746970177,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.0005,
      "step": 3010
    },
    {
      "epoch": 11.670542635658915,
      "grad_norm": 0.012343536131083965,
      "learning_rate": 3.832945736434109e-05,
      "loss": 0.0008,
      "step": 3011
    },
    {
      "epoch": 11.674418604651162,
      "grad_norm": 0.01748233288526535,
      "learning_rate": 3.832558139534884e-05,
      "loss": 0.001,
      "step": 3012
    },
    {
      "epoch": 11.678294573643411,
      "grad_norm": 0.059457145631313324,
      "learning_rate": 3.832170542635659e-05,
      "loss": 0.0024,
      "step": 3013
    },
    {
      "epoch": 11.682170542635658,
      "grad_norm": 0.17392560839653015,
      "learning_rate": 3.831782945736434e-05,
      "loss": 0.0063,
      "step": 3014
    },
    {
      "epoch": 11.686046511627907,
      "grad_norm": 0.005215246696025133,
      "learning_rate": 3.8313953488372097e-05,
      "loss": 0.0004,
      "step": 3015
    },
    {
      "epoch": 11.689922480620154,
      "grad_norm": 0.004692975431680679,
      "learning_rate": 3.831007751937984e-05,
      "loss": 0.0004,
      "step": 3016
    },
    {
      "epoch": 11.693798449612403,
      "grad_norm": 0.006730309687554836,
      "learning_rate": 3.83062015503876e-05,
      "loss": 0.0004,
      "step": 3017
    },
    {
      "epoch": 11.69767441860465,
      "grad_norm": 0.00923170056194067,
      "learning_rate": 3.830232558139535e-05,
      "loss": 0.0005,
      "step": 3018
    },
    {
      "epoch": 11.7015503875969,
      "grad_norm": 56.30181121826172,
      "learning_rate": 3.8298449612403106e-05,
      "loss": 0.0168,
      "step": 3019
    },
    {
      "epoch": 11.705426356589147,
      "grad_norm": 25.258665084838867,
      "learning_rate": 3.829457364341085e-05,
      "loss": 0.0839,
      "step": 3020
    },
    {
      "epoch": 11.709302325581396,
      "grad_norm": 30.68684196472168,
      "learning_rate": 3.8290697674418604e-05,
      "loss": 0.1394,
      "step": 3021
    },
    {
      "epoch": 11.713178294573643,
      "grad_norm": 0.004179769195616245,
      "learning_rate": 3.828682170542636e-05,
      "loss": 0.0003,
      "step": 3022
    },
    {
      "epoch": 11.717054263565892,
      "grad_norm": 0.003445085370913148,
      "learning_rate": 3.828294573643411e-05,
      "loss": 0.0003,
      "step": 3023
    },
    {
      "epoch": 11.720930232558139,
      "grad_norm": 0.027947815135121346,
      "learning_rate": 3.827906976744186e-05,
      "loss": 0.0005,
      "step": 3024
    },
    {
      "epoch": 11.724806201550388,
      "grad_norm": 0.05579531565308571,
      "learning_rate": 3.8275193798449614e-05,
      "loss": 0.0015,
      "step": 3025
    },
    {
      "epoch": 11.728682170542635,
      "grad_norm": 0.0035995300859212875,
      "learning_rate": 3.8271317829457366e-05,
      "loss": 0.0004,
      "step": 3026
    },
    {
      "epoch": 11.732558139534884,
      "grad_norm": 0.003965560346841812,
      "learning_rate": 3.826744186046512e-05,
      "loss": 0.0004,
      "step": 3027
    },
    {
      "epoch": 11.736434108527131,
      "grad_norm": 0.002878765109926462,
      "learning_rate": 3.826356589147287e-05,
      "loss": 0.0003,
      "step": 3028
    },
    {
      "epoch": 11.74031007751938,
      "grad_norm": 0.002795414999127388,
      "learning_rate": 3.8259689922480624e-05,
      "loss": 0.0003,
      "step": 3029
    },
    {
      "epoch": 11.744186046511627,
      "grad_norm": 26.048246383666992,
      "learning_rate": 3.8255813953488376e-05,
      "loss": 0.1973,
      "step": 3030
    },
    {
      "epoch": 11.748062015503876,
      "grad_norm": 0.06397677212953568,
      "learning_rate": 3.825193798449613e-05,
      "loss": 0.0005,
      "step": 3031
    },
    {
      "epoch": 11.751937984496124,
      "grad_norm": 0.006293721031397581,
      "learning_rate": 3.8248062015503874e-05,
      "loss": 0.0003,
      "step": 3032
    },
    {
      "epoch": 11.755813953488373,
      "grad_norm": 2.6080162525177,
      "learning_rate": 3.8244186046511633e-05,
      "loss": 0.1949,
      "step": 3033
    },
    {
      "epoch": 11.75968992248062,
      "grad_norm": 0.017367525026202202,
      "learning_rate": 3.824031007751938e-05,
      "loss": 0.001,
      "step": 3034
    },
    {
      "epoch": 11.763565891472869,
      "grad_norm": 0.2761784493923187,
      "learning_rate": 3.823643410852714e-05,
      "loss": 0.0012,
      "step": 3035
    },
    {
      "epoch": 11.767441860465116,
      "grad_norm": 0.0035291535314172506,
      "learning_rate": 3.8232558139534884e-05,
      "loss": 0.0004,
      "step": 3036
    },
    {
      "epoch": 11.771317829457365,
      "grad_norm": 5.865115165710449,
      "learning_rate": 3.822868217054264e-05,
      "loss": 0.1542,
      "step": 3037
    },
    {
      "epoch": 11.775193798449612,
      "grad_norm": 1.8822883367538452,
      "learning_rate": 3.822480620155039e-05,
      "loss": 0.3293,
      "step": 3038
    },
    {
      "epoch": 11.779069767441861,
      "grad_norm": 0.003945561125874519,
      "learning_rate": 3.822093023255814e-05,
      "loss": 0.0003,
      "step": 3039
    },
    {
      "epoch": 11.782945736434108,
      "grad_norm": 0.028198953717947006,
      "learning_rate": 3.8217054263565894e-05,
      "loss": 0.0004,
      "step": 3040
    },
    {
      "epoch": 11.786821705426357,
      "grad_norm": 0.019691191613674164,
      "learning_rate": 3.8213178294573646e-05,
      "loss": 0.001,
      "step": 3041
    },
    {
      "epoch": 11.790697674418604,
      "grad_norm": 0.026328884065151215,
      "learning_rate": 3.82093023255814e-05,
      "loss": 0.0014,
      "step": 3042
    },
    {
      "epoch": 11.794573643410853,
      "grad_norm": 49.710166931152344,
      "learning_rate": 3.8205426356589144e-05,
      "loss": 0.1753,
      "step": 3043
    },
    {
      "epoch": 11.7984496124031,
      "grad_norm": 0.06562979519367218,
      "learning_rate": 3.82015503875969e-05,
      "loss": 0.0009,
      "step": 3044
    },
    {
      "epoch": 11.80232558139535,
      "grad_norm": 0.006551320198923349,
      "learning_rate": 3.819767441860465e-05,
      "loss": 0.0003,
      "step": 3045
    },
    {
      "epoch": 11.806201550387597,
      "grad_norm": 10.894635200500488,
      "learning_rate": 3.819379844961241e-05,
      "loss": 0.2294,
      "step": 3046
    },
    {
      "epoch": 11.810077519379846,
      "grad_norm": 0.49875408411026,
      "learning_rate": 3.8189922480620154e-05,
      "loss": 0.0022,
      "step": 3047
    },
    {
      "epoch": 11.813953488372093,
      "grad_norm": 4.4571733474731445,
      "learning_rate": 3.818604651162791e-05,
      "loss": 0.2922,
      "step": 3048
    },
    {
      "epoch": 11.817829457364342,
      "grad_norm": 0.005004325415939093,
      "learning_rate": 3.818217054263566e-05,
      "loss": 0.0004,
      "step": 3049
    },
    {
      "epoch": 11.821705426356589,
      "grad_norm": 0.015791431069374084,
      "learning_rate": 3.817829457364341e-05,
      "loss": 0.0006,
      "step": 3050
    },
    {
      "epoch": 11.825581395348838,
      "grad_norm": 12.9478178024292,
      "learning_rate": 3.8174418604651163e-05,
      "loss": 0.1147,
      "step": 3051
    },
    {
      "epoch": 11.829457364341085,
      "grad_norm": 17.26764488220215,
      "learning_rate": 3.8170542635658916e-05,
      "loss": 0.4171,
      "step": 3052
    },
    {
      "epoch": 11.833333333333334,
      "grad_norm": 0.013703279197216034,
      "learning_rate": 3.816666666666667e-05,
      "loss": 0.0006,
      "step": 3053
    },
    {
      "epoch": 11.837209302325581,
      "grad_norm": 0.37349116802215576,
      "learning_rate": 3.816279069767442e-05,
      "loss": 0.008,
      "step": 3054
    },
    {
      "epoch": 11.84108527131783,
      "grad_norm": 4.247384071350098,
      "learning_rate": 3.815891472868217e-05,
      "loss": 0.3701,
      "step": 3055
    },
    {
      "epoch": 11.844961240310077,
      "grad_norm": 0.010191689245402813,
      "learning_rate": 3.8155038759689926e-05,
      "loss": 0.0008,
      "step": 3056
    },
    {
      "epoch": 11.848837209302326,
      "grad_norm": 0.026148157194256783,
      "learning_rate": 3.815116279069768e-05,
      "loss": 0.0007,
      "step": 3057
    },
    {
      "epoch": 11.852713178294573,
      "grad_norm": 0.025078361853957176,
      "learning_rate": 3.814728682170543e-05,
      "loss": 0.0008,
      "step": 3058
    },
    {
      "epoch": 11.856589147286822,
      "grad_norm": 23.909038543701172,
      "learning_rate": 3.814341085271318e-05,
      "loss": 0.0167,
      "step": 3059
    },
    {
      "epoch": 11.86046511627907,
      "grad_norm": 7.831101417541504,
      "learning_rate": 3.8139534883720935e-05,
      "loss": 0.3208,
      "step": 3060
    },
    {
      "epoch": 11.864341085271318,
      "grad_norm": 73.75092315673828,
      "learning_rate": 3.813565891472868e-05,
      "loss": 1.1596,
      "step": 3061
    },
    {
      "epoch": 11.868217054263566,
      "grad_norm": 0.10259969532489777,
      "learning_rate": 3.813178294573644e-05,
      "loss": 0.0016,
      "step": 3062
    },
    {
      "epoch": 11.872093023255815,
      "grad_norm": 4.036108016967773,
      "learning_rate": 3.8127906976744186e-05,
      "loss": 0.4497,
      "step": 3063
    },
    {
      "epoch": 11.875968992248062,
      "grad_norm": 0.00682444404810667,
      "learning_rate": 3.8124031007751945e-05,
      "loss": 0.0004,
      "step": 3064
    },
    {
      "epoch": 11.87984496124031,
      "grad_norm": 0.006288537289947271,
      "learning_rate": 3.812015503875969e-05,
      "loss": 0.0004,
      "step": 3065
    },
    {
      "epoch": 11.883720930232558,
      "grad_norm": 0.005043522920459509,
      "learning_rate": 3.811627906976744e-05,
      "loss": 0.0003,
      "step": 3066
    },
    {
      "epoch": 11.887596899224807,
      "grad_norm": 0.004178202711045742,
      "learning_rate": 3.8112403100775195e-05,
      "loss": 0.0003,
      "step": 3067
    },
    {
      "epoch": 11.891472868217054,
      "grad_norm": 6.9576287269592285,
      "learning_rate": 3.810852713178295e-05,
      "loss": 0.2911,
      "step": 3068
    },
    {
      "epoch": 11.895348837209303,
      "grad_norm": 0.02265022136271,
      "learning_rate": 3.81046511627907e-05,
      "loss": 0.0007,
      "step": 3069
    },
    {
      "epoch": 11.89922480620155,
      "grad_norm": 0.019228627905249596,
      "learning_rate": 3.8100775193798446e-05,
      "loss": 0.0007,
      "step": 3070
    },
    {
      "epoch": 11.9031007751938,
      "grad_norm": 3.678867816925049,
      "learning_rate": 3.8096899224806205e-05,
      "loss": 0.1798,
      "step": 3071
    },
    {
      "epoch": 11.906976744186046,
      "grad_norm": 0.006359218154102564,
      "learning_rate": 3.809302325581395e-05,
      "loss": 0.0004,
      "step": 3072
    },
    {
      "epoch": 11.910852713178295,
      "grad_norm": 0.007988202385604382,
      "learning_rate": 3.808914728682171e-05,
      "loss": 0.0005,
      "step": 3073
    },
    {
      "epoch": 11.914728682170542,
      "grad_norm": 2.726374387741089,
      "learning_rate": 3.8085271317829456e-05,
      "loss": 0.2447,
      "step": 3074
    },
    {
      "epoch": 11.918604651162791,
      "grad_norm": 0.0030585085041821003,
      "learning_rate": 3.8081395348837215e-05,
      "loss": 0.0003,
      "step": 3075
    },
    {
      "epoch": 11.922480620155039,
      "grad_norm": 0.02085692808032036,
      "learning_rate": 3.807751937984496e-05,
      "loss": 0.0006,
      "step": 3076
    },
    {
      "epoch": 11.926356589147288,
      "grad_norm": 0.09977993369102478,
      "learning_rate": 3.807364341085271e-05,
      "loss": 0.0044,
      "step": 3077
    },
    {
      "epoch": 11.930232558139535,
      "grad_norm": 0.008340079337358475,
      "learning_rate": 3.8069767441860465e-05,
      "loss": 0.0004,
      "step": 3078
    },
    {
      "epoch": 11.934108527131784,
      "grad_norm": 0.011496082879602909,
      "learning_rate": 3.806589147286822e-05,
      "loss": 0.0005,
      "step": 3079
    },
    {
      "epoch": 11.937984496124031,
      "grad_norm": 0.9158884286880493,
      "learning_rate": 3.806201550387597e-05,
      "loss": 0.0283,
      "step": 3080
    },
    {
      "epoch": 11.94186046511628,
      "grad_norm": 0.1278827041387558,
      "learning_rate": 3.805813953488372e-05,
      "loss": 0.004,
      "step": 3081
    },
    {
      "epoch": 11.945736434108527,
      "grad_norm": 0.004264169838279486,
      "learning_rate": 3.8054263565891475e-05,
      "loss": 0.0003,
      "step": 3082
    },
    {
      "epoch": 11.949612403100776,
      "grad_norm": 54.6235237121582,
      "learning_rate": 3.805038759689923e-05,
      "loss": 0.2135,
      "step": 3083
    },
    {
      "epoch": 11.953488372093023,
      "grad_norm": 0.05530114844441414,
      "learning_rate": 3.804651162790698e-05,
      "loss": 0.0007,
      "step": 3084
    },
    {
      "epoch": 11.957364341085272,
      "grad_norm": 0.003916644491255283,
      "learning_rate": 3.804263565891473e-05,
      "loss": 0.0003,
      "step": 3085
    },
    {
      "epoch": 11.96124031007752,
      "grad_norm": 0.013554475270211697,
      "learning_rate": 3.8038759689922485e-05,
      "loss": 0.0007,
      "step": 3086
    },
    {
      "epoch": 11.965116279069768,
      "grad_norm": 0.014423954300582409,
      "learning_rate": 3.803488372093024e-05,
      "loss": 0.0009,
      "step": 3087
    },
    {
      "epoch": 11.968992248062015,
      "grad_norm": 4.733891487121582,
      "learning_rate": 3.803100775193798e-05,
      "loss": 0.0649,
      "step": 3088
    },
    {
      "epoch": 11.972868217054263,
      "grad_norm": 0.006576904095709324,
      "learning_rate": 3.802713178294574e-05,
      "loss": 0.0003,
      "step": 3089
    },
    {
      "epoch": 11.976744186046512,
      "grad_norm": 0.7033500075340271,
      "learning_rate": 3.802325581395349e-05,
      "loss": 0.0236,
      "step": 3090
    },
    {
      "epoch": 11.98062015503876,
      "grad_norm": 0.012909761629998684,
      "learning_rate": 3.801937984496125e-05,
      "loss": 0.0009,
      "step": 3091
    },
    {
      "epoch": 11.984496124031008,
      "grad_norm": 0.003311761887744069,
      "learning_rate": 3.801550387596899e-05,
      "loss": 0.0003,
      "step": 3092
    },
    {
      "epoch": 11.988372093023255,
      "grad_norm": 0.0022216590587049723,
      "learning_rate": 3.8011627906976745e-05,
      "loss": 0.0003,
      "step": 3093
    },
    {
      "epoch": 11.992248062015504,
      "grad_norm": 1.873141884803772,
      "learning_rate": 3.80077519379845e-05,
      "loss": 0.0735,
      "step": 3094
    },
    {
      "epoch": 11.996124031007753,
      "grad_norm": 0.008888470008969307,
      "learning_rate": 3.800387596899225e-05,
      "loss": 0.0005,
      "step": 3095
    },
    {
      "epoch": 12.0,
      "grad_norm": 80.73624420166016,
      "learning_rate": 3.8e-05,
      "loss": 0.1287,
      "step": 3096
    },
    {
      "epoch": 12.003875968992247,
      "grad_norm": 0.019413582980632782,
      "learning_rate": 3.7996124031007755e-05,
      "loss": 0.0006,
      "step": 3097
    },
    {
      "epoch": 12.007751937984496,
      "grad_norm": 0.0033480185084044933,
      "learning_rate": 3.799224806201551e-05,
      "loss": 0.0003,
      "step": 3098
    },
    {
      "epoch": 12.011627906976743,
      "grad_norm": 0.01227535866200924,
      "learning_rate": 3.798837209302325e-05,
      "loss": 0.0005,
      "step": 3099
    },
    {
      "epoch": 12.015503875968992,
      "grad_norm": 1.4591081142425537,
      "learning_rate": 3.798449612403101e-05,
      "loss": 0.0964,
      "step": 3100
    },
    {
      "epoch": 12.01937984496124,
      "grad_norm": 0.0034744564909487963,
      "learning_rate": 3.798062015503876e-05,
      "loss": 0.0003,
      "step": 3101
    },
    {
      "epoch": 12.023255813953488,
      "grad_norm": 0.0031648497097194195,
      "learning_rate": 3.797674418604652e-05,
      "loss": 0.0003,
      "step": 3102
    },
    {
      "epoch": 12.027131782945736,
      "grad_norm": 0.05389785021543503,
      "learning_rate": 3.797286821705426e-05,
      "loss": 0.0022,
      "step": 3103
    },
    {
      "epoch": 12.031007751937985,
      "grad_norm": 3.311819076538086,
      "learning_rate": 3.796899224806202e-05,
      "loss": 0.2612,
      "step": 3104
    },
    {
      "epoch": 12.034883720930232,
      "grad_norm": 0.1119811087846756,
      "learning_rate": 3.796511627906977e-05,
      "loss": 0.0021,
      "step": 3105
    },
    {
      "epoch": 12.03875968992248,
      "grad_norm": 1.1067614555358887,
      "learning_rate": 3.796124031007752e-05,
      "loss": 0.0133,
      "step": 3106
    },
    {
      "epoch": 12.042635658914728,
      "grad_norm": 0.013352618552744389,
      "learning_rate": 3.795736434108527e-05,
      "loss": 0.0008,
      "step": 3107
    },
    {
      "epoch": 12.046511627906977,
      "grad_norm": 3.4071109294891357,
      "learning_rate": 3.7953488372093024e-05,
      "loss": 0.3659,
      "step": 3108
    },
    {
      "epoch": 12.050387596899224,
      "grad_norm": 0.005491304211318493,
      "learning_rate": 3.794961240310078e-05,
      "loss": 0.0003,
      "step": 3109
    },
    {
      "epoch": 12.054263565891473,
      "grad_norm": 0.002825280884280801,
      "learning_rate": 3.794573643410853e-05,
      "loss": 0.0003,
      "step": 3110
    },
    {
      "epoch": 12.05813953488372,
      "grad_norm": 0.07831830531358719,
      "learning_rate": 3.794186046511628e-05,
      "loss": 0.0003,
      "step": 3111
    },
    {
      "epoch": 12.062015503875969,
      "grad_norm": 0.002564038150012493,
      "learning_rate": 3.7937984496124034e-05,
      "loss": 0.0003,
      "step": 3112
    },
    {
      "epoch": 12.065891472868216,
      "grad_norm": 0.08382782340049744,
      "learning_rate": 3.7934108527131786e-05,
      "loss": 0.0006,
      "step": 3113
    },
    {
      "epoch": 12.069767441860465,
      "grad_norm": 0.004908703733235598,
      "learning_rate": 3.793023255813954e-05,
      "loss": 0.0004,
      "step": 3114
    },
    {
      "epoch": 12.073643410852712,
      "grad_norm": 0.0026856206823140383,
      "learning_rate": 3.792635658914729e-05,
      "loss": 0.0003,
      "step": 3115
    },
    {
      "epoch": 12.077519379844961,
      "grad_norm": 0.010758374817669392,
      "learning_rate": 3.7922480620155044e-05,
      "loss": 0.0007,
      "step": 3116
    },
    {
      "epoch": 12.081395348837209,
      "grad_norm": 0.03248893469572067,
      "learning_rate": 3.791860465116279e-05,
      "loss": 0.0016,
      "step": 3117
    },
    {
      "epoch": 12.085271317829458,
      "grad_norm": 0.01745470240712166,
      "learning_rate": 3.791472868217055e-05,
      "loss": 0.0004,
      "step": 3118
    },
    {
      "epoch": 12.089147286821705,
      "grad_norm": 17.136943817138672,
      "learning_rate": 3.7910852713178294e-05,
      "loss": 0.1105,
      "step": 3119
    },
    {
      "epoch": 12.093023255813954,
      "grad_norm": 0.004403112456202507,
      "learning_rate": 3.790697674418605e-05,
      "loss": 0.0003,
      "step": 3120
    },
    {
      "epoch": 12.0968992248062,
      "grad_norm": 0.00613096309825778,
      "learning_rate": 3.79031007751938e-05,
      "loss": 0.0004,
      "step": 3121
    },
    {
      "epoch": 12.10077519379845,
      "grad_norm": 0.006517569534480572,
      "learning_rate": 3.789922480620155e-05,
      "loss": 0.0003,
      "step": 3122
    },
    {
      "epoch": 12.104651162790697,
      "grad_norm": 0.01124107651412487,
      "learning_rate": 3.7895348837209304e-05,
      "loss": 0.0007,
      "step": 3123
    },
    {
      "epoch": 12.108527131782946,
      "grad_norm": 4.620488166809082,
      "learning_rate": 3.7891472868217056e-05,
      "loss": 0.1072,
      "step": 3124
    },
    {
      "epoch": 12.112403100775193,
      "grad_norm": 0.0029159935656934977,
      "learning_rate": 3.788759689922481e-05,
      "loss": 0.0003,
      "step": 3125
    },
    {
      "epoch": 12.116279069767442,
      "grad_norm": 0.1681780219078064,
      "learning_rate": 3.788372093023256e-05,
      "loss": 0.009,
      "step": 3126
    },
    {
      "epoch": 12.12015503875969,
      "grad_norm": 0.36440399289131165,
      "learning_rate": 3.7879844961240314e-05,
      "loss": 0.0025,
      "step": 3127
    },
    {
      "epoch": 12.124031007751938,
      "grad_norm": 1.818891167640686,
      "learning_rate": 3.787596899224806e-05,
      "loss": 0.2404,
      "step": 3128
    },
    {
      "epoch": 12.127906976744185,
      "grad_norm": 0.05478576943278313,
      "learning_rate": 3.787209302325582e-05,
      "loss": 0.0018,
      "step": 3129
    },
    {
      "epoch": 12.131782945736434,
      "grad_norm": 10.051931381225586,
      "learning_rate": 3.7868217054263564e-05,
      "loss": 0.3391,
      "step": 3130
    },
    {
      "epoch": 12.135658914728682,
      "grad_norm": 0.0037477281875908375,
      "learning_rate": 3.786434108527132e-05,
      "loss": 0.0003,
      "step": 3131
    },
    {
      "epoch": 12.13953488372093,
      "grad_norm": 0.011474354192614555,
      "learning_rate": 3.786046511627907e-05,
      "loss": 0.0006,
      "step": 3132
    },
    {
      "epoch": 12.143410852713178,
      "grad_norm": 0.06868372112512589,
      "learning_rate": 3.785658914728683e-05,
      "loss": 0.0022,
      "step": 3133
    },
    {
      "epoch": 12.147286821705427,
      "grad_norm": 0.05073659494519234,
      "learning_rate": 3.7852713178294574e-05,
      "loss": 0.0005,
      "step": 3134
    },
    {
      "epoch": 12.151162790697674,
      "grad_norm": 0.32328537106513977,
      "learning_rate": 3.7848837209302326e-05,
      "loss": 0.0082,
      "step": 3135
    },
    {
      "epoch": 12.155038759689923,
      "grad_norm": 0.02528604120016098,
      "learning_rate": 3.784496124031008e-05,
      "loss": 0.0013,
      "step": 3136
    },
    {
      "epoch": 12.15891472868217,
      "grad_norm": 0.2968299686908722,
      "learning_rate": 3.784108527131783e-05,
      "loss": 0.0024,
      "step": 3137
    },
    {
      "epoch": 12.162790697674419,
      "grad_norm": 0.00895339623093605,
      "learning_rate": 3.7837209302325583e-05,
      "loss": 0.0004,
      "step": 3138
    },
    {
      "epoch": 12.166666666666666,
      "grad_norm": 3.536816120147705,
      "learning_rate": 3.7833333333333336e-05,
      "loss": 0.0108,
      "step": 3139
    },
    {
      "epoch": 12.170542635658915,
      "grad_norm": 0.005680880509316921,
      "learning_rate": 3.782945736434109e-05,
      "loss": 0.0003,
      "step": 3140
    },
    {
      "epoch": 12.174418604651162,
      "grad_norm": 16.418121337890625,
      "learning_rate": 3.782558139534884e-05,
      "loss": 0.0788,
      "step": 3141
    },
    {
      "epoch": 12.178294573643411,
      "grad_norm": 0.004508273210376501,
      "learning_rate": 3.782170542635659e-05,
      "loss": 0.0004,
      "step": 3142
    },
    {
      "epoch": 12.182170542635658,
      "grad_norm": 0.0032579144462943077,
      "learning_rate": 3.7817829457364346e-05,
      "loss": 0.0003,
      "step": 3143
    },
    {
      "epoch": 12.186046511627907,
      "grad_norm": 0.004631546325981617,
      "learning_rate": 3.78139534883721e-05,
      "loss": 0.0003,
      "step": 3144
    },
    {
      "epoch": 12.189922480620154,
      "grad_norm": 0.011364701204001904,
      "learning_rate": 3.781007751937985e-05,
      "loss": 0.0005,
      "step": 3145
    },
    {
      "epoch": 12.193798449612403,
      "grad_norm": 0.20423321425914764,
      "learning_rate": 3.7806201550387596e-05,
      "loss": 0.0031,
      "step": 3146
    },
    {
      "epoch": 12.19767441860465,
      "grad_norm": 0.9654713869094849,
      "learning_rate": 3.780232558139535e-05,
      "loss": 0.0428,
      "step": 3147
    },
    {
      "epoch": 12.2015503875969,
      "grad_norm": 0.003797178855165839,
      "learning_rate": 3.77984496124031e-05,
      "loss": 0.0004,
      "step": 3148
    },
    {
      "epoch": 12.205426356589147,
      "grad_norm": 0.002904534339904785,
      "learning_rate": 3.779457364341085e-05,
      "loss": 0.0003,
      "step": 3149
    },
    {
      "epoch": 12.209302325581396,
      "grad_norm": 7.608323574066162,
      "learning_rate": 3.7790697674418606e-05,
      "loss": 0.1433,
      "step": 3150
    },
    {
      "epoch": 12.213178294573643,
      "grad_norm": 0.13283145427703857,
      "learning_rate": 3.778682170542636e-05,
      "loss": 0.0006,
      "step": 3151
    },
    {
      "epoch": 12.217054263565892,
      "grad_norm": 0.14273673295974731,
      "learning_rate": 3.778294573643411e-05,
      "loss": 0.0065,
      "step": 3152
    },
    {
      "epoch": 12.220930232558139,
      "grad_norm": 0.0025828201323747635,
      "learning_rate": 3.777906976744186e-05,
      "loss": 0.0003,
      "step": 3153
    },
    {
      "epoch": 12.224806201550388,
      "grad_norm": 0.0026222963351756334,
      "learning_rate": 3.7775193798449615e-05,
      "loss": 0.0002,
      "step": 3154
    },
    {
      "epoch": 12.228682170542635,
      "grad_norm": 4.641759872436523,
      "learning_rate": 3.777131782945736e-05,
      "loss": 0.0531,
      "step": 3155
    },
    {
      "epoch": 12.232558139534884,
      "grad_norm": 0.04064439609646797,
      "learning_rate": 3.776744186046512e-05,
      "loss": 0.0011,
      "step": 3156
    },
    {
      "epoch": 12.236434108527131,
      "grad_norm": 0.0029250518418848515,
      "learning_rate": 3.7763565891472866e-05,
      "loss": 0.0003,
      "step": 3157
    },
    {
      "epoch": 12.24031007751938,
      "grad_norm": 0.037530381232500076,
      "learning_rate": 3.7759689922480625e-05,
      "loss": 0.0005,
      "step": 3158
    },
    {
      "epoch": 12.244186046511627,
      "grad_norm": 0.09039139747619629,
      "learning_rate": 3.775581395348837e-05,
      "loss": 0.0017,
      "step": 3159
    },
    {
      "epoch": 12.248062015503876,
      "grad_norm": 0.02130456455051899,
      "learning_rate": 3.775193798449613e-05,
      "loss": 0.001,
      "step": 3160
    },
    {
      "epoch": 12.251937984496124,
      "grad_norm": 0.0022603850811719894,
      "learning_rate": 3.7748062015503876e-05,
      "loss": 0.0002,
      "step": 3161
    },
    {
      "epoch": 12.255813953488373,
      "grad_norm": 0.02472837269306183,
      "learning_rate": 3.7744186046511635e-05,
      "loss": 0.0011,
      "step": 3162
    },
    {
      "epoch": 12.25968992248062,
      "grad_norm": 0.029565993696451187,
      "learning_rate": 3.774031007751938e-05,
      "loss": 0.0012,
      "step": 3163
    },
    {
      "epoch": 12.263565891472869,
      "grad_norm": 0.0032046311534941196,
      "learning_rate": 3.773643410852713e-05,
      "loss": 0.0003,
      "step": 3164
    },
    {
      "epoch": 12.267441860465116,
      "grad_norm": 0.6464502811431885,
      "learning_rate": 3.7732558139534885e-05,
      "loss": 0.005,
      "step": 3165
    },
    {
      "epoch": 12.271317829457365,
      "grad_norm": 0.002911193761974573,
      "learning_rate": 3.772868217054264e-05,
      "loss": 0.0003,
      "step": 3166
    },
    {
      "epoch": 12.275193798449612,
      "grad_norm": 0.00363309308886528,
      "learning_rate": 3.772480620155039e-05,
      "loss": 0.0003,
      "step": 3167
    },
    {
      "epoch": 12.279069767441861,
      "grad_norm": 0.09076272696256638,
      "learning_rate": 3.772093023255814e-05,
      "loss": 0.0038,
      "step": 3168
    },
    {
      "epoch": 12.282945736434108,
      "grad_norm": 0.104149229824543,
      "learning_rate": 3.7717054263565895e-05,
      "loss": 0.0007,
      "step": 3169
    },
    {
      "epoch": 12.286821705426357,
      "grad_norm": 3.8692684173583984,
      "learning_rate": 3.771317829457365e-05,
      "loss": 0.1905,
      "step": 3170
    },
    {
      "epoch": 12.290697674418604,
      "grad_norm": 11.429826736450195,
      "learning_rate": 3.77093023255814e-05,
      "loss": 0.2561,
      "step": 3171
    },
    {
      "epoch": 12.294573643410853,
      "grad_norm": 0.003332999534904957,
      "learning_rate": 3.7705426356589145e-05,
      "loss": 0.0003,
      "step": 3172
    },
    {
      "epoch": 12.2984496124031,
      "grad_norm": 0.00304128578864038,
      "learning_rate": 3.77015503875969e-05,
      "loss": 0.0002,
      "step": 3173
    },
    {
      "epoch": 12.30232558139535,
      "grad_norm": 0.004205895122140646,
      "learning_rate": 3.769767441860465e-05,
      "loss": 0.0003,
      "step": 3174
    },
    {
      "epoch": 12.306201550387597,
      "grad_norm": 0.002321863081306219,
      "learning_rate": 3.76937984496124e-05,
      "loss": 0.0002,
      "step": 3175
    },
    {
      "epoch": 12.310077519379846,
      "grad_norm": 0.5751566886901855,
      "learning_rate": 3.7689922480620155e-05,
      "loss": 0.0062,
      "step": 3176
    },
    {
      "epoch": 12.313953488372093,
      "grad_norm": 0.058492887765169144,
      "learning_rate": 3.768604651162791e-05,
      "loss": 0.0025,
      "step": 3177
    },
    {
      "epoch": 12.317829457364342,
      "grad_norm": 0.007424752227962017,
      "learning_rate": 3.768217054263566e-05,
      "loss": 0.0004,
      "step": 3178
    },
    {
      "epoch": 12.321705426356589,
      "grad_norm": 0.005514069460332394,
      "learning_rate": 3.767829457364341e-05,
      "loss": 0.0003,
      "step": 3179
    },
    {
      "epoch": 12.325581395348838,
      "grad_norm": 14.641361236572266,
      "learning_rate": 3.7674418604651165e-05,
      "loss": 1.0896,
      "step": 3180
    },
    {
      "epoch": 12.329457364341085,
      "grad_norm": 0.0035645687021315098,
      "learning_rate": 3.767054263565892e-05,
      "loss": 0.0003,
      "step": 3181
    },
    {
      "epoch": 12.333333333333334,
      "grad_norm": 0.004760382696986198,
      "learning_rate": 3.766666666666667e-05,
      "loss": 0.0003,
      "step": 3182
    },
    {
      "epoch": 12.337209302325581,
      "grad_norm": 12.073570251464844,
      "learning_rate": 3.766279069767442e-05,
      "loss": 0.0504,
      "step": 3183
    },
    {
      "epoch": 12.34108527131783,
      "grad_norm": 20.995241165161133,
      "learning_rate": 3.765891472868217e-05,
      "loss": 0.4421,
      "step": 3184
    },
    {
      "epoch": 12.344961240310077,
      "grad_norm": 0.16291695833206177,
      "learning_rate": 3.765503875968993e-05,
      "loss": 0.0072,
      "step": 3185
    },
    {
      "epoch": 12.348837209302326,
      "grad_norm": 0.00711140688508749,
      "learning_rate": 3.765116279069767e-05,
      "loss": 0.0004,
      "step": 3186
    },
    {
      "epoch": 12.352713178294573,
      "grad_norm": 0.005714373663067818,
      "learning_rate": 3.764728682170543e-05,
      "loss": 0.0004,
      "step": 3187
    },
    {
      "epoch": 12.356589147286822,
      "grad_norm": 2.4010813236236572,
      "learning_rate": 3.764341085271318e-05,
      "loss": 0.0997,
      "step": 3188
    },
    {
      "epoch": 12.36046511627907,
      "grad_norm": 0.011958871968090534,
      "learning_rate": 3.763953488372094e-05,
      "loss": 0.0008,
      "step": 3189
    },
    {
      "epoch": 12.364341085271318,
      "grad_norm": 0.019183088093996048,
      "learning_rate": 3.763565891472868e-05,
      "loss": 0.0007,
      "step": 3190
    },
    {
      "epoch": 12.368217054263566,
      "grad_norm": 0.005976427812129259,
      "learning_rate": 3.7631782945736435e-05,
      "loss": 0.0003,
      "step": 3191
    },
    {
      "epoch": 12.372093023255815,
      "grad_norm": 0.057663824409246445,
      "learning_rate": 3.762790697674419e-05,
      "loss": 0.0015,
      "step": 3192
    },
    {
      "epoch": 12.375968992248062,
      "grad_norm": 0.014728792011737823,
      "learning_rate": 3.762403100775194e-05,
      "loss": 0.0006,
      "step": 3193
    },
    {
      "epoch": 12.37984496124031,
      "grad_norm": 0.03728366270661354,
      "learning_rate": 3.762015503875969e-05,
      "loss": 0.001,
      "step": 3194
    },
    {
      "epoch": 12.383720930232558,
      "grad_norm": 0.03644755855202675,
      "learning_rate": 3.7616279069767444e-05,
      "loss": 0.001,
      "step": 3195
    },
    {
      "epoch": 12.387596899224807,
      "grad_norm": 0.04676113650202751,
      "learning_rate": 3.76124031007752e-05,
      "loss": 0.0007,
      "step": 3196
    },
    {
      "epoch": 12.391472868217054,
      "grad_norm": 0.045148156583309174,
      "learning_rate": 3.760852713178295e-05,
      "loss": 0.0012,
      "step": 3197
    },
    {
      "epoch": 12.395348837209303,
      "grad_norm": 0.03901584818959236,
      "learning_rate": 3.76046511627907e-05,
      "loss": 0.0009,
      "step": 3198
    },
    {
      "epoch": 12.39922480620155,
      "grad_norm": 0.01714310422539711,
      "learning_rate": 3.760077519379845e-05,
      "loss": 0.0006,
      "step": 3199
    },
    {
      "epoch": 12.4031007751938,
      "grad_norm": 0.012278621084988117,
      "learning_rate": 3.7596899224806207e-05,
      "loss": 0.0006,
      "step": 3200
    },
    {
      "epoch": 12.406976744186046,
      "grad_norm": 1.2028323411941528,
      "learning_rate": 3.759302325581395e-05,
      "loss": 0.0572,
      "step": 3201
    },
    {
      "epoch": 12.410852713178295,
      "grad_norm": 0.0076214708387851715,
      "learning_rate": 3.7589147286821705e-05,
      "loss": 0.0006,
      "step": 3202
    },
    {
      "epoch": 12.414728682170542,
      "grad_norm": 0.004660656210035086,
      "learning_rate": 3.758527131782946e-05,
      "loss": 0.0004,
      "step": 3203
    },
    {
      "epoch": 12.418604651162791,
      "grad_norm": 0.008092792704701424,
      "learning_rate": 3.758139534883721e-05,
      "loss": 0.0004,
      "step": 3204
    },
    {
      "epoch": 12.422480620155039,
      "grad_norm": 14.382234573364258,
      "learning_rate": 3.757751937984496e-05,
      "loss": 0.0831,
      "step": 3205
    },
    {
      "epoch": 12.426356589147288,
      "grad_norm": 0.01002275850623846,
      "learning_rate": 3.7573643410852714e-05,
      "loss": 0.0007,
      "step": 3206
    },
    {
      "epoch": 12.430232558139535,
      "grad_norm": 0.022259991616010666,
      "learning_rate": 3.756976744186047e-05,
      "loss": 0.0006,
      "step": 3207
    },
    {
      "epoch": 12.434108527131784,
      "grad_norm": 9.129088401794434,
      "learning_rate": 3.756589147286822e-05,
      "loss": 0.9255,
      "step": 3208
    },
    {
      "epoch": 12.437984496124031,
      "grad_norm": 5.07838773727417,
      "learning_rate": 3.756201550387597e-05,
      "loss": 0.0624,
      "step": 3209
    },
    {
      "epoch": 12.44186046511628,
      "grad_norm": 119.99906158447266,
      "learning_rate": 3.7558139534883724e-05,
      "loss": 0.205,
      "step": 3210
    },
    {
      "epoch": 12.445736434108527,
      "grad_norm": 0.007498004008084536,
      "learning_rate": 3.7554263565891476e-05,
      "loss": 0.0006,
      "step": 3211
    },
    {
      "epoch": 12.449612403100776,
      "grad_norm": 11.67025089263916,
      "learning_rate": 3.755038759689923e-05,
      "loss": 0.3235,
      "step": 3212
    },
    {
      "epoch": 12.453488372093023,
      "grad_norm": 0.006135983392596245,
      "learning_rate": 3.7546511627906974e-05,
      "loss": 0.0004,
      "step": 3213
    },
    {
      "epoch": 12.457364341085272,
      "grad_norm": 10.282647132873535,
      "learning_rate": 3.7542635658914734e-05,
      "loss": 0.3373,
      "step": 3214
    },
    {
      "epoch": 12.46124031007752,
      "grad_norm": 0.010889042168855667,
      "learning_rate": 3.753875968992248e-05,
      "loss": 0.0005,
      "step": 3215
    },
    {
      "epoch": 12.465116279069768,
      "grad_norm": 0.3568863868713379,
      "learning_rate": 3.753488372093024e-05,
      "loss": 0.0119,
      "step": 3216
    },
    {
      "epoch": 12.468992248062015,
      "grad_norm": 0.04968532919883728,
      "learning_rate": 3.7531007751937984e-05,
      "loss": 0.0005,
      "step": 3217
    },
    {
      "epoch": 12.472868217054264,
      "grad_norm": 0.010783608071506023,
      "learning_rate": 3.752713178294574e-05,
      "loss": 0.0005,
      "step": 3218
    },
    {
      "epoch": 12.476744186046512,
      "grad_norm": 0.20335926115512848,
      "learning_rate": 3.752325581395349e-05,
      "loss": 0.0038,
      "step": 3219
    },
    {
      "epoch": 12.48062015503876,
      "grad_norm": 0.17208178341388702,
      "learning_rate": 3.751937984496124e-05,
      "loss": 0.0071,
      "step": 3220
    },
    {
      "epoch": 12.484496124031008,
      "grad_norm": 0.020353808999061584,
      "learning_rate": 3.7515503875968994e-05,
      "loss": 0.0005,
      "step": 3221
    },
    {
      "epoch": 12.488372093023255,
      "grad_norm": 0.01113902684301138,
      "learning_rate": 3.7511627906976746e-05,
      "loss": 0.0005,
      "step": 3222
    },
    {
      "epoch": 12.492248062015504,
      "grad_norm": 0.005802773870527744,
      "learning_rate": 3.75077519379845e-05,
      "loss": 0.0004,
      "step": 3223
    },
    {
      "epoch": 12.496124031007753,
      "grad_norm": 0.019543686881661415,
      "learning_rate": 3.750387596899225e-05,
      "loss": 0.0003,
      "step": 3224
    },
    {
      "epoch": 12.5,
      "grad_norm": 6.355860710144043,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.2015,
      "step": 3225
    },
    {
      "epoch": 12.503875968992247,
      "grad_norm": 0.11126995831727982,
      "learning_rate": 3.749612403100775e-05,
      "loss": 0.0053,
      "step": 3226
    },
    {
      "epoch": 12.507751937984496,
      "grad_norm": 0.004684177227318287,
      "learning_rate": 3.749224806201551e-05,
      "loss": 0.0003,
      "step": 3227
    },
    {
      "epoch": 12.511627906976745,
      "grad_norm": 0.00570372398942709,
      "learning_rate": 3.7488372093023254e-05,
      "loss": 0.0004,
      "step": 3228
    },
    {
      "epoch": 12.515503875968992,
      "grad_norm": 0.021186577156186104,
      "learning_rate": 3.748449612403101e-05,
      "loss": 0.0003,
      "step": 3229
    },
    {
      "epoch": 12.51937984496124,
      "grad_norm": 0.6333767771720886,
      "learning_rate": 3.748062015503876e-05,
      "loss": 0.0076,
      "step": 3230
    },
    {
      "epoch": 12.523255813953488,
      "grad_norm": 0.006185243371874094,
      "learning_rate": 3.747674418604651e-05,
      "loss": 0.0004,
      "step": 3231
    },
    {
      "epoch": 12.527131782945737,
      "grad_norm": 0.013984734192490578,
      "learning_rate": 3.7472868217054264e-05,
      "loss": 0.0004,
      "step": 3232
    },
    {
      "epoch": 12.531007751937985,
      "grad_norm": 0.005756732542067766,
      "learning_rate": 3.7468992248062016e-05,
      "loss": 0.0004,
      "step": 3233
    },
    {
      "epoch": 12.534883720930232,
      "grad_norm": 3.7135891914367676,
      "learning_rate": 3.746511627906977e-05,
      "loss": 0.4291,
      "step": 3234
    },
    {
      "epoch": 12.53875968992248,
      "grad_norm": 0.00682179955765605,
      "learning_rate": 3.746124031007752e-05,
      "loss": 0.0003,
      "step": 3235
    },
    {
      "epoch": 12.542635658914728,
      "grad_norm": 24.19036293029785,
      "learning_rate": 3.745736434108527e-05,
      "loss": 0.0623,
      "step": 3236
    },
    {
      "epoch": 12.546511627906977,
      "grad_norm": 1.52603018283844,
      "learning_rate": 3.7453488372093026e-05,
      "loss": 0.0037,
      "step": 3237
    },
    {
      "epoch": 12.550387596899224,
      "grad_norm": 0.004058019258081913,
      "learning_rate": 3.744961240310078e-05,
      "loss": 0.0003,
      "step": 3238
    },
    {
      "epoch": 12.554263565891473,
      "grad_norm": 0.11837245523929596,
      "learning_rate": 3.744573643410853e-05,
      "loss": 0.0007,
      "step": 3239
    },
    {
      "epoch": 12.55813953488372,
      "grad_norm": 0.008280714973807335,
      "learning_rate": 3.7441860465116276e-05,
      "loss": 0.0005,
      "step": 3240
    },
    {
      "epoch": 12.562015503875969,
      "grad_norm": 0.004518759902566671,
      "learning_rate": 3.7437984496124035e-05,
      "loss": 0.0003,
      "step": 3241
    },
    {
      "epoch": 12.565891472868216,
      "grad_norm": 0.13473571836948395,
      "learning_rate": 3.743410852713178e-05,
      "loss": 0.0068,
      "step": 3242
    },
    {
      "epoch": 12.569767441860465,
      "grad_norm": 0.22497150301933289,
      "learning_rate": 3.743023255813954e-05,
      "loss": 0.0003,
      "step": 3243
    },
    {
      "epoch": 12.573643410852712,
      "grad_norm": 0.018381470814347267,
      "learning_rate": 3.7426356589147286e-05,
      "loss": 0.0005,
      "step": 3244
    },
    {
      "epoch": 12.577519379844961,
      "grad_norm": 0.015919510275125504,
      "learning_rate": 3.7422480620155045e-05,
      "loss": 0.0003,
      "step": 3245
    },
    {
      "epoch": 12.581395348837209,
      "grad_norm": 0.06128992885351181,
      "learning_rate": 3.741860465116279e-05,
      "loss": 0.0025,
      "step": 3246
    },
    {
      "epoch": 12.585271317829458,
      "grad_norm": 0.4428552985191345,
      "learning_rate": 3.741472868217055e-05,
      "loss": 0.0075,
      "step": 3247
    },
    {
      "epoch": 12.589147286821705,
      "grad_norm": 0.006057405844330788,
      "learning_rate": 3.7410852713178296e-05,
      "loss": 0.0004,
      "step": 3248
    },
    {
      "epoch": 12.593023255813954,
      "grad_norm": 6.577808380126953,
      "learning_rate": 3.740697674418605e-05,
      "loss": 0.1247,
      "step": 3249
    },
    {
      "epoch": 12.5968992248062,
      "grad_norm": 0.004912336822599173,
      "learning_rate": 3.74031007751938e-05,
      "loss": 0.0003,
      "step": 3250
    },
    {
      "epoch": 12.60077519379845,
      "grad_norm": 0.03875875845551491,
      "learning_rate": 3.739922480620155e-05,
      "loss": 0.0006,
      "step": 3251
    },
    {
      "epoch": 12.604651162790697,
      "grad_norm": 1.9553465843200684,
      "learning_rate": 3.7395348837209305e-05,
      "loss": 0.0508,
      "step": 3252
    },
    {
      "epoch": 12.608527131782946,
      "grad_norm": 0.004424777813255787,
      "learning_rate": 3.739147286821705e-05,
      "loss": 0.0003,
      "step": 3253
    },
    {
      "epoch": 12.612403100775193,
      "grad_norm": 0.005911144427955151,
      "learning_rate": 3.738759689922481e-05,
      "loss": 0.0003,
      "step": 3254
    },
    {
      "epoch": 12.616279069767442,
      "grad_norm": 0.008094004355370998,
      "learning_rate": 3.7383720930232556e-05,
      "loss": 0.0005,
      "step": 3255
    },
    {
      "epoch": 12.62015503875969,
      "grad_norm": 0.01169267762452364,
      "learning_rate": 3.7379844961240315e-05,
      "loss": 0.0004,
      "step": 3256
    },
    {
      "epoch": 12.624031007751938,
      "grad_norm": 0.006380501203238964,
      "learning_rate": 3.737596899224806e-05,
      "loss": 0.0004,
      "step": 3257
    },
    {
      "epoch": 12.627906976744185,
      "grad_norm": 0.005588850937783718,
      "learning_rate": 3.737209302325581e-05,
      "loss": 0.0004,
      "step": 3258
    },
    {
      "epoch": 12.631782945736434,
      "grad_norm": 2.9768104553222656,
      "learning_rate": 3.7368217054263565e-05,
      "loss": 0.4534,
      "step": 3259
    },
    {
      "epoch": 12.635658914728682,
      "grad_norm": 19.85162925720215,
      "learning_rate": 3.736434108527132e-05,
      "loss": 0.9457,
      "step": 3260
    },
    {
      "epoch": 12.63953488372093,
      "grad_norm": 0.005806423723697662,
      "learning_rate": 3.736046511627907e-05,
      "loss": 0.0004,
      "step": 3261
    },
    {
      "epoch": 12.643410852713178,
      "grad_norm": 0.004439414478838444,
      "learning_rate": 3.735658914728682e-05,
      "loss": 0.0004,
      "step": 3262
    },
    {
      "epoch": 12.647286821705427,
      "grad_norm": 0.004735127091407776,
      "learning_rate": 3.7352713178294575e-05,
      "loss": 0.0003,
      "step": 3263
    },
    {
      "epoch": 12.651162790697674,
      "grad_norm": 0.007443352602422237,
      "learning_rate": 3.734883720930233e-05,
      "loss": 0.0004,
      "step": 3264
    },
    {
      "epoch": 12.655038759689923,
      "grad_norm": 0.00479792058467865,
      "learning_rate": 3.734496124031008e-05,
      "loss": 0.0004,
      "step": 3265
    },
    {
      "epoch": 12.65891472868217,
      "grad_norm": 5.727092742919922,
      "learning_rate": 3.734108527131783e-05,
      "loss": 0.0224,
      "step": 3266
    },
    {
      "epoch": 12.662790697674419,
      "grad_norm": 0.012146519497036934,
      "learning_rate": 3.7337209302325585e-05,
      "loss": 0.0006,
      "step": 3267
    },
    {
      "epoch": 12.666666666666666,
      "grad_norm": 0.0040038954466581345,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.0003,
      "step": 3268
    },
    {
      "epoch": 12.670542635658915,
      "grad_norm": 0.2923923134803772,
      "learning_rate": 3.732945736434108e-05,
      "loss": 0.008,
      "step": 3269
    },
    {
      "epoch": 12.674418604651162,
      "grad_norm": 0.05748067796230316,
      "learning_rate": 3.732558139534884e-05,
      "loss": 0.003,
      "step": 3270
    },
    {
      "epoch": 12.678294573643411,
      "grad_norm": 0.0030222544446587563,
      "learning_rate": 3.732170542635659e-05,
      "loss": 0.0003,
      "step": 3271
    },
    {
      "epoch": 12.682170542635658,
      "grad_norm": 0.009828586131334305,
      "learning_rate": 3.731782945736435e-05,
      "loss": 0.0004,
      "step": 3272
    },
    {
      "epoch": 12.686046511627907,
      "grad_norm": 0.00404531043022871,
      "learning_rate": 3.731395348837209e-05,
      "loss": 0.0003,
      "step": 3273
    },
    {
      "epoch": 12.689922480620154,
      "grad_norm": 0.15019004046916962,
      "learning_rate": 3.731007751937985e-05,
      "loss": 0.006,
      "step": 3274
    },
    {
      "epoch": 12.693798449612403,
      "grad_norm": 0.004888028837740421,
      "learning_rate": 3.73062015503876e-05,
      "loss": 0.0004,
      "step": 3275
    },
    {
      "epoch": 12.69767441860465,
      "grad_norm": 0.03176550567150116,
      "learning_rate": 3.730232558139535e-05,
      "loss": 0.0019,
      "step": 3276
    },
    {
      "epoch": 12.7015503875969,
      "grad_norm": 0.0055058738216757774,
      "learning_rate": 3.72984496124031e-05,
      "loss": 0.0003,
      "step": 3277
    },
    {
      "epoch": 12.705426356589147,
      "grad_norm": 0.006626856978982687,
      "learning_rate": 3.7294573643410855e-05,
      "loss": 0.0005,
      "step": 3278
    },
    {
      "epoch": 12.709302325581396,
      "grad_norm": 0.00784608069807291,
      "learning_rate": 3.729069767441861e-05,
      "loss": 0.0004,
      "step": 3279
    },
    {
      "epoch": 12.713178294573643,
      "grad_norm": 0.005182790104299784,
      "learning_rate": 3.728682170542635e-05,
      "loss": 0.0004,
      "step": 3280
    },
    {
      "epoch": 12.717054263565892,
      "grad_norm": 37.787288665771484,
      "learning_rate": 3.728294573643411e-05,
      "loss": 0.5032,
      "step": 3281
    },
    {
      "epoch": 12.720930232558139,
      "grad_norm": 0.017279746010899544,
      "learning_rate": 3.727906976744186e-05,
      "loss": 0.0004,
      "step": 3282
    },
    {
      "epoch": 12.724806201550388,
      "grad_norm": 3.8725361824035645,
      "learning_rate": 3.727519379844962e-05,
      "loss": 0.1735,
      "step": 3283
    },
    {
      "epoch": 12.728682170542635,
      "grad_norm": 0.0033198909368366003,
      "learning_rate": 3.727131782945736e-05,
      "loss": 0.0003,
      "step": 3284
    },
    {
      "epoch": 12.732558139534884,
      "grad_norm": 0.007201660890132189,
      "learning_rate": 3.726744186046512e-05,
      "loss": 0.0004,
      "step": 3285
    },
    {
      "epoch": 12.736434108527131,
      "grad_norm": 3.9215495586395264,
      "learning_rate": 3.726356589147287e-05,
      "loss": 0.2682,
      "step": 3286
    },
    {
      "epoch": 12.74031007751938,
      "grad_norm": 0.014930508099496365,
      "learning_rate": 3.725968992248062e-05,
      "loss": 0.0004,
      "step": 3287
    },
    {
      "epoch": 12.744186046511627,
      "grad_norm": 0.32998567819595337,
      "learning_rate": 3.725581395348837e-05,
      "loss": 0.0005,
      "step": 3288
    },
    {
      "epoch": 12.748062015503876,
      "grad_norm": 23.928234100341797,
      "learning_rate": 3.7251937984496125e-05,
      "loss": 0.4812,
      "step": 3289
    },
    {
      "epoch": 12.751937984496124,
      "grad_norm": 2.5655455589294434,
      "learning_rate": 3.724806201550388e-05,
      "loss": 0.5737,
      "step": 3290
    },
    {
      "epoch": 12.755813953488373,
      "grad_norm": 2.373941659927368,
      "learning_rate": 3.724418604651163e-05,
      "loss": 0.0025,
      "step": 3291
    },
    {
      "epoch": 12.75968992248062,
      "grad_norm": 44.64170837402344,
      "learning_rate": 3.724031007751938e-05,
      "loss": 0.3434,
      "step": 3292
    },
    {
      "epoch": 12.763565891472869,
      "grad_norm": 2.0843684673309326,
      "learning_rate": 3.7236434108527134e-05,
      "loss": 0.0238,
      "step": 3293
    },
    {
      "epoch": 12.767441860465116,
      "grad_norm": 0.11788754165172577,
      "learning_rate": 3.723255813953489e-05,
      "loss": 0.0012,
      "step": 3294
    },
    {
      "epoch": 12.771317829457365,
      "grad_norm": 0.0036738861817866564,
      "learning_rate": 3.722868217054264e-05,
      "loss": 0.0003,
      "step": 3295
    },
    {
      "epoch": 12.775193798449612,
      "grad_norm": 0.2143646627664566,
      "learning_rate": 3.722480620155039e-05,
      "loss": 0.0008,
      "step": 3296
    },
    {
      "epoch": 12.779069767441861,
      "grad_norm": 0.02010851725935936,
      "learning_rate": 3.7220930232558144e-05,
      "loss": 0.0009,
      "step": 3297
    },
    {
      "epoch": 12.782945736434108,
      "grad_norm": 0.0030664182268083096,
      "learning_rate": 3.721705426356589e-05,
      "loss": 0.0003,
      "step": 3298
    },
    {
      "epoch": 12.786821705426357,
      "grad_norm": 0.16114690899848938,
      "learning_rate": 3.721317829457365e-05,
      "loss": 0.0008,
      "step": 3299
    },
    {
      "epoch": 12.790697674418604,
      "grad_norm": 1.542590618133545,
      "learning_rate": 3.7209302325581394e-05,
      "loss": 0.127,
      "step": 3300
    },
    {
      "epoch": 12.794573643410853,
      "grad_norm": 0.005351837258785963,
      "learning_rate": 3.7205426356589154e-05,
      "loss": 0.0004,
      "step": 3301
    },
    {
      "epoch": 12.7984496124031,
      "grad_norm": 2.1114182472229004,
      "learning_rate": 3.72015503875969e-05,
      "loss": 0.0117,
      "step": 3302
    },
    {
      "epoch": 12.80232558139535,
      "grad_norm": 0.16961506009101868,
      "learning_rate": 3.719767441860466e-05,
      "loss": 0.006,
      "step": 3303
    },
    {
      "epoch": 12.806201550387597,
      "grad_norm": 0.13860392570495605,
      "learning_rate": 3.7193798449612404e-05,
      "loss": 0.003,
      "step": 3304
    },
    {
      "epoch": 12.810077519379846,
      "grad_norm": 0.014246602542698383,
      "learning_rate": 3.7189922480620157e-05,
      "loss": 0.0006,
      "step": 3305
    },
    {
      "epoch": 12.813953488372093,
      "grad_norm": 0.014207880944013596,
      "learning_rate": 3.718604651162791e-05,
      "loss": 0.0006,
      "step": 3306
    },
    {
      "epoch": 12.817829457364342,
      "grad_norm": 0.14753389358520508,
      "learning_rate": 3.718217054263566e-05,
      "loss": 0.0018,
      "step": 3307
    },
    {
      "epoch": 12.821705426356589,
      "grad_norm": 0.006943288259208202,
      "learning_rate": 3.7178294573643414e-05,
      "loss": 0.0004,
      "step": 3308
    },
    {
      "epoch": 12.825581395348838,
      "grad_norm": 0.016946086660027504,
      "learning_rate": 3.717441860465116e-05,
      "loss": 0.0006,
      "step": 3309
    },
    {
      "epoch": 12.829457364341085,
      "grad_norm": 0.009675365872681141,
      "learning_rate": 3.717054263565892e-05,
      "loss": 0.0005,
      "step": 3310
    },
    {
      "epoch": 12.833333333333334,
      "grad_norm": 0.023467546328902245,
      "learning_rate": 3.7166666666666664e-05,
      "loss": 0.0008,
      "step": 3311
    },
    {
      "epoch": 12.837209302325581,
      "grad_norm": 9.543684005737305,
      "learning_rate": 3.7162790697674424e-05,
      "loss": 1.4873,
      "step": 3312
    },
    {
      "epoch": 12.84108527131783,
      "grad_norm": 0.04090007394552231,
      "learning_rate": 3.715891472868217e-05,
      "loss": 0.0009,
      "step": 3313
    },
    {
      "epoch": 12.844961240310077,
      "grad_norm": 0.00853540375828743,
      "learning_rate": 3.715503875968993e-05,
      "loss": 0.0005,
      "step": 3314
    },
    {
      "epoch": 12.848837209302326,
      "grad_norm": 0.0956367701292038,
      "learning_rate": 3.7151162790697674e-05,
      "loss": 0.0036,
      "step": 3315
    },
    {
      "epoch": 12.852713178294573,
      "grad_norm": 0.014082521200180054,
      "learning_rate": 3.7147286821705426e-05,
      "loss": 0.0007,
      "step": 3316
    },
    {
      "epoch": 12.856589147286822,
      "grad_norm": 10.004892349243164,
      "learning_rate": 3.714341085271318e-05,
      "loss": 0.549,
      "step": 3317
    },
    {
      "epoch": 12.86046511627907,
      "grad_norm": 11.444929122924805,
      "learning_rate": 3.713953488372093e-05,
      "loss": 0.179,
      "step": 3318
    },
    {
      "epoch": 12.864341085271318,
      "grad_norm": 0.018050704151391983,
      "learning_rate": 3.7135658914728684e-05,
      "loss": 0.0006,
      "step": 3319
    },
    {
      "epoch": 12.868217054263566,
      "grad_norm": 0.9869491457939148,
      "learning_rate": 3.7131782945736436e-05,
      "loss": 0.0106,
      "step": 3320
    },
    {
      "epoch": 12.872093023255815,
      "grad_norm": 1.6758928298950195,
      "learning_rate": 3.712790697674419e-05,
      "loss": 0.0043,
      "step": 3321
    },
    {
      "epoch": 12.875968992248062,
      "grad_norm": 0.019119104370474815,
      "learning_rate": 3.712403100775194e-05,
      "loss": 0.0008,
      "step": 3322
    },
    {
      "epoch": 12.87984496124031,
      "grad_norm": 18.3430233001709,
      "learning_rate": 3.712015503875969e-05,
      "loss": 0.397,
      "step": 3323
    },
    {
      "epoch": 12.883720930232558,
      "grad_norm": 0.9950685501098633,
      "learning_rate": 3.7116279069767446e-05,
      "loss": 0.0261,
      "step": 3324
    },
    {
      "epoch": 12.887596899224807,
      "grad_norm": 0.012187090702354908,
      "learning_rate": 3.71124031007752e-05,
      "loss": 0.0005,
      "step": 3325
    },
    {
      "epoch": 12.891472868217054,
      "grad_norm": 0.015069248154759407,
      "learning_rate": 3.710852713178295e-05,
      "loss": 0.0008,
      "step": 3326
    },
    {
      "epoch": 12.895348837209303,
      "grad_norm": 0.010488181374967098,
      "learning_rate": 3.7104651162790696e-05,
      "loss": 0.0006,
      "step": 3327
    },
    {
      "epoch": 12.89922480620155,
      "grad_norm": 0.011265222914516926,
      "learning_rate": 3.7100775193798455e-05,
      "loss": 0.0005,
      "step": 3328
    },
    {
      "epoch": 12.9031007751938,
      "grad_norm": 1.3619239330291748,
      "learning_rate": 3.70968992248062e-05,
      "loss": 0.1964,
      "step": 3329
    },
    {
      "epoch": 12.906976744186046,
      "grad_norm": 9.511281967163086,
      "learning_rate": 3.709302325581396e-05,
      "loss": 0.7192,
      "step": 3330
    },
    {
      "epoch": 12.910852713178295,
      "grad_norm": 0.010961925610899925,
      "learning_rate": 3.7089147286821706e-05,
      "loss": 0.0005,
      "step": 3331
    },
    {
      "epoch": 12.914728682170542,
      "grad_norm": 6.359097480773926,
      "learning_rate": 3.708527131782946e-05,
      "loss": 0.3497,
      "step": 3332
    },
    {
      "epoch": 12.918604651162791,
      "grad_norm": 0.04964197427034378,
      "learning_rate": 3.708139534883721e-05,
      "loss": 0.0007,
      "step": 3333
    },
    {
      "epoch": 12.922480620155039,
      "grad_norm": 0.012462378479540348,
      "learning_rate": 3.707751937984496e-05,
      "loss": 0.0005,
      "step": 3334
    },
    {
      "epoch": 12.926356589147288,
      "grad_norm": 0.2927047312259674,
      "learning_rate": 3.7073643410852716e-05,
      "loss": 0.0034,
      "step": 3335
    },
    {
      "epoch": 12.930232558139535,
      "grad_norm": 1.742383599281311,
      "learning_rate": 3.706976744186046e-05,
      "loss": 0.0085,
      "step": 3336
    },
    {
      "epoch": 12.934108527131784,
      "grad_norm": 0.03160771727561951,
      "learning_rate": 3.706589147286822e-05,
      "loss": 0.0008,
      "step": 3337
    },
    {
      "epoch": 12.937984496124031,
      "grad_norm": 0.011443672701716423,
      "learning_rate": 3.7062015503875966e-05,
      "loss": 0.0006,
      "step": 3338
    },
    {
      "epoch": 12.94186046511628,
      "grad_norm": 0.9036794304847717,
      "learning_rate": 3.7058139534883725e-05,
      "loss": 0.0142,
      "step": 3339
    },
    {
      "epoch": 12.945736434108527,
      "grad_norm": 0.01988467574119568,
      "learning_rate": 3.705426356589147e-05,
      "loss": 0.0013,
      "step": 3340
    },
    {
      "epoch": 12.949612403100776,
      "grad_norm": 0.5885177850723267,
      "learning_rate": 3.705038759689923e-05,
      "loss": 0.0023,
      "step": 3341
    },
    {
      "epoch": 12.953488372093023,
      "grad_norm": 0.016787009313702583,
      "learning_rate": 3.7046511627906976e-05,
      "loss": 0.0006,
      "step": 3342
    },
    {
      "epoch": 12.957364341085272,
      "grad_norm": 0.018858378753066063,
      "learning_rate": 3.7042635658914735e-05,
      "loss": 0.0011,
      "step": 3343
    },
    {
      "epoch": 12.96124031007752,
      "grad_norm": 0.01315424032509327,
      "learning_rate": 3.703875968992248e-05,
      "loss": 0.0009,
      "step": 3344
    },
    {
      "epoch": 12.965116279069768,
      "grad_norm": 0.0358903706073761,
      "learning_rate": 3.703488372093023e-05,
      "loss": 0.0019,
      "step": 3345
    },
    {
      "epoch": 12.968992248062015,
      "grad_norm": 0.015160644426941872,
      "learning_rate": 3.7031007751937986e-05,
      "loss": 0.0006,
      "step": 3346
    },
    {
      "epoch": 12.972868217054263,
      "grad_norm": 0.02558477222919464,
      "learning_rate": 3.702713178294574e-05,
      "loss": 0.0009,
      "step": 3347
    },
    {
      "epoch": 12.976744186046512,
      "grad_norm": 0.09229161590337753,
      "learning_rate": 3.702325581395349e-05,
      "loss": 0.0007,
      "step": 3348
    },
    {
      "epoch": 12.98062015503876,
      "grad_norm": 0.7339839935302734,
      "learning_rate": 3.701937984496124e-05,
      "loss": 0.0093,
      "step": 3349
    },
    {
      "epoch": 12.984496124031008,
      "grad_norm": 3.063324213027954,
      "learning_rate": 3.7015503875968995e-05,
      "loss": 0.0563,
      "step": 3350
    },
    {
      "epoch": 12.988372093023255,
      "grad_norm": 0.006636811885982752,
      "learning_rate": 3.701162790697675e-05,
      "loss": 0.0005,
      "step": 3351
    },
    {
      "epoch": 12.992248062015504,
      "grad_norm": 0.014788579195737839,
      "learning_rate": 3.70077519379845e-05,
      "loss": 0.0009,
      "step": 3352
    },
    {
      "epoch": 12.996124031007753,
      "grad_norm": 26.865264892578125,
      "learning_rate": 3.700387596899225e-05,
      "loss": 0.7072,
      "step": 3353
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.03383691608905792,
      "learning_rate": 3.7e-05,
      "loss": 0.0005,
      "step": 3354
    },
    {
      "epoch": 13.003875968992247,
      "grad_norm": 0.011283393017947674,
      "learning_rate": 3.699612403100776e-05,
      "loss": 0.0008,
      "step": 3355
    },
    {
      "epoch": 13.007751937984496,
      "grad_norm": 2.369147777557373,
      "learning_rate": 3.69922480620155e-05,
      "loss": 0.1513,
      "step": 3356
    },
    {
      "epoch": 13.011627906976743,
      "grad_norm": 0.019360654056072235,
      "learning_rate": 3.698837209302326e-05,
      "loss": 0.0011,
      "step": 3357
    },
    {
      "epoch": 13.015503875968992,
      "grad_norm": 0.00794949010014534,
      "learning_rate": 3.698449612403101e-05,
      "loss": 0.0005,
      "step": 3358
    },
    {
      "epoch": 13.01937984496124,
      "grad_norm": 0.005338563583791256,
      "learning_rate": 3.698062015503876e-05,
      "loss": 0.0004,
      "step": 3359
    },
    {
      "epoch": 13.023255813953488,
      "grad_norm": 0.007494671735912561,
      "learning_rate": 3.697674418604651e-05,
      "loss": 0.0004,
      "step": 3360
    },
    {
      "epoch": 13.027131782945736,
      "grad_norm": 5.309138298034668,
      "learning_rate": 3.6972868217054265e-05,
      "loss": 0.0226,
      "step": 3361
    },
    {
      "epoch": 13.031007751937985,
      "grad_norm": 0.5318320989608765,
      "learning_rate": 3.696899224806202e-05,
      "loss": 0.0066,
      "step": 3362
    },
    {
      "epoch": 13.034883720930232,
      "grad_norm": 0.11473872512578964,
      "learning_rate": 3.696511627906977e-05,
      "loss": 0.0009,
      "step": 3363
    },
    {
      "epoch": 13.03875968992248,
      "grad_norm": 0.025021443143486977,
      "learning_rate": 3.696124031007752e-05,
      "loss": 0.0006,
      "step": 3364
    },
    {
      "epoch": 13.042635658914728,
      "grad_norm": 0.05828503146767616,
      "learning_rate": 3.695736434108527e-05,
      "loss": 0.0011,
      "step": 3365
    },
    {
      "epoch": 13.046511627906977,
      "grad_norm": 0.07617127150297165,
      "learning_rate": 3.695348837209303e-05,
      "loss": 0.0028,
      "step": 3366
    },
    {
      "epoch": 13.050387596899224,
      "grad_norm": 0.029395466670393944,
      "learning_rate": 3.694961240310077e-05,
      "loss": 0.0013,
      "step": 3367
    },
    {
      "epoch": 13.054263565891473,
      "grad_norm": 0.578529417514801,
      "learning_rate": 3.694573643410853e-05,
      "loss": 0.0042,
      "step": 3368
    },
    {
      "epoch": 13.05813953488372,
      "grad_norm": 0.01171674020588398,
      "learning_rate": 3.694186046511628e-05,
      "loss": 0.0005,
      "step": 3369
    },
    {
      "epoch": 13.062015503875969,
      "grad_norm": 0.007134608458727598,
      "learning_rate": 3.693798449612404e-05,
      "loss": 0.0004,
      "step": 3370
    },
    {
      "epoch": 13.065891472868216,
      "grad_norm": 0.0043020895682275295,
      "learning_rate": 3.693410852713178e-05,
      "loss": 0.0003,
      "step": 3371
    },
    {
      "epoch": 13.069767441860465,
      "grad_norm": 20.3398380279541,
      "learning_rate": 3.6930232558139535e-05,
      "loss": 0.2344,
      "step": 3372
    },
    {
      "epoch": 13.073643410852712,
      "grad_norm": 0.04054150730371475,
      "learning_rate": 3.692635658914729e-05,
      "loss": 0.0026,
      "step": 3373
    },
    {
      "epoch": 13.077519379844961,
      "grad_norm": 2.8661413192749023,
      "learning_rate": 3.692248062015504e-05,
      "loss": 0.1096,
      "step": 3374
    },
    {
      "epoch": 13.081395348837209,
      "grad_norm": 0.008831637911498547,
      "learning_rate": 3.691860465116279e-05,
      "loss": 0.0006,
      "step": 3375
    },
    {
      "epoch": 13.085271317829458,
      "grad_norm": 0.004048259928822517,
      "learning_rate": 3.6914728682170545e-05,
      "loss": 0.0003,
      "step": 3376
    },
    {
      "epoch": 13.089147286821705,
      "grad_norm": 0.013513422571122646,
      "learning_rate": 3.69108527131783e-05,
      "loss": 0.0004,
      "step": 3377
    },
    {
      "epoch": 13.093023255813954,
      "grad_norm": 0.8468078970909119,
      "learning_rate": 3.690697674418605e-05,
      "loss": 0.0101,
      "step": 3378
    },
    {
      "epoch": 13.0968992248062,
      "grad_norm": 0.02975812368094921,
      "learning_rate": 3.69031007751938e-05,
      "loss": 0.0016,
      "step": 3379
    },
    {
      "epoch": 13.10077519379845,
      "grad_norm": 0.003299623029306531,
      "learning_rate": 3.6899224806201554e-05,
      "loss": 0.0003,
      "step": 3380
    },
    {
      "epoch": 13.104651162790697,
      "grad_norm": 0.0034883248154073954,
      "learning_rate": 3.689534883720931e-05,
      "loss": 0.0003,
      "step": 3381
    },
    {
      "epoch": 13.108527131782946,
      "grad_norm": 0.004700352903455496,
      "learning_rate": 3.689147286821706e-05,
      "loss": 0.0003,
      "step": 3382
    },
    {
      "epoch": 13.112403100775193,
      "grad_norm": 4.260137557983398,
      "learning_rate": 3.6887596899224805e-05,
      "loss": 0.1187,
      "step": 3383
    },
    {
      "epoch": 13.116279069767442,
      "grad_norm": 0.0033368661534041166,
      "learning_rate": 3.6883720930232564e-05,
      "loss": 0.0003,
      "step": 3384
    },
    {
      "epoch": 13.12015503875969,
      "grad_norm": 0.025584986433386803,
      "learning_rate": 3.687984496124031e-05,
      "loss": 0.0008,
      "step": 3385
    },
    {
      "epoch": 13.124031007751938,
      "grad_norm": 0.004447996150702238,
      "learning_rate": 3.687596899224806e-05,
      "loss": 0.0004,
      "step": 3386
    },
    {
      "epoch": 13.127906976744185,
      "grad_norm": 0.0029832571744918823,
      "learning_rate": 3.6872093023255814e-05,
      "loss": 0.0003,
      "step": 3387
    },
    {
      "epoch": 13.131782945736434,
      "grad_norm": 0.006150231231004,
      "learning_rate": 3.686821705426357e-05,
      "loss": 0.0004,
      "step": 3388
    },
    {
      "epoch": 13.135658914728682,
      "grad_norm": 0.0046341088600456715,
      "learning_rate": 3.686434108527132e-05,
      "loss": 0.0003,
      "step": 3389
    },
    {
      "epoch": 13.13953488372093,
      "grad_norm": 0.0037561787758022547,
      "learning_rate": 3.686046511627907e-05,
      "loss": 0.0003,
      "step": 3390
    },
    {
      "epoch": 13.143410852713178,
      "grad_norm": 16.98859977722168,
      "learning_rate": 3.6856589147286824e-05,
      "loss": 0.8289,
      "step": 3391
    },
    {
      "epoch": 13.147286821705427,
      "grad_norm": 0.003197982907295227,
      "learning_rate": 3.6852713178294577e-05,
      "loss": 0.0003,
      "step": 3392
    },
    {
      "epoch": 13.151162790697674,
      "grad_norm": 0.008748841471970081,
      "learning_rate": 3.684883720930233e-05,
      "loss": 0.0007,
      "step": 3393
    },
    {
      "epoch": 13.155038759689923,
      "grad_norm": 1.9808489084243774,
      "learning_rate": 3.6844961240310075e-05,
      "loss": 0.2254,
      "step": 3394
    },
    {
      "epoch": 13.15891472868217,
      "grad_norm": 0.0042913225479424,
      "learning_rate": 3.6841085271317834e-05,
      "loss": 0.0003,
      "step": 3395
    },
    {
      "epoch": 13.162790697674419,
      "grad_norm": 6.312513828277588,
      "learning_rate": 3.683720930232558e-05,
      "loss": 0.2991,
      "step": 3396
    },
    {
      "epoch": 13.166666666666666,
      "grad_norm": 0.003671971382573247,
      "learning_rate": 3.683333333333334e-05,
      "loss": 0.0003,
      "step": 3397
    },
    {
      "epoch": 13.170542635658915,
      "grad_norm": 0.012883632443845272,
      "learning_rate": 3.6829457364341084e-05,
      "loss": 0.0006,
      "step": 3398
    },
    {
      "epoch": 13.174418604651162,
      "grad_norm": 0.22748532891273499,
      "learning_rate": 3.6825581395348844e-05,
      "loss": 0.0027,
      "step": 3399
    },
    {
      "epoch": 13.178294573643411,
      "grad_norm": 0.04094848781824112,
      "learning_rate": 3.682170542635659e-05,
      "loss": 0.0011,
      "step": 3400
    },
    {
      "epoch": 13.182170542635658,
      "grad_norm": 0.0037151805590838194,
      "learning_rate": 3.681782945736434e-05,
      "loss": 0.0003,
      "step": 3401
    },
    {
      "epoch": 13.186046511627907,
      "grad_norm": 7.967408180236816,
      "learning_rate": 3.6813953488372094e-05,
      "loss": 0.0976,
      "step": 3402
    },
    {
      "epoch": 13.189922480620154,
      "grad_norm": 0.023549214005470276,
      "learning_rate": 3.6810077519379846e-05,
      "loss": 0.0009,
      "step": 3403
    },
    {
      "epoch": 13.193798449612403,
      "grad_norm": 21.335657119750977,
      "learning_rate": 3.68062015503876e-05,
      "loss": 0.3813,
      "step": 3404
    },
    {
      "epoch": 13.19767441860465,
      "grad_norm": 0.022270487621426582,
      "learning_rate": 3.680232558139535e-05,
      "loss": 0.0008,
      "step": 3405
    },
    {
      "epoch": 13.2015503875969,
      "grad_norm": 0.0047352309338748455,
      "learning_rate": 3.6798449612403104e-05,
      "loss": 0.0004,
      "step": 3406
    },
    {
      "epoch": 13.205426356589147,
      "grad_norm": 0.27506425976753235,
      "learning_rate": 3.6794573643410856e-05,
      "loss": 0.0022,
      "step": 3407
    },
    {
      "epoch": 13.209302325581396,
      "grad_norm": 0.0062239873223006725,
      "learning_rate": 3.679069767441861e-05,
      "loss": 0.0004,
      "step": 3408
    },
    {
      "epoch": 13.213178294573643,
      "grad_norm": 0.0032331570982933044,
      "learning_rate": 3.678682170542636e-05,
      "loss": 0.0003,
      "step": 3409
    },
    {
      "epoch": 13.217054263565892,
      "grad_norm": 0.03653738275170326,
      "learning_rate": 3.6782945736434113e-05,
      "loss": 0.001,
      "step": 3410
    },
    {
      "epoch": 13.220930232558139,
      "grad_norm": 0.0031750774942338467,
      "learning_rate": 3.6779069767441866e-05,
      "loss": 0.0003,
      "step": 3411
    },
    {
      "epoch": 13.224806201550388,
      "grad_norm": 0.0047351340763270855,
      "learning_rate": 3.677519379844961e-05,
      "loss": 0.0003,
      "step": 3412
    },
    {
      "epoch": 13.228682170542635,
      "grad_norm": 0.004527998622506857,
      "learning_rate": 3.6771317829457364e-05,
      "loss": 0.0003,
      "step": 3413
    },
    {
      "epoch": 13.232558139534884,
      "grad_norm": 0.0041047376580536366,
      "learning_rate": 3.6767441860465116e-05,
      "loss": 0.0003,
      "step": 3414
    },
    {
      "epoch": 13.236434108527131,
      "grad_norm": 0.01312124915421009,
      "learning_rate": 3.676356589147287e-05,
      "loss": 0.0006,
      "step": 3415
    },
    {
      "epoch": 13.24031007751938,
      "grad_norm": 0.005231366492807865,
      "learning_rate": 3.675968992248062e-05,
      "loss": 0.0003,
      "step": 3416
    },
    {
      "epoch": 13.244186046511627,
      "grad_norm": 0.1954745352268219,
      "learning_rate": 3.6755813953488374e-05,
      "loss": 0.005,
      "step": 3417
    },
    {
      "epoch": 13.248062015503876,
      "grad_norm": 0.021299663931131363,
      "learning_rate": 3.6751937984496126e-05,
      "loss": 0.0006,
      "step": 3418
    },
    {
      "epoch": 13.251937984496124,
      "grad_norm": 0.003090218873694539,
      "learning_rate": 3.674806201550388e-05,
      "loss": 0.0003,
      "step": 3419
    },
    {
      "epoch": 13.255813953488373,
      "grad_norm": 0.8830428123474121,
      "learning_rate": 3.674418604651163e-05,
      "loss": 0.0289,
      "step": 3420
    },
    {
      "epoch": 13.25968992248062,
      "grad_norm": 0.017039595171809196,
      "learning_rate": 3.6740310077519376e-05,
      "loss": 0.0009,
      "step": 3421
    },
    {
      "epoch": 13.263565891472869,
      "grad_norm": 1.7575126886367798,
      "learning_rate": 3.6736434108527136e-05,
      "loss": 0.194,
      "step": 3422
    },
    {
      "epoch": 13.267441860465116,
      "grad_norm": 0.003691532649099827,
      "learning_rate": 3.673255813953488e-05,
      "loss": 0.0003,
      "step": 3423
    },
    {
      "epoch": 13.271317829457365,
      "grad_norm": 0.024746306240558624,
      "learning_rate": 3.672868217054264e-05,
      "loss": 0.0013,
      "step": 3424
    },
    {
      "epoch": 13.275193798449612,
      "grad_norm": 0.04662943631410599,
      "learning_rate": 3.6724806201550386e-05,
      "loss": 0.001,
      "step": 3425
    },
    {
      "epoch": 13.279069767441861,
      "grad_norm": 0.04554726183414459,
      "learning_rate": 3.6720930232558145e-05,
      "loss": 0.0008,
      "step": 3426
    },
    {
      "epoch": 13.282945736434108,
      "grad_norm": 2.199397563934326,
      "learning_rate": 3.671705426356589e-05,
      "loss": 0.0071,
      "step": 3427
    },
    {
      "epoch": 13.286821705426357,
      "grad_norm": 0.017026912420988083,
      "learning_rate": 3.671317829457365e-05,
      "loss": 0.001,
      "step": 3428
    },
    {
      "epoch": 13.290697674418604,
      "grad_norm": 0.002885297406464815,
      "learning_rate": 3.6709302325581396e-05,
      "loss": 0.0003,
      "step": 3429
    },
    {
      "epoch": 13.294573643410853,
      "grad_norm": 0.008536899462342262,
      "learning_rate": 3.670542635658915e-05,
      "loss": 0.0004,
      "step": 3430
    },
    {
      "epoch": 13.2984496124031,
      "grad_norm": 0.00724117923527956,
      "learning_rate": 3.67015503875969e-05,
      "loss": 0.0004,
      "step": 3431
    },
    {
      "epoch": 13.30232558139535,
      "grad_norm": 0.005258525721728802,
      "learning_rate": 3.669767441860465e-05,
      "loss": 0.0003,
      "step": 3432
    },
    {
      "epoch": 13.306201550387597,
      "grad_norm": 0.0036425082944333553,
      "learning_rate": 3.6693798449612406e-05,
      "loss": 0.0003,
      "step": 3433
    },
    {
      "epoch": 13.310077519379846,
      "grad_norm": 16.519500732421875,
      "learning_rate": 3.668992248062016e-05,
      "loss": 0.547,
      "step": 3434
    },
    {
      "epoch": 13.313953488372093,
      "grad_norm": 0.002510786522179842,
      "learning_rate": 3.668604651162791e-05,
      "loss": 0.0002,
      "step": 3435
    },
    {
      "epoch": 13.317829457364342,
      "grad_norm": 6.319100856781006,
      "learning_rate": 3.668217054263566e-05,
      "loss": 1.0396,
      "step": 3436
    },
    {
      "epoch": 13.321705426356589,
      "grad_norm": 0.0033765893895179033,
      "learning_rate": 3.6678294573643415e-05,
      "loss": 0.0003,
      "step": 3437
    },
    {
      "epoch": 13.325581395348838,
      "grad_norm": 0.0031993279699236155,
      "learning_rate": 3.667441860465117e-05,
      "loss": 0.0003,
      "step": 3438
    },
    {
      "epoch": 13.329457364341085,
      "grad_norm": 0.019933171570301056,
      "learning_rate": 3.667054263565891e-05,
      "loss": 0.0007,
      "step": 3439
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 0.0034756851382553577,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.0003,
      "step": 3440
    },
    {
      "epoch": 13.337209302325581,
      "grad_norm": 0.004862439818680286,
      "learning_rate": 3.666279069767442e-05,
      "loss": 0.0004,
      "step": 3441
    },
    {
      "epoch": 13.34108527131783,
      "grad_norm": 5.369354248046875,
      "learning_rate": 3.665891472868217e-05,
      "loss": 0.2995,
      "step": 3442
    },
    {
      "epoch": 13.344961240310077,
      "grad_norm": 0.21609526872634888,
      "learning_rate": 3.665503875968992e-05,
      "loss": 0.0006,
      "step": 3443
    },
    {
      "epoch": 13.348837209302326,
      "grad_norm": 17.217233657836914,
      "learning_rate": 3.6651162790697675e-05,
      "loss": 0.3415,
      "step": 3444
    },
    {
      "epoch": 13.352713178294573,
      "grad_norm": 0.009331420063972473,
      "learning_rate": 3.664728682170543e-05,
      "loss": 0.0005,
      "step": 3445
    },
    {
      "epoch": 13.356589147286822,
      "grad_norm": 0.025669770315289497,
      "learning_rate": 3.664341085271318e-05,
      "loss": 0.0008,
      "step": 3446
    },
    {
      "epoch": 13.36046511627907,
      "grad_norm": 0.024177776649594307,
      "learning_rate": 3.663953488372093e-05,
      "loss": 0.001,
      "step": 3447
    },
    {
      "epoch": 13.364341085271318,
      "grad_norm": 0.018505217507481575,
      "learning_rate": 3.6635658914728685e-05,
      "loss": 0.0007,
      "step": 3448
    },
    {
      "epoch": 13.368217054263566,
      "grad_norm": 11.655884742736816,
      "learning_rate": 3.663178294573644e-05,
      "loss": 0.434,
      "step": 3449
    },
    {
      "epoch": 13.372093023255815,
      "grad_norm": 0.3449721932411194,
      "learning_rate": 3.662790697674418e-05,
      "loss": 0.0028,
      "step": 3450
    },
    {
      "epoch": 13.375968992248062,
      "grad_norm": 0.14849917590618134,
      "learning_rate": 3.662403100775194e-05,
      "loss": 0.0046,
      "step": 3451
    },
    {
      "epoch": 13.37984496124031,
      "grad_norm": 0.00647227605804801,
      "learning_rate": 3.662015503875969e-05,
      "loss": 0.0004,
      "step": 3452
    },
    {
      "epoch": 13.383720930232558,
      "grad_norm": 0.013909241184592247,
      "learning_rate": 3.661627906976745e-05,
      "loss": 0.0006,
      "step": 3453
    },
    {
      "epoch": 13.387596899224807,
      "grad_norm": 0.013891296461224556,
      "learning_rate": 3.661240310077519e-05,
      "loss": 0.0006,
      "step": 3454
    },
    {
      "epoch": 13.391472868217054,
      "grad_norm": 0.010453629307448864,
      "learning_rate": 3.660852713178295e-05,
      "loss": 0.0005,
      "step": 3455
    },
    {
      "epoch": 13.395348837209303,
      "grad_norm": 25.007522583007812,
      "learning_rate": 3.66046511627907e-05,
      "loss": 0.2607,
      "step": 3456
    },
    {
      "epoch": 13.39922480620155,
      "grad_norm": 4.721836090087891,
      "learning_rate": 3.660077519379845e-05,
      "loss": 0.5496,
      "step": 3457
    },
    {
      "epoch": 13.4031007751938,
      "grad_norm": 0.04044730216264725,
      "learning_rate": 3.65968992248062e-05,
      "loss": 0.0014,
      "step": 3458
    },
    {
      "epoch": 13.406976744186046,
      "grad_norm": 0.11530593782663345,
      "learning_rate": 3.6593023255813955e-05,
      "loss": 0.0023,
      "step": 3459
    },
    {
      "epoch": 13.410852713178295,
      "grad_norm": 0.055795855820178986,
      "learning_rate": 3.658914728682171e-05,
      "loss": 0.0015,
      "step": 3460
    },
    {
      "epoch": 13.414728682170542,
      "grad_norm": 0.3302314877510071,
      "learning_rate": 3.658527131782946e-05,
      "loss": 0.0051,
      "step": 3461
    },
    {
      "epoch": 13.418604651162791,
      "grad_norm": 1.6451301574707031,
      "learning_rate": 3.658139534883721e-05,
      "loss": 0.0734,
      "step": 3462
    },
    {
      "epoch": 13.422480620155039,
      "grad_norm": 0.2817070484161377,
      "learning_rate": 3.6577519379844965e-05,
      "loss": 0.0069,
      "step": 3463
    },
    {
      "epoch": 13.426356589147288,
      "grad_norm": 0.12367235869169235,
      "learning_rate": 3.657364341085272e-05,
      "loss": 0.003,
      "step": 3464
    },
    {
      "epoch": 13.430232558139535,
      "grad_norm": 1.783922791481018,
      "learning_rate": 3.656976744186046e-05,
      "loss": 0.0433,
      "step": 3465
    },
    {
      "epoch": 13.434108527131784,
      "grad_norm": 0.8531976938247681,
      "learning_rate": 3.656589147286822e-05,
      "loss": 0.0228,
      "step": 3466
    },
    {
      "epoch": 13.437984496124031,
      "grad_norm": 0.02874494157731533,
      "learning_rate": 3.656201550387597e-05,
      "loss": 0.0014,
      "step": 3467
    },
    {
      "epoch": 13.44186046511628,
      "grad_norm": 0.032917480915784836,
      "learning_rate": 3.655813953488372e-05,
      "loss": 0.0012,
      "step": 3468
    },
    {
      "epoch": 13.445736434108527,
      "grad_norm": 4.572145462036133,
      "learning_rate": 3.655426356589147e-05,
      "loss": 0.1814,
      "step": 3469
    },
    {
      "epoch": 13.449612403100776,
      "grad_norm": 0.00637190043926239,
      "learning_rate": 3.6550387596899225e-05,
      "loss": 0.0004,
      "step": 3470
    },
    {
      "epoch": 13.453488372093023,
      "grad_norm": 0.031237222254276276,
      "learning_rate": 3.654651162790698e-05,
      "loss": 0.001,
      "step": 3471
    },
    {
      "epoch": 13.457364341085272,
      "grad_norm": 0.03561806306242943,
      "learning_rate": 3.654263565891473e-05,
      "loss": 0.001,
      "step": 3472
    },
    {
      "epoch": 13.46124031007752,
      "grad_norm": 1.0208988189697266,
      "learning_rate": 3.653875968992248e-05,
      "loss": 0.0234,
      "step": 3473
    },
    {
      "epoch": 13.465116279069768,
      "grad_norm": 0.057092346251010895,
      "learning_rate": 3.6534883720930234e-05,
      "loss": 0.001,
      "step": 3474
    },
    {
      "epoch": 13.468992248062015,
      "grad_norm": 0.0032081282697618008,
      "learning_rate": 3.653100775193799e-05,
      "loss": 0.0003,
      "step": 3475
    },
    {
      "epoch": 13.472868217054264,
      "grad_norm": 17.392410278320312,
      "learning_rate": 3.652713178294574e-05,
      "loss": 0.453,
      "step": 3476
    },
    {
      "epoch": 13.476744186046512,
      "grad_norm": 0.006159804295748472,
      "learning_rate": 3.652325581395349e-05,
      "loss": 0.0004,
      "step": 3477
    },
    {
      "epoch": 13.48062015503876,
      "grad_norm": 9.160459518432617,
      "learning_rate": 3.6519379844961244e-05,
      "loss": 1.0542,
      "step": 3478
    },
    {
      "epoch": 13.484496124031008,
      "grad_norm": 0.004584436770528555,
      "learning_rate": 3.651550387596899e-05,
      "loss": 0.0003,
      "step": 3479
    },
    {
      "epoch": 13.488372093023255,
      "grad_norm": 0.2228206843137741,
      "learning_rate": 3.651162790697675e-05,
      "loss": 0.0031,
      "step": 3480
    },
    {
      "epoch": 13.492248062015504,
      "grad_norm": 0.19756895303726196,
      "learning_rate": 3.6507751937984495e-05,
      "loss": 0.0068,
      "step": 3481
    },
    {
      "epoch": 13.496124031007753,
      "grad_norm": 0.004672430921345949,
      "learning_rate": 3.6503875968992254e-05,
      "loss": 0.0003,
      "step": 3482
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.007035576272755861,
      "learning_rate": 3.65e-05,
      "loss": 0.0004,
      "step": 3483
    },
    {
      "epoch": 13.503875968992247,
      "grad_norm": 0.09689158946275711,
      "learning_rate": 3.649612403100776e-05,
      "loss": 0.0009,
      "step": 3484
    },
    {
      "epoch": 13.507751937984496,
      "grad_norm": 0.0072057126089930534,
      "learning_rate": 3.6492248062015504e-05,
      "loss": 0.0005,
      "step": 3485
    },
    {
      "epoch": 13.511627906976745,
      "grad_norm": 0.013345721177756786,
      "learning_rate": 3.648837209302326e-05,
      "loss": 0.0009,
      "step": 3486
    },
    {
      "epoch": 13.515503875968992,
      "grad_norm": 0.00622587138786912,
      "learning_rate": 3.648449612403101e-05,
      "loss": 0.0005,
      "step": 3487
    },
    {
      "epoch": 13.51937984496124,
      "grad_norm": 3.4348552227020264,
      "learning_rate": 3.648062015503876e-05,
      "loss": 0.0462,
      "step": 3488
    },
    {
      "epoch": 13.523255813953488,
      "grad_norm": 6.473760604858398,
      "learning_rate": 3.6476744186046514e-05,
      "loss": 0.0189,
      "step": 3489
    },
    {
      "epoch": 13.527131782945737,
      "grad_norm": 10.508219718933105,
      "learning_rate": 3.6472868217054266e-05,
      "loss": 0.9193,
      "step": 3490
    },
    {
      "epoch": 13.531007751937985,
      "grad_norm": 0.026692863553762436,
      "learning_rate": 3.646899224806202e-05,
      "loss": 0.0007,
      "step": 3491
    },
    {
      "epoch": 13.534883720930232,
      "grad_norm": 0.07672332227230072,
      "learning_rate": 3.6465116279069765e-05,
      "loss": 0.0015,
      "step": 3492
    },
    {
      "epoch": 13.53875968992248,
      "grad_norm": 0.08723927289247513,
      "learning_rate": 3.6461240310077524e-05,
      "loss": 0.0019,
      "step": 3493
    },
    {
      "epoch": 13.542635658914728,
      "grad_norm": 2.998692750930786,
      "learning_rate": 3.645736434108527e-05,
      "loss": 0.0234,
      "step": 3494
    },
    {
      "epoch": 13.546511627906977,
      "grad_norm": 0.2024608701467514,
      "learning_rate": 3.645348837209303e-05,
      "loss": 0.0058,
      "step": 3495
    },
    {
      "epoch": 13.550387596899224,
      "grad_norm": 1.5085419416427612,
      "learning_rate": 3.6449612403100774e-05,
      "loss": 0.0822,
      "step": 3496
    },
    {
      "epoch": 13.554263565891473,
      "grad_norm": 0.13948586583137512,
      "learning_rate": 3.644573643410853e-05,
      "loss": 0.0036,
      "step": 3497
    },
    {
      "epoch": 13.55813953488372,
      "grad_norm": 0.13949927687644958,
      "learning_rate": 3.644186046511628e-05,
      "loss": 0.0038,
      "step": 3498
    },
    {
      "epoch": 13.562015503875969,
      "grad_norm": 2.8555748462677,
      "learning_rate": 3.643798449612403e-05,
      "loss": 0.213,
      "step": 3499
    },
    {
      "epoch": 13.565891472868216,
      "grad_norm": 0.016516564413905144,
      "learning_rate": 3.6434108527131784e-05,
      "loss": 0.0007,
      "step": 3500
    },
    {
      "epoch": 13.569767441860465,
      "grad_norm": 13.095051765441895,
      "learning_rate": 3.6430232558139536e-05,
      "loss": 0.1036,
      "step": 3501
    },
    {
      "epoch": 13.573643410852712,
      "grad_norm": 0.028848255053162575,
      "learning_rate": 3.642635658914729e-05,
      "loss": 0.0008,
      "step": 3502
    },
    {
      "epoch": 13.577519379844961,
      "grad_norm": 14.437870979309082,
      "learning_rate": 3.642248062015504e-05,
      "loss": 1.502,
      "step": 3503
    },
    {
      "epoch": 13.581395348837209,
      "grad_norm": 0.09329879283905029,
      "learning_rate": 3.6418604651162794e-05,
      "loss": 0.001,
      "step": 3504
    },
    {
      "epoch": 13.585271317829458,
      "grad_norm": 0.13817331194877625,
      "learning_rate": 3.6414728682170546e-05,
      "loss": 0.0025,
      "step": 3505
    },
    {
      "epoch": 13.589147286821705,
      "grad_norm": 0.010380922816693783,
      "learning_rate": 3.64108527131783e-05,
      "loss": 0.0005,
      "step": 3506
    },
    {
      "epoch": 13.593023255813954,
      "grad_norm": 0.008072002790868282,
      "learning_rate": 3.640697674418605e-05,
      "loss": 0.0004,
      "step": 3507
    },
    {
      "epoch": 13.5968992248062,
      "grad_norm": 0.7417645454406738,
      "learning_rate": 3.6403100775193797e-05,
      "loss": 0.0132,
      "step": 3508
    },
    {
      "epoch": 13.60077519379845,
      "grad_norm": 0.018859073519706726,
      "learning_rate": 3.6399224806201556e-05,
      "loss": 0.0007,
      "step": 3509
    },
    {
      "epoch": 13.604651162790697,
      "grad_norm": 3.2256886959075928,
      "learning_rate": 3.63953488372093e-05,
      "loss": 0.5812,
      "step": 3510
    },
    {
      "epoch": 13.608527131782946,
      "grad_norm": 0.007688365411013365,
      "learning_rate": 3.639147286821706e-05,
      "loss": 0.0004,
      "step": 3511
    },
    {
      "epoch": 13.612403100775193,
      "grad_norm": 0.3925456404685974,
      "learning_rate": 3.6387596899224806e-05,
      "loss": 0.0024,
      "step": 3512
    },
    {
      "epoch": 13.616279069767442,
      "grad_norm": 0.1864161193370819,
      "learning_rate": 3.6383720930232565e-05,
      "loss": 0.0009,
      "step": 3513
    },
    {
      "epoch": 13.62015503875969,
      "grad_norm": 0.028830844908952713,
      "learning_rate": 3.637984496124031e-05,
      "loss": 0.0011,
      "step": 3514
    },
    {
      "epoch": 13.624031007751938,
      "grad_norm": 0.016352569684386253,
      "learning_rate": 3.6375968992248063e-05,
      "loss": 0.0007,
      "step": 3515
    },
    {
      "epoch": 13.627906976744185,
      "grad_norm": 0.007895165123045444,
      "learning_rate": 3.6372093023255816e-05,
      "loss": 0.0005,
      "step": 3516
    },
    {
      "epoch": 13.631782945736434,
      "grad_norm": 0.02113770693540573,
      "learning_rate": 3.636821705426357e-05,
      "loss": 0.0006,
      "step": 3517
    },
    {
      "epoch": 13.635658914728682,
      "grad_norm": 201.33909606933594,
      "learning_rate": 3.636434108527132e-05,
      "loss": 0.2092,
      "step": 3518
    },
    {
      "epoch": 13.63953488372093,
      "grad_norm": 0.031077755615115166,
      "learning_rate": 3.6360465116279066e-05,
      "loss": 0.0008,
      "step": 3519
    },
    {
      "epoch": 13.643410852713178,
      "grad_norm": 18.240793228149414,
      "learning_rate": 3.6356589147286826e-05,
      "loss": 1.0182,
      "step": 3520
    },
    {
      "epoch": 13.647286821705427,
      "grad_norm": 11.325482368469238,
      "learning_rate": 3.635271317829457e-05,
      "loss": 0.011,
      "step": 3521
    },
    {
      "epoch": 13.651162790697674,
      "grad_norm": 0.043499190360307693,
      "learning_rate": 3.634883720930233e-05,
      "loss": 0.0009,
      "step": 3522
    },
    {
      "epoch": 13.655038759689923,
      "grad_norm": 0.08128350228071213,
      "learning_rate": 3.6344961240310076e-05,
      "loss": 0.0016,
      "step": 3523
    },
    {
      "epoch": 13.65891472868217,
      "grad_norm": 0.021148821339011192,
      "learning_rate": 3.634108527131783e-05,
      "loss": 0.0015,
      "step": 3524
    },
    {
      "epoch": 13.662790697674419,
      "grad_norm": 0.14795565605163574,
      "learning_rate": 3.633720930232558e-05,
      "loss": 0.0012,
      "step": 3525
    },
    {
      "epoch": 13.666666666666666,
      "grad_norm": 0.03359859064221382,
      "learning_rate": 3.633333333333333e-05,
      "loss": 0.002,
      "step": 3526
    },
    {
      "epoch": 13.670542635658915,
      "grad_norm": 0.9611731171607971,
      "learning_rate": 3.6329457364341086e-05,
      "loss": 0.0064,
      "step": 3527
    },
    {
      "epoch": 13.674418604651162,
      "grad_norm": 0.03877368941903114,
      "learning_rate": 3.632558139534884e-05,
      "loss": 0.0008,
      "step": 3528
    },
    {
      "epoch": 13.678294573643411,
      "grad_norm": 0.0036283403169363737,
      "learning_rate": 3.632170542635659e-05,
      "loss": 0.0003,
      "step": 3529
    },
    {
      "epoch": 13.682170542635658,
      "grad_norm": 19.81106185913086,
      "learning_rate": 3.631782945736434e-05,
      "loss": 0.2184,
      "step": 3530
    },
    {
      "epoch": 13.686046511627907,
      "grad_norm": 27.068151473999023,
      "learning_rate": 3.6313953488372095e-05,
      "loss": 0.2527,
      "step": 3531
    },
    {
      "epoch": 13.689922480620154,
      "grad_norm": 9.988350868225098,
      "learning_rate": 3.631007751937985e-05,
      "loss": 0.0282,
      "step": 3532
    },
    {
      "epoch": 13.693798449612403,
      "grad_norm": 0.004703697748482227,
      "learning_rate": 3.63062015503876e-05,
      "loss": 0.0003,
      "step": 3533
    },
    {
      "epoch": 13.69767441860465,
      "grad_norm": 0.004709157627075911,
      "learning_rate": 3.630232558139535e-05,
      "loss": 0.0003,
      "step": 3534
    },
    {
      "epoch": 13.7015503875969,
      "grad_norm": 0.020768608897924423,
      "learning_rate": 3.62984496124031e-05,
      "loss": 0.0006,
      "step": 3535
    },
    {
      "epoch": 13.705426356589147,
      "grad_norm": 4.7107133865356445,
      "learning_rate": 3.629457364341086e-05,
      "loss": 0.0945,
      "step": 3536
    },
    {
      "epoch": 13.709302325581396,
      "grad_norm": 0.0037859519943594933,
      "learning_rate": 3.62906976744186e-05,
      "loss": 0.0003,
      "step": 3537
    },
    {
      "epoch": 13.713178294573643,
      "grad_norm": 0.0059621334075927734,
      "learning_rate": 3.628682170542636e-05,
      "loss": 0.0003,
      "step": 3538
    },
    {
      "epoch": 13.717054263565892,
      "grad_norm": 0.07352891564369202,
      "learning_rate": 3.628294573643411e-05,
      "loss": 0.0027,
      "step": 3539
    },
    {
      "epoch": 13.720930232558139,
      "grad_norm": 0.005434777121990919,
      "learning_rate": 3.627906976744187e-05,
      "loss": 0.0003,
      "step": 3540
    },
    {
      "epoch": 13.724806201550388,
      "grad_norm": 4.358122825622559,
      "learning_rate": 3.627519379844961e-05,
      "loss": 0.4316,
      "step": 3541
    },
    {
      "epoch": 13.728682170542635,
      "grad_norm": 0.004902312532067299,
      "learning_rate": 3.6271317829457365e-05,
      "loss": 0.0004,
      "step": 3542
    },
    {
      "epoch": 13.732558139534884,
      "grad_norm": 17.64162254333496,
      "learning_rate": 3.626744186046512e-05,
      "loss": 0.2308,
      "step": 3543
    },
    {
      "epoch": 13.736434108527131,
      "grad_norm": 0.0033969006035476923,
      "learning_rate": 3.626356589147287e-05,
      "loss": 0.0003,
      "step": 3544
    },
    {
      "epoch": 13.74031007751938,
      "grad_norm": 0.029539627954363823,
      "learning_rate": 3.625968992248062e-05,
      "loss": 0.0018,
      "step": 3545
    },
    {
      "epoch": 13.744186046511627,
      "grad_norm": 0.13731913268566132,
      "learning_rate": 3.625581395348837e-05,
      "loss": 0.0028,
      "step": 3546
    },
    {
      "epoch": 13.748062015503876,
      "grad_norm": 0.0545838288962841,
      "learning_rate": 3.625193798449613e-05,
      "loss": 0.0006,
      "step": 3547
    },
    {
      "epoch": 13.751937984496124,
      "grad_norm": 0.004726523067802191,
      "learning_rate": 3.624806201550387e-05,
      "loss": 0.0004,
      "step": 3548
    },
    {
      "epoch": 13.755813953488373,
      "grad_norm": 0.00434077437967062,
      "learning_rate": 3.624418604651163e-05,
      "loss": 0.0003,
      "step": 3549
    },
    {
      "epoch": 13.75968992248062,
      "grad_norm": 0.04869452863931656,
      "learning_rate": 3.624031007751938e-05,
      "loss": 0.002,
      "step": 3550
    },
    {
      "epoch": 13.763565891472869,
      "grad_norm": 0.0033016724046319723,
      "learning_rate": 3.623643410852714e-05,
      "loss": 0.0003,
      "step": 3551
    },
    {
      "epoch": 13.767441860465116,
      "grad_norm": 0.008725927211344242,
      "learning_rate": 3.623255813953488e-05,
      "loss": 0.0007,
      "step": 3552
    },
    {
      "epoch": 13.771317829457365,
      "grad_norm": 0.047845449298620224,
      "learning_rate": 3.6228682170542635e-05,
      "loss": 0.002,
      "step": 3553
    },
    {
      "epoch": 13.775193798449612,
      "grad_norm": 0.07175493985414505,
      "learning_rate": 3.622480620155039e-05,
      "loss": 0.0011,
      "step": 3554
    },
    {
      "epoch": 13.779069767441861,
      "grad_norm": 0.09577812999486923,
      "learning_rate": 3.622093023255814e-05,
      "loss": 0.0019,
      "step": 3555
    },
    {
      "epoch": 13.782945736434108,
      "grad_norm": 0.004746303427964449,
      "learning_rate": 3.621705426356589e-05,
      "loss": 0.0004,
      "step": 3556
    },
    {
      "epoch": 13.786821705426357,
      "grad_norm": 0.01202167198061943,
      "learning_rate": 3.6213178294573645e-05,
      "loss": 0.0008,
      "step": 3557
    },
    {
      "epoch": 13.790697674418604,
      "grad_norm": 0.0031259446404874325,
      "learning_rate": 3.62093023255814e-05,
      "loss": 0.0003,
      "step": 3558
    },
    {
      "epoch": 13.794573643410853,
      "grad_norm": 3.306398391723633,
      "learning_rate": 3.620542635658915e-05,
      "loss": 0.0143,
      "step": 3559
    },
    {
      "epoch": 13.7984496124031,
      "grad_norm": 0.004509663674980402,
      "learning_rate": 3.62015503875969e-05,
      "loss": 0.0004,
      "step": 3560
    },
    {
      "epoch": 13.80232558139535,
      "grad_norm": 0.15407636761665344,
      "learning_rate": 3.6197674418604655e-05,
      "loss": 0.0035,
      "step": 3561
    },
    {
      "epoch": 13.806201550387597,
      "grad_norm": 0.0067213899455964565,
      "learning_rate": 3.619379844961241e-05,
      "loss": 0.0004,
      "step": 3562
    },
    {
      "epoch": 13.810077519379846,
      "grad_norm": 0.03942568600177765,
      "learning_rate": 3.618992248062016e-05,
      "loss": 0.0007,
      "step": 3563
    },
    {
      "epoch": 13.813953488372093,
      "grad_norm": 0.0248298067599535,
      "learning_rate": 3.6186046511627905e-05,
      "loss": 0.0004,
      "step": 3564
    },
    {
      "epoch": 13.817829457364342,
      "grad_norm": 0.011005428619682789,
      "learning_rate": 3.6182170542635664e-05,
      "loss": 0.0003,
      "step": 3565
    },
    {
      "epoch": 13.821705426356589,
      "grad_norm": 0.07595141232013702,
      "learning_rate": 3.617829457364341e-05,
      "loss": 0.0015,
      "step": 3566
    },
    {
      "epoch": 13.825581395348838,
      "grad_norm": 3.344567060470581,
      "learning_rate": 3.617441860465117e-05,
      "loss": 0.1302,
      "step": 3567
    },
    {
      "epoch": 13.829457364341085,
      "grad_norm": 0.003325312165543437,
      "learning_rate": 3.6170542635658915e-05,
      "loss": 0.0002,
      "step": 3568
    },
    {
      "epoch": 13.833333333333334,
      "grad_norm": 3.5729820728302,
      "learning_rate": 3.6166666666666674e-05,
      "loss": 0.0389,
      "step": 3569
    },
    {
      "epoch": 13.837209302325581,
      "grad_norm": 0.006120964419096708,
      "learning_rate": 3.616279069767442e-05,
      "loss": 0.0004,
      "step": 3570
    },
    {
      "epoch": 13.84108527131783,
      "grad_norm": 0.0029408184345811605,
      "learning_rate": 3.615891472868217e-05,
      "loss": 0.0003,
      "step": 3571
    },
    {
      "epoch": 13.844961240310077,
      "grad_norm": 0.03282790631055832,
      "learning_rate": 3.6155038759689924e-05,
      "loss": 0.0014,
      "step": 3572
    },
    {
      "epoch": 13.848837209302326,
      "grad_norm": 1.6034278869628906,
      "learning_rate": 3.615116279069768e-05,
      "loss": 0.0267,
      "step": 3573
    },
    {
      "epoch": 13.852713178294573,
      "grad_norm": 0.0025215947534888983,
      "learning_rate": 3.614728682170543e-05,
      "loss": 0.0003,
      "step": 3574
    },
    {
      "epoch": 13.856589147286822,
      "grad_norm": 0.002341109560802579,
      "learning_rate": 3.6143410852713175e-05,
      "loss": 0.0002,
      "step": 3575
    },
    {
      "epoch": 13.86046511627907,
      "grad_norm": 0.008706679567694664,
      "learning_rate": 3.6139534883720934e-05,
      "loss": 0.0006,
      "step": 3576
    },
    {
      "epoch": 13.864341085271318,
      "grad_norm": 0.0026041478849947453,
      "learning_rate": 3.613565891472868e-05,
      "loss": 0.0002,
      "step": 3577
    },
    {
      "epoch": 13.868217054263566,
      "grad_norm": 0.009769530966877937,
      "learning_rate": 3.613178294573644e-05,
      "loss": 0.0003,
      "step": 3578
    },
    {
      "epoch": 13.872093023255815,
      "grad_norm": 0.04092256352305412,
      "learning_rate": 3.6127906976744185e-05,
      "loss": 0.0005,
      "step": 3579
    },
    {
      "epoch": 13.875968992248062,
      "grad_norm": 0.0024993212427943945,
      "learning_rate": 3.6124031007751944e-05,
      "loss": 0.0002,
      "step": 3580
    },
    {
      "epoch": 13.87984496124031,
      "grad_norm": 0.03746889531612396,
      "learning_rate": 3.612015503875969e-05,
      "loss": 0.0023,
      "step": 3581
    },
    {
      "epoch": 13.883720930232558,
      "grad_norm": 0.030482428148388863,
      "learning_rate": 3.611627906976744e-05,
      "loss": 0.0005,
      "step": 3582
    },
    {
      "epoch": 13.887596899224807,
      "grad_norm": 0.003002036362886429,
      "learning_rate": 3.6112403100775194e-05,
      "loss": 0.0002,
      "step": 3583
    },
    {
      "epoch": 13.891472868217054,
      "grad_norm": 0.0025259496178478003,
      "learning_rate": 3.610852713178295e-05,
      "loss": 0.0002,
      "step": 3584
    },
    {
      "epoch": 13.895348837209303,
      "grad_norm": 2.074037551879883,
      "learning_rate": 3.61046511627907e-05,
      "loss": 0.1088,
      "step": 3585
    },
    {
      "epoch": 13.89922480620155,
      "grad_norm": 6.4821248054504395,
      "learning_rate": 3.610077519379845e-05,
      "loss": 0.1639,
      "step": 3586
    },
    {
      "epoch": 13.9031007751938,
      "grad_norm": 3.3750689029693604,
      "learning_rate": 3.6096899224806204e-05,
      "loss": 0.1195,
      "step": 3587
    },
    {
      "epoch": 13.906976744186046,
      "grad_norm": 4.158672332763672,
      "learning_rate": 3.6093023255813956e-05,
      "loss": 0.1319,
      "step": 3588
    },
    {
      "epoch": 13.910852713178295,
      "grad_norm": 0.14192426204681396,
      "learning_rate": 3.608914728682171e-05,
      "loss": 0.0057,
      "step": 3589
    },
    {
      "epoch": 13.914728682170542,
      "grad_norm": 0.008915498852729797,
      "learning_rate": 3.608527131782946e-05,
      "loss": 0.0006,
      "step": 3590
    },
    {
      "epoch": 13.918604651162791,
      "grad_norm": 0.004555217456072569,
      "learning_rate": 3.6081395348837214e-05,
      "loss": 0.0003,
      "step": 3591
    },
    {
      "epoch": 13.922480620155039,
      "grad_norm": 5.524872303009033,
      "learning_rate": 3.6077519379844966e-05,
      "loss": 0.0636,
      "step": 3592
    },
    {
      "epoch": 13.926356589147288,
      "grad_norm": 0.0025248154997825623,
      "learning_rate": 3.607364341085271e-05,
      "loss": 0.0002,
      "step": 3593
    },
    {
      "epoch": 13.930232558139535,
      "grad_norm": 0.005356764420866966,
      "learning_rate": 3.606976744186047e-05,
      "loss": 0.0003,
      "step": 3594
    },
    {
      "epoch": 13.934108527131784,
      "grad_norm": 0.02000117301940918,
      "learning_rate": 3.6065891472868217e-05,
      "loss": 0.0011,
      "step": 3595
    },
    {
      "epoch": 13.937984496124031,
      "grad_norm": 0.0037351518403738737,
      "learning_rate": 3.6062015503875976e-05,
      "loss": 0.0002,
      "step": 3596
    },
    {
      "epoch": 13.94186046511628,
      "grad_norm": 0.006844082847237587,
      "learning_rate": 3.605813953488372e-05,
      "loss": 0.0003,
      "step": 3597
    },
    {
      "epoch": 13.945736434108527,
      "grad_norm": 0.012278069742023945,
      "learning_rate": 3.605426356589148e-05,
      "loss": 0.0003,
      "step": 3598
    },
    {
      "epoch": 13.949612403100776,
      "grad_norm": 0.0029873677995055914,
      "learning_rate": 3.6050387596899226e-05,
      "loss": 0.0003,
      "step": 3599
    },
    {
      "epoch": 13.953488372093023,
      "grad_norm": 0.002395765157416463,
      "learning_rate": 3.604651162790698e-05,
      "loss": 0.0002,
      "step": 3600
    },
    {
      "epoch": 13.957364341085272,
      "grad_norm": 0.19026432931423187,
      "learning_rate": 3.604263565891473e-05,
      "loss": 0.0077,
      "step": 3601
    },
    {
      "epoch": 13.96124031007752,
      "grad_norm": 0.0035729703959077597,
      "learning_rate": 3.603875968992248e-05,
      "loss": 0.0003,
      "step": 3602
    },
    {
      "epoch": 13.965116279069768,
      "grad_norm": 0.00270014232955873,
      "learning_rate": 3.6034883720930236e-05,
      "loss": 0.0003,
      "step": 3603
    },
    {
      "epoch": 13.968992248062015,
      "grad_norm": 0.016756899654865265,
      "learning_rate": 3.603100775193798e-05,
      "loss": 0.0003,
      "step": 3604
    },
    {
      "epoch": 13.972868217054263,
      "grad_norm": 0.0023799503687769175,
      "learning_rate": 3.602713178294574e-05,
      "loss": 0.0002,
      "step": 3605
    },
    {
      "epoch": 13.976744186046512,
      "grad_norm": 0.009439769200980663,
      "learning_rate": 3.6023255813953486e-05,
      "loss": 0.0003,
      "step": 3606
    },
    {
      "epoch": 13.98062015503876,
      "grad_norm": 0.009440327994525433,
      "learning_rate": 3.6019379844961246e-05,
      "loss": 0.0006,
      "step": 3607
    },
    {
      "epoch": 13.984496124031008,
      "grad_norm": 0.09240572154521942,
      "learning_rate": 3.601550387596899e-05,
      "loss": 0.0023,
      "step": 3608
    },
    {
      "epoch": 13.988372093023255,
      "grad_norm": 0.04283621162176132,
      "learning_rate": 3.601162790697675e-05,
      "loss": 0.0008,
      "step": 3609
    },
    {
      "epoch": 13.992248062015504,
      "grad_norm": 0.02099071629345417,
      "learning_rate": 3.6007751937984496e-05,
      "loss": 0.0009,
      "step": 3610
    },
    {
      "epoch": 13.996124031007753,
      "grad_norm": 0.053936198353767395,
      "learning_rate": 3.600387596899225e-05,
      "loss": 0.002,
      "step": 3611
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.05697821080684662,
      "learning_rate": 3.6e-05,
      "loss": 0.0022,
      "step": 3612
    },
    {
      "epoch": 14.003875968992247,
      "grad_norm": 5.725481033325195,
      "learning_rate": 3.599612403100775e-05,
      "loss": 0.1547,
      "step": 3613
    },
    {
      "epoch": 14.007751937984496,
      "grad_norm": 0.08591742068529129,
      "learning_rate": 3.5992248062015506e-05,
      "loss": 0.0006,
      "step": 3614
    },
    {
      "epoch": 14.011627906976743,
      "grad_norm": 0.002780298935249448,
      "learning_rate": 3.598837209302326e-05,
      "loss": 0.0002,
      "step": 3615
    },
    {
      "epoch": 14.015503875968992,
      "grad_norm": 0.005747443530708551,
      "learning_rate": 3.598449612403101e-05,
      "loss": 0.0003,
      "step": 3616
    },
    {
      "epoch": 14.01937984496124,
      "grad_norm": 0.002677937736734748,
      "learning_rate": 3.598062015503876e-05,
      "loss": 0.0003,
      "step": 3617
    },
    {
      "epoch": 14.023255813953488,
      "grad_norm": 0.004673185758292675,
      "learning_rate": 3.5976744186046515e-05,
      "loss": 0.0003,
      "step": 3618
    },
    {
      "epoch": 14.027131782945736,
      "grad_norm": 0.004013015888631344,
      "learning_rate": 3.597286821705427e-05,
      "loss": 0.0003,
      "step": 3619
    },
    {
      "epoch": 14.031007751937985,
      "grad_norm": 0.017491530627012253,
      "learning_rate": 3.5968992248062014e-05,
      "loss": 0.0004,
      "step": 3620
    },
    {
      "epoch": 14.034883720930232,
      "grad_norm": 0.0026420443318784237,
      "learning_rate": 3.596511627906977e-05,
      "loss": 0.0002,
      "step": 3621
    },
    {
      "epoch": 14.03875968992248,
      "grad_norm": 0.00860584806650877,
      "learning_rate": 3.596124031007752e-05,
      "loss": 0.0003,
      "step": 3622
    },
    {
      "epoch": 14.042635658914728,
      "grad_norm": 0.14676280319690704,
      "learning_rate": 3.595736434108528e-05,
      "loss": 0.0021,
      "step": 3623
    },
    {
      "epoch": 14.046511627906977,
      "grad_norm": 0.003768548369407654,
      "learning_rate": 3.595348837209302e-05,
      "loss": 0.0003,
      "step": 3624
    },
    {
      "epoch": 14.050387596899224,
      "grad_norm": 42.40898513793945,
      "learning_rate": 3.5949612403100776e-05,
      "loss": 0.0314,
      "step": 3625
    },
    {
      "epoch": 14.054263565891473,
      "grad_norm": 0.044138532131910324,
      "learning_rate": 3.594573643410853e-05,
      "loss": 0.0019,
      "step": 3626
    },
    {
      "epoch": 14.05813953488372,
      "grad_norm": 0.0022797989659011364,
      "learning_rate": 3.594186046511628e-05,
      "loss": 0.0002,
      "step": 3627
    },
    {
      "epoch": 14.062015503875969,
      "grad_norm": 0.003171041142195463,
      "learning_rate": 3.593798449612403e-05,
      "loss": 0.0003,
      "step": 3628
    },
    {
      "epoch": 14.065891472868216,
      "grad_norm": 0.0026890826411545277,
      "learning_rate": 3.5934108527131785e-05,
      "loss": 0.0002,
      "step": 3629
    },
    {
      "epoch": 14.069767441860465,
      "grad_norm": 0.003121389541774988,
      "learning_rate": 3.593023255813954e-05,
      "loss": 0.0003,
      "step": 3630
    },
    {
      "epoch": 14.073643410852712,
      "grad_norm": 0.002969975583255291,
      "learning_rate": 3.592635658914728e-05,
      "loss": 0.0003,
      "step": 3631
    },
    {
      "epoch": 14.077519379844961,
      "grad_norm": 0.004163980484008789,
      "learning_rate": 3.592248062015504e-05,
      "loss": 0.0003,
      "step": 3632
    },
    {
      "epoch": 14.081395348837209,
      "grad_norm": 0.002934540854766965,
      "learning_rate": 3.591860465116279e-05,
      "loss": 0.0003,
      "step": 3633
    },
    {
      "epoch": 14.085271317829458,
      "grad_norm": 0.028013024479150772,
      "learning_rate": 3.591472868217055e-05,
      "loss": 0.001,
      "step": 3634
    },
    {
      "epoch": 14.089147286821705,
      "grad_norm": 15.767228126525879,
      "learning_rate": 3.591085271317829e-05,
      "loss": 0.33,
      "step": 3635
    },
    {
      "epoch": 14.093023255813954,
      "grad_norm": 0.002773795509710908,
      "learning_rate": 3.590697674418605e-05,
      "loss": 0.0003,
      "step": 3636
    },
    {
      "epoch": 14.0968992248062,
      "grad_norm": 0.0031989440321922302,
      "learning_rate": 3.59031007751938e-05,
      "loss": 0.0003,
      "step": 3637
    },
    {
      "epoch": 14.10077519379845,
      "grad_norm": 0.0044002654030919075,
      "learning_rate": 3.589922480620155e-05,
      "loss": 0.0004,
      "step": 3638
    },
    {
      "epoch": 14.104651162790697,
      "grad_norm": 0.002374078147113323,
      "learning_rate": 3.58953488372093e-05,
      "loss": 0.0002,
      "step": 3639
    },
    {
      "epoch": 14.108527131782946,
      "grad_norm": 0.0043092155829072,
      "learning_rate": 3.5891472868217055e-05,
      "loss": 0.0003,
      "step": 3640
    },
    {
      "epoch": 14.112403100775193,
      "grad_norm": 0.03197915479540825,
      "learning_rate": 3.588759689922481e-05,
      "loss": 0.0018,
      "step": 3641
    },
    {
      "epoch": 14.116279069767442,
      "grad_norm": 0.003925991710275412,
      "learning_rate": 3.588372093023256e-05,
      "loss": 0.0003,
      "step": 3642
    },
    {
      "epoch": 14.12015503875969,
      "grad_norm": 0.004306213464587927,
      "learning_rate": 3.587984496124031e-05,
      "loss": 0.0003,
      "step": 3643
    },
    {
      "epoch": 14.124031007751938,
      "grad_norm": 0.15324030816555023,
      "learning_rate": 3.5875968992248065e-05,
      "loss": 0.0014,
      "step": 3644
    },
    {
      "epoch": 14.127906976744185,
      "grad_norm": 0.002933199517428875,
      "learning_rate": 3.587209302325582e-05,
      "loss": 0.0002,
      "step": 3645
    },
    {
      "epoch": 14.131782945736434,
      "grad_norm": 0.0035128514282405376,
      "learning_rate": 3.586821705426357e-05,
      "loss": 0.0002,
      "step": 3646
    },
    {
      "epoch": 14.135658914728682,
      "grad_norm": 0.013599302619695663,
      "learning_rate": 3.586434108527132e-05,
      "loss": 0.0009,
      "step": 3647
    },
    {
      "epoch": 14.13953488372093,
      "grad_norm": 0.0028897032607346773,
      "learning_rate": 3.5860465116279075e-05,
      "loss": 0.0002,
      "step": 3648
    },
    {
      "epoch": 14.143410852713178,
      "grad_norm": 0.721014678478241,
      "learning_rate": 3.585658914728682e-05,
      "loss": 0.0316,
      "step": 3649
    },
    {
      "epoch": 14.147286821705427,
      "grad_norm": 0.002435889095067978,
      "learning_rate": 3.585271317829458e-05,
      "loss": 0.0002,
      "step": 3650
    },
    {
      "epoch": 14.151162790697674,
      "grad_norm": 0.0024433056823909283,
      "learning_rate": 3.5848837209302325e-05,
      "loss": 0.0002,
      "step": 3651
    },
    {
      "epoch": 14.155038759689923,
      "grad_norm": 0.003965212497860193,
      "learning_rate": 3.584496124031008e-05,
      "loss": 0.0002,
      "step": 3652
    },
    {
      "epoch": 14.15891472868217,
      "grad_norm": 0.003031502477824688,
      "learning_rate": 3.584108527131783e-05,
      "loss": 0.0003,
      "step": 3653
    },
    {
      "epoch": 14.162790697674419,
      "grad_norm": 0.008442415855824947,
      "learning_rate": 3.583720930232558e-05,
      "loss": 0.0003,
      "step": 3654
    },
    {
      "epoch": 14.166666666666666,
      "grad_norm": 15.663946151733398,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 0.4979,
      "step": 3655
    },
    {
      "epoch": 14.170542635658915,
      "grad_norm": 1.9354097843170166,
      "learning_rate": 3.582945736434109e-05,
      "loss": 0.2268,
      "step": 3656
    },
    {
      "epoch": 14.174418604651162,
      "grad_norm": 4.067127227783203,
      "learning_rate": 3.582558139534884e-05,
      "loss": 0.116,
      "step": 3657
    },
    {
      "epoch": 14.178294573643411,
      "grad_norm": 0.006030613090842962,
      "learning_rate": 3.582170542635659e-05,
      "loss": 0.0003,
      "step": 3658
    },
    {
      "epoch": 14.182170542635658,
      "grad_norm": 0.004342184402048588,
      "learning_rate": 3.5817829457364344e-05,
      "loss": 0.0003,
      "step": 3659
    },
    {
      "epoch": 14.186046511627907,
      "grad_norm": 265.96905517578125,
      "learning_rate": 3.581395348837209e-05,
      "loss": 0.1325,
      "step": 3660
    },
    {
      "epoch": 14.189922480620154,
      "grad_norm": 0.003639131784439087,
      "learning_rate": 3.581007751937985e-05,
      "loss": 0.0002,
      "step": 3661
    },
    {
      "epoch": 14.193798449612403,
      "grad_norm": 0.002839299850165844,
      "learning_rate": 3.5806201550387595e-05,
      "loss": 0.0003,
      "step": 3662
    },
    {
      "epoch": 14.19767441860465,
      "grad_norm": 2.8112926483154297,
      "learning_rate": 3.5802325581395354e-05,
      "loss": 0.1592,
      "step": 3663
    },
    {
      "epoch": 14.2015503875969,
      "grad_norm": 0.16076108813285828,
      "learning_rate": 3.57984496124031e-05,
      "loss": 0.007,
      "step": 3664
    },
    {
      "epoch": 14.205426356589147,
      "grad_norm": 0.003029139945283532,
      "learning_rate": 3.579457364341086e-05,
      "loss": 0.0002,
      "step": 3665
    },
    {
      "epoch": 14.209302325581396,
      "grad_norm": 0.006954727228730917,
      "learning_rate": 3.5790697674418605e-05,
      "loss": 0.0005,
      "step": 3666
    },
    {
      "epoch": 14.213178294573643,
      "grad_norm": 0.3803340196609497,
      "learning_rate": 3.578682170542636e-05,
      "loss": 0.0022,
      "step": 3667
    },
    {
      "epoch": 14.217054263565892,
      "grad_norm": 0.008162321522831917,
      "learning_rate": 3.578294573643411e-05,
      "loss": 0.0005,
      "step": 3668
    },
    {
      "epoch": 14.220930232558139,
      "grad_norm": 3.4741432666778564,
      "learning_rate": 3.577906976744186e-05,
      "loss": 0.1624,
      "step": 3669
    },
    {
      "epoch": 14.224806201550388,
      "grad_norm": 0.007727106101810932,
      "learning_rate": 3.5775193798449614e-05,
      "loss": 0.0006,
      "step": 3670
    },
    {
      "epoch": 14.228682170542635,
      "grad_norm": 3.156386375427246,
      "learning_rate": 3.577131782945737e-05,
      "loss": 0.3653,
      "step": 3671
    },
    {
      "epoch": 14.232558139534884,
      "grad_norm": 0.01718338392674923,
      "learning_rate": 3.576744186046512e-05,
      "loss": 0.0011,
      "step": 3672
    },
    {
      "epoch": 14.236434108527131,
      "grad_norm": 14.383711814880371,
      "learning_rate": 3.576356589147287e-05,
      "loss": 0.2499,
      "step": 3673
    },
    {
      "epoch": 14.24031007751938,
      "grad_norm": 0.14515748620033264,
      "learning_rate": 3.5759689922480624e-05,
      "loss": 0.0041,
      "step": 3674
    },
    {
      "epoch": 14.244186046511627,
      "grad_norm": 0.032581180334091187,
      "learning_rate": 3.5755813953488376e-05,
      "loss": 0.0018,
      "step": 3675
    },
    {
      "epoch": 14.248062015503876,
      "grad_norm": 116.44171142578125,
      "learning_rate": 3.575193798449613e-05,
      "loss": 0.0692,
      "step": 3676
    },
    {
      "epoch": 14.251937984496124,
      "grad_norm": 6.533956527709961,
      "learning_rate": 3.574806201550388e-05,
      "loss": 0.3248,
      "step": 3677
    },
    {
      "epoch": 14.255813953488373,
      "grad_norm": 0.0031683731358498335,
      "learning_rate": 3.574418604651163e-05,
      "loss": 0.0003,
      "step": 3678
    },
    {
      "epoch": 14.25968992248062,
      "grad_norm": 0.007691043894737959,
      "learning_rate": 3.574031007751938e-05,
      "loss": 0.0005,
      "step": 3679
    },
    {
      "epoch": 14.263565891472869,
      "grad_norm": 0.00543927913531661,
      "learning_rate": 3.573643410852713e-05,
      "loss": 0.0003,
      "step": 3680
    },
    {
      "epoch": 14.267441860465116,
      "grad_norm": 0.005145056173205376,
      "learning_rate": 3.5732558139534884e-05,
      "loss": 0.0003,
      "step": 3681
    },
    {
      "epoch": 14.271317829457365,
      "grad_norm": 23.86644744873047,
      "learning_rate": 3.5728682170542637e-05,
      "loss": 0.6783,
      "step": 3682
    },
    {
      "epoch": 14.275193798449612,
      "grad_norm": 8.655588150024414,
      "learning_rate": 3.572480620155039e-05,
      "loss": 0.2272,
      "step": 3683
    },
    {
      "epoch": 14.279069767441861,
      "grad_norm": 0.0059900907799601555,
      "learning_rate": 3.572093023255814e-05,
      "loss": 0.0004,
      "step": 3684
    },
    {
      "epoch": 14.282945736434108,
      "grad_norm": 0.031633518636226654,
      "learning_rate": 3.5717054263565894e-05,
      "loss": 0.0016,
      "step": 3685
    },
    {
      "epoch": 14.286821705426357,
      "grad_norm": 0.5023218393325806,
      "learning_rate": 3.5713178294573646e-05,
      "loss": 0.0021,
      "step": 3686
    },
    {
      "epoch": 14.290697674418604,
      "grad_norm": 0.3588743507862091,
      "learning_rate": 3.570930232558139e-05,
      "loss": 0.0099,
      "step": 3687
    },
    {
      "epoch": 14.294573643410853,
      "grad_norm": 0.06029545143246651,
      "learning_rate": 3.570542635658915e-05,
      "loss": 0.0005,
      "step": 3688
    },
    {
      "epoch": 14.2984496124031,
      "grad_norm": 0.0061483439058065414,
      "learning_rate": 3.57015503875969e-05,
      "loss": 0.0003,
      "step": 3689
    },
    {
      "epoch": 14.30232558139535,
      "grad_norm": 3.0996127128601074,
      "learning_rate": 3.5697674418604656e-05,
      "loss": 0.0089,
      "step": 3690
    },
    {
      "epoch": 14.306201550387597,
      "grad_norm": 0.005285851191729307,
      "learning_rate": 3.56937984496124e-05,
      "loss": 0.0003,
      "step": 3691
    },
    {
      "epoch": 14.310077519379846,
      "grad_norm": 0.007424738723784685,
      "learning_rate": 3.568992248062016e-05,
      "loss": 0.0004,
      "step": 3692
    },
    {
      "epoch": 14.313953488372093,
      "grad_norm": 0.015533259138464928,
      "learning_rate": 3.5686046511627906e-05,
      "loss": 0.0007,
      "step": 3693
    },
    {
      "epoch": 14.317829457364342,
      "grad_norm": 0.003268170403316617,
      "learning_rate": 3.5682170542635666e-05,
      "loss": 0.0003,
      "step": 3694
    },
    {
      "epoch": 14.321705426356589,
      "grad_norm": 0.00920814648270607,
      "learning_rate": 3.567829457364341e-05,
      "loss": 0.0003,
      "step": 3695
    },
    {
      "epoch": 14.325581395348838,
      "grad_norm": 0.01660429872572422,
      "learning_rate": 3.5674418604651164e-05,
      "loss": 0.001,
      "step": 3696
    },
    {
      "epoch": 14.329457364341085,
      "grad_norm": 1.0297423601150513,
      "learning_rate": 3.5670542635658916e-05,
      "loss": 0.0005,
      "step": 3697
    },
    {
      "epoch": 14.333333333333334,
      "grad_norm": 0.06494148820638657,
      "learning_rate": 3.566666666666667e-05,
      "loss": 0.0008,
      "step": 3698
    },
    {
      "epoch": 14.337209302325581,
      "grad_norm": 0.007748517673462629,
      "learning_rate": 3.566279069767442e-05,
      "loss": 0.0003,
      "step": 3699
    },
    {
      "epoch": 14.34108527131783,
      "grad_norm": 12.45660400390625,
      "learning_rate": 3.565891472868217e-05,
      "loss": 0.1124,
      "step": 3700
    },
    {
      "epoch": 14.344961240310077,
      "grad_norm": 0.003827787470072508,
      "learning_rate": 3.5655038759689926e-05,
      "loss": 0.0003,
      "step": 3701
    },
    {
      "epoch": 14.348837209302326,
      "grad_norm": 0.002196128247305751,
      "learning_rate": 3.565116279069768e-05,
      "loss": 0.0002,
      "step": 3702
    },
    {
      "epoch": 14.352713178294573,
      "grad_norm": 23.76412010192871,
      "learning_rate": 3.564728682170543e-05,
      "loss": 0.5157,
      "step": 3703
    },
    {
      "epoch": 14.356589147286822,
      "grad_norm": 0.005858405027538538,
      "learning_rate": 3.564341085271318e-05,
      "loss": 0.0005,
      "step": 3704
    },
    {
      "epoch": 14.36046511627907,
      "grad_norm": 13.148340225219727,
      "learning_rate": 3.563953488372093e-05,
      "loss": 0.1827,
      "step": 3705
    },
    {
      "epoch": 14.364341085271318,
      "grad_norm": 0.006528588943183422,
      "learning_rate": 3.563565891472868e-05,
      "loss": 0.0005,
      "step": 3706
    },
    {
      "epoch": 14.368217054263566,
      "grad_norm": 0.029972555115818977,
      "learning_rate": 3.5631782945736434e-05,
      "loss": 0.0019,
      "step": 3707
    },
    {
      "epoch": 14.372093023255815,
      "grad_norm": 0.005064254626631737,
      "learning_rate": 3.5627906976744186e-05,
      "loss": 0.0004,
      "step": 3708
    },
    {
      "epoch": 14.375968992248062,
      "grad_norm": 0.06100011244416237,
      "learning_rate": 3.562403100775194e-05,
      "loss": 0.0008,
      "step": 3709
    },
    {
      "epoch": 14.37984496124031,
      "grad_norm": 0.0039351885206997395,
      "learning_rate": 3.562015503875969e-05,
      "loss": 0.0003,
      "step": 3710
    },
    {
      "epoch": 14.383720930232558,
      "grad_norm": 0.004368534777313471,
      "learning_rate": 3.561627906976744e-05,
      "loss": 0.0003,
      "step": 3711
    },
    {
      "epoch": 14.387596899224807,
      "grad_norm": 0.405366986989975,
      "learning_rate": 3.5612403100775196e-05,
      "loss": 0.0048,
      "step": 3712
    },
    {
      "epoch": 14.391472868217054,
      "grad_norm": 3.557159185409546,
      "learning_rate": 3.560852713178295e-05,
      "loss": 0.4595,
      "step": 3713
    },
    {
      "epoch": 14.395348837209303,
      "grad_norm": 0.5231197476387024,
      "learning_rate": 3.56046511627907e-05,
      "loss": 0.0071,
      "step": 3714
    },
    {
      "epoch": 14.39922480620155,
      "grad_norm": 0.1058984026312828,
      "learning_rate": 3.560077519379845e-05,
      "loss": 0.0011,
      "step": 3715
    },
    {
      "epoch": 14.4031007751938,
      "grad_norm": 159.26116943359375,
      "learning_rate": 3.55968992248062e-05,
      "loss": 0.1446,
      "step": 3716
    },
    {
      "epoch": 14.406976744186046,
      "grad_norm": 0.2433611899614334,
      "learning_rate": 3.559302325581396e-05,
      "loss": 0.0048,
      "step": 3717
    },
    {
      "epoch": 14.410852713178295,
      "grad_norm": 0.045040782541036606,
      "learning_rate": 3.5589147286821703e-05,
      "loss": 0.0016,
      "step": 3718
    },
    {
      "epoch": 14.414728682170542,
      "grad_norm": 2.6301941871643066,
      "learning_rate": 3.558527131782946e-05,
      "loss": 0.2068,
      "step": 3719
    },
    {
      "epoch": 14.418604651162791,
      "grad_norm": 0.03525711968541145,
      "learning_rate": 3.558139534883721e-05,
      "loss": 0.001,
      "step": 3720
    },
    {
      "epoch": 14.422480620155039,
      "grad_norm": 0.04348057880997658,
      "learning_rate": 3.557751937984497e-05,
      "loss": 0.0014,
      "step": 3721
    },
    {
      "epoch": 14.426356589147288,
      "grad_norm": 55.84511184692383,
      "learning_rate": 3.557364341085271e-05,
      "loss": 0.0646,
      "step": 3722
    },
    {
      "epoch": 14.430232558139535,
      "grad_norm": 1.2109800577163696,
      "learning_rate": 3.5569767441860465e-05,
      "loss": 0.2423,
      "step": 3723
    },
    {
      "epoch": 14.434108527131784,
      "grad_norm": 0.055821921676397324,
      "learning_rate": 3.556589147286822e-05,
      "loss": 0.0022,
      "step": 3724
    },
    {
      "epoch": 14.437984496124031,
      "grad_norm": 0.06627658754587173,
      "learning_rate": 3.556201550387597e-05,
      "loss": 0.0021,
      "step": 3725
    },
    {
      "epoch": 14.44186046511628,
      "grad_norm": 0.036680981516838074,
      "learning_rate": 3.555813953488372e-05,
      "loss": 0.0014,
      "step": 3726
    },
    {
      "epoch": 14.445736434108527,
      "grad_norm": 11.234309196472168,
      "learning_rate": 3.5554263565891475e-05,
      "loss": 1.1319,
      "step": 3727
    },
    {
      "epoch": 14.449612403100776,
      "grad_norm": 0.0349331796169281,
      "learning_rate": 3.555038759689923e-05,
      "loss": 0.0012,
      "step": 3728
    },
    {
      "epoch": 14.453488372093023,
      "grad_norm": 3.066920280456543,
      "learning_rate": 3.554651162790698e-05,
      "loss": 0.0615,
      "step": 3729
    },
    {
      "epoch": 14.457364341085272,
      "grad_norm": 0.8265904188156128,
      "learning_rate": 3.554263565891473e-05,
      "loss": 0.0139,
      "step": 3730
    },
    {
      "epoch": 14.46124031007752,
      "grad_norm": 0.0454673208296299,
      "learning_rate": 3.5538759689922485e-05,
      "loss": 0.0018,
      "step": 3731
    },
    {
      "epoch": 14.465116279069768,
      "grad_norm": 2.224743366241455,
      "learning_rate": 3.553488372093024e-05,
      "loss": 0.0713,
      "step": 3732
    },
    {
      "epoch": 14.468992248062015,
      "grad_norm": 0.08667095750570297,
      "learning_rate": 3.553100775193798e-05,
      "loss": 0.0028,
      "step": 3733
    },
    {
      "epoch": 14.472868217054264,
      "grad_norm": 0.014100726693868637,
      "learning_rate": 3.5527131782945735e-05,
      "loss": 0.0007,
      "step": 3734
    },
    {
      "epoch": 14.476744186046512,
      "grad_norm": 0.009548570960760117,
      "learning_rate": 3.552325581395349e-05,
      "loss": 0.0006,
      "step": 3735
    },
    {
      "epoch": 14.48062015503876,
      "grad_norm": 0.015120670199394226,
      "learning_rate": 3.551937984496124e-05,
      "loss": 0.0007,
      "step": 3736
    },
    {
      "epoch": 14.484496124031008,
      "grad_norm": 0.0067992727272212505,
      "learning_rate": 3.551550387596899e-05,
      "loss": 0.0005,
      "step": 3737
    },
    {
      "epoch": 14.488372093023255,
      "grad_norm": 0.006786287296563387,
      "learning_rate": 3.5511627906976745e-05,
      "loss": 0.0005,
      "step": 3738
    },
    {
      "epoch": 14.492248062015504,
      "grad_norm": 0.7732155323028564,
      "learning_rate": 3.55077519379845e-05,
      "loss": 0.1757,
      "step": 3739
    },
    {
      "epoch": 14.496124031007753,
      "grad_norm": 0.004252208396792412,
      "learning_rate": 3.550387596899225e-05,
      "loss": 0.0003,
      "step": 3740
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.0047748396173119545,
      "learning_rate": 3.55e-05,
      "loss": 0.0004,
      "step": 3741
    },
    {
      "epoch": 14.503875968992247,
      "grad_norm": 0.005295733455568552,
      "learning_rate": 3.5496124031007755e-05,
      "loss": 0.0003,
      "step": 3742
    },
    {
      "epoch": 14.507751937984496,
      "grad_norm": 5.825863838195801,
      "learning_rate": 3.549224806201551e-05,
      "loss": 0.0889,
      "step": 3743
    },
    {
      "epoch": 14.511627906976745,
      "grad_norm": 4.259243488311768,
      "learning_rate": 3.548837209302326e-05,
      "loss": 0.7765,
      "step": 3744
    },
    {
      "epoch": 14.515503875968992,
      "grad_norm": 0.012250682339072227,
      "learning_rate": 3.5484496124031005e-05,
      "loss": 0.0007,
      "step": 3745
    },
    {
      "epoch": 14.51937984496124,
      "grad_norm": 0.055777836591005325,
      "learning_rate": 3.5480620155038764e-05,
      "loss": 0.0011,
      "step": 3746
    },
    {
      "epoch": 14.523255813953488,
      "grad_norm": 0.020860424265265465,
      "learning_rate": 3.547674418604651e-05,
      "loss": 0.001,
      "step": 3747
    },
    {
      "epoch": 14.527131782945737,
      "grad_norm": 0.5256581902503967,
      "learning_rate": 3.547286821705427e-05,
      "loss": 0.021,
      "step": 3748
    },
    {
      "epoch": 14.531007751937985,
      "grad_norm": 0.015151407569646835,
      "learning_rate": 3.5468992248062015e-05,
      "loss": 0.0008,
      "step": 3749
    },
    {
      "epoch": 14.534883720930232,
      "grad_norm": 0.35580894351005554,
      "learning_rate": 3.5465116279069774e-05,
      "loss": 0.0026,
      "step": 3750
    },
    {
      "epoch": 14.53875968992248,
      "grad_norm": 0.025657037273049355,
      "learning_rate": 3.546124031007752e-05,
      "loss": 0.0014,
      "step": 3751
    },
    {
      "epoch": 14.542635658914728,
      "grad_norm": 0.17029403150081635,
      "learning_rate": 3.545736434108527e-05,
      "loss": 0.003,
      "step": 3752
    },
    {
      "epoch": 14.546511627906977,
      "grad_norm": 0.0963699221611023,
      "learning_rate": 3.5453488372093025e-05,
      "loss": 0.003,
      "step": 3753
    },
    {
      "epoch": 14.550387596899224,
      "grad_norm": 0.042642414569854736,
      "learning_rate": 3.544961240310078e-05,
      "loss": 0.0017,
      "step": 3754
    },
    {
      "epoch": 14.554263565891473,
      "grad_norm": 1.0211927890777588,
      "learning_rate": 3.544573643410853e-05,
      "loss": 0.1955,
      "step": 3755
    },
    {
      "epoch": 14.55813953488372,
      "grad_norm": 2.758514404296875,
      "learning_rate": 3.544186046511628e-05,
      "loss": 0.0015,
      "step": 3756
    },
    {
      "epoch": 14.562015503875969,
      "grad_norm": 1.4515581130981445,
      "learning_rate": 3.5437984496124034e-05,
      "loss": 0.1757,
      "step": 3757
    },
    {
      "epoch": 14.565891472868216,
      "grad_norm": 2.8113036155700684,
      "learning_rate": 3.543410852713179e-05,
      "loss": 0.3734,
      "step": 3758
    },
    {
      "epoch": 14.569767441860465,
      "grad_norm": 0.90794837474823,
      "learning_rate": 3.543023255813954e-05,
      "loss": 0.1357,
      "step": 3759
    },
    {
      "epoch": 14.573643410852712,
      "grad_norm": 0.14291507005691528,
      "learning_rate": 3.5426356589147285e-05,
      "loss": 0.0065,
      "step": 3760
    },
    {
      "epoch": 14.577519379844961,
      "grad_norm": 2.135369062423706,
      "learning_rate": 3.5422480620155044e-05,
      "loss": 0.3303,
      "step": 3761
    },
    {
      "epoch": 14.581395348837209,
      "grad_norm": 0.30003902316093445,
      "learning_rate": 3.541860465116279e-05,
      "loss": 0.0145,
      "step": 3762
    },
    {
      "epoch": 14.585271317829458,
      "grad_norm": 0.5031324625015259,
      "learning_rate": 3.541472868217054e-05,
      "loss": 0.0137,
      "step": 3763
    },
    {
      "epoch": 14.589147286821705,
      "grad_norm": 0.6094143986701965,
      "learning_rate": 3.5410852713178294e-05,
      "loss": 0.0244,
      "step": 3764
    },
    {
      "epoch": 14.593023255813954,
      "grad_norm": 0.4007771611213684,
      "learning_rate": 3.540697674418605e-05,
      "loss": 0.0156,
      "step": 3765
    },
    {
      "epoch": 14.5968992248062,
      "grad_norm": 0.8490599989891052,
      "learning_rate": 3.54031007751938e-05,
      "loss": 0.0341,
      "step": 3766
    },
    {
      "epoch": 14.60077519379845,
      "grad_norm": 1.1871758699417114,
      "learning_rate": 3.539922480620155e-05,
      "loss": 0.0506,
      "step": 3767
    },
    {
      "epoch": 14.604651162790697,
      "grad_norm": 1.5579686164855957,
      "learning_rate": 3.5395348837209304e-05,
      "loss": 0.1715,
      "step": 3768
    },
    {
      "epoch": 14.608527131782946,
      "grad_norm": 0.03609619662165642,
      "learning_rate": 3.5391472868217057e-05,
      "loss": 0.0018,
      "step": 3769
    },
    {
      "epoch": 14.612403100775193,
      "grad_norm": 1.2033785581588745,
      "learning_rate": 3.538759689922481e-05,
      "loss": 0.2952,
      "step": 3770
    },
    {
      "epoch": 14.616279069767442,
      "grad_norm": 0.5418669581413269,
      "learning_rate": 3.538372093023256e-05,
      "loss": 0.0813,
      "step": 3771
    },
    {
      "epoch": 14.62015503875969,
      "grad_norm": 0.0324835442006588,
      "learning_rate": 3.5379844961240314e-05,
      "loss": 0.0019,
      "step": 3772
    },
    {
      "epoch": 14.624031007751938,
      "grad_norm": 0.09703173488378525,
      "learning_rate": 3.5375968992248066e-05,
      "loss": 0.0031,
      "step": 3773
    },
    {
      "epoch": 14.627906976744185,
      "grad_norm": 0.6336095929145813,
      "learning_rate": 3.537209302325581e-05,
      "loss": 0.0958,
      "step": 3774
    },
    {
      "epoch": 14.631782945736434,
      "grad_norm": 0.05069989338517189,
      "learning_rate": 3.536821705426357e-05,
      "loss": 0.0027,
      "step": 3775
    },
    {
      "epoch": 14.635658914728682,
      "grad_norm": 3.375826120376587,
      "learning_rate": 3.536434108527132e-05,
      "loss": 0.0133,
      "step": 3776
    },
    {
      "epoch": 14.63953488372093,
      "grad_norm": 0.032871928066015244,
      "learning_rate": 3.5360465116279076e-05,
      "loss": 0.0017,
      "step": 3777
    },
    {
      "epoch": 14.643410852713178,
      "grad_norm": 0.14011073112487793,
      "learning_rate": 3.535658914728682e-05,
      "loss": 0.0045,
      "step": 3778
    },
    {
      "epoch": 14.647286821705427,
      "grad_norm": 0.9942890405654907,
      "learning_rate": 3.535271317829458e-05,
      "loss": 0.0119,
      "step": 3779
    },
    {
      "epoch": 14.651162790697674,
      "grad_norm": 6.07130241394043,
      "learning_rate": 3.5348837209302326e-05,
      "loss": 0.0027,
      "step": 3780
    },
    {
      "epoch": 14.655038759689923,
      "grad_norm": 6.589253902435303,
      "learning_rate": 3.534496124031008e-05,
      "loss": 0.2505,
      "step": 3781
    },
    {
      "epoch": 14.65891472868217,
      "grad_norm": 3.7262842655181885,
      "learning_rate": 3.534108527131783e-05,
      "loss": 0.0283,
      "step": 3782
    },
    {
      "epoch": 14.662790697674419,
      "grad_norm": 0.12190953642129898,
      "learning_rate": 3.5337209302325584e-05,
      "loss": 0.0053,
      "step": 3783
    },
    {
      "epoch": 14.666666666666666,
      "grad_norm": 0.36317911744117737,
      "learning_rate": 3.5333333333333336e-05,
      "loss": 0.0044,
      "step": 3784
    },
    {
      "epoch": 14.670542635658915,
      "grad_norm": 4.904181003570557,
      "learning_rate": 3.532945736434108e-05,
      "loss": 0.0421,
      "step": 3785
    },
    {
      "epoch": 14.674418604651162,
      "grad_norm": 0.06140584871172905,
      "learning_rate": 3.532558139534884e-05,
      "loss": 0.0034,
      "step": 3786
    },
    {
      "epoch": 14.678294573643411,
      "grad_norm": 1.688978910446167,
      "learning_rate": 3.5321705426356587e-05,
      "loss": 0.2069,
      "step": 3787
    },
    {
      "epoch": 14.682170542635658,
      "grad_norm": 0.12838424742221832,
      "learning_rate": 3.5317829457364346e-05,
      "loss": 0.0048,
      "step": 3788
    },
    {
      "epoch": 14.686046511627907,
      "grad_norm": 0.06012757867574692,
      "learning_rate": 3.531395348837209e-05,
      "loss": 0.0027,
      "step": 3789
    },
    {
      "epoch": 14.689922480620154,
      "grad_norm": 0.16496947407722473,
      "learning_rate": 3.5310077519379844e-05,
      "loss": 0.0058,
      "step": 3790
    },
    {
      "epoch": 14.693798449612403,
      "grad_norm": 0.5067605972290039,
      "learning_rate": 3.5306201550387596e-05,
      "loss": 0.0133,
      "step": 3791
    },
    {
      "epoch": 14.69767441860465,
      "grad_norm": 1.1734528541564941,
      "learning_rate": 3.530232558139535e-05,
      "loss": 0.1444,
      "step": 3792
    },
    {
      "epoch": 14.7015503875969,
      "grad_norm": 16.287527084350586,
      "learning_rate": 3.52984496124031e-05,
      "loss": 0.1911,
      "step": 3793
    },
    {
      "epoch": 14.705426356589147,
      "grad_norm": 25.709678649902344,
      "learning_rate": 3.5294573643410854e-05,
      "loss": 0.2436,
      "step": 3794
    },
    {
      "epoch": 14.709302325581396,
      "grad_norm": 0.007443815004080534,
      "learning_rate": 3.5290697674418606e-05,
      "loss": 0.0006,
      "step": 3795
    },
    {
      "epoch": 14.713178294573643,
      "grad_norm": 0.6284409761428833,
      "learning_rate": 3.528682170542636e-05,
      "loss": 0.0272,
      "step": 3796
    },
    {
      "epoch": 14.717054263565892,
      "grad_norm": 1.3593173027038574,
      "learning_rate": 3.528294573643411e-05,
      "loss": 0.0212,
      "step": 3797
    },
    {
      "epoch": 14.720930232558139,
      "grad_norm": 0.40954190492630005,
      "learning_rate": 3.527906976744186e-05,
      "loss": 0.0871,
      "step": 3798
    },
    {
      "epoch": 14.724806201550388,
      "grad_norm": 3.5382239818573,
      "learning_rate": 3.5275193798449616e-05,
      "loss": 0.2889,
      "step": 3799
    },
    {
      "epoch": 14.728682170542635,
      "grad_norm": 0.01328069344162941,
      "learning_rate": 3.527131782945737e-05,
      "loss": 0.0009,
      "step": 3800
    },
    {
      "epoch": 14.732558139534884,
      "grad_norm": 0.18969818949699402,
      "learning_rate": 3.5267441860465114e-05,
      "loss": 0.0067,
      "step": 3801
    },
    {
      "epoch": 14.736434108527131,
      "grad_norm": 29.177814483642578,
      "learning_rate": 3.526356589147287e-05,
      "loss": 0.0868,
      "step": 3802
    },
    {
      "epoch": 14.74031007751938,
      "grad_norm": 0.28375956416130066,
      "learning_rate": 3.525968992248062e-05,
      "loss": 0.01,
      "step": 3803
    },
    {
      "epoch": 14.744186046511627,
      "grad_norm": 0.028316067531704903,
      "learning_rate": 3.525581395348838e-05,
      "loss": 0.001,
      "step": 3804
    },
    {
      "epoch": 14.748062015503876,
      "grad_norm": 0.042259473353624344,
      "learning_rate": 3.5251937984496123e-05,
      "loss": 0.0013,
      "step": 3805
    },
    {
      "epoch": 14.751937984496124,
      "grad_norm": 0.13340584933757782,
      "learning_rate": 3.524806201550388e-05,
      "loss": 0.0048,
      "step": 3806
    },
    {
      "epoch": 14.755813953488373,
      "grad_norm": 0.3268498480319977,
      "learning_rate": 3.524418604651163e-05,
      "loss": 0.0109,
      "step": 3807
    },
    {
      "epoch": 14.75968992248062,
      "grad_norm": 0.05305716395378113,
      "learning_rate": 3.524031007751938e-05,
      "loss": 0.0023,
      "step": 3808
    },
    {
      "epoch": 14.763565891472869,
      "grad_norm": 0.03396494686603546,
      "learning_rate": 3.523643410852713e-05,
      "loss": 0.0021,
      "step": 3809
    },
    {
      "epoch": 14.767441860465116,
      "grad_norm": 0.03222982585430145,
      "learning_rate": 3.5232558139534886e-05,
      "loss": 0.0011,
      "step": 3810
    },
    {
      "epoch": 14.771317829457365,
      "grad_norm": 0.02069106698036194,
      "learning_rate": 3.522868217054264e-05,
      "loss": 0.001,
      "step": 3811
    },
    {
      "epoch": 14.775193798449612,
      "grad_norm": 0.024161100387573242,
      "learning_rate": 3.5224806201550384e-05,
      "loss": 0.0014,
      "step": 3812
    },
    {
      "epoch": 14.779069767441861,
      "grad_norm": 0.0722893700003624,
      "learning_rate": 3.522093023255814e-05,
      "loss": 0.0028,
      "step": 3813
    },
    {
      "epoch": 14.782945736434108,
      "grad_norm": 2.2528786659240723,
      "learning_rate": 3.521705426356589e-05,
      "loss": 0.0238,
      "step": 3814
    },
    {
      "epoch": 14.786821705426357,
      "grad_norm": 0.021594896912574768,
      "learning_rate": 3.521317829457365e-05,
      "loss": 0.0013,
      "step": 3815
    },
    {
      "epoch": 14.790697674418604,
      "grad_norm": 0.19338850677013397,
      "learning_rate": 3.520930232558139e-05,
      "loss": 0.0063,
      "step": 3816
    },
    {
      "epoch": 14.794573643410853,
      "grad_norm": 8.382513046264648,
      "learning_rate": 3.520542635658915e-05,
      "loss": 0.4781,
      "step": 3817
    },
    {
      "epoch": 14.7984496124031,
      "grad_norm": 26.399051666259766,
      "learning_rate": 3.52015503875969e-05,
      "loss": 1.0403,
      "step": 3818
    },
    {
      "epoch": 14.80232558139535,
      "grad_norm": 0.025946635752916336,
      "learning_rate": 3.519767441860465e-05,
      "loss": 0.0009,
      "step": 3819
    },
    {
      "epoch": 14.806201550387597,
      "grad_norm": 0.01693393662571907,
      "learning_rate": 3.51937984496124e-05,
      "loss": 0.0014,
      "step": 3820
    },
    {
      "epoch": 14.810077519379846,
      "grad_norm": 0.008380583487451077,
      "learning_rate": 3.5189922480620155e-05,
      "loss": 0.0007,
      "step": 3821
    },
    {
      "epoch": 14.813953488372093,
      "grad_norm": 0.5142509341239929,
      "learning_rate": 3.518604651162791e-05,
      "loss": 0.0131,
      "step": 3822
    },
    {
      "epoch": 14.817829457364342,
      "grad_norm": 0.126637801527977,
      "learning_rate": 3.518217054263566e-05,
      "loss": 0.0047,
      "step": 3823
    },
    {
      "epoch": 14.821705426356589,
      "grad_norm": 0.02290371246635914,
      "learning_rate": 3.517829457364341e-05,
      "loss": 0.0012,
      "step": 3824
    },
    {
      "epoch": 14.825581395348838,
      "grad_norm": 3.6099278926849365,
      "learning_rate": 3.5174418604651165e-05,
      "loss": 0.6277,
      "step": 3825
    },
    {
      "epoch": 14.829457364341085,
      "grad_norm": 0.009768299758434296,
      "learning_rate": 3.517054263565892e-05,
      "loss": 0.0008,
      "step": 3826
    },
    {
      "epoch": 14.833333333333334,
      "grad_norm": 0.8886801600456238,
      "learning_rate": 3.516666666666667e-05,
      "loss": 0.1525,
      "step": 3827
    },
    {
      "epoch": 14.837209302325581,
      "grad_norm": 0.06667806208133698,
      "learning_rate": 3.516279069767442e-05,
      "loss": 0.0021,
      "step": 3828
    },
    {
      "epoch": 14.84108527131783,
      "grad_norm": 5.44934606552124,
      "learning_rate": 3.5158914728682175e-05,
      "loss": 0.003,
      "step": 3829
    },
    {
      "epoch": 14.844961240310077,
      "grad_norm": 7.291025161743164,
      "learning_rate": 3.515503875968992e-05,
      "loss": 0.1497,
      "step": 3830
    },
    {
      "epoch": 14.848837209302326,
      "grad_norm": 25.88286018371582,
      "learning_rate": 3.515116279069768e-05,
      "loss": 0.0879,
      "step": 3831
    },
    {
      "epoch": 14.852713178294573,
      "grad_norm": 0.06142236292362213,
      "learning_rate": 3.5147286821705425e-05,
      "loss": 0.001,
      "step": 3832
    },
    {
      "epoch": 14.856589147286822,
      "grad_norm": 7.162472724914551,
      "learning_rate": 3.5143410852713184e-05,
      "loss": 0.6693,
      "step": 3833
    },
    {
      "epoch": 14.86046511627907,
      "grad_norm": 0.1019660159945488,
      "learning_rate": 3.513953488372093e-05,
      "loss": 0.0045,
      "step": 3834
    },
    {
      "epoch": 14.864341085271318,
      "grad_norm": 0.018872948363423347,
      "learning_rate": 3.513565891472869e-05,
      "loss": 0.0007,
      "step": 3835
    },
    {
      "epoch": 14.868217054263566,
      "grad_norm": 3.868722677230835,
      "learning_rate": 3.5131782945736435e-05,
      "loss": 0.1986,
      "step": 3836
    },
    {
      "epoch": 14.872093023255815,
      "grad_norm": 0.8535405397415161,
      "learning_rate": 3.512790697674419e-05,
      "loss": 0.0283,
      "step": 3837
    },
    {
      "epoch": 14.875968992248062,
      "grad_norm": 0.06433595716953278,
      "learning_rate": 3.512403100775194e-05,
      "loss": 0.0032,
      "step": 3838
    },
    {
      "epoch": 14.87984496124031,
      "grad_norm": 0.12996603548526764,
      "learning_rate": 3.512015503875969e-05,
      "loss": 0.0007,
      "step": 3839
    },
    {
      "epoch": 14.883720930232558,
      "grad_norm": 0.010862738825380802,
      "learning_rate": 3.5116279069767445e-05,
      "loss": 0.0008,
      "step": 3840
    },
    {
      "epoch": 14.887596899224807,
      "grad_norm": 0.15491926670074463,
      "learning_rate": 3.511240310077519e-05,
      "loss": 0.0071,
      "step": 3841
    },
    {
      "epoch": 14.891472868217054,
      "grad_norm": 0.009519966319203377,
      "learning_rate": 3.510852713178295e-05,
      "loss": 0.0008,
      "step": 3842
    },
    {
      "epoch": 14.895348837209303,
      "grad_norm": 19.283031463623047,
      "learning_rate": 3.5104651162790695e-05,
      "loss": 0.2139,
      "step": 3843
    },
    {
      "epoch": 14.89922480620155,
      "grad_norm": 0.008180025033652782,
      "learning_rate": 3.5100775193798454e-05,
      "loss": 0.0007,
      "step": 3844
    },
    {
      "epoch": 14.9031007751938,
      "grad_norm": 0.036956530064344406,
      "learning_rate": 3.50968992248062e-05,
      "loss": 0.0012,
      "step": 3845
    },
    {
      "epoch": 14.906976744186046,
      "grad_norm": 0.007720771711319685,
      "learning_rate": 3.509302325581396e-05,
      "loss": 0.0006,
      "step": 3846
    },
    {
      "epoch": 14.910852713178295,
      "grad_norm": 0.03235427290201187,
      "learning_rate": 3.5089147286821705e-05,
      "loss": 0.0009,
      "step": 3847
    },
    {
      "epoch": 14.914728682170542,
      "grad_norm": 0.006291497964411974,
      "learning_rate": 3.508527131782946e-05,
      "loss": 0.0006,
      "step": 3848
    },
    {
      "epoch": 14.918604651162791,
      "grad_norm": 0.007497710175812244,
      "learning_rate": 3.508139534883721e-05,
      "loss": 0.0005,
      "step": 3849
    },
    {
      "epoch": 14.922480620155039,
      "grad_norm": 0.08506506681442261,
      "learning_rate": 3.507751937984496e-05,
      "loss": 0.0041,
      "step": 3850
    },
    {
      "epoch": 14.926356589147288,
      "grad_norm": 0.037564247846603394,
      "learning_rate": 3.5073643410852714e-05,
      "loss": 0.0017,
      "step": 3851
    },
    {
      "epoch": 14.930232558139535,
      "grad_norm": 0.006836972665041685,
      "learning_rate": 3.506976744186047e-05,
      "loss": 0.0006,
      "step": 3852
    },
    {
      "epoch": 14.934108527131784,
      "grad_norm": 6.481431484222412,
      "learning_rate": 3.506589147286822e-05,
      "loss": 0.1254,
      "step": 3853
    },
    {
      "epoch": 14.937984496124031,
      "grad_norm": 0.00854466948658228,
      "learning_rate": 3.506201550387597e-05,
      "loss": 0.0006,
      "step": 3854
    },
    {
      "epoch": 14.94186046511628,
      "grad_norm": 17.365942001342773,
      "learning_rate": 3.5058139534883724e-05,
      "loss": 0.2406,
      "step": 3855
    },
    {
      "epoch": 14.945736434108527,
      "grad_norm": 0.020142287015914917,
      "learning_rate": 3.5054263565891477e-05,
      "loss": 0.001,
      "step": 3856
    },
    {
      "epoch": 14.949612403100776,
      "grad_norm": 0.07154202461242676,
      "learning_rate": 3.505038759689923e-05,
      "loss": 0.0013,
      "step": 3857
    },
    {
      "epoch": 14.953488372093023,
      "grad_norm": 0.0072356900200247765,
      "learning_rate": 3.504651162790698e-05,
      "loss": 0.0006,
      "step": 3858
    },
    {
      "epoch": 14.957364341085272,
      "grad_norm": 0.009075969457626343,
      "learning_rate": 3.504263565891473e-05,
      "loss": 0.0006,
      "step": 3859
    },
    {
      "epoch": 14.96124031007752,
      "grad_norm": 0.009868157096207142,
      "learning_rate": 3.5038759689922486e-05,
      "loss": 0.0007,
      "step": 3860
    },
    {
      "epoch": 14.965116279069768,
      "grad_norm": 3.5385422706604004,
      "learning_rate": 3.503488372093023e-05,
      "loss": 0.1448,
      "step": 3861
    },
    {
      "epoch": 14.968992248062015,
      "grad_norm": 0.006891296710819006,
      "learning_rate": 3.503100775193799e-05,
      "loss": 0.0006,
      "step": 3862
    },
    {
      "epoch": 14.972868217054263,
      "grad_norm": 0.017833441495895386,
      "learning_rate": 3.502713178294574e-05,
      "loss": 0.0012,
      "step": 3863
    },
    {
      "epoch": 14.976744186046512,
      "grad_norm": 0.01807217486202717,
      "learning_rate": 3.5023255813953496e-05,
      "loss": 0.0013,
      "step": 3864
    },
    {
      "epoch": 14.98062015503876,
      "grad_norm": 0.006464404985308647,
      "learning_rate": 3.501937984496124e-05,
      "loss": 0.0005,
      "step": 3865
    },
    {
      "epoch": 14.984496124031008,
      "grad_norm": 7.106368541717529,
      "learning_rate": 3.5015503875968994e-05,
      "loss": 0.0821,
      "step": 3866
    },
    {
      "epoch": 14.988372093023255,
      "grad_norm": 0.009395310655236244,
      "learning_rate": 3.5011627906976746e-05,
      "loss": 0.0006,
      "step": 3867
    },
    {
      "epoch": 14.992248062015504,
      "grad_norm": 0.07310141623020172,
      "learning_rate": 3.500775193798449e-05,
      "loss": 0.0031,
      "step": 3868
    },
    {
      "epoch": 14.996124031007753,
      "grad_norm": 0.0066435933113098145,
      "learning_rate": 3.500387596899225e-05,
      "loss": 0.0005,
      "step": 3869
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.013120386749505997,
      "learning_rate": 3.5e-05,
      "loss": 0.0007,
      "step": 3870
    },
    {
      "epoch": 15.003875968992247,
      "grad_norm": 0.013179274275898933,
      "learning_rate": 3.4996124031007756e-05,
      "loss": 0.0006,
      "step": 3871
    },
    {
      "epoch": 15.007751937984496,
      "grad_norm": 0.008779406547546387,
      "learning_rate": 3.49922480620155e-05,
      "loss": 0.0006,
      "step": 3872
    },
    {
      "epoch": 15.011627906976743,
      "grad_norm": 0.008511115796864033,
      "learning_rate": 3.498837209302326e-05,
      "loss": 0.0007,
      "step": 3873
    },
    {
      "epoch": 15.015503875968992,
      "grad_norm": 0.004875265993177891,
      "learning_rate": 3.498449612403101e-05,
      "loss": 0.0005,
      "step": 3874
    },
    {
      "epoch": 15.01937984496124,
      "grad_norm": 0.0059656803496181965,
      "learning_rate": 3.4980620155038766e-05,
      "loss": 0.0005,
      "step": 3875
    },
    {
      "epoch": 15.023255813953488,
      "grad_norm": 0.5740677118301392,
      "learning_rate": 3.497674418604651e-05,
      "loss": 0.008,
      "step": 3876
    },
    {
      "epoch": 15.027131782945736,
      "grad_norm": 0.006341587286442518,
      "learning_rate": 3.4972868217054264e-05,
      "loss": 0.0005,
      "step": 3877
    },
    {
      "epoch": 15.031007751937985,
      "grad_norm": 0.009644515812397003,
      "learning_rate": 3.4968992248062016e-05,
      "loss": 0.0006,
      "step": 3878
    },
    {
      "epoch": 15.034883720930232,
      "grad_norm": 54.438453674316406,
      "learning_rate": 3.496511627906977e-05,
      "loss": 0.5661,
      "step": 3879
    },
    {
      "epoch": 15.03875968992248,
      "grad_norm": 0.00812748447060585,
      "learning_rate": 3.496124031007752e-05,
      "loss": 0.0005,
      "step": 3880
    },
    {
      "epoch": 15.042635658914728,
      "grad_norm": 22.860034942626953,
      "learning_rate": 3.4957364341085274e-05,
      "loss": 0.0844,
      "step": 3881
    },
    {
      "epoch": 15.046511627906977,
      "grad_norm": 0.0445232130587101,
      "learning_rate": 3.4953488372093026e-05,
      "loss": 0.0011,
      "step": 3882
    },
    {
      "epoch": 15.050387596899224,
      "grad_norm": 0.005838858895003796,
      "learning_rate": 3.494961240310078e-05,
      "loss": 0.0004,
      "step": 3883
    },
    {
      "epoch": 15.054263565891473,
      "grad_norm": 0.08782905340194702,
      "learning_rate": 3.494573643410853e-05,
      "loss": 0.0037,
      "step": 3884
    },
    {
      "epoch": 15.05813953488372,
      "grad_norm": 0.02304236590862274,
      "learning_rate": 3.494186046511628e-05,
      "loss": 0.0013,
      "step": 3885
    },
    {
      "epoch": 15.062015503875969,
      "grad_norm": 0.2801501154899597,
      "learning_rate": 3.493798449612403e-05,
      "loss": 0.0057,
      "step": 3886
    },
    {
      "epoch": 15.065891472868216,
      "grad_norm": 0.005674149375408888,
      "learning_rate": 3.493410852713179e-05,
      "loss": 0.0004,
      "step": 3887
    },
    {
      "epoch": 15.069767441860465,
      "grad_norm": 0.007271762937307358,
      "learning_rate": 3.4930232558139534e-05,
      "loss": 0.0005,
      "step": 3888
    },
    {
      "epoch": 15.073643410852712,
      "grad_norm": 0.005373536143451929,
      "learning_rate": 3.492635658914729e-05,
      "loss": 0.0004,
      "step": 3889
    },
    {
      "epoch": 15.077519379844961,
      "grad_norm": 0.008502199314534664,
      "learning_rate": 3.492248062015504e-05,
      "loss": 0.0006,
      "step": 3890
    },
    {
      "epoch": 15.081395348837209,
      "grad_norm": 0.01317070983350277,
      "learning_rate": 3.49186046511628e-05,
      "loss": 0.0005,
      "step": 3891
    },
    {
      "epoch": 15.085271317829458,
      "grad_norm": 0.5552027821540833,
      "learning_rate": 3.4914728682170543e-05,
      "loss": 0.007,
      "step": 3892
    },
    {
      "epoch": 15.089147286821705,
      "grad_norm": 3.1102075576782227,
      "learning_rate": 3.4910852713178296e-05,
      "loss": 0.0939,
      "step": 3893
    },
    {
      "epoch": 15.093023255813954,
      "grad_norm": 0.008296935819089413,
      "learning_rate": 3.490697674418605e-05,
      "loss": 0.0007,
      "step": 3894
    },
    {
      "epoch": 15.0968992248062,
      "grad_norm": 0.03296073153614998,
      "learning_rate": 3.49031007751938e-05,
      "loss": 0.0013,
      "step": 3895
    },
    {
      "epoch": 15.10077519379845,
      "grad_norm": 0.005439857952296734,
      "learning_rate": 3.489922480620155e-05,
      "loss": 0.0004,
      "step": 3896
    },
    {
      "epoch": 15.104651162790697,
      "grad_norm": 0.004986342042684555,
      "learning_rate": 3.48953488372093e-05,
      "loss": 0.0004,
      "step": 3897
    },
    {
      "epoch": 15.108527131782946,
      "grad_norm": 1.1331137418746948,
      "learning_rate": 3.489147286821706e-05,
      "loss": 0.1736,
      "step": 3898
    },
    {
      "epoch": 15.112403100775193,
      "grad_norm": 0.006354164332151413,
      "learning_rate": 3.4887596899224804e-05,
      "loss": 0.0004,
      "step": 3899
    },
    {
      "epoch": 15.116279069767442,
      "grad_norm": 0.008029649965465069,
      "learning_rate": 3.488372093023256e-05,
      "loss": 0.0006,
      "step": 3900
    },
    {
      "epoch": 15.12015503875969,
      "grad_norm": 0.04321917146444321,
      "learning_rate": 3.487984496124031e-05,
      "loss": 0.0008,
      "step": 3901
    },
    {
      "epoch": 15.124031007751938,
      "grad_norm": 0.0066978647373616695,
      "learning_rate": 3.487596899224807e-05,
      "loss": 0.0005,
      "step": 3902
    },
    {
      "epoch": 15.127906976744185,
      "grad_norm": 421.7996520996094,
      "learning_rate": 3.487209302325581e-05,
      "loss": 0.3762,
      "step": 3903
    },
    {
      "epoch": 15.131782945736434,
      "grad_norm": 0.012364789843559265,
      "learning_rate": 3.4868217054263566e-05,
      "loss": 0.0008,
      "step": 3904
    },
    {
      "epoch": 15.135658914728682,
      "grad_norm": 0.012088058516383171,
      "learning_rate": 3.486434108527132e-05,
      "loss": 0.0008,
      "step": 3905
    },
    {
      "epoch": 15.13953488372093,
      "grad_norm": 0.01649654656648636,
      "learning_rate": 3.486046511627907e-05,
      "loss": 0.0009,
      "step": 3906
    },
    {
      "epoch": 15.143410852713178,
      "grad_norm": 0.04766220226883888,
      "learning_rate": 3.485658914728682e-05,
      "loss": 0.0022,
      "step": 3907
    },
    {
      "epoch": 15.147286821705427,
      "grad_norm": 8.472350120544434,
      "learning_rate": 3.4852713178294575e-05,
      "loss": 0.2252,
      "step": 3908
    },
    {
      "epoch": 15.151162790697674,
      "grad_norm": 18.254791259765625,
      "learning_rate": 3.484883720930233e-05,
      "loss": 0.644,
      "step": 3909
    },
    {
      "epoch": 15.155038759689923,
      "grad_norm": 0.013336512260138988,
      "learning_rate": 3.484496124031008e-05,
      "loss": 0.0005,
      "step": 3910
    },
    {
      "epoch": 15.15891472868217,
      "grad_norm": 0.017798088490962982,
      "learning_rate": 3.484108527131783e-05,
      "loss": 0.0009,
      "step": 3911
    },
    {
      "epoch": 15.162790697674419,
      "grad_norm": 0.0342814177274704,
      "learning_rate": 3.4837209302325585e-05,
      "loss": 0.0013,
      "step": 3912
    },
    {
      "epoch": 15.166666666666666,
      "grad_norm": 0.0040457420982420444,
      "learning_rate": 3.483333333333334e-05,
      "loss": 0.0004,
      "step": 3913
    },
    {
      "epoch": 15.170542635658915,
      "grad_norm": 0.004421589896082878,
      "learning_rate": 3.482945736434109e-05,
      "loss": 0.0004,
      "step": 3914
    },
    {
      "epoch": 15.174418604651162,
      "grad_norm": 0.005434432532638311,
      "learning_rate": 3.4825581395348836e-05,
      "loss": 0.0004,
      "step": 3915
    },
    {
      "epoch": 15.178294573643411,
      "grad_norm": 0.0071772560477256775,
      "learning_rate": 3.4821705426356595e-05,
      "loss": 0.0005,
      "step": 3916
    },
    {
      "epoch": 15.182170542635658,
      "grad_norm": 0.060570381581783295,
      "learning_rate": 3.481782945736434e-05,
      "loss": 0.0022,
      "step": 3917
    },
    {
      "epoch": 15.186046511627907,
      "grad_norm": 0.36628955602645874,
      "learning_rate": 3.481395348837209e-05,
      "loss": 0.0028,
      "step": 3918
    },
    {
      "epoch": 15.189922480620154,
      "grad_norm": 3.2318129539489746,
      "learning_rate": 3.4810077519379845e-05,
      "loss": 0.4816,
      "step": 3919
    },
    {
      "epoch": 15.193798449612403,
      "grad_norm": 0.004335865378379822,
      "learning_rate": 3.48062015503876e-05,
      "loss": 0.0004,
      "step": 3920
    },
    {
      "epoch": 15.19767441860465,
      "grad_norm": 0.04274240508675575,
      "learning_rate": 3.480232558139535e-05,
      "loss": 0.0012,
      "step": 3921
    },
    {
      "epoch": 15.2015503875969,
      "grad_norm": 0.07196059077978134,
      "learning_rate": 3.47984496124031e-05,
      "loss": 0.0026,
      "step": 3922
    },
    {
      "epoch": 15.205426356589147,
      "grad_norm": 3.309748649597168,
      "learning_rate": 3.4794573643410855e-05,
      "loss": 0.0737,
      "step": 3923
    },
    {
      "epoch": 15.209302325581396,
      "grad_norm": 0.017718147486448288,
      "learning_rate": 3.479069767441861e-05,
      "loss": 0.0005,
      "step": 3924
    },
    {
      "epoch": 15.213178294573643,
      "grad_norm": 0.0035430756397545338,
      "learning_rate": 3.478682170542636e-05,
      "loss": 0.0003,
      "step": 3925
    },
    {
      "epoch": 15.217054263565892,
      "grad_norm": 0.07858535647392273,
      "learning_rate": 3.4782945736434105e-05,
      "loss": 0.0014,
      "step": 3926
    },
    {
      "epoch": 15.220930232558139,
      "grad_norm": 0.03514337167143822,
      "learning_rate": 3.4779069767441865e-05,
      "loss": 0.0015,
      "step": 3927
    },
    {
      "epoch": 15.224806201550388,
      "grad_norm": 0.035817261785268784,
      "learning_rate": 3.477519379844961e-05,
      "loss": 0.0015,
      "step": 3928
    },
    {
      "epoch": 15.228682170542635,
      "grad_norm": 0.24409399926662445,
      "learning_rate": 3.477131782945737e-05,
      "loss": 0.0077,
      "step": 3929
    },
    {
      "epoch": 15.232558139534884,
      "grad_norm": 0.02297322079539299,
      "learning_rate": 3.4767441860465115e-05,
      "loss": 0.0011,
      "step": 3930
    },
    {
      "epoch": 15.236434108527131,
      "grad_norm": 0.05459658056497574,
      "learning_rate": 3.4763565891472874e-05,
      "loss": 0.0011,
      "step": 3931
    },
    {
      "epoch": 15.24031007751938,
      "grad_norm": 0.00913020595908165,
      "learning_rate": 3.475968992248062e-05,
      "loss": 0.0006,
      "step": 3932
    },
    {
      "epoch": 15.244186046511627,
      "grad_norm": 0.04916283115744591,
      "learning_rate": 3.475581395348837e-05,
      "loss": 0.0017,
      "step": 3933
    },
    {
      "epoch": 15.248062015503876,
      "grad_norm": 0.013345188461244106,
      "learning_rate": 3.4751937984496125e-05,
      "loss": 0.0009,
      "step": 3934
    },
    {
      "epoch": 15.251937984496124,
      "grad_norm": 0.022171223536133766,
      "learning_rate": 3.474806201550388e-05,
      "loss": 0.0013,
      "step": 3935
    },
    {
      "epoch": 15.255813953488373,
      "grad_norm": 0.06857119500637054,
      "learning_rate": 3.474418604651163e-05,
      "loss": 0.002,
      "step": 3936
    },
    {
      "epoch": 15.25968992248062,
      "grad_norm": 0.01621994562447071,
      "learning_rate": 3.474031007751938e-05,
      "loss": 0.0008,
      "step": 3937
    },
    {
      "epoch": 15.263565891472869,
      "grad_norm": 0.008954787626862526,
      "learning_rate": 3.4736434108527134e-05,
      "loss": 0.0004,
      "step": 3938
    },
    {
      "epoch": 15.267441860465116,
      "grad_norm": 0.016208898276090622,
      "learning_rate": 3.473255813953489e-05,
      "loss": 0.0008,
      "step": 3939
    },
    {
      "epoch": 15.271317829457365,
      "grad_norm": 0.011534650810062885,
      "learning_rate": 3.472868217054264e-05,
      "loss": 0.0004,
      "step": 3940
    },
    {
      "epoch": 15.275193798449612,
      "grad_norm": 0.0032207751646637917,
      "learning_rate": 3.472480620155039e-05,
      "loss": 0.0003,
      "step": 3941
    },
    {
      "epoch": 15.279069767441861,
      "grad_norm": 0.023122049868106842,
      "learning_rate": 3.4720930232558144e-05,
      "loss": 0.001,
      "step": 3942
    },
    {
      "epoch": 15.282945736434108,
      "grad_norm": 0.010175776667892933,
      "learning_rate": 3.4717054263565897e-05,
      "loss": 0.0008,
      "step": 3943
    },
    {
      "epoch": 15.286821705426357,
      "grad_norm": 0.015191004611551762,
      "learning_rate": 3.471317829457364e-05,
      "loss": 0.0008,
      "step": 3944
    },
    {
      "epoch": 15.290697674418604,
      "grad_norm": 0.0070104836486279964,
      "learning_rate": 3.4709302325581395e-05,
      "loss": 0.0006,
      "step": 3945
    },
    {
      "epoch": 15.294573643410853,
      "grad_norm": 9.422340393066406,
      "learning_rate": 3.470542635658915e-05,
      "loss": 0.1878,
      "step": 3946
    },
    {
      "epoch": 15.2984496124031,
      "grad_norm": 0.012733394280076027,
      "learning_rate": 3.47015503875969e-05,
      "loss": 0.0008,
      "step": 3947
    },
    {
      "epoch": 15.30232558139535,
      "grad_norm": 0.008026275783777237,
      "learning_rate": 3.469767441860465e-05,
      "loss": 0.0005,
      "step": 3948
    },
    {
      "epoch": 15.306201550387597,
      "grad_norm": 0.007074553985148668,
      "learning_rate": 3.4693798449612404e-05,
      "loss": 0.0005,
      "step": 3949
    },
    {
      "epoch": 15.310077519379846,
      "grad_norm": 1.484835147857666,
      "learning_rate": 3.468992248062016e-05,
      "loss": 0.0196,
      "step": 3950
    },
    {
      "epoch": 15.313953488372093,
      "grad_norm": 0.6972169876098633,
      "learning_rate": 3.468604651162791e-05,
      "loss": 0.1019,
      "step": 3951
    },
    {
      "epoch": 15.317829457364342,
      "grad_norm": 0.006798523012548685,
      "learning_rate": 3.468217054263566e-05,
      "loss": 0.0005,
      "step": 3952
    },
    {
      "epoch": 15.321705426356589,
      "grad_norm": 0.02101283334195614,
      "learning_rate": 3.467829457364341e-05,
      "loss": 0.001,
      "step": 3953
    },
    {
      "epoch": 15.325581395348838,
      "grad_norm": 0.016699302941560745,
      "learning_rate": 3.4674418604651166e-05,
      "loss": 0.0008,
      "step": 3954
    },
    {
      "epoch": 15.329457364341085,
      "grad_norm": 0.021607978269457817,
      "learning_rate": 3.467054263565891e-05,
      "loss": 0.001,
      "step": 3955
    },
    {
      "epoch": 15.333333333333334,
      "grad_norm": 0.009006422944366932,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.0006,
      "step": 3956
    },
    {
      "epoch": 15.337209302325581,
      "grad_norm": 0.013663236051797867,
      "learning_rate": 3.466279069767442e-05,
      "loss": 0.0009,
      "step": 3957
    },
    {
      "epoch": 15.34108527131783,
      "grad_norm": 0.022122574970126152,
      "learning_rate": 3.4658914728682176e-05,
      "loss": 0.0014,
      "step": 3958
    },
    {
      "epoch": 15.344961240310077,
      "grad_norm": 8.168460845947266,
      "learning_rate": 3.465503875968992e-05,
      "loss": 0.4863,
      "step": 3959
    },
    {
      "epoch": 15.348837209302326,
      "grad_norm": 25.193031311035156,
      "learning_rate": 3.465116279069768e-05,
      "loss": 1.0347,
      "step": 3960
    },
    {
      "epoch": 15.352713178294573,
      "grad_norm": 0.040902670472860336,
      "learning_rate": 3.464728682170543e-05,
      "loss": 0.0023,
      "step": 3961
    },
    {
      "epoch": 15.356589147286822,
      "grad_norm": 5.669012069702148,
      "learning_rate": 3.464341085271318e-05,
      "loss": 0.1923,
      "step": 3962
    },
    {
      "epoch": 15.36046511627907,
      "grad_norm": 0.010155576281249523,
      "learning_rate": 3.463953488372093e-05,
      "loss": 0.0007,
      "step": 3963
    },
    {
      "epoch": 15.364341085271318,
      "grad_norm": 0.0064017619006335735,
      "learning_rate": 3.4635658914728684e-05,
      "loss": 0.0005,
      "step": 3964
    },
    {
      "epoch": 15.368217054263566,
      "grad_norm": 0.006792379543185234,
      "learning_rate": 3.4631782945736436e-05,
      "loss": 0.0005,
      "step": 3965
    },
    {
      "epoch": 15.372093023255815,
      "grad_norm": 2.092893362045288,
      "learning_rate": 3.462790697674419e-05,
      "loss": 0.0485,
      "step": 3966
    },
    {
      "epoch": 15.375968992248062,
      "grad_norm": 0.004252877552062273,
      "learning_rate": 3.462403100775194e-05,
      "loss": 0.0003,
      "step": 3967
    },
    {
      "epoch": 15.37984496124031,
      "grad_norm": 0.14257216453552246,
      "learning_rate": 3.4620155038759694e-05,
      "loss": 0.0023,
      "step": 3968
    },
    {
      "epoch": 15.383720930232558,
      "grad_norm": 2.8388748168945312,
      "learning_rate": 3.4616279069767446e-05,
      "loss": 0.2897,
      "step": 3969
    },
    {
      "epoch": 15.387596899224807,
      "grad_norm": 0.3086458742618561,
      "learning_rate": 3.46124031007752e-05,
      "loss": 0.013,
      "step": 3970
    },
    {
      "epoch": 15.391472868217054,
      "grad_norm": 4.35716438293457,
      "learning_rate": 3.4608527131782944e-05,
      "loss": 0.3502,
      "step": 3971
    },
    {
      "epoch": 15.395348837209303,
      "grad_norm": 0.009305039420723915,
      "learning_rate": 3.4604651162790697e-05,
      "loss": 0.0007,
      "step": 3972
    },
    {
      "epoch": 15.39922480620155,
      "grad_norm": 4.56373929977417,
      "learning_rate": 3.460077519379845e-05,
      "loss": 0.0562,
      "step": 3973
    },
    {
      "epoch": 15.4031007751938,
      "grad_norm": 9.561230659484863,
      "learning_rate": 3.45968992248062e-05,
      "loss": 0.0588,
      "step": 3974
    },
    {
      "epoch": 15.406976744186046,
      "grad_norm": 0.008228106424212456,
      "learning_rate": 3.4593023255813954e-05,
      "loss": 0.0006,
      "step": 3975
    },
    {
      "epoch": 15.410852713178295,
      "grad_norm": 0.006725900340825319,
      "learning_rate": 3.4589147286821706e-05,
      "loss": 0.0005,
      "step": 3976
    },
    {
      "epoch": 15.414728682170542,
      "grad_norm": 0.014113380573689938,
      "learning_rate": 3.458527131782946e-05,
      "loss": 0.0009,
      "step": 3977
    },
    {
      "epoch": 15.418604651162791,
      "grad_norm": 0.014639806002378464,
      "learning_rate": 3.458139534883721e-05,
      "loss": 0.0009,
      "step": 3978
    },
    {
      "epoch": 15.422480620155039,
      "grad_norm": 0.012181578204035759,
      "learning_rate": 3.4577519379844963e-05,
      "loss": 0.001,
      "step": 3979
    },
    {
      "epoch": 15.426356589147288,
      "grad_norm": 0.011511649936437607,
      "learning_rate": 3.4573643410852716e-05,
      "loss": 0.0008,
      "step": 3980
    },
    {
      "epoch": 15.430232558139535,
      "grad_norm": 0.08630950003862381,
      "learning_rate": 3.456976744186047e-05,
      "loss": 0.0039,
      "step": 3981
    },
    {
      "epoch": 15.434108527131784,
      "grad_norm": 6.757002353668213,
      "learning_rate": 3.4565891472868214e-05,
      "loss": 0.6483,
      "step": 3982
    },
    {
      "epoch": 15.437984496124031,
      "grad_norm": 2.982020139694214,
      "learning_rate": 3.456201550387597e-05,
      "loss": 0.3164,
      "step": 3983
    },
    {
      "epoch": 15.44186046511628,
      "grad_norm": 0.011439475230872631,
      "learning_rate": 3.455813953488372e-05,
      "loss": 0.0007,
      "step": 3984
    },
    {
      "epoch": 15.445736434108527,
      "grad_norm": 0.007954971864819527,
      "learning_rate": 3.455426356589148e-05,
      "loss": 0.0006,
      "step": 3985
    },
    {
      "epoch": 15.449612403100776,
      "grad_norm": 0.02249140664935112,
      "learning_rate": 3.4550387596899224e-05,
      "loss": 0.0008,
      "step": 3986
    },
    {
      "epoch": 15.453488372093023,
      "grad_norm": 0.01881757378578186,
      "learning_rate": 3.454651162790698e-05,
      "loss": 0.001,
      "step": 3987
    },
    {
      "epoch": 15.457364341085272,
      "grad_norm": 2.3472678661346436,
      "learning_rate": 3.454263565891473e-05,
      "loss": 0.0043,
      "step": 3988
    },
    {
      "epoch": 15.46124031007752,
      "grad_norm": 0.008260366506874561,
      "learning_rate": 3.453875968992248e-05,
      "loss": 0.0006,
      "step": 3989
    },
    {
      "epoch": 15.465116279069768,
      "grad_norm": 12.853531837463379,
      "learning_rate": 3.453488372093023e-05,
      "loss": 0.2935,
      "step": 3990
    },
    {
      "epoch": 15.468992248062015,
      "grad_norm": 0.11134126037359238,
      "learning_rate": 3.4531007751937986e-05,
      "loss": 0.0038,
      "step": 3991
    },
    {
      "epoch": 15.472868217054264,
      "grad_norm": 0.10876400768756866,
      "learning_rate": 3.452713178294574e-05,
      "loss": 0.0022,
      "step": 3992
    },
    {
      "epoch": 15.476744186046512,
      "grad_norm": 0.019818270578980446,
      "learning_rate": 3.452325581395349e-05,
      "loss": 0.001,
      "step": 3993
    },
    {
      "epoch": 15.48062015503876,
      "grad_norm": 2.937734603881836,
      "learning_rate": 3.451937984496124e-05,
      "loss": 0.2852,
      "step": 3994
    },
    {
      "epoch": 15.484496124031008,
      "grad_norm": 70.3212890625,
      "learning_rate": 3.4515503875968995e-05,
      "loss": 0.0969,
      "step": 3995
    },
    {
      "epoch": 15.488372093023255,
      "grad_norm": 0.018247012048959732,
      "learning_rate": 3.451162790697675e-05,
      "loss": 0.0012,
      "step": 3996
    },
    {
      "epoch": 15.492248062015504,
      "grad_norm": 0.01735670678317547,
      "learning_rate": 3.45077519379845e-05,
      "loss": 0.0009,
      "step": 3997
    },
    {
      "epoch": 15.496124031007753,
      "grad_norm": 3.429497480392456,
      "learning_rate": 3.450387596899225e-05,
      "loss": 0.0972,
      "step": 3998
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.011543678119778633,
      "learning_rate": 3.45e-05,
      "loss": 0.0007,
      "step": 3999
    },
    {
      "epoch": 15.503875968992247,
      "grad_norm": 0.012438290752470493,
      "learning_rate": 3.449612403100775e-05,
      "loss": 0.0007,
      "step": 4000
    },
    {
      "epoch": 15.507751937984496,
      "grad_norm": 0.03409675881266594,
      "learning_rate": 3.44922480620155e-05,
      "loss": 0.0019,
      "step": 4001
    },
    {
      "epoch": 15.511627906976745,
      "grad_norm": 0.006134598050266504,
      "learning_rate": 3.4488372093023256e-05,
      "loss": 0.0004,
      "step": 4002
    },
    {
      "epoch": 15.515503875968992,
      "grad_norm": 0.007997533306479454,
      "learning_rate": 3.448449612403101e-05,
      "loss": 0.0006,
      "step": 4003
    },
    {
      "epoch": 15.51937984496124,
      "grad_norm": 0.011667028069496155,
      "learning_rate": 3.448062015503876e-05,
      "loss": 0.0007,
      "step": 4004
    },
    {
      "epoch": 15.523255813953488,
      "grad_norm": 0.027413571253418922,
      "learning_rate": 3.447674418604651e-05,
      "loss": 0.0011,
      "step": 4005
    },
    {
      "epoch": 15.527131782945737,
      "grad_norm": 2.8088061809539795,
      "learning_rate": 3.4472868217054265e-05,
      "loss": 0.0725,
      "step": 4006
    },
    {
      "epoch": 15.531007751937985,
      "grad_norm": 0.014974567107856274,
      "learning_rate": 3.446899224806202e-05,
      "loss": 0.0008,
      "step": 4007
    },
    {
      "epoch": 15.534883720930232,
      "grad_norm": 0.007389575708657503,
      "learning_rate": 3.446511627906977e-05,
      "loss": 0.0006,
      "step": 4008
    },
    {
      "epoch": 15.53875968992248,
      "grad_norm": 0.5164734721183777,
      "learning_rate": 3.446124031007752e-05,
      "loss": 0.0172,
      "step": 4009
    },
    {
      "epoch": 15.542635658914728,
      "grad_norm": 0.0061232526786625385,
      "learning_rate": 3.4457364341085275e-05,
      "loss": 0.0005,
      "step": 4010
    },
    {
      "epoch": 15.546511627906977,
      "grad_norm": 0.4439055919647217,
      "learning_rate": 3.445348837209302e-05,
      "loss": 0.0182,
      "step": 4011
    },
    {
      "epoch": 15.550387596899224,
      "grad_norm": 0.02226094901561737,
      "learning_rate": 3.444961240310078e-05,
      "loss": 0.0011,
      "step": 4012
    },
    {
      "epoch": 15.554263565891473,
      "grad_norm": 0.015392862260341644,
      "learning_rate": 3.4445736434108525e-05,
      "loss": 0.0005,
      "step": 4013
    },
    {
      "epoch": 15.55813953488372,
      "grad_norm": 0.011733656749129295,
      "learning_rate": 3.4441860465116285e-05,
      "loss": 0.0006,
      "step": 4014
    },
    {
      "epoch": 15.562015503875969,
      "grad_norm": 0.027969632297754288,
      "learning_rate": 3.443798449612403e-05,
      "loss": 0.0015,
      "step": 4015
    },
    {
      "epoch": 15.565891472868216,
      "grad_norm": 0.005362048279494047,
      "learning_rate": 3.443410852713179e-05,
      "loss": 0.0004,
      "step": 4016
    },
    {
      "epoch": 15.569767441860465,
      "grad_norm": 0.017405498772859573,
      "learning_rate": 3.4430232558139535e-05,
      "loss": 0.0006,
      "step": 4017
    },
    {
      "epoch": 15.573643410852712,
      "grad_norm": 0.004777085967361927,
      "learning_rate": 3.442635658914729e-05,
      "loss": 0.0004,
      "step": 4018
    },
    {
      "epoch": 15.577519379844961,
      "grad_norm": 0.005200590007007122,
      "learning_rate": 3.442248062015504e-05,
      "loss": 0.0004,
      "step": 4019
    },
    {
      "epoch": 15.581395348837209,
      "grad_norm": 0.004259061999619007,
      "learning_rate": 3.441860465116279e-05,
      "loss": 0.0003,
      "step": 4020
    },
    {
      "epoch": 15.585271317829458,
      "grad_norm": 0.017176328226923943,
      "learning_rate": 3.4414728682170545e-05,
      "loss": 0.0005,
      "step": 4021
    },
    {
      "epoch": 15.589147286821705,
      "grad_norm": 0.008363020606338978,
      "learning_rate": 3.44108527131783e-05,
      "loss": 0.0006,
      "step": 4022
    },
    {
      "epoch": 15.593023255813954,
      "grad_norm": 0.005035030655562878,
      "learning_rate": 3.440697674418605e-05,
      "loss": 0.0004,
      "step": 4023
    },
    {
      "epoch": 15.5968992248062,
      "grad_norm": 0.004827126860618591,
      "learning_rate": 3.44031007751938e-05,
      "loss": 0.0004,
      "step": 4024
    },
    {
      "epoch": 15.60077519379845,
      "grad_norm": 0.004270005505532026,
      "learning_rate": 3.4399224806201555e-05,
      "loss": 0.0004,
      "step": 4025
    },
    {
      "epoch": 15.604651162790697,
      "grad_norm": 0.15722809731960297,
      "learning_rate": 3.43953488372093e-05,
      "loss": 0.0058,
      "step": 4026
    },
    {
      "epoch": 15.608527131782946,
      "grad_norm": 0.4173599183559418,
      "learning_rate": 3.439147286821706e-05,
      "loss": 0.0181,
      "step": 4027
    },
    {
      "epoch": 15.612403100775193,
      "grad_norm": 0.009258253499865532,
      "learning_rate": 3.4387596899224805e-05,
      "loss": 0.0004,
      "step": 4028
    },
    {
      "epoch": 15.616279069767442,
      "grad_norm": 0.0039647785015404224,
      "learning_rate": 3.438372093023256e-05,
      "loss": 0.0003,
      "step": 4029
    },
    {
      "epoch": 15.62015503875969,
      "grad_norm": 0.004602300934493542,
      "learning_rate": 3.437984496124031e-05,
      "loss": 0.0004,
      "step": 4030
    },
    {
      "epoch": 15.624031007751938,
      "grad_norm": 0.0036900625564157963,
      "learning_rate": 3.437596899224806e-05,
      "loss": 0.0003,
      "step": 4031
    },
    {
      "epoch": 15.627906976744185,
      "grad_norm": 6.1581878662109375,
      "learning_rate": 3.4372093023255815e-05,
      "loss": 0.0206,
      "step": 4032
    },
    {
      "epoch": 15.631782945736434,
      "grad_norm": 0.02338220365345478,
      "learning_rate": 3.436821705426357e-05,
      "loss": 0.0013,
      "step": 4033
    },
    {
      "epoch": 15.635658914728682,
      "grad_norm": 9.544557571411133,
      "learning_rate": 3.436434108527132e-05,
      "loss": 0.2515,
      "step": 4034
    },
    {
      "epoch": 15.63953488372093,
      "grad_norm": 0.0071524567902088165,
      "learning_rate": 3.436046511627907e-05,
      "loss": 0.0004,
      "step": 4035
    },
    {
      "epoch": 15.643410852713178,
      "grad_norm": 0.04631303995847702,
      "learning_rate": 3.4356589147286824e-05,
      "loss": 0.0018,
      "step": 4036
    },
    {
      "epoch": 15.647286821705427,
      "grad_norm": 0.014136966317892075,
      "learning_rate": 3.435271317829458e-05,
      "loss": 0.0009,
      "step": 4037
    },
    {
      "epoch": 15.651162790697674,
      "grad_norm": 0.005456758663058281,
      "learning_rate": 3.434883720930233e-05,
      "loss": 0.0004,
      "step": 4038
    },
    {
      "epoch": 15.655038759689923,
      "grad_norm": 0.003111914498731494,
      "learning_rate": 3.434496124031008e-05,
      "loss": 0.0003,
      "step": 4039
    },
    {
      "epoch": 15.65891472868217,
      "grad_norm": 0.017926102504134178,
      "learning_rate": 3.434108527131783e-05,
      "loss": 0.0005,
      "step": 4040
    },
    {
      "epoch": 15.662790697674419,
      "grad_norm": 0.003948374651372433,
      "learning_rate": 3.4337209302325586e-05,
      "loss": 0.0003,
      "step": 4041
    },
    {
      "epoch": 15.666666666666666,
      "grad_norm": 0.0030479696579277515,
      "learning_rate": 3.433333333333333e-05,
      "loss": 0.0003,
      "step": 4042
    },
    {
      "epoch": 15.670542635658915,
      "grad_norm": 0.004104472231119871,
      "learning_rate": 3.432945736434109e-05,
      "loss": 0.0004,
      "step": 4043
    },
    {
      "epoch": 15.674418604651162,
      "grad_norm": 0.0870913714170456,
      "learning_rate": 3.432558139534884e-05,
      "loss": 0.0029,
      "step": 4044
    },
    {
      "epoch": 15.678294573643411,
      "grad_norm": 9.126605987548828,
      "learning_rate": 3.4321705426356596e-05,
      "loss": 0.0875,
      "step": 4045
    },
    {
      "epoch": 15.682170542635658,
      "grad_norm": 1.0096737146377563,
      "learning_rate": 3.431782945736434e-05,
      "loss": 0.1731,
      "step": 4046
    },
    {
      "epoch": 15.686046511627907,
      "grad_norm": 0.003743615234270692,
      "learning_rate": 3.4313953488372094e-05,
      "loss": 0.0004,
      "step": 4047
    },
    {
      "epoch": 15.689922480620154,
      "grad_norm": 0.5339028835296631,
      "learning_rate": 3.431007751937985e-05,
      "loss": 0.0015,
      "step": 4048
    },
    {
      "epoch": 15.693798449612403,
      "grad_norm": 10.123409271240234,
      "learning_rate": 3.43062015503876e-05,
      "loss": 0.3544,
      "step": 4049
    },
    {
      "epoch": 15.69767441860465,
      "grad_norm": 4.253368377685547,
      "learning_rate": 3.430232558139535e-05,
      "loss": 0.2526,
      "step": 4050
    },
    {
      "epoch": 15.7015503875969,
      "grad_norm": 0.00370863638818264,
      "learning_rate": 3.4298449612403104e-05,
      "loss": 0.0004,
      "step": 4051
    },
    {
      "epoch": 15.705426356589147,
      "grad_norm": 0.006985098589211702,
      "learning_rate": 3.4294573643410856e-05,
      "loss": 0.0005,
      "step": 4052
    },
    {
      "epoch": 15.709302325581396,
      "grad_norm": 47.10378646850586,
      "learning_rate": 3.42906976744186e-05,
      "loss": 0.5605,
      "step": 4053
    },
    {
      "epoch": 15.713178294573643,
      "grad_norm": 0.046189889311790466,
      "learning_rate": 3.428682170542636e-05,
      "loss": 0.0005,
      "step": 4054
    },
    {
      "epoch": 15.717054263565892,
      "grad_norm": 2.8392534255981445,
      "learning_rate": 3.428294573643411e-05,
      "loss": 0.0202,
      "step": 4055
    },
    {
      "epoch": 15.720930232558139,
      "grad_norm": 0.003829541150480509,
      "learning_rate": 3.427906976744186e-05,
      "loss": 0.0004,
      "step": 4056
    },
    {
      "epoch": 15.724806201550388,
      "grad_norm": 0.0049512023106217384,
      "learning_rate": 3.427519379844961e-05,
      "loss": 0.0003,
      "step": 4057
    },
    {
      "epoch": 15.728682170542635,
      "grad_norm": 11.036099433898926,
      "learning_rate": 3.4271317829457364e-05,
      "loss": 1.5113,
      "step": 4058
    },
    {
      "epoch": 15.732558139534884,
      "grad_norm": 0.06032107025384903,
      "learning_rate": 3.4267441860465117e-05,
      "loss": 0.0022,
      "step": 4059
    },
    {
      "epoch": 15.736434108527131,
      "grad_norm": 0.004775607492774725,
      "learning_rate": 3.426356589147287e-05,
      "loss": 0.0004,
      "step": 4060
    },
    {
      "epoch": 15.74031007751938,
      "grad_norm": 0.009030414745211601,
      "learning_rate": 3.425968992248062e-05,
      "loss": 0.0006,
      "step": 4061
    },
    {
      "epoch": 15.744186046511627,
      "grad_norm": 0.003114948747679591,
      "learning_rate": 3.4255813953488374e-05,
      "loss": 0.0003,
      "step": 4062
    },
    {
      "epoch": 15.748062015503876,
      "grad_norm": 0.02095063403248787,
      "learning_rate": 3.4251937984496126e-05,
      "loss": 0.0006,
      "step": 4063
    },
    {
      "epoch": 15.751937984496124,
      "grad_norm": 0.005804325919598341,
      "learning_rate": 3.424806201550388e-05,
      "loss": 0.0004,
      "step": 4064
    },
    {
      "epoch": 15.755813953488373,
      "grad_norm": 0.008380345068871975,
      "learning_rate": 3.424418604651163e-05,
      "loss": 0.0005,
      "step": 4065
    },
    {
      "epoch": 15.75968992248062,
      "grad_norm": 2.8182880878448486,
      "learning_rate": 3.4240310077519383e-05,
      "loss": 0.0147,
      "step": 4066
    },
    {
      "epoch": 15.763565891472869,
      "grad_norm": 0.01205266173928976,
      "learning_rate": 3.423643410852713e-05,
      "loss": 0.0006,
      "step": 4067
    },
    {
      "epoch": 15.767441860465116,
      "grad_norm": 0.006123182363808155,
      "learning_rate": 3.423255813953489e-05,
      "loss": 0.0004,
      "step": 4068
    },
    {
      "epoch": 15.771317829457365,
      "grad_norm": 0.03351496160030365,
      "learning_rate": 3.4228682170542634e-05,
      "loss": 0.0012,
      "step": 4069
    },
    {
      "epoch": 15.775193798449612,
      "grad_norm": 0.04340659826993942,
      "learning_rate": 3.422480620155039e-05,
      "loss": 0.0011,
      "step": 4070
    },
    {
      "epoch": 15.779069767441861,
      "grad_norm": 0.020433221012353897,
      "learning_rate": 3.422093023255814e-05,
      "loss": 0.0013,
      "step": 4071
    },
    {
      "epoch": 15.782945736434108,
      "grad_norm": 0.028202950954437256,
      "learning_rate": 3.42170542635659e-05,
      "loss": 0.0009,
      "step": 4072
    },
    {
      "epoch": 15.786821705426357,
      "grad_norm": 0.25563013553619385,
      "learning_rate": 3.4213178294573644e-05,
      "loss": 0.003,
      "step": 4073
    },
    {
      "epoch": 15.790697674418604,
      "grad_norm": 0.7716059684753418,
      "learning_rate": 3.4209302325581396e-05,
      "loss": 0.0021,
      "step": 4074
    },
    {
      "epoch": 15.794573643410853,
      "grad_norm": 1.230427622795105,
      "learning_rate": 3.420542635658915e-05,
      "loss": 0.0428,
      "step": 4075
    },
    {
      "epoch": 15.7984496124031,
      "grad_norm": 0.005221818573772907,
      "learning_rate": 3.42015503875969e-05,
      "loss": 0.0004,
      "step": 4076
    },
    {
      "epoch": 15.80232558139535,
      "grad_norm": 1.570314645767212,
      "learning_rate": 3.419767441860465e-05,
      "loss": 0.0085,
      "step": 4077
    },
    {
      "epoch": 15.806201550387597,
      "grad_norm": 0.0064653027802705765,
      "learning_rate": 3.41937984496124e-05,
      "loss": 0.0004,
      "step": 4078
    },
    {
      "epoch": 15.810077519379846,
      "grad_norm": 0.008791118860244751,
      "learning_rate": 3.418992248062016e-05,
      "loss": 0.0007,
      "step": 4079
    },
    {
      "epoch": 15.813953488372093,
      "grad_norm": 0.011855047196149826,
      "learning_rate": 3.4186046511627904e-05,
      "loss": 0.0006,
      "step": 4080
    },
    {
      "epoch": 15.817829457364342,
      "grad_norm": 4.595144748687744,
      "learning_rate": 3.418217054263566e-05,
      "loss": 0.112,
      "step": 4081
    },
    {
      "epoch": 15.821705426356589,
      "grad_norm": 1.0345507860183716,
      "learning_rate": 3.417829457364341e-05,
      "loss": 0.1441,
      "step": 4082
    },
    {
      "epoch": 15.825581395348838,
      "grad_norm": 0.2293211817741394,
      "learning_rate": 3.417441860465117e-05,
      "loss": 0.0091,
      "step": 4083
    },
    {
      "epoch": 15.829457364341085,
      "grad_norm": 0.02037128247320652,
      "learning_rate": 3.4170542635658914e-05,
      "loss": 0.0006,
      "step": 4084
    },
    {
      "epoch": 15.833333333333334,
      "grad_norm": 0.045870933681726456,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 0.0017,
      "step": 4085
    },
    {
      "epoch": 15.837209302325581,
      "grad_norm": 0.4768795073032379,
      "learning_rate": 3.416279069767442e-05,
      "loss": 0.0186,
      "step": 4086
    },
    {
      "epoch": 15.84108527131783,
      "grad_norm": 0.0027022601570934057,
      "learning_rate": 3.415891472868217e-05,
      "loss": 0.0003,
      "step": 4087
    },
    {
      "epoch": 15.844961240310077,
      "grad_norm": 0.004201869945973158,
      "learning_rate": 3.415503875968992e-05,
      "loss": 0.0004,
      "step": 4088
    },
    {
      "epoch": 15.848837209302326,
      "grad_norm": 0.35475820302963257,
      "learning_rate": 3.4151162790697676e-05,
      "loss": 0.0068,
      "step": 4089
    },
    {
      "epoch": 15.852713178294573,
      "grad_norm": 0.004731822293251753,
      "learning_rate": 3.414728682170543e-05,
      "loss": 0.0004,
      "step": 4090
    },
    {
      "epoch": 15.856589147286822,
      "grad_norm": 0.0031285076402127743,
      "learning_rate": 3.414341085271318e-05,
      "loss": 0.0003,
      "step": 4091
    },
    {
      "epoch": 15.86046511627907,
      "grad_norm": 0.004903717432171106,
      "learning_rate": 3.413953488372093e-05,
      "loss": 0.0004,
      "step": 4092
    },
    {
      "epoch": 15.864341085271318,
      "grad_norm": 0.07182520627975464,
      "learning_rate": 3.4135658914728685e-05,
      "loss": 0.0029,
      "step": 4093
    },
    {
      "epoch": 15.868217054263566,
      "grad_norm": 0.00496269715949893,
      "learning_rate": 3.413178294573644e-05,
      "loss": 0.0003,
      "step": 4094
    },
    {
      "epoch": 15.872093023255815,
      "grad_norm": 0.0037825298495590687,
      "learning_rate": 3.412790697674419e-05,
      "loss": 0.0004,
      "step": 4095
    },
    {
      "epoch": 15.875968992248062,
      "grad_norm": 0.02962091565132141,
      "learning_rate": 3.4124031007751936e-05,
      "loss": 0.0018,
      "step": 4096
    },
    {
      "epoch": 15.87984496124031,
      "grad_norm": 0.0034952342975884676,
      "learning_rate": 3.4120155038759695e-05,
      "loss": 0.0003,
      "step": 4097
    },
    {
      "epoch": 15.883720930232558,
      "grad_norm": 0.005768102128058672,
      "learning_rate": 3.411627906976744e-05,
      "loss": 0.0003,
      "step": 4098
    },
    {
      "epoch": 15.887596899224807,
      "grad_norm": 0.0033038135152310133,
      "learning_rate": 3.41124031007752e-05,
      "loss": 0.0003,
      "step": 4099
    },
    {
      "epoch": 15.891472868217054,
      "grad_norm": 0.002928694011643529,
      "learning_rate": 3.4108527131782945e-05,
      "loss": 0.0003,
      "step": 4100
    },
    {
      "epoch": 15.895348837209303,
      "grad_norm": 0.002581254579126835,
      "learning_rate": 3.4104651162790705e-05,
      "loss": 0.0003,
      "step": 4101
    },
    {
      "epoch": 15.89922480620155,
      "grad_norm": 0.006596774328500032,
      "learning_rate": 3.410077519379845e-05,
      "loss": 0.0003,
      "step": 4102
    },
    {
      "epoch": 15.9031007751938,
      "grad_norm": 8.490769386291504,
      "learning_rate": 3.40968992248062e-05,
      "loss": 0.523,
      "step": 4103
    },
    {
      "epoch": 15.906976744186046,
      "grad_norm": 0.004074079915881157,
      "learning_rate": 3.4093023255813955e-05,
      "loss": 0.0003,
      "step": 4104
    },
    {
      "epoch": 15.910852713178295,
      "grad_norm": 0.020988829433918,
      "learning_rate": 3.408914728682171e-05,
      "loss": 0.0011,
      "step": 4105
    },
    {
      "epoch": 15.914728682170542,
      "grad_norm": 0.00313678290694952,
      "learning_rate": 3.408527131782946e-05,
      "loss": 0.0003,
      "step": 4106
    },
    {
      "epoch": 15.918604651162791,
      "grad_norm": 0.03446653112769127,
      "learning_rate": 3.4081395348837206e-05,
      "loss": 0.0016,
      "step": 4107
    },
    {
      "epoch": 15.922480620155039,
      "grad_norm": 3.9401934146881104,
      "learning_rate": 3.4077519379844965e-05,
      "loss": 0.1603,
      "step": 4108
    },
    {
      "epoch": 15.926356589147288,
      "grad_norm": 0.0035323924385011196,
      "learning_rate": 3.407364341085271e-05,
      "loss": 0.0003,
      "step": 4109
    },
    {
      "epoch": 15.930232558139535,
      "grad_norm": 0.005101884715259075,
      "learning_rate": 3.406976744186047e-05,
      "loss": 0.0003,
      "step": 4110
    },
    {
      "epoch": 15.934108527131784,
      "grad_norm": 0.00386524829082191,
      "learning_rate": 3.4065891472868215e-05,
      "loss": 0.0003,
      "step": 4111
    },
    {
      "epoch": 15.937984496124031,
      "grad_norm": 0.021382620558142662,
      "learning_rate": 3.4062015503875975e-05,
      "loss": 0.0011,
      "step": 4112
    },
    {
      "epoch": 15.94186046511628,
      "grad_norm": 0.003529102075845003,
      "learning_rate": 3.405813953488372e-05,
      "loss": 0.0003,
      "step": 4113
    },
    {
      "epoch": 15.945736434108527,
      "grad_norm": 7.092528820037842,
      "learning_rate": 3.405426356589147e-05,
      "loss": 0.1598,
      "step": 4114
    },
    {
      "epoch": 15.949612403100776,
      "grad_norm": 2.0144569873809814,
      "learning_rate": 3.4050387596899225e-05,
      "loss": 0.1708,
      "step": 4115
    },
    {
      "epoch": 15.953488372093023,
      "grad_norm": 0.004083461593836546,
      "learning_rate": 3.404651162790698e-05,
      "loss": 0.0003,
      "step": 4116
    },
    {
      "epoch": 15.957364341085272,
      "grad_norm": 6.222153663635254,
      "learning_rate": 3.404263565891473e-05,
      "loss": 0.6482,
      "step": 4117
    },
    {
      "epoch": 15.96124031007752,
      "grad_norm": 0.053238123655319214,
      "learning_rate": 3.403875968992248e-05,
      "loss": 0.0005,
      "step": 4118
    },
    {
      "epoch": 15.965116279069768,
      "grad_norm": 8.887993812561035,
      "learning_rate": 3.4034883720930235e-05,
      "loss": 0.1017,
      "step": 4119
    },
    {
      "epoch": 15.968992248062015,
      "grad_norm": 0.005085783079266548,
      "learning_rate": 3.403100775193799e-05,
      "loss": 0.0004,
      "step": 4120
    },
    {
      "epoch": 15.972868217054263,
      "grad_norm": 1.4944525957107544,
      "learning_rate": 3.402713178294574e-05,
      "loss": 0.196,
      "step": 4121
    },
    {
      "epoch": 15.976744186046512,
      "grad_norm": 0.08415261656045914,
      "learning_rate": 3.402325581395349e-05,
      "loss": 0.0039,
      "step": 4122
    },
    {
      "epoch": 15.98062015503876,
      "grad_norm": 0.04251907765865326,
      "learning_rate": 3.4019379844961244e-05,
      "loss": 0.002,
      "step": 4123
    },
    {
      "epoch": 15.984496124031008,
      "grad_norm": 6.097516059875488,
      "learning_rate": 3.4015503875969e-05,
      "loss": 0.7479,
      "step": 4124
    },
    {
      "epoch": 15.988372093023255,
      "grad_norm": 0.004722459241747856,
      "learning_rate": 3.401162790697674e-05,
      "loss": 0.0004,
      "step": 4125
    },
    {
      "epoch": 15.992248062015504,
      "grad_norm": 0.007656303700059652,
      "learning_rate": 3.40077519379845e-05,
      "loss": 0.0006,
      "step": 4126
    },
    {
      "epoch": 15.996124031007753,
      "grad_norm": 0.008897055871784687,
      "learning_rate": 3.400387596899225e-05,
      "loss": 0.0005,
      "step": 4127
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.007302613463252783,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0005,
      "step": 4128
    },
    {
      "epoch": 16.003875968992247,
      "grad_norm": 0.019524557515978813,
      "learning_rate": 3.399612403100775e-05,
      "loss": 0.0012,
      "step": 4129
    },
    {
      "epoch": 16.007751937984494,
      "grad_norm": 0.018586764112114906,
      "learning_rate": 3.399224806201551e-05,
      "loss": 0.0008,
      "step": 4130
    },
    {
      "epoch": 16.011627906976745,
      "grad_norm": 0.020643241703510284,
      "learning_rate": 3.398837209302326e-05,
      "loss": 0.0013,
      "step": 4131
    },
    {
      "epoch": 16.015503875968992,
      "grad_norm": 0.022206464782357216,
      "learning_rate": 3.398449612403101e-05,
      "loss": 0.0014,
      "step": 4132
    },
    {
      "epoch": 16.01937984496124,
      "grad_norm": 0.3315335512161255,
      "learning_rate": 3.398062015503876e-05,
      "loss": 0.0142,
      "step": 4133
    },
    {
      "epoch": 16.023255813953487,
      "grad_norm": 0.08261476457118988,
      "learning_rate": 3.397674418604651e-05,
      "loss": 0.0025,
      "step": 4134
    },
    {
      "epoch": 16.027131782945737,
      "grad_norm": 0.027933456003665924,
      "learning_rate": 3.397286821705427e-05,
      "loss": 0.0011,
      "step": 4135
    },
    {
      "epoch": 16.031007751937985,
      "grad_norm": 4.380967140197754,
      "learning_rate": 3.396899224806201e-05,
      "loss": 0.2849,
      "step": 4136
    },
    {
      "epoch": 16.03488372093023,
      "grad_norm": 0.011257166042923927,
      "learning_rate": 3.396511627906977e-05,
      "loss": 0.0006,
      "step": 4137
    },
    {
      "epoch": 16.03875968992248,
      "grad_norm": 0.08923504501581192,
      "learning_rate": 3.396124031007752e-05,
      "loss": 0.0044,
      "step": 4138
    },
    {
      "epoch": 16.04263565891473,
      "grad_norm": 0.04796598479151726,
      "learning_rate": 3.3957364341085276e-05,
      "loss": 0.0029,
      "step": 4139
    },
    {
      "epoch": 16.046511627906977,
      "grad_norm": 2.5971920490264893,
      "learning_rate": 3.395348837209302e-05,
      "loss": 0.3536,
      "step": 4140
    },
    {
      "epoch": 16.050387596899224,
      "grad_norm": 0.46086105704307556,
      "learning_rate": 3.394961240310078e-05,
      "loss": 0.0169,
      "step": 4141
    },
    {
      "epoch": 16.05426356589147,
      "grad_norm": 0.014131969772279263,
      "learning_rate": 3.394573643410853e-05,
      "loss": 0.0006,
      "step": 4142
    },
    {
      "epoch": 16.058139534883722,
      "grad_norm": 9.962126731872559,
      "learning_rate": 3.394186046511628e-05,
      "loss": 0.1809,
      "step": 4143
    },
    {
      "epoch": 16.06201550387597,
      "grad_norm": 0.01973290555179119,
      "learning_rate": 3.393798449612403e-05,
      "loss": 0.0008,
      "step": 4144
    },
    {
      "epoch": 16.065891472868216,
      "grad_norm": 0.003730539930984378,
      "learning_rate": 3.3934108527131784e-05,
      "loss": 0.0003,
      "step": 4145
    },
    {
      "epoch": 16.069767441860463,
      "grad_norm": 0.9659188389778137,
      "learning_rate": 3.3930232558139537e-05,
      "loss": 0.0133,
      "step": 4146
    },
    {
      "epoch": 16.073643410852714,
      "grad_norm": 0.0064304666593670845,
      "learning_rate": 3.392635658914729e-05,
      "loss": 0.0004,
      "step": 4147
    },
    {
      "epoch": 16.07751937984496,
      "grad_norm": 0.06677411496639252,
      "learning_rate": 3.392248062015504e-05,
      "loss": 0.0037,
      "step": 4148
    },
    {
      "epoch": 16.08139534883721,
      "grad_norm": 0.026209713891148567,
      "learning_rate": 3.3918604651162794e-05,
      "loss": 0.0016,
      "step": 4149
    },
    {
      "epoch": 16.085271317829456,
      "grad_norm": 0.005419782362878323,
      "learning_rate": 3.3914728682170546e-05,
      "loss": 0.0004,
      "step": 4150
    },
    {
      "epoch": 16.089147286821706,
      "grad_norm": 0.034620970487594604,
      "learning_rate": 3.39108527131783e-05,
      "loss": 0.0018,
      "step": 4151
    },
    {
      "epoch": 16.093023255813954,
      "grad_norm": 4.132718563079834,
      "learning_rate": 3.3906976744186044e-05,
      "loss": 0.2045,
      "step": 4152
    },
    {
      "epoch": 16.0968992248062,
      "grad_norm": 0.0027997910510748625,
      "learning_rate": 3.3903100775193803e-05,
      "loss": 0.0003,
      "step": 4153
    },
    {
      "epoch": 16.100775193798448,
      "grad_norm": 0.04952431842684746,
      "learning_rate": 3.389922480620155e-05,
      "loss": 0.0014,
      "step": 4154
    },
    {
      "epoch": 16.1046511627907,
      "grad_norm": 0.004139219410717487,
      "learning_rate": 3.389534883720931e-05,
      "loss": 0.0003,
      "step": 4155
    },
    {
      "epoch": 16.108527131782946,
      "grad_norm": 0.003392233280465007,
      "learning_rate": 3.3891472868217054e-05,
      "loss": 0.0003,
      "step": 4156
    },
    {
      "epoch": 16.112403100775193,
      "grad_norm": 0.0058748056180775166,
      "learning_rate": 3.388759689922481e-05,
      "loss": 0.0004,
      "step": 4157
    },
    {
      "epoch": 16.11627906976744,
      "grad_norm": 0.0029032742604613304,
      "learning_rate": 3.388372093023256e-05,
      "loss": 0.0003,
      "step": 4158
    },
    {
      "epoch": 16.12015503875969,
      "grad_norm": 0.0052151791751384735,
      "learning_rate": 3.387984496124031e-05,
      "loss": 0.0004,
      "step": 4159
    },
    {
      "epoch": 16.124031007751938,
      "grad_norm": 0.0035087286960333586,
      "learning_rate": 3.3875968992248064e-05,
      "loss": 0.0003,
      "step": 4160
    },
    {
      "epoch": 16.127906976744185,
      "grad_norm": 0.10464292764663696,
      "learning_rate": 3.3872093023255816e-05,
      "loss": 0.0016,
      "step": 4161
    },
    {
      "epoch": 16.131782945736433,
      "grad_norm": 0.2298538237810135,
      "learning_rate": 3.386821705426357e-05,
      "loss": 0.0064,
      "step": 4162
    },
    {
      "epoch": 16.135658914728683,
      "grad_norm": 0.018660133704543114,
      "learning_rate": 3.3864341085271314e-05,
      "loss": 0.001,
      "step": 4163
    },
    {
      "epoch": 16.13953488372093,
      "grad_norm": 0.009729101322591305,
      "learning_rate": 3.386046511627907e-05,
      "loss": 0.0004,
      "step": 4164
    },
    {
      "epoch": 16.143410852713178,
      "grad_norm": 0.0028640367090702057,
      "learning_rate": 3.385658914728682e-05,
      "loss": 0.0003,
      "step": 4165
    },
    {
      "epoch": 16.147286821705425,
      "grad_norm": 0.00426321430131793,
      "learning_rate": 3.385271317829458e-05,
      "loss": 0.0004,
      "step": 4166
    },
    {
      "epoch": 16.151162790697676,
      "grad_norm": 3.2734358310699463,
      "learning_rate": 3.3848837209302324e-05,
      "loss": 0.3069,
      "step": 4167
    },
    {
      "epoch": 16.155038759689923,
      "grad_norm": 0.0033652959391474724,
      "learning_rate": 3.384496124031008e-05,
      "loss": 0.0003,
      "step": 4168
    },
    {
      "epoch": 16.15891472868217,
      "grad_norm": 0.004798869602382183,
      "learning_rate": 3.384108527131783e-05,
      "loss": 0.0004,
      "step": 4169
    },
    {
      "epoch": 16.162790697674417,
      "grad_norm": 0.9260033369064331,
      "learning_rate": 3.383720930232558e-05,
      "loss": 0.0223,
      "step": 4170
    },
    {
      "epoch": 16.166666666666668,
      "grad_norm": 7.399214267730713,
      "learning_rate": 3.3833333333333334e-05,
      "loss": 0.9903,
      "step": 4171
    },
    {
      "epoch": 16.170542635658915,
      "grad_norm": 2.612213611602783,
      "learning_rate": 3.3829457364341086e-05,
      "loss": 0.0571,
      "step": 4172
    },
    {
      "epoch": 16.174418604651162,
      "grad_norm": 0.00734096672385931,
      "learning_rate": 3.382558139534884e-05,
      "loss": 0.0006,
      "step": 4173
    },
    {
      "epoch": 16.17829457364341,
      "grad_norm": 0.0055514234118163586,
      "learning_rate": 3.382170542635659e-05,
      "loss": 0.0004,
      "step": 4174
    },
    {
      "epoch": 16.18217054263566,
      "grad_norm": 0.11823683977127075,
      "learning_rate": 3.381782945736434e-05,
      "loss": 0.0044,
      "step": 4175
    },
    {
      "epoch": 16.186046511627907,
      "grad_norm": 0.007564856205135584,
      "learning_rate": 3.3813953488372096e-05,
      "loss": 0.0006,
      "step": 4176
    },
    {
      "epoch": 16.189922480620154,
      "grad_norm": 5.242776870727539,
      "learning_rate": 3.381007751937985e-05,
      "loss": 0.0059,
      "step": 4177
    },
    {
      "epoch": 16.1937984496124,
      "grad_norm": 0.003942993003875017,
      "learning_rate": 3.38062015503876e-05,
      "loss": 0.0004,
      "step": 4178
    },
    {
      "epoch": 16.197674418604652,
      "grad_norm": 0.0034538758918642998,
      "learning_rate": 3.380232558139535e-05,
      "loss": 0.0003,
      "step": 4179
    },
    {
      "epoch": 16.2015503875969,
      "grad_norm": 0.002922078361734748,
      "learning_rate": 3.3798449612403105e-05,
      "loss": 0.0003,
      "step": 4180
    },
    {
      "epoch": 16.205426356589147,
      "grad_norm": 21.695215225219727,
      "learning_rate": 3.379457364341085e-05,
      "loss": 0.0875,
      "step": 4181
    },
    {
      "epoch": 16.209302325581394,
      "grad_norm": 0.02405567467212677,
      "learning_rate": 3.379069767441861e-05,
      "loss": 0.0013,
      "step": 4182
    },
    {
      "epoch": 16.213178294573645,
      "grad_norm": 0.0048685879446566105,
      "learning_rate": 3.3786821705426356e-05,
      "loss": 0.0003,
      "step": 4183
    },
    {
      "epoch": 16.217054263565892,
      "grad_norm": 0.7459185719490051,
      "learning_rate": 3.3782945736434115e-05,
      "loss": 0.0035,
      "step": 4184
    },
    {
      "epoch": 16.22093023255814,
      "grad_norm": 0.003988707438111305,
      "learning_rate": 3.377906976744186e-05,
      "loss": 0.0004,
      "step": 4185
    },
    {
      "epoch": 16.224806201550386,
      "grad_norm": 0.0033030358608812094,
      "learning_rate": 3.377519379844961e-05,
      "loss": 0.0003,
      "step": 4186
    },
    {
      "epoch": 16.228682170542637,
      "grad_norm": 0.011050205677747726,
      "learning_rate": 3.3771317829457366e-05,
      "loss": 0.0005,
      "step": 4187
    },
    {
      "epoch": 16.232558139534884,
      "grad_norm": 3.6119868755340576,
      "learning_rate": 3.376744186046512e-05,
      "loss": 0.7007,
      "step": 4188
    },
    {
      "epoch": 16.23643410852713,
      "grad_norm": 1.0479471683502197,
      "learning_rate": 3.376356589147287e-05,
      "loss": 0.0331,
      "step": 4189
    },
    {
      "epoch": 16.24031007751938,
      "grad_norm": 0.009217272512614727,
      "learning_rate": 3.375968992248062e-05,
      "loss": 0.0007,
      "step": 4190
    },
    {
      "epoch": 16.24418604651163,
      "grad_norm": 0.013709735125303268,
      "learning_rate": 3.3755813953488375e-05,
      "loss": 0.0008,
      "step": 4191
    },
    {
      "epoch": 16.248062015503876,
      "grad_norm": 2.5899250507354736,
      "learning_rate": 3.375193798449612e-05,
      "loss": 0.1671,
      "step": 4192
    },
    {
      "epoch": 16.251937984496124,
      "grad_norm": 0.003387324744835496,
      "learning_rate": 3.374806201550388e-05,
      "loss": 0.0003,
      "step": 4193
    },
    {
      "epoch": 16.25581395348837,
      "grad_norm": 0.020506585016846657,
      "learning_rate": 3.3744186046511626e-05,
      "loss": 0.0011,
      "step": 4194
    },
    {
      "epoch": 16.25968992248062,
      "grad_norm": 0.0033799377270042896,
      "learning_rate": 3.3740310077519385e-05,
      "loss": 0.0003,
      "step": 4195
    },
    {
      "epoch": 16.26356589147287,
      "grad_norm": 0.01019041333347559,
      "learning_rate": 3.373643410852713e-05,
      "loss": 0.0004,
      "step": 4196
    },
    {
      "epoch": 16.267441860465116,
      "grad_norm": 0.007138057146221399,
      "learning_rate": 3.373255813953489e-05,
      "loss": 0.0004,
      "step": 4197
    },
    {
      "epoch": 16.271317829457363,
      "grad_norm": 7.6729326248168945,
      "learning_rate": 3.3728682170542635e-05,
      "loss": 0.4888,
      "step": 4198
    },
    {
      "epoch": 16.275193798449614,
      "grad_norm": 0.018215006217360497,
      "learning_rate": 3.372480620155039e-05,
      "loss": 0.0005,
      "step": 4199
    },
    {
      "epoch": 16.27906976744186,
      "grad_norm": 0.03160759061574936,
      "learning_rate": 3.372093023255814e-05,
      "loss": 0.0018,
      "step": 4200
    },
    {
      "epoch": 16.282945736434108,
      "grad_norm": 0.1290031522512436,
      "learning_rate": 3.371705426356589e-05,
      "loss": 0.0008,
      "step": 4201
    },
    {
      "epoch": 16.286821705426355,
      "grad_norm": 0.0035624487791210413,
      "learning_rate": 3.3713178294573645e-05,
      "loss": 0.0003,
      "step": 4202
    },
    {
      "epoch": 16.290697674418606,
      "grad_norm": 0.09236552566289902,
      "learning_rate": 3.37093023255814e-05,
      "loss": 0.0023,
      "step": 4203
    },
    {
      "epoch": 16.294573643410853,
      "grad_norm": 1.8182929754257202,
      "learning_rate": 3.370542635658915e-05,
      "loss": 0.1654,
      "step": 4204
    },
    {
      "epoch": 16.2984496124031,
      "grad_norm": 0.007661035750061274,
      "learning_rate": 3.37015503875969e-05,
      "loss": 0.0003,
      "step": 4205
    },
    {
      "epoch": 16.302325581395348,
      "grad_norm": 0.002589517505839467,
      "learning_rate": 3.3697674418604655e-05,
      "loss": 0.0003,
      "step": 4206
    },
    {
      "epoch": 16.3062015503876,
      "grad_norm": 0.003373882733285427,
      "learning_rate": 3.369379844961241e-05,
      "loss": 0.0003,
      "step": 4207
    },
    {
      "epoch": 16.310077519379846,
      "grad_norm": 0.005966160446405411,
      "learning_rate": 3.368992248062016e-05,
      "loss": 0.0003,
      "step": 4208
    },
    {
      "epoch": 16.313953488372093,
      "grad_norm": 0.004219975788146257,
      "learning_rate": 3.368604651162791e-05,
      "loss": 0.0003,
      "step": 4209
    },
    {
      "epoch": 16.31782945736434,
      "grad_norm": 0.0848865732550621,
      "learning_rate": 3.368217054263566e-05,
      "loss": 0.0022,
      "step": 4210
    },
    {
      "epoch": 16.32170542635659,
      "grad_norm": 0.002392333699390292,
      "learning_rate": 3.367829457364342e-05,
      "loss": 0.0002,
      "step": 4211
    },
    {
      "epoch": 16.325581395348838,
      "grad_norm": 0.008508237078785896,
      "learning_rate": 3.367441860465116e-05,
      "loss": 0.0004,
      "step": 4212
    },
    {
      "epoch": 16.329457364341085,
      "grad_norm": 0.15421873331069946,
      "learning_rate": 3.3670542635658915e-05,
      "loss": 0.0025,
      "step": 4213
    },
    {
      "epoch": 16.333333333333332,
      "grad_norm": 0.003967450000345707,
      "learning_rate": 3.366666666666667e-05,
      "loss": 0.0003,
      "step": 4214
    },
    {
      "epoch": 16.337209302325583,
      "grad_norm": 0.08663134276866913,
      "learning_rate": 3.366279069767442e-05,
      "loss": 0.0007,
      "step": 4215
    },
    {
      "epoch": 16.34108527131783,
      "grad_norm": 4.154176712036133,
      "learning_rate": 3.365891472868217e-05,
      "loss": 0.5337,
      "step": 4216
    },
    {
      "epoch": 16.344961240310077,
      "grad_norm": 8.597378730773926,
      "learning_rate": 3.3655038759689925e-05,
      "loss": 0.1381,
      "step": 4217
    },
    {
      "epoch": 16.348837209302324,
      "grad_norm": 0.003254649229347706,
      "learning_rate": 3.365116279069768e-05,
      "loss": 0.0003,
      "step": 4218
    },
    {
      "epoch": 16.352713178294575,
      "grad_norm": 8.890443801879883,
      "learning_rate": 3.364728682170542e-05,
      "loss": 0.0087,
      "step": 4219
    },
    {
      "epoch": 16.356589147286822,
      "grad_norm": 0.08097400516271591,
      "learning_rate": 3.364341085271318e-05,
      "loss": 0.0033,
      "step": 4220
    },
    {
      "epoch": 16.36046511627907,
      "grad_norm": 0.0028896403964608908,
      "learning_rate": 3.363953488372093e-05,
      "loss": 0.0003,
      "step": 4221
    },
    {
      "epoch": 16.364341085271317,
      "grad_norm": 0.003476581070572138,
      "learning_rate": 3.363565891472869e-05,
      "loss": 0.0003,
      "step": 4222
    },
    {
      "epoch": 16.368217054263567,
      "grad_norm": 0.03633306547999382,
      "learning_rate": 3.363178294573643e-05,
      "loss": 0.0014,
      "step": 4223
    },
    {
      "epoch": 16.372093023255815,
      "grad_norm": 0.03179053217172623,
      "learning_rate": 3.362790697674419e-05,
      "loss": 0.0014,
      "step": 4224
    },
    {
      "epoch": 16.375968992248062,
      "grad_norm": 0.005155032966285944,
      "learning_rate": 3.362403100775194e-05,
      "loss": 0.0004,
      "step": 4225
    },
    {
      "epoch": 16.37984496124031,
      "grad_norm": 0.06757689267396927,
      "learning_rate": 3.3620155038759696e-05,
      "loss": 0.0026,
      "step": 4226
    },
    {
      "epoch": 16.38372093023256,
      "grad_norm": 0.2462201714515686,
      "learning_rate": 3.361627906976744e-05,
      "loss": 0.0021,
      "step": 4227
    },
    {
      "epoch": 16.387596899224807,
      "grad_norm": 0.8721504211425781,
      "learning_rate": 3.3612403100775194e-05,
      "loss": 0.0137,
      "step": 4228
    },
    {
      "epoch": 16.391472868217054,
      "grad_norm": 2.2420296669006348,
      "learning_rate": 3.360852713178295e-05,
      "loss": 0.2047,
      "step": 4229
    },
    {
      "epoch": 16.3953488372093,
      "grad_norm": 0.009724151343107224,
      "learning_rate": 3.36046511627907e-05,
      "loss": 0.0004,
      "step": 4230
    },
    {
      "epoch": 16.399224806201552,
      "grad_norm": 0.006486465223133564,
      "learning_rate": 3.360077519379845e-05,
      "loss": 0.0004,
      "step": 4231
    },
    {
      "epoch": 16.4031007751938,
      "grad_norm": 0.04982730373740196,
      "learning_rate": 3.3596899224806204e-05,
      "loss": 0.0023,
      "step": 4232
    },
    {
      "epoch": 16.406976744186046,
      "grad_norm": 4.021480083465576,
      "learning_rate": 3.3593023255813957e-05,
      "loss": 0.5131,
      "step": 4233
    },
    {
      "epoch": 16.410852713178294,
      "grad_norm": 0.004209701903164387,
      "learning_rate": 3.358914728682171e-05,
      "loss": 0.0004,
      "step": 4234
    },
    {
      "epoch": 16.414728682170544,
      "grad_norm": 0.010425406508147717,
      "learning_rate": 3.358527131782946e-05,
      "loss": 0.0006,
      "step": 4235
    },
    {
      "epoch": 16.41860465116279,
      "grad_norm": 0.017865508794784546,
      "learning_rate": 3.3581395348837214e-05,
      "loss": 0.001,
      "step": 4236
    },
    {
      "epoch": 16.42248062015504,
      "grad_norm": 0.006152160000056028,
      "learning_rate": 3.357751937984496e-05,
      "loss": 0.0004,
      "step": 4237
    },
    {
      "epoch": 16.426356589147286,
      "grad_norm": 0.0037693437188863754,
      "learning_rate": 3.357364341085271e-05,
      "loss": 0.0004,
      "step": 4238
    },
    {
      "epoch": 16.430232558139537,
      "grad_norm": 0.0033932807855308056,
      "learning_rate": 3.3569767441860464e-05,
      "loss": 0.0003,
      "step": 4239
    },
    {
      "epoch": 16.434108527131784,
      "grad_norm": 0.0069369482807815075,
      "learning_rate": 3.356589147286822e-05,
      "loss": 0.0004,
      "step": 4240
    },
    {
      "epoch": 16.43798449612403,
      "grad_norm": 0.047782160341739655,
      "learning_rate": 3.356201550387597e-05,
      "loss": 0.0009,
      "step": 4241
    },
    {
      "epoch": 16.441860465116278,
      "grad_norm": 8.215680122375488,
      "learning_rate": 3.355813953488372e-05,
      "loss": 0.3151,
      "step": 4242
    },
    {
      "epoch": 16.44573643410853,
      "grad_norm": 0.02052944526076317,
      "learning_rate": 3.3554263565891474e-05,
      "loss": 0.0005,
      "step": 4243
    },
    {
      "epoch": 16.449612403100776,
      "grad_norm": 0.0035809369292110205,
      "learning_rate": 3.3550387596899226e-05,
      "loss": 0.0003,
      "step": 4244
    },
    {
      "epoch": 16.453488372093023,
      "grad_norm": 3.007183313369751,
      "learning_rate": 3.354651162790698e-05,
      "loss": 0.116,
      "step": 4245
    },
    {
      "epoch": 16.45736434108527,
      "grad_norm": 0.01287789922207594,
      "learning_rate": 3.354263565891473e-05,
      "loss": 0.0004,
      "step": 4246
    },
    {
      "epoch": 16.46124031007752,
      "grad_norm": 0.003959389869123697,
      "learning_rate": 3.3538759689922484e-05,
      "loss": 0.0003,
      "step": 4247
    },
    {
      "epoch": 16.46511627906977,
      "grad_norm": 0.005225206725299358,
      "learning_rate": 3.353488372093023e-05,
      "loss": 0.0004,
      "step": 4248
    },
    {
      "epoch": 16.468992248062015,
      "grad_norm": 0.00409917626529932,
      "learning_rate": 3.353100775193799e-05,
      "loss": 0.0003,
      "step": 4249
    },
    {
      "epoch": 16.472868217054263,
      "grad_norm": 1.4452039003372192,
      "learning_rate": 3.3527131782945734e-05,
      "loss": 0.046,
      "step": 4250
    },
    {
      "epoch": 16.476744186046513,
      "grad_norm": 0.003483603708446026,
      "learning_rate": 3.352325581395349e-05,
      "loss": 0.0003,
      "step": 4251
    },
    {
      "epoch": 16.48062015503876,
      "grad_norm": 0.0029288812074810266,
      "learning_rate": 3.351937984496124e-05,
      "loss": 0.0003,
      "step": 4252
    },
    {
      "epoch": 16.484496124031008,
      "grad_norm": 1.0028170347213745,
      "learning_rate": 3.3515503875969e-05,
      "loss": 0.1327,
      "step": 4253
    },
    {
      "epoch": 16.488372093023255,
      "grad_norm": 0.0029606276657432318,
      "learning_rate": 3.3511627906976744e-05,
      "loss": 0.0003,
      "step": 4254
    },
    {
      "epoch": 16.492248062015506,
      "grad_norm": 0.010149569250643253,
      "learning_rate": 3.3507751937984496e-05,
      "loss": 0.0005,
      "step": 4255
    },
    {
      "epoch": 16.496124031007753,
      "grad_norm": 0.05266182869672775,
      "learning_rate": 3.350387596899225e-05,
      "loss": 0.0016,
      "step": 4256
    },
    {
      "epoch": 16.5,
      "grad_norm": 2.7189207077026367,
      "learning_rate": 3.35e-05,
      "loss": 0.0084,
      "step": 4257
    },
    {
      "epoch": 16.503875968992247,
      "grad_norm": 0.005100262351334095,
      "learning_rate": 3.3496124031007754e-05,
      "loss": 0.0004,
      "step": 4258
    },
    {
      "epoch": 16.507751937984494,
      "grad_norm": 0.005674093496054411,
      "learning_rate": 3.3492248062015506e-05,
      "loss": 0.0004,
      "step": 4259
    },
    {
      "epoch": 16.511627906976745,
      "grad_norm": 0.0277542844414711,
      "learning_rate": 3.348837209302326e-05,
      "loss": 0.0006,
      "step": 4260
    },
    {
      "epoch": 16.515503875968992,
      "grad_norm": 0.022125760093331337,
      "learning_rate": 3.348449612403101e-05,
      "loss": 0.0005,
      "step": 4261
    },
    {
      "epoch": 16.51937984496124,
      "grad_norm": 2.443838357925415,
      "learning_rate": 3.348062015503876e-05,
      "loss": 0.1185,
      "step": 4262
    },
    {
      "epoch": 16.52325581395349,
      "grad_norm": 0.008131846785545349,
      "learning_rate": 3.3476744186046516e-05,
      "loss": 0.0004,
      "step": 4263
    },
    {
      "epoch": 16.527131782945737,
      "grad_norm": 1.3378580808639526,
      "learning_rate": 3.347286821705427e-05,
      "loss": 0.0498,
      "step": 4264
    },
    {
      "epoch": 16.531007751937985,
      "grad_norm": 0.025164378806948662,
      "learning_rate": 3.3468992248062014e-05,
      "loss": 0.0013,
      "step": 4265
    },
    {
      "epoch": 16.53488372093023,
      "grad_norm": 0.011518090032041073,
      "learning_rate": 3.3465116279069766e-05,
      "loss": 0.0006,
      "step": 4266
    },
    {
      "epoch": 16.53875968992248,
      "grad_norm": 0.03221318870782852,
      "learning_rate": 3.346124031007752e-05,
      "loss": 0.001,
      "step": 4267
    },
    {
      "epoch": 16.54263565891473,
      "grad_norm": 0.03888537362217903,
      "learning_rate": 3.345736434108527e-05,
      "loss": 0.0012,
      "step": 4268
    },
    {
      "epoch": 16.546511627906977,
      "grad_norm": 0.04292492941021919,
      "learning_rate": 3.3453488372093023e-05,
      "loss": 0.0018,
      "step": 4269
    },
    {
      "epoch": 16.550387596899224,
      "grad_norm": 11.291813850402832,
      "learning_rate": 3.3449612403100776e-05,
      "loss": 0.0984,
      "step": 4270
    },
    {
      "epoch": 16.55426356589147,
      "grad_norm": 0.21934004127979279,
      "learning_rate": 3.344573643410853e-05,
      "loss": 0.0019,
      "step": 4271
    },
    {
      "epoch": 16.558139534883722,
      "grad_norm": 0.013465805910527706,
      "learning_rate": 3.344186046511628e-05,
      "loss": 0.0006,
      "step": 4272
    },
    {
      "epoch": 16.56201550387597,
      "grad_norm": 0.03459994122385979,
      "learning_rate": 3.343798449612403e-05,
      "loss": 0.0005,
      "step": 4273
    },
    {
      "epoch": 16.565891472868216,
      "grad_norm": 0.01830286905169487,
      "learning_rate": 3.3434108527131786e-05,
      "loss": 0.0011,
      "step": 4274
    },
    {
      "epoch": 16.569767441860463,
      "grad_norm": 2.979848623275757,
      "learning_rate": 3.343023255813954e-05,
      "loss": 0.0698,
      "step": 4275
    },
    {
      "epoch": 16.573643410852714,
      "grad_norm": 0.011167812161147594,
      "learning_rate": 3.342635658914729e-05,
      "loss": 0.0008,
      "step": 4276
    },
    {
      "epoch": 16.57751937984496,
      "grad_norm": 0.010035164654254913,
      "learning_rate": 3.3422480620155036e-05,
      "loss": 0.0005,
      "step": 4277
    },
    {
      "epoch": 16.58139534883721,
      "grad_norm": 0.007256930693984032,
      "learning_rate": 3.3418604651162795e-05,
      "loss": 0.0004,
      "step": 4278
    },
    {
      "epoch": 16.585271317829456,
      "grad_norm": 0.006379431579262018,
      "learning_rate": 3.341472868217054e-05,
      "loss": 0.0004,
      "step": 4279
    },
    {
      "epoch": 16.589147286821706,
      "grad_norm": 0.007472216617316008,
      "learning_rate": 3.34108527131783e-05,
      "loss": 0.0005,
      "step": 4280
    },
    {
      "epoch": 16.593023255813954,
      "grad_norm": 0.0049783941358327866,
      "learning_rate": 3.3406976744186046e-05,
      "loss": 0.0004,
      "step": 4281
    },
    {
      "epoch": 16.5968992248062,
      "grad_norm": 0.0037930661346763372,
      "learning_rate": 3.3403100775193805e-05,
      "loss": 0.0003,
      "step": 4282
    },
    {
      "epoch": 16.600775193798448,
      "grad_norm": 0.010131956078112125,
      "learning_rate": 3.339922480620155e-05,
      "loss": 0.0007,
      "step": 4283
    },
    {
      "epoch": 16.6046511627907,
      "grad_norm": 0.005783275701105595,
      "learning_rate": 3.33953488372093e-05,
      "loss": 0.0004,
      "step": 4284
    },
    {
      "epoch": 16.608527131782946,
      "grad_norm": 3.5270233154296875,
      "learning_rate": 3.3391472868217055e-05,
      "loss": 0.0795,
      "step": 4285
    },
    {
      "epoch": 16.612403100775193,
      "grad_norm": 0.03798691928386688,
      "learning_rate": 3.338759689922481e-05,
      "loss": 0.002,
      "step": 4286
    },
    {
      "epoch": 16.61627906976744,
      "grad_norm": 0.012529018335044384,
      "learning_rate": 3.338372093023256e-05,
      "loss": 0.0008,
      "step": 4287
    },
    {
      "epoch": 16.62015503875969,
      "grad_norm": 0.013676539994776249,
      "learning_rate": 3.337984496124031e-05,
      "loss": 0.0009,
      "step": 4288
    },
    {
      "epoch": 16.624031007751938,
      "grad_norm": 0.36979249119758606,
      "learning_rate": 3.3375968992248065e-05,
      "loss": 0.0153,
      "step": 4289
    },
    {
      "epoch": 16.627906976744185,
      "grad_norm": 0.003376416163519025,
      "learning_rate": 3.337209302325582e-05,
      "loss": 0.0003,
      "step": 4290
    },
    {
      "epoch": 16.631782945736433,
      "grad_norm": 0.4855270981788635,
      "learning_rate": 3.336821705426357e-05,
      "loss": 0.0116,
      "step": 4291
    },
    {
      "epoch": 16.635658914728683,
      "grad_norm": 0.022140970453619957,
      "learning_rate": 3.3364341085271316e-05,
      "loss": 0.0012,
      "step": 4292
    },
    {
      "epoch": 16.63953488372093,
      "grad_norm": 0.0048335823230445385,
      "learning_rate": 3.3360465116279075e-05,
      "loss": 0.0003,
      "step": 4293
    },
    {
      "epoch": 16.643410852713178,
      "grad_norm": 0.0032912723254412413,
      "learning_rate": 3.335658914728682e-05,
      "loss": 0.0003,
      "step": 4294
    },
    {
      "epoch": 16.647286821705425,
      "grad_norm": 0.0037387963384389877,
      "learning_rate": 3.335271317829457e-05,
      "loss": 0.0003,
      "step": 4295
    },
    {
      "epoch": 16.651162790697676,
      "grad_norm": 0.17568404972553253,
      "learning_rate": 3.3348837209302325e-05,
      "loss": 0.0057,
      "step": 4296
    },
    {
      "epoch": 16.655038759689923,
      "grad_norm": 0.04069976508617401,
      "learning_rate": 3.334496124031008e-05,
      "loss": 0.0017,
      "step": 4297
    },
    {
      "epoch": 16.65891472868217,
      "grad_norm": 0.00427102018147707,
      "learning_rate": 3.334108527131783e-05,
      "loss": 0.0004,
      "step": 4298
    },
    {
      "epoch": 16.662790697674417,
      "grad_norm": 0.0025109073612838984,
      "learning_rate": 3.333720930232558e-05,
      "loss": 0.0003,
      "step": 4299
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.02295812778174877,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0013,
      "step": 4300
    },
    {
      "epoch": 16.670542635658915,
      "grad_norm": 0.6820347309112549,
      "learning_rate": 3.332945736434109e-05,
      "loss": 0.0506,
      "step": 4301
    },
    {
      "epoch": 16.674418604651162,
      "grad_norm": 0.0026698133442550898,
      "learning_rate": 3.332558139534884e-05,
      "loss": 0.0003,
      "step": 4302
    },
    {
      "epoch": 16.67829457364341,
      "grad_norm": 0.002483807038515806,
      "learning_rate": 3.332170542635659e-05,
      "loss": 0.0003,
      "step": 4303
    },
    {
      "epoch": 16.68217054263566,
      "grad_norm": 0.005759910214692354,
      "learning_rate": 3.3317829457364345e-05,
      "loss": 0.0004,
      "step": 4304
    },
    {
      "epoch": 16.686046511627907,
      "grad_norm": 0.00421367259696126,
      "learning_rate": 3.33139534883721e-05,
      "loss": 0.0003,
      "step": 4305
    },
    {
      "epoch": 16.689922480620154,
      "grad_norm": 0.012336733750998974,
      "learning_rate": 3.331007751937984e-05,
      "loss": 0.0003,
      "step": 4306
    },
    {
      "epoch": 16.6937984496124,
      "grad_norm": 0.00290135620161891,
      "learning_rate": 3.33062015503876e-05,
      "loss": 0.0003,
      "step": 4307
    },
    {
      "epoch": 16.697674418604652,
      "grad_norm": 0.3301335573196411,
      "learning_rate": 3.330232558139535e-05,
      "loss": 0.0082,
      "step": 4308
    },
    {
      "epoch": 16.7015503875969,
      "grad_norm": 0.004118261858820915,
      "learning_rate": 3.329844961240311e-05,
      "loss": 0.0004,
      "step": 4309
    },
    {
      "epoch": 16.705426356589147,
      "grad_norm": 0.1403304636478424,
      "learning_rate": 3.329457364341085e-05,
      "loss": 0.0049,
      "step": 4310
    },
    {
      "epoch": 16.709302325581394,
      "grad_norm": 0.0031432779505848885,
      "learning_rate": 3.329069767441861e-05,
      "loss": 0.0003,
      "step": 4311
    },
    {
      "epoch": 16.713178294573645,
      "grad_norm": 0.0025855377316474915,
      "learning_rate": 3.328682170542636e-05,
      "loss": 0.0003,
      "step": 4312
    },
    {
      "epoch": 16.717054263565892,
      "grad_norm": 0.003706095740199089,
      "learning_rate": 3.328294573643411e-05,
      "loss": 0.0003,
      "step": 4313
    },
    {
      "epoch": 16.72093023255814,
      "grad_norm": 0.0027758104261010885,
      "learning_rate": 3.327906976744186e-05,
      "loss": 0.0003,
      "step": 4314
    },
    {
      "epoch": 16.724806201550386,
      "grad_norm": 0.12155713140964508,
      "learning_rate": 3.3275193798449614e-05,
      "loss": 0.0026,
      "step": 4315
    },
    {
      "epoch": 16.728682170542637,
      "grad_norm": 2.7115187644958496,
      "learning_rate": 3.327131782945737e-05,
      "loss": 0.2554,
      "step": 4316
    },
    {
      "epoch": 16.732558139534884,
      "grad_norm": 0.0028283812571316957,
      "learning_rate": 3.326744186046512e-05,
      "loss": 0.0003,
      "step": 4317
    },
    {
      "epoch": 16.73643410852713,
      "grad_norm": 1.3742190599441528,
      "learning_rate": 3.326356589147287e-05,
      "loss": 0.0609,
      "step": 4318
    },
    {
      "epoch": 16.74031007751938,
      "grad_norm": 0.0029378843028098345,
      "learning_rate": 3.325968992248062e-05,
      "loss": 0.0003,
      "step": 4319
    },
    {
      "epoch": 16.74418604651163,
      "grad_norm": 0.003449484007433057,
      "learning_rate": 3.3255813953488377e-05,
      "loss": 0.0003,
      "step": 4320
    },
    {
      "epoch": 16.748062015503876,
      "grad_norm": 0.0031695240177214146,
      "learning_rate": 3.325193798449612e-05,
      "loss": 0.0003,
      "step": 4321
    },
    {
      "epoch": 16.751937984496124,
      "grad_norm": 0.0035646790638566017,
      "learning_rate": 3.3248062015503875e-05,
      "loss": 0.0003,
      "step": 4322
    },
    {
      "epoch": 16.75581395348837,
      "grad_norm": 0.0031034371349960566,
      "learning_rate": 3.324418604651163e-05,
      "loss": 0.0003,
      "step": 4323
    },
    {
      "epoch": 16.75968992248062,
      "grad_norm": 0.0036968975327908993,
      "learning_rate": 3.324031007751938e-05,
      "loss": 0.0003,
      "step": 4324
    },
    {
      "epoch": 16.76356589147287,
      "grad_norm": 1.2785011529922485,
      "learning_rate": 3.323643410852713e-05,
      "loss": 0.0481,
      "step": 4325
    },
    {
      "epoch": 16.767441860465116,
      "grad_norm": 0.002964235842227936,
      "learning_rate": 3.3232558139534884e-05,
      "loss": 0.0003,
      "step": 4326
    },
    {
      "epoch": 16.771317829457363,
      "grad_norm": 2.5334484577178955,
      "learning_rate": 3.322868217054264e-05,
      "loss": 0.1857,
      "step": 4327
    },
    {
      "epoch": 16.775193798449614,
      "grad_norm": 0.003966945223510265,
      "learning_rate": 3.322480620155039e-05,
      "loss": 0.0003,
      "step": 4328
    },
    {
      "epoch": 16.77906976744186,
      "grad_norm": 0.00332773313857615,
      "learning_rate": 3.322093023255814e-05,
      "loss": 0.0003,
      "step": 4329
    },
    {
      "epoch": 16.782945736434108,
      "grad_norm": 0.0029724964406341314,
      "learning_rate": 3.3217054263565894e-05,
      "loss": 0.0003,
      "step": 4330
    },
    {
      "epoch": 16.786821705426355,
      "grad_norm": 0.002684924518689513,
      "learning_rate": 3.3213178294573646e-05,
      "loss": 0.0003,
      "step": 4331
    },
    {
      "epoch": 16.790697674418606,
      "grad_norm": 0.004892215598374605,
      "learning_rate": 3.32093023255814e-05,
      "loss": 0.0003,
      "step": 4332
    },
    {
      "epoch": 16.794573643410853,
      "grad_norm": 0.083465576171875,
      "learning_rate": 3.3205426356589145e-05,
      "loss": 0.0031,
      "step": 4333
    },
    {
      "epoch": 16.7984496124031,
      "grad_norm": 0.0035566564183682203,
      "learning_rate": 3.3201550387596904e-05,
      "loss": 0.0003,
      "step": 4334
    },
    {
      "epoch": 16.802325581395348,
      "grad_norm": 0.0037799375131726265,
      "learning_rate": 3.319767441860465e-05,
      "loss": 0.0003,
      "step": 4335
    },
    {
      "epoch": 16.8062015503876,
      "grad_norm": 0.003136700252071023,
      "learning_rate": 3.319379844961241e-05,
      "loss": 0.0003,
      "step": 4336
    },
    {
      "epoch": 16.810077519379846,
      "grad_norm": 0.002341916086152196,
      "learning_rate": 3.3189922480620154e-05,
      "loss": 0.0002,
      "step": 4337
    },
    {
      "epoch": 16.813953488372093,
      "grad_norm": 5.193631649017334,
      "learning_rate": 3.3186046511627913e-05,
      "loss": 0.6145,
      "step": 4338
    },
    {
      "epoch": 16.81782945736434,
      "grad_norm": 0.002800178714096546,
      "learning_rate": 3.318217054263566e-05,
      "loss": 0.0003,
      "step": 4339
    },
    {
      "epoch": 16.82170542635659,
      "grad_norm": 4.509255886077881,
      "learning_rate": 3.317829457364341e-05,
      "loss": 0.3283,
      "step": 4340
    },
    {
      "epoch": 16.825581395348838,
      "grad_norm": 0.27587175369262695,
      "learning_rate": 3.3174418604651164e-05,
      "loss": 0.0128,
      "step": 4341
    },
    {
      "epoch": 16.829457364341085,
      "grad_norm": 0.002402407117187977,
      "learning_rate": 3.3170542635658916e-05,
      "loss": 0.0003,
      "step": 4342
    },
    {
      "epoch": 16.833333333333332,
      "grad_norm": 17.0330753326416,
      "learning_rate": 3.316666666666667e-05,
      "loss": 0.6387,
      "step": 4343
    },
    {
      "epoch": 16.837209302325583,
      "grad_norm": 0.03262244164943695,
      "learning_rate": 3.316279069767442e-05,
      "loss": 0.0017,
      "step": 4344
    },
    {
      "epoch": 16.84108527131783,
      "grad_norm": 0.009539416991174221,
      "learning_rate": 3.3158914728682174e-05,
      "loss": 0.0004,
      "step": 4345
    },
    {
      "epoch": 16.844961240310077,
      "grad_norm": 0.025587506592273712,
      "learning_rate": 3.315503875968992e-05,
      "loss": 0.0005,
      "step": 4346
    },
    {
      "epoch": 16.848837209302324,
      "grad_norm": 0.0030786264687776566,
      "learning_rate": 3.315116279069768e-05,
      "loss": 0.0003,
      "step": 4347
    },
    {
      "epoch": 16.852713178294575,
      "grad_norm": 0.13042084872722626,
      "learning_rate": 3.3147286821705424e-05,
      "loss": 0.0049,
      "step": 4348
    },
    {
      "epoch": 16.856589147286822,
      "grad_norm": 0.007080884650349617,
      "learning_rate": 3.314341085271318e-05,
      "loss": 0.0004,
      "step": 4349
    },
    {
      "epoch": 16.86046511627907,
      "grad_norm": 0.004399545956403017,
      "learning_rate": 3.313953488372093e-05,
      "loss": 0.0003,
      "step": 4350
    },
    {
      "epoch": 16.864341085271317,
      "grad_norm": 16.32192611694336,
      "learning_rate": 3.313565891472868e-05,
      "loss": 0.4321,
      "step": 4351
    },
    {
      "epoch": 16.868217054263567,
      "grad_norm": 1.379153847694397,
      "learning_rate": 3.3131782945736434e-05,
      "loss": 0.0171,
      "step": 4352
    },
    {
      "epoch": 16.872093023255815,
      "grad_norm": 0.0030051071662455797,
      "learning_rate": 3.3127906976744186e-05,
      "loss": 0.0003,
      "step": 4353
    },
    {
      "epoch": 16.875968992248062,
      "grad_norm": 0.1584702581167221,
      "learning_rate": 3.312403100775194e-05,
      "loss": 0.0068,
      "step": 4354
    },
    {
      "epoch": 16.87984496124031,
      "grad_norm": 0.003603088203817606,
      "learning_rate": 3.312015503875969e-05,
      "loss": 0.0004,
      "step": 4355
    },
    {
      "epoch": 16.88372093023256,
      "grad_norm": 3.578047513961792,
      "learning_rate": 3.3116279069767443e-05,
      "loss": 0.2118,
      "step": 4356
    },
    {
      "epoch": 16.887596899224807,
      "grad_norm": 0.0035512102767825127,
      "learning_rate": 3.3112403100775196e-05,
      "loss": 0.0003,
      "step": 4357
    },
    {
      "epoch": 16.891472868217054,
      "grad_norm": 0.009991822764277458,
      "learning_rate": 3.310852713178295e-05,
      "loss": 0.0007,
      "step": 4358
    },
    {
      "epoch": 16.8953488372093,
      "grad_norm": 0.028512105345726013,
      "learning_rate": 3.31046511627907e-05,
      "loss": 0.0015,
      "step": 4359
    },
    {
      "epoch": 16.899224806201552,
      "grad_norm": 4.891696453094482,
      "learning_rate": 3.310077519379845e-05,
      "loss": 0.2005,
      "step": 4360
    },
    {
      "epoch": 16.9031007751938,
      "grad_norm": 0.004143681842833757,
      "learning_rate": 3.3096899224806206e-05,
      "loss": 0.0003,
      "step": 4361
    },
    {
      "epoch": 16.906976744186046,
      "grad_norm": 0.020472761243581772,
      "learning_rate": 3.309302325581395e-05,
      "loss": 0.0004,
      "step": 4362
    },
    {
      "epoch": 16.910852713178294,
      "grad_norm": 0.03809647262096405,
      "learning_rate": 3.308914728682171e-05,
      "loss": 0.0008,
      "step": 4363
    },
    {
      "epoch": 16.914728682170544,
      "grad_norm": 2.474285840988159,
      "learning_rate": 3.3085271317829456e-05,
      "loss": 0.0799,
      "step": 4364
    },
    {
      "epoch": 16.91860465116279,
      "grad_norm": 0.006361440755426884,
      "learning_rate": 3.3081395348837215e-05,
      "loss": 0.0004,
      "step": 4365
    },
    {
      "epoch": 16.92248062015504,
      "grad_norm": 0.05210747942328453,
      "learning_rate": 3.307751937984496e-05,
      "loss": 0.0019,
      "step": 4366
    },
    {
      "epoch": 16.926356589147286,
      "grad_norm": 3.865633964538574,
      "learning_rate": 3.307364341085272e-05,
      "loss": 0.288,
      "step": 4367
    },
    {
      "epoch": 16.930232558139537,
      "grad_norm": 0.0036128349602222443,
      "learning_rate": 3.3069767441860466e-05,
      "loss": 0.0003,
      "step": 4368
    },
    {
      "epoch": 16.934108527131784,
      "grad_norm": 1.0828652381896973,
      "learning_rate": 3.306589147286822e-05,
      "loss": 0.1208,
      "step": 4369
    },
    {
      "epoch": 16.93798449612403,
      "grad_norm": 3.1332082748413086,
      "learning_rate": 3.306201550387597e-05,
      "loss": 0.1069,
      "step": 4370
    },
    {
      "epoch": 16.941860465116278,
      "grad_norm": 0.11678764224052429,
      "learning_rate": 3.305813953488372e-05,
      "loss": 0.0028,
      "step": 4371
    },
    {
      "epoch": 16.94573643410853,
      "grad_norm": 0.0123222004622221,
      "learning_rate": 3.3054263565891475e-05,
      "loss": 0.0005,
      "step": 4372
    },
    {
      "epoch": 16.949612403100776,
      "grad_norm": 0.02636309340596199,
      "learning_rate": 3.305038759689922e-05,
      "loss": 0.0007,
      "step": 4373
    },
    {
      "epoch": 16.953488372093023,
      "grad_norm": 0.005672621075063944,
      "learning_rate": 3.304651162790698e-05,
      "loss": 0.0003,
      "step": 4374
    },
    {
      "epoch": 16.95736434108527,
      "grad_norm": 0.006790893618017435,
      "learning_rate": 3.3042635658914726e-05,
      "loss": 0.0004,
      "step": 4375
    },
    {
      "epoch": 16.96124031007752,
      "grad_norm": 0.48226550221443176,
      "learning_rate": 3.3038759689922485e-05,
      "loss": 0.0044,
      "step": 4376
    },
    {
      "epoch": 16.96511627906977,
      "grad_norm": 0.01883520558476448,
      "learning_rate": 3.303488372093023e-05,
      "loss": 0.0005,
      "step": 4377
    },
    {
      "epoch": 16.968992248062015,
      "grad_norm": 0.01023575384169817,
      "learning_rate": 3.303100775193799e-05,
      "loss": 0.0004,
      "step": 4378
    },
    {
      "epoch": 16.972868217054263,
      "grad_norm": 0.7530931830406189,
      "learning_rate": 3.3027131782945736e-05,
      "loss": 0.0097,
      "step": 4379
    },
    {
      "epoch": 16.97674418604651,
      "grad_norm": 0.050118327140808105,
      "learning_rate": 3.302325581395349e-05,
      "loss": 0.0013,
      "step": 4380
    },
    {
      "epoch": 16.98062015503876,
      "grad_norm": 0.24049745500087738,
      "learning_rate": 3.301937984496124e-05,
      "loss": 0.0066,
      "step": 4381
    },
    {
      "epoch": 16.984496124031008,
      "grad_norm": 0.007945629768073559,
      "learning_rate": 3.301550387596899e-05,
      "loss": 0.0006,
      "step": 4382
    },
    {
      "epoch": 16.988372093023255,
      "grad_norm": 3.0460000038146973,
      "learning_rate": 3.3011627906976745e-05,
      "loss": 0.0511,
      "step": 4383
    },
    {
      "epoch": 16.992248062015506,
      "grad_norm": 0.003034909488633275,
      "learning_rate": 3.30077519379845e-05,
      "loss": 0.0003,
      "step": 4384
    },
    {
      "epoch": 16.996124031007753,
      "grad_norm": 0.003639975795522332,
      "learning_rate": 3.300387596899225e-05,
      "loss": 0.0003,
      "step": 4385
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.005979557987302542,
      "learning_rate": 3.3e-05,
      "loss": 0.0003,
      "step": 4386
    },
    {
      "epoch": 17.003875968992247,
      "grad_norm": 0.005121268332004547,
      "learning_rate": 3.2996124031007755e-05,
      "loss": 0.0004,
      "step": 4387
    },
    {
      "epoch": 17.007751937984494,
      "grad_norm": 0.0025198336225003004,
      "learning_rate": 3.299224806201551e-05,
      "loss": 0.0003,
      "step": 4388
    },
    {
      "epoch": 17.011627906976745,
      "grad_norm": 0.004265157505869865,
      "learning_rate": 3.298837209302326e-05,
      "loss": 0.0003,
      "step": 4389
    },
    {
      "epoch": 17.015503875968992,
      "grad_norm": 11.32481861114502,
      "learning_rate": 3.298449612403101e-05,
      "loss": 0.0294,
      "step": 4390
    },
    {
      "epoch": 17.01937984496124,
      "grad_norm": 0.0025882485788315535,
      "learning_rate": 3.298062015503876e-05,
      "loss": 0.0003,
      "step": 4391
    },
    {
      "epoch": 17.023255813953487,
      "grad_norm": 0.031879816204309464,
      "learning_rate": 3.297674418604652e-05,
      "loss": 0.0015,
      "step": 4392
    },
    {
      "epoch": 17.027131782945737,
      "grad_norm": 1.7974623441696167,
      "learning_rate": 3.297286821705426e-05,
      "loss": 0.1265,
      "step": 4393
    },
    {
      "epoch": 17.031007751937985,
      "grad_norm": 0.0028550808783620596,
      "learning_rate": 3.296899224806202e-05,
      "loss": 0.0003,
      "step": 4394
    },
    {
      "epoch": 17.03488372093023,
      "grad_norm": 2.1610682010650635,
      "learning_rate": 3.296511627906977e-05,
      "loss": 0.09,
      "step": 4395
    },
    {
      "epoch": 17.03875968992248,
      "grad_norm": 0.003623406635597348,
      "learning_rate": 3.296124031007753e-05,
      "loss": 0.0003,
      "step": 4396
    },
    {
      "epoch": 17.04263565891473,
      "grad_norm": 0.16460531949996948,
      "learning_rate": 3.295736434108527e-05,
      "loss": 0.0075,
      "step": 4397
    },
    {
      "epoch": 17.046511627906977,
      "grad_norm": 0.14833852648735046,
      "learning_rate": 3.2953488372093025e-05,
      "loss": 0.0032,
      "step": 4398
    },
    {
      "epoch": 17.050387596899224,
      "grad_norm": 0.012894516810774803,
      "learning_rate": 3.294961240310078e-05,
      "loss": 0.0008,
      "step": 4399
    },
    {
      "epoch": 17.05426356589147,
      "grad_norm": 0.0028670059982687235,
      "learning_rate": 3.294573643410852e-05,
      "loss": 0.0003,
      "step": 4400
    },
    {
      "epoch": 17.058139534883722,
      "grad_norm": 0.0038040620274841785,
      "learning_rate": 3.294186046511628e-05,
      "loss": 0.0003,
      "step": 4401
    },
    {
      "epoch": 17.06201550387597,
      "grad_norm": 0.006253409199416637,
      "learning_rate": 3.293798449612403e-05,
      "loss": 0.0004,
      "step": 4402
    },
    {
      "epoch": 17.065891472868216,
      "grad_norm": 0.005447370931506157,
      "learning_rate": 3.293410852713179e-05,
      "loss": 0.0003,
      "step": 4403
    },
    {
      "epoch": 17.069767441860463,
      "grad_norm": 0.0027040019631385803,
      "learning_rate": 3.293023255813953e-05,
      "loss": 0.0003,
      "step": 4404
    },
    {
      "epoch": 17.073643410852714,
      "grad_norm": 10.738603591918945,
      "learning_rate": 3.292635658914729e-05,
      "loss": 1.1579,
      "step": 4405
    },
    {
      "epoch": 17.07751937984496,
      "grad_norm": 0.004874852020293474,
      "learning_rate": 3.292248062015504e-05,
      "loss": 0.0003,
      "step": 4406
    },
    {
      "epoch": 17.08139534883721,
      "grad_norm": 0.003660605987533927,
      "learning_rate": 3.2918604651162797e-05,
      "loss": 0.0003,
      "step": 4407
    },
    {
      "epoch": 17.085271317829456,
      "grad_norm": 0.004127958789467812,
      "learning_rate": 3.291472868217054e-05,
      "loss": 0.0003,
      "step": 4408
    },
    {
      "epoch": 17.089147286821706,
      "grad_norm": 9.361448287963867,
      "learning_rate": 3.2910852713178295e-05,
      "loss": 0.0868,
      "step": 4409
    },
    {
      "epoch": 17.093023255813954,
      "grad_norm": 0.7617495059967041,
      "learning_rate": 3.290697674418605e-05,
      "loss": 0.0099,
      "step": 4410
    },
    {
      "epoch": 17.0968992248062,
      "grad_norm": 1.217639684677124,
      "learning_rate": 3.29031007751938e-05,
      "loss": 0.1268,
      "step": 4411
    },
    {
      "epoch": 17.100775193798448,
      "grad_norm": 0.004350063391029835,
      "learning_rate": 3.289922480620155e-05,
      "loss": 0.0003,
      "step": 4412
    },
    {
      "epoch": 17.1046511627907,
      "grad_norm": 0.003222147235646844,
      "learning_rate": 3.2895348837209304e-05,
      "loss": 0.0003,
      "step": 4413
    },
    {
      "epoch": 17.108527131782946,
      "grad_norm": 0.002738063922151923,
      "learning_rate": 3.289147286821706e-05,
      "loss": 0.0003,
      "step": 4414
    },
    {
      "epoch": 17.112403100775193,
      "grad_norm": 24.35689926147461,
      "learning_rate": 3.288759689922481e-05,
      "loss": 0.4809,
      "step": 4415
    },
    {
      "epoch": 17.11627906976744,
      "grad_norm": 0.004657902289181948,
      "learning_rate": 3.288372093023256e-05,
      "loss": 0.0003,
      "step": 4416
    },
    {
      "epoch": 17.12015503875969,
      "grad_norm": 12.275301933288574,
      "learning_rate": 3.2879844961240314e-05,
      "loss": 0.237,
      "step": 4417
    },
    {
      "epoch": 17.124031007751938,
      "grad_norm": 3.235677480697632,
      "learning_rate": 3.287596899224806e-05,
      "loss": 0.2506,
      "step": 4418
    },
    {
      "epoch": 17.127906976744185,
      "grad_norm": 0.009333526715636253,
      "learning_rate": 3.287209302325582e-05,
      "loss": 0.0005,
      "step": 4419
    },
    {
      "epoch": 17.131782945736433,
      "grad_norm": 0.013310732319951057,
      "learning_rate": 3.2868217054263565e-05,
      "loss": 0.0004,
      "step": 4420
    },
    {
      "epoch": 17.135658914728683,
      "grad_norm": 0.008403445594012737,
      "learning_rate": 3.2864341085271324e-05,
      "loss": 0.0005,
      "step": 4421
    },
    {
      "epoch": 17.13953488372093,
      "grad_norm": 0.01828988827764988,
      "learning_rate": 3.286046511627907e-05,
      "loss": 0.0006,
      "step": 4422
    },
    {
      "epoch": 17.143410852713178,
      "grad_norm": 0.019342657178640366,
      "learning_rate": 3.285658914728683e-05,
      "loss": 0.0006,
      "step": 4423
    },
    {
      "epoch": 17.147286821705425,
      "grad_norm": 22.29863929748535,
      "learning_rate": 3.2852713178294574e-05,
      "loss": 0.0517,
      "step": 4424
    },
    {
      "epoch": 17.151162790697676,
      "grad_norm": 0.02267952263355255,
      "learning_rate": 3.284883720930233e-05,
      "loss": 0.0007,
      "step": 4425
    },
    {
      "epoch": 17.155038759689923,
      "grad_norm": 0.011680517345666885,
      "learning_rate": 3.284496124031008e-05,
      "loss": 0.0005,
      "step": 4426
    },
    {
      "epoch": 17.15891472868217,
      "grad_norm": 0.02638574130833149,
      "learning_rate": 3.284108527131783e-05,
      "loss": 0.0008,
      "step": 4427
    },
    {
      "epoch": 17.162790697674417,
      "grad_norm": 0.0326235331594944,
      "learning_rate": 3.2837209302325584e-05,
      "loss": 0.0009,
      "step": 4428
    },
    {
      "epoch": 17.166666666666668,
      "grad_norm": 0.01612217165529728,
      "learning_rate": 3.283333333333333e-05,
      "loss": 0.0006,
      "step": 4429
    },
    {
      "epoch": 17.170542635658915,
      "grad_norm": 0.036180611699819565,
      "learning_rate": 3.282945736434109e-05,
      "loss": 0.0018,
      "step": 4430
    },
    {
      "epoch": 17.174418604651162,
      "grad_norm": 0.0096600241959095,
      "learning_rate": 3.2825581395348834e-05,
      "loss": 0.0005,
      "step": 4431
    },
    {
      "epoch": 17.17829457364341,
      "grad_norm": 0.0074987867847085,
      "learning_rate": 3.2821705426356594e-05,
      "loss": 0.0004,
      "step": 4432
    },
    {
      "epoch": 17.18217054263566,
      "grad_norm": 0.004944360814988613,
      "learning_rate": 3.281782945736434e-05,
      "loss": 0.0004,
      "step": 4433
    },
    {
      "epoch": 17.186046511627907,
      "grad_norm": 0.035451460629701614,
      "learning_rate": 3.28139534883721e-05,
      "loss": 0.0016,
      "step": 4434
    },
    {
      "epoch": 17.189922480620154,
      "grad_norm": 0.017866013571619987,
      "learning_rate": 3.2810077519379844e-05,
      "loss": 0.0006,
      "step": 4435
    },
    {
      "epoch": 17.1937984496124,
      "grad_norm": 0.18137440085411072,
      "learning_rate": 3.2806201550387597e-05,
      "loss": 0.0068,
      "step": 4436
    },
    {
      "epoch": 17.197674418604652,
      "grad_norm": 0.007214844226837158,
      "learning_rate": 3.280232558139535e-05,
      "loss": 0.0004,
      "step": 4437
    },
    {
      "epoch": 17.2015503875969,
      "grad_norm": 0.27445781230926514,
      "learning_rate": 3.27984496124031e-05,
      "loss": 0.0005,
      "step": 4438
    },
    {
      "epoch": 17.205426356589147,
      "grad_norm": 0.007590914145112038,
      "learning_rate": 3.2794573643410854e-05,
      "loss": 0.0004,
      "step": 4439
    },
    {
      "epoch": 17.209302325581394,
      "grad_norm": 0.00865079928189516,
      "learning_rate": 3.2790697674418606e-05,
      "loss": 0.0004,
      "step": 4440
    },
    {
      "epoch": 17.213178294573645,
      "grad_norm": 0.02362825535237789,
      "learning_rate": 3.278682170542636e-05,
      "loss": 0.0006,
      "step": 4441
    },
    {
      "epoch": 17.217054263565892,
      "grad_norm": 1.776984691619873,
      "learning_rate": 3.278294573643411e-05,
      "loss": 0.0108,
      "step": 4442
    },
    {
      "epoch": 17.22093023255814,
      "grad_norm": 0.004882817156612873,
      "learning_rate": 3.2779069767441863e-05,
      "loss": 0.0003,
      "step": 4443
    },
    {
      "epoch": 17.224806201550386,
      "grad_norm": 0.002573561854660511,
      "learning_rate": 3.2775193798449616e-05,
      "loss": 0.0002,
      "step": 4444
    },
    {
      "epoch": 17.228682170542637,
      "grad_norm": 1.8734192848205566,
      "learning_rate": 3.277131782945737e-05,
      "loss": 0.0019,
      "step": 4445
    },
    {
      "epoch": 17.232558139534884,
      "grad_norm": 0.22079278528690338,
      "learning_rate": 3.276744186046512e-05,
      "loss": 0.0096,
      "step": 4446
    },
    {
      "epoch": 17.23643410852713,
      "grad_norm": 2.7363667488098145,
      "learning_rate": 3.2763565891472866e-05,
      "loss": 0.0375,
      "step": 4447
    },
    {
      "epoch": 17.24031007751938,
      "grad_norm": 0.023161228746175766,
      "learning_rate": 3.2759689922480626e-05,
      "loss": 0.001,
      "step": 4448
    },
    {
      "epoch": 17.24418604651163,
      "grad_norm": 0.006533770356327295,
      "learning_rate": 3.275581395348837e-05,
      "loss": 0.0003,
      "step": 4449
    },
    {
      "epoch": 17.248062015503876,
      "grad_norm": 0.004129644483327866,
      "learning_rate": 3.275193798449613e-05,
      "loss": 0.0003,
      "step": 4450
    },
    {
      "epoch": 17.251937984496124,
      "grad_norm": 0.03685275837779045,
      "learning_rate": 3.2748062015503876e-05,
      "loss": 0.0017,
      "step": 4451
    },
    {
      "epoch": 17.25581395348837,
      "grad_norm": 0.004060715436935425,
      "learning_rate": 3.274418604651163e-05,
      "loss": 0.0003,
      "step": 4452
    },
    {
      "epoch": 17.25968992248062,
      "grad_norm": 0.0034687956795096397,
      "learning_rate": 3.274031007751938e-05,
      "loss": 0.0003,
      "step": 4453
    },
    {
      "epoch": 17.26356589147287,
      "grad_norm": 0.0027045980095863342,
      "learning_rate": 3.273643410852713e-05,
      "loss": 0.0003,
      "step": 4454
    },
    {
      "epoch": 17.267441860465116,
      "grad_norm": 11.855863571166992,
      "learning_rate": 3.2732558139534886e-05,
      "loss": 0.2807,
      "step": 4455
    },
    {
      "epoch": 17.271317829457363,
      "grad_norm": 0.00381017685867846,
      "learning_rate": 3.272868217054264e-05,
      "loss": 0.0003,
      "step": 4456
    },
    {
      "epoch": 17.275193798449614,
      "grad_norm": 0.002808675402775407,
      "learning_rate": 3.272480620155039e-05,
      "loss": 0.0003,
      "step": 4457
    },
    {
      "epoch": 17.27906976744186,
      "grad_norm": 8.699578285217285,
      "learning_rate": 3.2720930232558136e-05,
      "loss": 0.039,
      "step": 4458
    },
    {
      "epoch": 17.282945736434108,
      "grad_norm": 0.007807510439306498,
      "learning_rate": 3.2717054263565895e-05,
      "loss": 0.0004,
      "step": 4459
    },
    {
      "epoch": 17.286821705426355,
      "grad_norm": 0.07102455198764801,
      "learning_rate": 3.271317829457364e-05,
      "loss": 0.0028,
      "step": 4460
    },
    {
      "epoch": 17.290697674418606,
      "grad_norm": 0.06678163260221481,
      "learning_rate": 3.27093023255814e-05,
      "loss": 0.0018,
      "step": 4461
    },
    {
      "epoch": 17.294573643410853,
      "grad_norm": 0.002788353944197297,
      "learning_rate": 3.2705426356589146e-05,
      "loss": 0.0003,
      "step": 4462
    },
    {
      "epoch": 17.2984496124031,
      "grad_norm": 7.968695163726807,
      "learning_rate": 3.2701550387596905e-05,
      "loss": 0.2266,
      "step": 4463
    },
    {
      "epoch": 17.302325581395348,
      "grad_norm": 0.006043469067662954,
      "learning_rate": 3.269767441860465e-05,
      "loss": 0.0003,
      "step": 4464
    },
    {
      "epoch": 17.3062015503876,
      "grad_norm": 0.02778448723256588,
      "learning_rate": 3.26937984496124e-05,
      "loss": 0.0009,
      "step": 4465
    },
    {
      "epoch": 17.310077519379846,
      "grad_norm": 3.9479074478149414,
      "learning_rate": 3.2689922480620156e-05,
      "loss": 0.0275,
      "step": 4466
    },
    {
      "epoch": 17.313953488372093,
      "grad_norm": 4.924537658691406,
      "learning_rate": 3.268604651162791e-05,
      "loss": 0.3457,
      "step": 4467
    },
    {
      "epoch": 17.31782945736434,
      "grad_norm": 0.003856370924040675,
      "learning_rate": 3.268217054263566e-05,
      "loss": 0.0003,
      "step": 4468
    },
    {
      "epoch": 17.32170542635659,
      "grad_norm": 0.13968077301979065,
      "learning_rate": 3.267829457364341e-05,
      "loss": 0.0043,
      "step": 4469
    },
    {
      "epoch": 17.325581395348838,
      "grad_norm": 0.07210598140954971,
      "learning_rate": 3.2674418604651165e-05,
      "loss": 0.001,
      "step": 4470
    },
    {
      "epoch": 17.329457364341085,
      "grad_norm": 0.023237943649291992,
      "learning_rate": 3.267054263565892e-05,
      "loss": 0.001,
      "step": 4471
    },
    {
      "epoch": 17.333333333333332,
      "grad_norm": 0.043208781629800797,
      "learning_rate": 3.266666666666667e-05,
      "loss": 0.0016,
      "step": 4472
    },
    {
      "epoch": 17.337209302325583,
      "grad_norm": 0.013737556524574757,
      "learning_rate": 3.266279069767442e-05,
      "loss": 0.0008,
      "step": 4473
    },
    {
      "epoch": 17.34108527131783,
      "grad_norm": 0.005601448938250542,
      "learning_rate": 3.2658914728682175e-05,
      "loss": 0.0003,
      "step": 4474
    },
    {
      "epoch": 17.344961240310077,
      "grad_norm": 0.0028888643719255924,
      "learning_rate": 3.265503875968993e-05,
      "loss": 0.0003,
      "step": 4475
    },
    {
      "epoch": 17.348837209302324,
      "grad_norm": 0.012410467490553856,
      "learning_rate": 3.265116279069767e-05,
      "loss": 0.0003,
      "step": 4476
    },
    {
      "epoch": 17.352713178294575,
      "grad_norm": 0.00437585124745965,
      "learning_rate": 3.264728682170543e-05,
      "loss": 0.0003,
      "step": 4477
    },
    {
      "epoch": 17.356589147286822,
      "grad_norm": 0.010167213156819344,
      "learning_rate": 3.264341085271318e-05,
      "loss": 0.0003,
      "step": 4478
    },
    {
      "epoch": 17.36046511627907,
      "grad_norm": 0.004133690148591995,
      "learning_rate": 3.263953488372093e-05,
      "loss": 0.0003,
      "step": 4479
    },
    {
      "epoch": 17.364341085271317,
      "grad_norm": 0.011105850338935852,
      "learning_rate": 3.263565891472868e-05,
      "loss": 0.0007,
      "step": 4480
    },
    {
      "epoch": 17.368217054263567,
      "grad_norm": 57.29277801513672,
      "learning_rate": 3.2631782945736435e-05,
      "loss": 0.1927,
      "step": 4481
    },
    {
      "epoch": 17.372093023255815,
      "grad_norm": 47.9696044921875,
      "learning_rate": 3.262790697674419e-05,
      "loss": 0.3337,
      "step": 4482
    },
    {
      "epoch": 17.375968992248062,
      "grad_norm": 0.09902065992355347,
      "learning_rate": 3.262403100775194e-05,
      "loss": 0.0042,
      "step": 4483
    },
    {
      "epoch": 17.37984496124031,
      "grad_norm": 0.0464613139629364,
      "learning_rate": 3.262015503875969e-05,
      "loss": 0.0022,
      "step": 4484
    },
    {
      "epoch": 17.38372093023256,
      "grad_norm": 0.009941917844116688,
      "learning_rate": 3.261627906976744e-05,
      "loss": 0.0006,
      "step": 4485
    },
    {
      "epoch": 17.387596899224807,
      "grad_norm": 0.008090203627943993,
      "learning_rate": 3.26124031007752e-05,
      "loss": 0.0004,
      "step": 4486
    },
    {
      "epoch": 17.391472868217054,
      "grad_norm": 2.3723626136779785,
      "learning_rate": 3.260852713178294e-05,
      "loss": 0.2827,
      "step": 4487
    },
    {
      "epoch": 17.3953488372093,
      "grad_norm": 0.08114566653966904,
      "learning_rate": 3.26046511627907e-05,
      "loss": 0.0035,
      "step": 4488
    },
    {
      "epoch": 17.399224806201552,
      "grad_norm": 0.0028588532004505396,
      "learning_rate": 3.260077519379845e-05,
      "loss": 0.0003,
      "step": 4489
    },
    {
      "epoch": 17.4031007751938,
      "grad_norm": 0.004155187401920557,
      "learning_rate": 3.259689922480621e-05,
      "loss": 0.0003,
      "step": 4490
    },
    {
      "epoch": 17.406976744186046,
      "grad_norm": 0.009377673268318176,
      "learning_rate": 3.259302325581395e-05,
      "loss": 0.0006,
      "step": 4491
    },
    {
      "epoch": 17.410852713178294,
      "grad_norm": 0.0791781097650528,
      "learning_rate": 3.258914728682171e-05,
      "loss": 0.0005,
      "step": 4492
    },
    {
      "epoch": 17.414728682170544,
      "grad_norm": 0.0022083779331296682,
      "learning_rate": 3.258527131782946e-05,
      "loss": 0.0002,
      "step": 4493
    },
    {
      "epoch": 17.41860465116279,
      "grad_norm": 5.3109354972839355,
      "learning_rate": 3.258139534883721e-05,
      "loss": 0.1853,
      "step": 4494
    },
    {
      "epoch": 17.42248062015504,
      "grad_norm": 0.0028176766354590654,
      "learning_rate": 3.257751937984496e-05,
      "loss": 0.0003,
      "step": 4495
    },
    {
      "epoch": 17.426356589147286,
      "grad_norm": 0.003724734066054225,
      "learning_rate": 3.2573643410852715e-05,
      "loss": 0.0003,
      "step": 4496
    },
    {
      "epoch": 17.430232558139537,
      "grad_norm": 0.007570956367999315,
      "learning_rate": 3.256976744186047e-05,
      "loss": 0.0003,
      "step": 4497
    },
    {
      "epoch": 17.434108527131784,
      "grad_norm": 0.00264171976596117,
      "learning_rate": 3.256589147286822e-05,
      "loss": 0.0003,
      "step": 4498
    },
    {
      "epoch": 17.43798449612403,
      "grad_norm": 0.022654548287391663,
      "learning_rate": 3.256201550387597e-05,
      "loss": 0.0004,
      "step": 4499
    },
    {
      "epoch": 17.441860465116278,
      "grad_norm": 0.0035548375453799963,
      "learning_rate": 3.2558139534883724e-05,
      "loss": 0.0002,
      "step": 4500
    },
    {
      "epoch": 17.44573643410853,
      "grad_norm": 0.0030523736495524645,
      "learning_rate": 3.255426356589148e-05,
      "loss": 0.0002,
      "step": 4501
    },
    {
      "epoch": 17.449612403100776,
      "grad_norm": 12.65119743347168,
      "learning_rate": 3.255038759689923e-05,
      "loss": 0.2421,
      "step": 4502
    },
    {
      "epoch": 17.453488372093023,
      "grad_norm": 0.8770368695259094,
      "learning_rate": 3.2546511627906975e-05,
      "loss": 0.053,
      "step": 4503
    },
    {
      "epoch": 17.45736434108527,
      "grad_norm": 0.0033100664149969816,
      "learning_rate": 3.2542635658914734e-05,
      "loss": 0.0003,
      "step": 4504
    },
    {
      "epoch": 17.46124031007752,
      "grad_norm": 0.624602735042572,
      "learning_rate": 3.253875968992248e-05,
      "loss": 0.014,
      "step": 4505
    },
    {
      "epoch": 17.46511627906977,
      "grad_norm": 0.0037138424813747406,
      "learning_rate": 3.253488372093023e-05,
      "loss": 0.0003,
      "step": 4506
    },
    {
      "epoch": 17.468992248062015,
      "grad_norm": 1.3969392776489258,
      "learning_rate": 3.2531007751937985e-05,
      "loss": 0.1119,
      "step": 4507
    },
    {
      "epoch": 17.472868217054263,
      "grad_norm": 0.0022822641767561436,
      "learning_rate": 3.252713178294574e-05,
      "loss": 0.0002,
      "step": 4508
    },
    {
      "epoch": 17.476744186046513,
      "grad_norm": 0.03133382648229599,
      "learning_rate": 3.252325581395349e-05,
      "loss": 0.0005,
      "step": 4509
    },
    {
      "epoch": 17.48062015503876,
      "grad_norm": 1.379742980003357,
      "learning_rate": 3.251937984496124e-05,
      "loss": 0.1073,
      "step": 4510
    },
    {
      "epoch": 17.484496124031008,
      "grad_norm": 0.004058727994561195,
      "learning_rate": 3.2515503875968994e-05,
      "loss": 0.0003,
      "step": 4511
    },
    {
      "epoch": 17.488372093023255,
      "grad_norm": 0.002704642480239272,
      "learning_rate": 3.251162790697675e-05,
      "loss": 0.0003,
      "step": 4512
    },
    {
      "epoch": 17.492248062015506,
      "grad_norm": 3.7754039764404297,
      "learning_rate": 3.25077519379845e-05,
      "loss": 0.2698,
      "step": 4513
    },
    {
      "epoch": 17.496124031007753,
      "grad_norm": 13.536248207092285,
      "learning_rate": 3.2503875968992245e-05,
      "loss": 0.037,
      "step": 4514
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.004215837921947241,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0002,
      "step": 4515
    },
    {
      "epoch": 17.503875968992247,
      "grad_norm": 0.002084716223180294,
      "learning_rate": 3.249612403100775e-05,
      "loss": 0.0002,
      "step": 4516
    },
    {
      "epoch": 17.507751937984494,
      "grad_norm": 0.0025559510104358196,
      "learning_rate": 3.249224806201551e-05,
      "loss": 0.0002,
      "step": 4517
    },
    {
      "epoch": 17.511627906976745,
      "grad_norm": 0.004632274154573679,
      "learning_rate": 3.2488372093023254e-05,
      "loss": 0.0003,
      "step": 4518
    },
    {
      "epoch": 17.515503875968992,
      "grad_norm": 0.002241515088826418,
      "learning_rate": 3.2484496124031014e-05,
      "loss": 0.0002,
      "step": 4519
    },
    {
      "epoch": 17.51937984496124,
      "grad_norm": 0.002347982954233885,
      "learning_rate": 3.248062015503876e-05,
      "loss": 0.0002,
      "step": 4520
    },
    {
      "epoch": 17.52325581395349,
      "grad_norm": 0.023330701515078545,
      "learning_rate": 3.247674418604651e-05,
      "loss": 0.0013,
      "step": 4521
    },
    {
      "epoch": 17.527131782945737,
      "grad_norm": 0.002719373442232609,
      "learning_rate": 3.2472868217054264e-05,
      "loss": 0.0003,
      "step": 4522
    },
    {
      "epoch": 17.531007751937985,
      "grad_norm": 0.002890742849558592,
      "learning_rate": 3.2468992248062017e-05,
      "loss": 0.0002,
      "step": 4523
    },
    {
      "epoch": 17.53488372093023,
      "grad_norm": 0.030566159635782242,
      "learning_rate": 3.246511627906977e-05,
      "loss": 0.0011,
      "step": 4524
    },
    {
      "epoch": 17.53875968992248,
      "grad_norm": 0.02293222025036812,
      "learning_rate": 3.246124031007752e-05,
      "loss": 0.0009,
      "step": 4525
    },
    {
      "epoch": 17.54263565891473,
      "grad_norm": 0.019241226837038994,
      "learning_rate": 3.2457364341085274e-05,
      "loss": 0.0011,
      "step": 4526
    },
    {
      "epoch": 17.546511627906977,
      "grad_norm": 0.12051564455032349,
      "learning_rate": 3.2453488372093026e-05,
      "loss": 0.0006,
      "step": 4527
    },
    {
      "epoch": 17.550387596899224,
      "grad_norm": 7.23432731628418,
      "learning_rate": 3.244961240310078e-05,
      "loss": 0.6056,
      "step": 4528
    },
    {
      "epoch": 17.55426356589147,
      "grad_norm": 0.07677394151687622,
      "learning_rate": 3.244573643410853e-05,
      "loss": 0.0025,
      "step": 4529
    },
    {
      "epoch": 17.558139534883722,
      "grad_norm": 0.0025888707023113966,
      "learning_rate": 3.2441860465116283e-05,
      "loss": 0.0002,
      "step": 4530
    },
    {
      "epoch": 17.56201550387597,
      "grad_norm": 0.029685186222195625,
      "learning_rate": 3.243798449612403e-05,
      "loss": 0.0014,
      "step": 4531
    },
    {
      "epoch": 17.565891472868216,
      "grad_norm": 0.005633713211864233,
      "learning_rate": 3.243410852713178e-05,
      "loss": 0.0003,
      "step": 4532
    },
    {
      "epoch": 17.569767441860463,
      "grad_norm": 0.001964170252904296,
      "learning_rate": 3.2430232558139534e-05,
      "loss": 0.0002,
      "step": 4533
    },
    {
      "epoch": 17.573643410852714,
      "grad_norm": 0.0033183391205966473,
      "learning_rate": 3.2426356589147286e-05,
      "loss": 0.0003,
      "step": 4534
    },
    {
      "epoch": 17.57751937984496,
      "grad_norm": 0.5025843977928162,
      "learning_rate": 3.242248062015504e-05,
      "loss": 0.0189,
      "step": 4535
    },
    {
      "epoch": 17.58139534883721,
      "grad_norm": 0.004659691359847784,
      "learning_rate": 3.241860465116279e-05,
      "loss": 0.0004,
      "step": 4536
    },
    {
      "epoch": 17.585271317829456,
      "grad_norm": 0.0027913840021938086,
      "learning_rate": 3.2414728682170544e-05,
      "loss": 0.0003,
      "step": 4537
    },
    {
      "epoch": 17.589147286821706,
      "grad_norm": 0.002786013064906001,
      "learning_rate": 3.2410852713178296e-05,
      "loss": 0.0002,
      "step": 4538
    },
    {
      "epoch": 17.593023255813954,
      "grad_norm": 0.0029807393439114094,
      "learning_rate": 3.240697674418605e-05,
      "loss": 0.0003,
      "step": 4539
    },
    {
      "epoch": 17.5968992248062,
      "grad_norm": 0.0033656428568065166,
      "learning_rate": 3.24031007751938e-05,
      "loss": 0.0003,
      "step": 4540
    },
    {
      "epoch": 17.600775193798448,
      "grad_norm": 0.0036129425279796124,
      "learning_rate": 3.239922480620155e-05,
      "loss": 0.0003,
      "step": 4541
    },
    {
      "epoch": 17.6046511627907,
      "grad_norm": 0.0035362374037504196,
      "learning_rate": 3.2395348837209306e-05,
      "loss": 0.0002,
      "step": 4542
    },
    {
      "epoch": 17.608527131782946,
      "grad_norm": 0.00360418320633471,
      "learning_rate": 3.239147286821705e-05,
      "loss": 0.0003,
      "step": 4543
    },
    {
      "epoch": 17.612403100775193,
      "grad_norm": 0.002877761609852314,
      "learning_rate": 3.238759689922481e-05,
      "loss": 0.0003,
      "step": 4544
    },
    {
      "epoch": 17.61627906976744,
      "grad_norm": 17.514888763427734,
      "learning_rate": 3.2383720930232556e-05,
      "loss": 0.1995,
      "step": 4545
    },
    {
      "epoch": 17.62015503875969,
      "grad_norm": 0.0028418030124157667,
      "learning_rate": 3.2379844961240315e-05,
      "loss": 0.0003,
      "step": 4546
    },
    {
      "epoch": 17.624031007751938,
      "grad_norm": 11.509902954101562,
      "learning_rate": 3.237596899224806e-05,
      "loss": 0.0985,
      "step": 4547
    },
    {
      "epoch": 17.627906976744185,
      "grad_norm": 0.002065878128632903,
      "learning_rate": 3.237209302325582e-05,
      "loss": 0.0002,
      "step": 4548
    },
    {
      "epoch": 17.631782945736433,
      "grad_norm": 0.0036056688986718655,
      "learning_rate": 3.2368217054263566e-05,
      "loss": 0.0003,
      "step": 4549
    },
    {
      "epoch": 17.635658914728683,
      "grad_norm": 0.004671445116400719,
      "learning_rate": 3.236434108527132e-05,
      "loss": 0.0003,
      "step": 4550
    },
    {
      "epoch": 17.63953488372093,
      "grad_norm": 0.41594189405441284,
      "learning_rate": 3.236046511627907e-05,
      "loss": 0.0005,
      "step": 4551
    },
    {
      "epoch": 17.643410852713178,
      "grad_norm": 0.039832208305597305,
      "learning_rate": 3.235658914728682e-05,
      "loss": 0.0003,
      "step": 4552
    },
    {
      "epoch": 17.647286821705425,
      "grad_norm": 0.005805536173284054,
      "learning_rate": 3.2352713178294576e-05,
      "loss": 0.0004,
      "step": 4553
    },
    {
      "epoch": 17.651162790697676,
      "grad_norm": 8.132984161376953,
      "learning_rate": 3.234883720930233e-05,
      "loss": 0.3933,
      "step": 4554
    },
    {
      "epoch": 17.655038759689923,
      "grad_norm": 0.00704883923754096,
      "learning_rate": 3.234496124031008e-05,
      "loss": 0.0005,
      "step": 4555
    },
    {
      "epoch": 17.65891472868217,
      "grad_norm": 0.007885717786848545,
      "learning_rate": 3.234108527131783e-05,
      "loss": 0.0003,
      "step": 4556
    },
    {
      "epoch": 17.662790697674417,
      "grad_norm": 0.002242420567199588,
      "learning_rate": 3.2337209302325585e-05,
      "loss": 0.0002,
      "step": 4557
    },
    {
      "epoch": 17.666666666666668,
      "grad_norm": 0.7954980731010437,
      "learning_rate": 3.233333333333333e-05,
      "loss": 0.0027,
      "step": 4558
    },
    {
      "epoch": 17.670542635658915,
      "grad_norm": 35.2047233581543,
      "learning_rate": 3.232945736434109e-05,
      "loss": 0.3715,
      "step": 4559
    },
    {
      "epoch": 17.674418604651162,
      "grad_norm": 0.0026636836118996143,
      "learning_rate": 3.2325581395348836e-05,
      "loss": 0.0003,
      "step": 4560
    },
    {
      "epoch": 17.67829457364341,
      "grad_norm": 1.4458048343658447,
      "learning_rate": 3.232170542635659e-05,
      "loss": 0.0951,
      "step": 4561
    },
    {
      "epoch": 17.68217054263566,
      "grad_norm": 0.1385149508714676,
      "learning_rate": 3.231782945736434e-05,
      "loss": 0.0044,
      "step": 4562
    },
    {
      "epoch": 17.686046511627907,
      "grad_norm": 0.007801637053489685,
      "learning_rate": 3.231395348837209e-05,
      "loss": 0.0005,
      "step": 4563
    },
    {
      "epoch": 17.689922480620154,
      "grad_norm": 0.0024501674342900515,
      "learning_rate": 3.2310077519379845e-05,
      "loss": 0.0002,
      "step": 4564
    },
    {
      "epoch": 17.6937984496124,
      "grad_norm": 22.903282165527344,
      "learning_rate": 3.23062015503876e-05,
      "loss": 0.207,
      "step": 4565
    },
    {
      "epoch": 17.697674418604652,
      "grad_norm": 0.0024230394046753645,
      "learning_rate": 3.230232558139535e-05,
      "loss": 0.0002,
      "step": 4566
    },
    {
      "epoch": 17.7015503875969,
      "grad_norm": 0.002508066827431321,
      "learning_rate": 3.22984496124031e-05,
      "loss": 0.0003,
      "step": 4567
    },
    {
      "epoch": 17.705426356589147,
      "grad_norm": 0.0023849152494221926,
      "learning_rate": 3.2294573643410855e-05,
      "loss": 0.0002,
      "step": 4568
    },
    {
      "epoch": 17.709302325581394,
      "grad_norm": 0.020180784165859222,
      "learning_rate": 3.229069767441861e-05,
      "loss": 0.0008,
      "step": 4569
    },
    {
      "epoch": 17.713178294573645,
      "grad_norm": 0.05447039753198624,
      "learning_rate": 3.228682170542636e-05,
      "loss": 0.0006,
      "step": 4570
    },
    {
      "epoch": 17.717054263565892,
      "grad_norm": 2.3233184814453125,
      "learning_rate": 3.228294573643411e-05,
      "loss": 0.1352,
      "step": 4571
    },
    {
      "epoch": 17.72093023255814,
      "grad_norm": 0.45101022720336914,
      "learning_rate": 3.227906976744186e-05,
      "loss": 0.0107,
      "step": 4572
    },
    {
      "epoch": 17.724806201550386,
      "grad_norm": 0.01203905139118433,
      "learning_rate": 3.227519379844962e-05,
      "loss": 0.0007,
      "step": 4573
    },
    {
      "epoch": 17.728682170542637,
      "grad_norm": 3.3886702060699463,
      "learning_rate": 3.227131782945736e-05,
      "loss": 0.188,
      "step": 4574
    },
    {
      "epoch": 17.732558139534884,
      "grad_norm": 0.0024830272886902094,
      "learning_rate": 3.226744186046512e-05,
      "loss": 0.0002,
      "step": 4575
    },
    {
      "epoch": 17.73643410852713,
      "grad_norm": 0.003535039257258177,
      "learning_rate": 3.226356589147287e-05,
      "loss": 0.0002,
      "step": 4576
    },
    {
      "epoch": 17.74031007751938,
      "grad_norm": 0.002191737527027726,
      "learning_rate": 3.225968992248063e-05,
      "loss": 0.0002,
      "step": 4577
    },
    {
      "epoch": 17.74418604651163,
      "grad_norm": 0.00419952068477869,
      "learning_rate": 3.225581395348837e-05,
      "loss": 0.0003,
      "step": 4578
    },
    {
      "epoch": 17.748062015503876,
      "grad_norm": 2.583585500717163,
      "learning_rate": 3.2251937984496125e-05,
      "loss": 0.2562,
      "step": 4579
    },
    {
      "epoch": 17.751937984496124,
      "grad_norm": 0.0028372611850500107,
      "learning_rate": 3.224806201550388e-05,
      "loss": 0.0003,
      "step": 4580
    },
    {
      "epoch": 17.75581395348837,
      "grad_norm": 8.800119400024414,
      "learning_rate": 3.224418604651163e-05,
      "loss": 0.1339,
      "step": 4581
    },
    {
      "epoch": 17.75968992248062,
      "grad_norm": 0.011289047077298164,
      "learning_rate": 3.224031007751938e-05,
      "loss": 0.0006,
      "step": 4582
    },
    {
      "epoch": 17.76356589147287,
      "grad_norm": 5.520178318023682,
      "learning_rate": 3.2236434108527135e-05,
      "loss": 0.1014,
      "step": 4583
    },
    {
      "epoch": 17.767441860465116,
      "grad_norm": 0.08036841452121735,
      "learning_rate": 3.223255813953489e-05,
      "loss": 0.0019,
      "step": 4584
    },
    {
      "epoch": 17.771317829457363,
      "grad_norm": 12.007965087890625,
      "learning_rate": 3.222868217054263e-05,
      "loss": 0.0324,
      "step": 4585
    },
    {
      "epoch": 17.775193798449614,
      "grad_norm": 0.0026586130261421204,
      "learning_rate": 3.222480620155039e-05,
      "loss": 0.0002,
      "step": 4586
    },
    {
      "epoch": 17.77906976744186,
      "grad_norm": 0.04788535088300705,
      "learning_rate": 3.222093023255814e-05,
      "loss": 0.0012,
      "step": 4587
    },
    {
      "epoch": 17.782945736434108,
      "grad_norm": 7.1767683029174805,
      "learning_rate": 3.221705426356589e-05,
      "loss": 0.5881,
      "step": 4588
    },
    {
      "epoch": 17.786821705426355,
      "grad_norm": 0.6447998285293579,
      "learning_rate": 3.221317829457364e-05,
      "loss": 0.0239,
      "step": 4589
    },
    {
      "epoch": 17.790697674418606,
      "grad_norm": 6.951781749725342,
      "learning_rate": 3.2209302325581395e-05,
      "loss": 0.8113,
      "step": 4590
    },
    {
      "epoch": 17.794573643410853,
      "grad_norm": 4.318137168884277,
      "learning_rate": 3.220542635658915e-05,
      "loss": 0.124,
      "step": 4591
    },
    {
      "epoch": 17.7984496124031,
      "grad_norm": 0.0023861927911639214,
      "learning_rate": 3.22015503875969e-05,
      "loss": 0.0002,
      "step": 4592
    },
    {
      "epoch": 17.802325581395348,
      "grad_norm": 0.0020359086338430643,
      "learning_rate": 3.219767441860465e-05,
      "loss": 0.0002,
      "step": 4593
    },
    {
      "epoch": 17.8062015503876,
      "grad_norm": 2.9835073947906494,
      "learning_rate": 3.2193798449612405e-05,
      "loss": 0.0255,
      "step": 4594
    },
    {
      "epoch": 17.810077519379846,
      "grad_norm": 0.002064066706225276,
      "learning_rate": 3.218992248062016e-05,
      "loss": 0.0002,
      "step": 4595
    },
    {
      "epoch": 17.813953488372093,
      "grad_norm": 0.002682026010006666,
      "learning_rate": 3.218604651162791e-05,
      "loss": 0.0002,
      "step": 4596
    },
    {
      "epoch": 17.81782945736434,
      "grad_norm": 0.004091842100024223,
      "learning_rate": 3.218217054263566e-05,
      "loss": 0.0003,
      "step": 4597
    },
    {
      "epoch": 17.82170542635659,
      "grad_norm": 0.006439132150262594,
      "learning_rate": 3.2178294573643414e-05,
      "loss": 0.0003,
      "step": 4598
    },
    {
      "epoch": 17.825581395348838,
      "grad_norm": 0.002548645483329892,
      "learning_rate": 3.217441860465116e-05,
      "loss": 0.0003,
      "step": 4599
    },
    {
      "epoch": 17.829457364341085,
      "grad_norm": 0.02112187072634697,
      "learning_rate": 3.217054263565892e-05,
      "loss": 0.0003,
      "step": 4600
    },
    {
      "epoch": 17.833333333333332,
      "grad_norm": 0.00231060734950006,
      "learning_rate": 3.2166666666666665e-05,
      "loss": 0.0002,
      "step": 4601
    },
    {
      "epoch": 17.837209302325583,
      "grad_norm": 16.727357864379883,
      "learning_rate": 3.2162790697674424e-05,
      "loss": 0.5623,
      "step": 4602
    },
    {
      "epoch": 17.84108527131783,
      "grad_norm": 0.0021272338926792145,
      "learning_rate": 3.215891472868217e-05,
      "loss": 0.0002,
      "step": 4603
    },
    {
      "epoch": 17.844961240310077,
      "grad_norm": 0.003507074434310198,
      "learning_rate": 3.215503875968993e-05,
      "loss": 0.0003,
      "step": 4604
    },
    {
      "epoch": 17.848837209302324,
      "grad_norm": 0.02861754596233368,
      "learning_rate": 3.2151162790697674e-05,
      "loss": 0.0014,
      "step": 4605
    },
    {
      "epoch": 17.852713178294575,
      "grad_norm": 0.35392287373542786,
      "learning_rate": 3.214728682170543e-05,
      "loss": 0.0126,
      "step": 4606
    },
    {
      "epoch": 17.856589147286822,
      "grad_norm": 8.426969528198242,
      "learning_rate": 3.214341085271318e-05,
      "loss": 0.1795,
      "step": 4607
    },
    {
      "epoch": 17.86046511627907,
      "grad_norm": 0.03642414137721062,
      "learning_rate": 3.213953488372093e-05,
      "loss": 0.0017,
      "step": 4608
    },
    {
      "epoch": 17.864341085271317,
      "grad_norm": 0.04326736927032471,
      "learning_rate": 3.2135658914728684e-05,
      "loss": 0.002,
      "step": 4609
    },
    {
      "epoch": 17.868217054263567,
      "grad_norm": 0.002332253847271204,
      "learning_rate": 3.2131782945736437e-05,
      "loss": 0.0002,
      "step": 4610
    },
    {
      "epoch": 17.872093023255815,
      "grad_norm": 0.0019313156371936202,
      "learning_rate": 3.212790697674419e-05,
      "loss": 0.0002,
      "step": 4611
    },
    {
      "epoch": 17.875968992248062,
      "grad_norm": 0.0021471695508807898,
      "learning_rate": 3.2124031007751935e-05,
      "loss": 0.0002,
      "step": 4612
    },
    {
      "epoch": 17.87984496124031,
      "grad_norm": 0.004165062680840492,
      "learning_rate": 3.2120155038759694e-05,
      "loss": 0.0003,
      "step": 4613
    },
    {
      "epoch": 17.88372093023256,
      "grad_norm": 0.0023030417505651712,
      "learning_rate": 3.211627906976744e-05,
      "loss": 0.0002,
      "step": 4614
    },
    {
      "epoch": 17.887596899224807,
      "grad_norm": 2.093233108520508,
      "learning_rate": 3.21124031007752e-05,
      "loss": 0.1622,
      "step": 4615
    },
    {
      "epoch": 17.891472868217054,
      "grad_norm": 0.0024530827067792416,
      "learning_rate": 3.2108527131782944e-05,
      "loss": 0.0002,
      "step": 4616
    },
    {
      "epoch": 17.8953488372093,
      "grad_norm": 0.003034003311768174,
      "learning_rate": 3.21046511627907e-05,
      "loss": 0.0002,
      "step": 4617
    },
    {
      "epoch": 17.899224806201552,
      "grad_norm": 0.0034123233053833246,
      "learning_rate": 3.210077519379845e-05,
      "loss": 0.0003,
      "step": 4618
    },
    {
      "epoch": 17.9031007751938,
      "grad_norm": 0.00178209925070405,
      "learning_rate": 3.20968992248062e-05,
      "loss": 0.0002,
      "step": 4619
    },
    {
      "epoch": 17.906976744186046,
      "grad_norm": 0.005561850965023041,
      "learning_rate": 3.2093023255813954e-05,
      "loss": 0.0004,
      "step": 4620
    },
    {
      "epoch": 17.910852713178294,
      "grad_norm": 0.026765847578644753,
      "learning_rate": 3.2089147286821706e-05,
      "loss": 0.0013,
      "step": 4621
    },
    {
      "epoch": 17.914728682170544,
      "grad_norm": 0.022714605554938316,
      "learning_rate": 3.208527131782946e-05,
      "loss": 0.0003,
      "step": 4622
    },
    {
      "epoch": 17.91860465116279,
      "grad_norm": 0.011567385867238045,
      "learning_rate": 3.208139534883721e-05,
      "loss": 0.0003,
      "step": 4623
    },
    {
      "epoch": 17.92248062015504,
      "grad_norm": 19.474897384643555,
      "learning_rate": 3.2077519379844964e-05,
      "loss": 0.0782,
      "step": 4624
    },
    {
      "epoch": 17.926356589147286,
      "grad_norm": 0.0018536691786721349,
      "learning_rate": 3.2073643410852716e-05,
      "loss": 0.0002,
      "step": 4625
    },
    {
      "epoch": 17.930232558139537,
      "grad_norm": 13.582412719726562,
      "learning_rate": 3.206976744186047e-05,
      "loss": 0.3004,
      "step": 4626
    },
    {
      "epoch": 17.934108527131784,
      "grad_norm": 0.007221048232167959,
      "learning_rate": 3.206589147286822e-05,
      "loss": 0.0003,
      "step": 4627
    },
    {
      "epoch": 17.93798449612403,
      "grad_norm": 0.007273194845765829,
      "learning_rate": 3.2062015503875967e-05,
      "loss": 0.0005,
      "step": 4628
    },
    {
      "epoch": 17.941860465116278,
      "grad_norm": 0.027086550369858742,
      "learning_rate": 3.2058139534883726e-05,
      "loss": 0.0013,
      "step": 4629
    },
    {
      "epoch": 17.94573643410853,
      "grad_norm": 0.002506200224161148,
      "learning_rate": 3.205426356589147e-05,
      "loss": 0.0002,
      "step": 4630
    },
    {
      "epoch": 17.949612403100776,
      "grad_norm": 0.0021077441051602364,
      "learning_rate": 3.205038759689923e-05,
      "loss": 0.0002,
      "step": 4631
    },
    {
      "epoch": 17.953488372093023,
      "grad_norm": 0.004759565927088261,
      "learning_rate": 3.2046511627906976e-05,
      "loss": 0.0002,
      "step": 4632
    },
    {
      "epoch": 17.95736434108527,
      "grad_norm": 0.04307331517338753,
      "learning_rate": 3.2042635658914735e-05,
      "loss": 0.0018,
      "step": 4633
    },
    {
      "epoch": 17.96124031007752,
      "grad_norm": 1.3440824747085571,
      "learning_rate": 3.203875968992248e-05,
      "loss": 0.0355,
      "step": 4634
    },
    {
      "epoch": 17.96511627906977,
      "grad_norm": 0.0033282556105405092,
      "learning_rate": 3.2034883720930234e-05,
      "loss": 0.0002,
      "step": 4635
    },
    {
      "epoch": 17.968992248062015,
      "grad_norm": 0.003795274766162038,
      "learning_rate": 3.2031007751937986e-05,
      "loss": 0.0002,
      "step": 4636
    },
    {
      "epoch": 17.972868217054263,
      "grad_norm": 0.02461828850209713,
      "learning_rate": 3.202713178294574e-05,
      "loss": 0.001,
      "step": 4637
    },
    {
      "epoch": 17.97674418604651,
      "grad_norm": 0.0024304601829499006,
      "learning_rate": 3.202325581395349e-05,
      "loss": 0.0002,
      "step": 4638
    },
    {
      "epoch": 17.98062015503876,
      "grad_norm": 4.70875883102417,
      "learning_rate": 3.2019379844961236e-05,
      "loss": 0.0794,
      "step": 4639
    },
    {
      "epoch": 17.984496124031008,
      "grad_norm": 0.0021108028013259172,
      "learning_rate": 3.2015503875968996e-05,
      "loss": 0.0002,
      "step": 4640
    },
    {
      "epoch": 17.988372093023255,
      "grad_norm": 0.005230713170021772,
      "learning_rate": 3.201162790697674e-05,
      "loss": 0.0004,
      "step": 4641
    },
    {
      "epoch": 17.992248062015506,
      "grad_norm": 0.0027488097548484802,
      "learning_rate": 3.20077519379845e-05,
      "loss": 0.0002,
      "step": 4642
    },
    {
      "epoch": 17.996124031007753,
      "grad_norm": 0.0028777250554412603,
      "learning_rate": 3.2003875968992246e-05,
      "loss": 0.0003,
      "step": 4643
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.003947651479393244,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0002,
      "step": 4644
    },
    {
      "epoch": 18.003875968992247,
      "grad_norm": 0.002010311232879758,
      "learning_rate": 3.199612403100775e-05,
      "loss": 0.0002,
      "step": 4645
    },
    {
      "epoch": 18.007751937984494,
      "grad_norm": 0.0063249897211790085,
      "learning_rate": 3.1992248062015503e-05,
      "loss": 0.0002,
      "step": 4646
    },
    {
      "epoch": 18.011627906976745,
      "grad_norm": 0.0021532888058573008,
      "learning_rate": 3.1988372093023256e-05,
      "loss": 0.0002,
      "step": 4647
    },
    {
      "epoch": 18.015503875968992,
      "grad_norm": 0.013221032917499542,
      "learning_rate": 3.198449612403101e-05,
      "loss": 0.0007,
      "step": 4648
    },
    {
      "epoch": 18.01937984496124,
      "grad_norm": 52.30366897583008,
      "learning_rate": 3.198062015503876e-05,
      "loss": 0.1416,
      "step": 4649
    },
    {
      "epoch": 18.023255813953487,
      "grad_norm": 0.0016448023961856961,
      "learning_rate": 3.197674418604651e-05,
      "loss": 0.0002,
      "step": 4650
    },
    {
      "epoch": 18.027131782945737,
      "grad_norm": 0.013497238047420979,
      "learning_rate": 3.1972868217054266e-05,
      "loss": 0.0007,
      "step": 4651
    },
    {
      "epoch": 18.031007751937985,
      "grad_norm": 5.547168254852295,
      "learning_rate": 3.196899224806202e-05,
      "loss": 0.4408,
      "step": 4652
    },
    {
      "epoch": 18.03488372093023,
      "grad_norm": 3.1336028575897217,
      "learning_rate": 3.196511627906977e-05,
      "loss": 0.0822,
      "step": 4653
    },
    {
      "epoch": 18.03875968992248,
      "grad_norm": 0.002485878998413682,
      "learning_rate": 3.196124031007752e-05,
      "loss": 0.0002,
      "step": 4654
    },
    {
      "epoch": 18.04263565891473,
      "grad_norm": 0.002201684284955263,
      "learning_rate": 3.1957364341085275e-05,
      "loss": 0.0002,
      "step": 4655
    },
    {
      "epoch": 18.046511627906977,
      "grad_norm": 1.1771165132522583,
      "learning_rate": 3.195348837209303e-05,
      "loss": 0.0029,
      "step": 4656
    },
    {
      "epoch": 18.050387596899224,
      "grad_norm": 0.022943157702684402,
      "learning_rate": 3.194961240310077e-05,
      "loss": 0.0012,
      "step": 4657
    },
    {
      "epoch": 18.05426356589147,
      "grad_norm": 1.9262064695358276,
      "learning_rate": 3.194573643410853e-05,
      "loss": 0.077,
      "step": 4658
    },
    {
      "epoch": 18.058139534883722,
      "grad_norm": 0.37187647819519043,
      "learning_rate": 3.194186046511628e-05,
      "loss": 0.0004,
      "step": 4659
    },
    {
      "epoch": 18.06201550387597,
      "grad_norm": 0.005086786113679409,
      "learning_rate": 3.193798449612404e-05,
      "loss": 0.0002,
      "step": 4660
    },
    {
      "epoch": 18.065891472868216,
      "grad_norm": 0.7425389885902405,
      "learning_rate": 3.193410852713178e-05,
      "loss": 0.0277,
      "step": 4661
    },
    {
      "epoch": 18.069767441860463,
      "grad_norm": 1.694490909576416,
      "learning_rate": 3.193023255813954e-05,
      "loss": 0.0389,
      "step": 4662
    },
    {
      "epoch": 18.073643410852714,
      "grad_norm": 0.0030915928073227406,
      "learning_rate": 3.192635658914729e-05,
      "loss": 0.0003,
      "step": 4663
    },
    {
      "epoch": 18.07751937984496,
      "grad_norm": 0.007508125156164169,
      "learning_rate": 3.192248062015504e-05,
      "loss": 0.0002,
      "step": 4664
    },
    {
      "epoch": 18.08139534883721,
      "grad_norm": 1.02614426612854,
      "learning_rate": 3.191860465116279e-05,
      "loss": 0.1935,
      "step": 4665
    },
    {
      "epoch": 18.085271317829456,
      "grad_norm": 0.0021888224873691797,
      "learning_rate": 3.191472868217054e-05,
      "loss": 0.0002,
      "step": 4666
    },
    {
      "epoch": 18.089147286821706,
      "grad_norm": 9.318556785583496,
      "learning_rate": 3.19108527131783e-05,
      "loss": 0.533,
      "step": 4667
    },
    {
      "epoch": 18.093023255813954,
      "grad_norm": 2.7854723930358887,
      "learning_rate": 3.190697674418604e-05,
      "loss": 0.025,
      "step": 4668
    },
    {
      "epoch": 18.0968992248062,
      "grad_norm": 0.23446308076381683,
      "learning_rate": 3.19031007751938e-05,
      "loss": 0.0025,
      "step": 4669
    },
    {
      "epoch": 18.100775193798448,
      "grad_norm": 0.04990391433238983,
      "learning_rate": 3.189922480620155e-05,
      "loss": 0.0014,
      "step": 4670
    },
    {
      "epoch": 18.1046511627907,
      "grad_norm": 0.05634763836860657,
      "learning_rate": 3.189534883720931e-05,
      "loss": 0.0014,
      "step": 4671
    },
    {
      "epoch": 18.108527131782946,
      "grad_norm": 5.457721710205078,
      "learning_rate": 3.189147286821705e-05,
      "loss": 0.3178,
      "step": 4672
    },
    {
      "epoch": 18.112403100775193,
      "grad_norm": 12.967018127441406,
      "learning_rate": 3.188759689922481e-05,
      "loss": 0.6007,
      "step": 4673
    },
    {
      "epoch": 18.11627906976744,
      "grad_norm": 0.13721336424350739,
      "learning_rate": 3.188372093023256e-05,
      "loss": 0.0034,
      "step": 4674
    },
    {
      "epoch": 18.12015503875969,
      "grad_norm": 0.0516444630920887,
      "learning_rate": 3.187984496124031e-05,
      "loss": 0.0015,
      "step": 4675
    },
    {
      "epoch": 18.124031007751938,
      "grad_norm": 5.307248592376709,
      "learning_rate": 3.187596899224806e-05,
      "loss": 0.4232,
      "step": 4676
    },
    {
      "epoch": 18.127906976744185,
      "grad_norm": 0.1429835557937622,
      "learning_rate": 3.1872093023255815e-05,
      "loss": 0.0051,
      "step": 4677
    },
    {
      "epoch": 18.131782945736433,
      "grad_norm": 0.035614557564258575,
      "learning_rate": 3.186821705426357e-05,
      "loss": 0.0013,
      "step": 4678
    },
    {
      "epoch": 18.135658914728683,
      "grad_norm": 0.06184433400630951,
      "learning_rate": 3.186434108527132e-05,
      "loss": 0.0019,
      "step": 4679
    },
    {
      "epoch": 18.13953488372093,
      "grad_norm": 1.531629204750061,
      "learning_rate": 3.186046511627907e-05,
      "loss": 0.0111,
      "step": 4680
    },
    {
      "epoch": 18.143410852713178,
      "grad_norm": 0.044649142771959305,
      "learning_rate": 3.1856589147286825e-05,
      "loss": 0.0016,
      "step": 4681
    },
    {
      "epoch": 18.147286821705425,
      "grad_norm": 4.909513473510742,
      "learning_rate": 3.185271317829458e-05,
      "loss": 0.1605,
      "step": 4682
    },
    {
      "epoch": 18.151162790697676,
      "grad_norm": 0.02236040122807026,
      "learning_rate": 3.184883720930233e-05,
      "loss": 0.0012,
      "step": 4683
    },
    {
      "epoch": 18.155038759689923,
      "grad_norm": 2.90242862701416,
      "learning_rate": 3.1844961240310075e-05,
      "loss": 0.2233,
      "step": 4684
    },
    {
      "epoch": 18.15891472868217,
      "grad_norm": 0.005078176502138376,
      "learning_rate": 3.1841085271317834e-05,
      "loss": 0.0004,
      "step": 4685
    },
    {
      "epoch": 18.162790697674417,
      "grad_norm": 0.19319340586662292,
      "learning_rate": 3.183720930232558e-05,
      "loss": 0.0037,
      "step": 4686
    },
    {
      "epoch": 18.166666666666668,
      "grad_norm": 0.008046134375035763,
      "learning_rate": 3.183333333333334e-05,
      "loss": 0.0005,
      "step": 4687
    },
    {
      "epoch": 18.170542635658915,
      "grad_norm": 0.011039506644010544,
      "learning_rate": 3.1829457364341085e-05,
      "loss": 0.0007,
      "step": 4688
    },
    {
      "epoch": 18.174418604651162,
      "grad_norm": 0.00881008617579937,
      "learning_rate": 3.1825581395348844e-05,
      "loss": 0.0006,
      "step": 4689
    },
    {
      "epoch": 18.17829457364341,
      "grad_norm": 1.0130279064178467,
      "learning_rate": 3.182170542635659e-05,
      "loss": 0.0221,
      "step": 4690
    },
    {
      "epoch": 18.18217054263566,
      "grad_norm": 0.004006987437605858,
      "learning_rate": 3.181782945736434e-05,
      "loss": 0.0003,
      "step": 4691
    },
    {
      "epoch": 18.186046511627907,
      "grad_norm": 0.0037460988387465477,
      "learning_rate": 3.1813953488372094e-05,
      "loss": 0.0003,
      "step": 4692
    },
    {
      "epoch": 18.189922480620154,
      "grad_norm": 0.00626106932759285,
      "learning_rate": 3.181007751937985e-05,
      "loss": 0.0003,
      "step": 4693
    },
    {
      "epoch": 18.1937984496124,
      "grad_norm": 0.009091679938137531,
      "learning_rate": 3.18062015503876e-05,
      "loss": 0.0003,
      "step": 4694
    },
    {
      "epoch": 18.197674418604652,
      "grad_norm": 0.027915962040424347,
      "learning_rate": 3.1802325581395345e-05,
      "loss": 0.0005,
      "step": 4695
    },
    {
      "epoch": 18.2015503875969,
      "grad_norm": 0.4775489866733551,
      "learning_rate": 3.1798449612403104e-05,
      "loss": 0.0269,
      "step": 4696
    },
    {
      "epoch": 18.205426356589147,
      "grad_norm": 12.403444290161133,
      "learning_rate": 3.179457364341085e-05,
      "loss": 0.1015,
      "step": 4697
    },
    {
      "epoch": 18.209302325581394,
      "grad_norm": 7.797199726104736,
      "learning_rate": 3.179069767441861e-05,
      "loss": 0.0858,
      "step": 4698
    },
    {
      "epoch": 18.213178294573645,
      "grad_norm": 42.4893798828125,
      "learning_rate": 3.1786821705426355e-05,
      "loss": 0.6135,
      "step": 4699
    },
    {
      "epoch": 18.217054263565892,
      "grad_norm": 0.0029069825541228056,
      "learning_rate": 3.1782945736434114e-05,
      "loss": 0.0003,
      "step": 4700
    },
    {
      "epoch": 18.22093023255814,
      "grad_norm": 0.003707218449562788,
      "learning_rate": 3.177906976744186e-05,
      "loss": 0.0003,
      "step": 4701
    },
    {
      "epoch": 18.224806201550386,
      "grad_norm": 6.768320560455322,
      "learning_rate": 3.177519379844961e-05,
      "loss": 0.0057,
      "step": 4702
    },
    {
      "epoch": 18.228682170542637,
      "grad_norm": 0.005061428062617779,
      "learning_rate": 3.1771317829457364e-05,
      "loss": 0.0003,
      "step": 4703
    },
    {
      "epoch": 18.232558139534884,
      "grad_norm": 0.009938054718077183,
      "learning_rate": 3.176744186046512e-05,
      "loss": 0.0003,
      "step": 4704
    },
    {
      "epoch": 18.23643410852713,
      "grad_norm": 4.062583923339844,
      "learning_rate": 3.176356589147287e-05,
      "loss": 0.2657,
      "step": 4705
    },
    {
      "epoch": 18.24031007751938,
      "grad_norm": 0.07297925651073456,
      "learning_rate": 3.175968992248062e-05,
      "loss": 0.0004,
      "step": 4706
    },
    {
      "epoch": 18.24418604651163,
      "grad_norm": 0.0029086729045957327,
      "learning_rate": 3.1755813953488374e-05,
      "loss": 0.0003,
      "step": 4707
    },
    {
      "epoch": 18.248062015503876,
      "grad_norm": 0.0955854132771492,
      "learning_rate": 3.1751937984496126e-05,
      "loss": 0.0038,
      "step": 4708
    },
    {
      "epoch": 18.251937984496124,
      "grad_norm": 0.004066186957061291,
      "learning_rate": 3.174806201550388e-05,
      "loss": 0.0003,
      "step": 4709
    },
    {
      "epoch": 18.25581395348837,
      "grad_norm": 0.004767237696796656,
      "learning_rate": 3.174418604651163e-05,
      "loss": 0.0003,
      "step": 4710
    },
    {
      "epoch": 18.25968992248062,
      "grad_norm": 0.0294850654900074,
      "learning_rate": 3.1740310077519384e-05,
      "loss": 0.0003,
      "step": 4711
    },
    {
      "epoch": 18.26356589147287,
      "grad_norm": 0.012358107604086399,
      "learning_rate": 3.1736434108527136e-05,
      "loss": 0.0008,
      "step": 4712
    },
    {
      "epoch": 18.267441860465116,
      "grad_norm": 0.0512423999607563,
      "learning_rate": 3.173255813953488e-05,
      "loss": 0.0021,
      "step": 4713
    },
    {
      "epoch": 18.271317829457363,
      "grad_norm": 0.47082969546318054,
      "learning_rate": 3.172868217054264e-05,
      "loss": 0.0191,
      "step": 4714
    },
    {
      "epoch": 18.275193798449614,
      "grad_norm": 1.515136480331421,
      "learning_rate": 3.1724806201550387e-05,
      "loss": 0.0169,
      "step": 4715
    },
    {
      "epoch": 18.27906976744186,
      "grad_norm": 3.2243969440460205,
      "learning_rate": 3.1720930232558146e-05,
      "loss": 0.2092,
      "step": 4716
    },
    {
      "epoch": 18.282945736434108,
      "grad_norm": 0.007672956213355064,
      "learning_rate": 3.171705426356589e-05,
      "loss": 0.0004,
      "step": 4717
    },
    {
      "epoch": 18.286821705426355,
      "grad_norm": 0.0050930455327034,
      "learning_rate": 3.1713178294573644e-05,
      "loss": 0.0003,
      "step": 4718
    },
    {
      "epoch": 18.290697674418606,
      "grad_norm": 0.034226011484861374,
      "learning_rate": 3.1709302325581396e-05,
      "loss": 0.0004,
      "step": 4719
    },
    {
      "epoch": 18.294573643410853,
      "grad_norm": 0.3679698705673218,
      "learning_rate": 3.170542635658915e-05,
      "loss": 0.0046,
      "step": 4720
    },
    {
      "epoch": 18.2984496124031,
      "grad_norm": 0.14810828864574432,
      "learning_rate": 3.17015503875969e-05,
      "loss": 0.005,
      "step": 4721
    },
    {
      "epoch": 18.302325581395348,
      "grad_norm": 0.0034114194568246603,
      "learning_rate": 3.1697674418604654e-05,
      "loss": 0.0003,
      "step": 4722
    },
    {
      "epoch": 18.3062015503876,
      "grad_norm": 0.10770989954471588,
      "learning_rate": 3.1693798449612406e-05,
      "loss": 0.0008,
      "step": 4723
    },
    {
      "epoch": 18.310077519379846,
      "grad_norm": 5.103921890258789,
      "learning_rate": 3.168992248062015e-05,
      "loss": 0.4178,
      "step": 4724
    },
    {
      "epoch": 18.313953488372093,
      "grad_norm": 9.135348320007324,
      "learning_rate": 3.168604651162791e-05,
      "loss": 0.2224,
      "step": 4725
    },
    {
      "epoch": 18.31782945736434,
      "grad_norm": 0.003944797907024622,
      "learning_rate": 3.1682170542635656e-05,
      "loss": 0.0003,
      "step": 4726
    },
    {
      "epoch": 18.32170542635659,
      "grad_norm": 0.006667739246040583,
      "learning_rate": 3.1678294573643416e-05,
      "loss": 0.0004,
      "step": 4727
    },
    {
      "epoch": 18.325581395348838,
      "grad_norm": 0.018482085317373276,
      "learning_rate": 3.167441860465116e-05,
      "loss": 0.0007,
      "step": 4728
    },
    {
      "epoch": 18.329457364341085,
      "grad_norm": 0.016981860622763634,
      "learning_rate": 3.167054263565892e-05,
      "loss": 0.0006,
      "step": 4729
    },
    {
      "epoch": 18.333333333333332,
      "grad_norm": 10.004376411437988,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.0545,
      "step": 4730
    },
    {
      "epoch": 18.337209302325583,
      "grad_norm": 0.032552290707826614,
      "learning_rate": 3.166279069767442e-05,
      "loss": 0.0011,
      "step": 4731
    },
    {
      "epoch": 18.34108527131783,
      "grad_norm": 0.05446787178516388,
      "learning_rate": 3.165891472868217e-05,
      "loss": 0.0014,
      "step": 4732
    },
    {
      "epoch": 18.344961240310077,
      "grad_norm": 0.0480441078543663,
      "learning_rate": 3.1655038759689923e-05,
      "loss": 0.0014,
      "step": 4733
    },
    {
      "epoch": 18.348837209302324,
      "grad_norm": 0.041154760867357254,
      "learning_rate": 3.1651162790697676e-05,
      "loss": 0.0011,
      "step": 4734
    },
    {
      "epoch": 18.352713178294575,
      "grad_norm": 0.46145498752593994,
      "learning_rate": 3.164728682170543e-05,
      "loss": 0.0107,
      "step": 4735
    },
    {
      "epoch": 18.356589147286822,
      "grad_norm": 0.021142225712537766,
      "learning_rate": 3.164341085271318e-05,
      "loss": 0.0007,
      "step": 4736
    },
    {
      "epoch": 18.36046511627907,
      "grad_norm": 1.6054961681365967,
      "learning_rate": 3.163953488372093e-05,
      "loss": 0.0196,
      "step": 4737
    },
    {
      "epoch": 18.364341085271317,
      "grad_norm": 0.012907994911074638,
      "learning_rate": 3.1635658914728686e-05,
      "loss": 0.0006,
      "step": 4738
    },
    {
      "epoch": 18.368217054263567,
      "grad_norm": 0.012104727327823639,
      "learning_rate": 3.163178294573644e-05,
      "loss": 0.0005,
      "step": 4739
    },
    {
      "epoch": 18.372093023255815,
      "grad_norm": 0.00785848218947649,
      "learning_rate": 3.162790697674419e-05,
      "loss": 0.0004,
      "step": 4740
    },
    {
      "epoch": 18.375968992248062,
      "grad_norm": 0.005075526889413595,
      "learning_rate": 3.162403100775194e-05,
      "loss": 0.0003,
      "step": 4741
    },
    {
      "epoch": 18.37984496124031,
      "grad_norm": 0.012784665450453758,
      "learning_rate": 3.162015503875969e-05,
      "loss": 0.0006,
      "step": 4742
    },
    {
      "epoch": 18.38372093023256,
      "grad_norm": 0.010337517596781254,
      "learning_rate": 3.161627906976745e-05,
      "loss": 0.0006,
      "step": 4743
    },
    {
      "epoch": 18.387596899224807,
      "grad_norm": 0.0052763293497264385,
      "learning_rate": 3.161240310077519e-05,
      "loss": 0.0004,
      "step": 4744
    },
    {
      "epoch": 18.391472868217054,
      "grad_norm": 0.9098932147026062,
      "learning_rate": 3.1608527131782946e-05,
      "loss": 0.0572,
      "step": 4745
    },
    {
      "epoch": 18.3953488372093,
      "grad_norm": 0.0027966825291514397,
      "learning_rate": 3.16046511627907e-05,
      "loss": 0.0003,
      "step": 4746
    },
    {
      "epoch": 18.399224806201552,
      "grad_norm": 0.0028668942395597696,
      "learning_rate": 3.160077519379845e-05,
      "loss": 0.0002,
      "step": 4747
    },
    {
      "epoch": 18.4031007751938,
      "grad_norm": 0.0040703401900827885,
      "learning_rate": 3.15968992248062e-05,
      "loss": 0.0003,
      "step": 4748
    },
    {
      "epoch": 18.406976744186046,
      "grad_norm": 0.0037271238397806883,
      "learning_rate": 3.1593023255813955e-05,
      "loss": 0.0003,
      "step": 4749
    },
    {
      "epoch": 18.410852713178294,
      "grad_norm": 0.0024941102601587772,
      "learning_rate": 3.158914728682171e-05,
      "loss": 0.0003,
      "step": 4750
    },
    {
      "epoch": 18.414728682170544,
      "grad_norm": 0.0784725472331047,
      "learning_rate": 3.1585271317829453e-05,
      "loss": 0.0007,
      "step": 4751
    },
    {
      "epoch": 18.41860465116279,
      "grad_norm": 3.676988363265991,
      "learning_rate": 3.158139534883721e-05,
      "loss": 0.0157,
      "step": 4752
    },
    {
      "epoch": 18.42248062015504,
      "grad_norm": 0.014876739121973515,
      "learning_rate": 3.157751937984496e-05,
      "loss": 0.0009,
      "step": 4753
    },
    {
      "epoch": 18.426356589147286,
      "grad_norm": 0.013175196945667267,
      "learning_rate": 3.157364341085272e-05,
      "loss": 0.0003,
      "step": 4754
    },
    {
      "epoch": 18.430232558139537,
      "grad_norm": 0.20660564303398132,
      "learning_rate": 3.156976744186046e-05,
      "loss": 0.0099,
      "step": 4755
    },
    {
      "epoch": 18.434108527131784,
      "grad_norm": 0.009204495698213577,
      "learning_rate": 3.156589147286822e-05,
      "loss": 0.0003,
      "step": 4756
    },
    {
      "epoch": 18.43798449612403,
      "grad_norm": 0.0032630483619868755,
      "learning_rate": 3.156201550387597e-05,
      "loss": 0.0003,
      "step": 4757
    },
    {
      "epoch": 18.441860465116278,
      "grad_norm": 0.0032618672121316195,
      "learning_rate": 3.155813953488373e-05,
      "loss": 0.0003,
      "step": 4758
    },
    {
      "epoch": 18.44573643410853,
      "grad_norm": 0.006245902739465237,
      "learning_rate": 3.155426356589147e-05,
      "loss": 0.0004,
      "step": 4759
    },
    {
      "epoch": 18.449612403100776,
      "grad_norm": 0.0050794817507267,
      "learning_rate": 3.1550387596899225e-05,
      "loss": 0.0003,
      "step": 4760
    },
    {
      "epoch": 18.453488372093023,
      "grad_norm": 18.869558334350586,
      "learning_rate": 3.154651162790698e-05,
      "loss": 0.9977,
      "step": 4761
    },
    {
      "epoch": 18.45736434108527,
      "grad_norm": 0.002819308778271079,
      "learning_rate": 3.154263565891473e-05,
      "loss": 0.0003,
      "step": 4762
    },
    {
      "epoch": 18.46124031007752,
      "grad_norm": 0.2113562971353531,
      "learning_rate": 3.153875968992248e-05,
      "loss": 0.0072,
      "step": 4763
    },
    {
      "epoch": 18.46511627906977,
      "grad_norm": 0.002197776222601533,
      "learning_rate": 3.1534883720930235e-05,
      "loss": 0.0002,
      "step": 4764
    },
    {
      "epoch": 18.468992248062015,
      "grad_norm": 0.003291425993666053,
      "learning_rate": 3.153100775193799e-05,
      "loss": 0.0003,
      "step": 4765
    },
    {
      "epoch": 18.472868217054263,
      "grad_norm": 0.0122313117608428,
      "learning_rate": 3.152713178294574e-05,
      "loss": 0.0008,
      "step": 4766
    },
    {
      "epoch": 18.476744186046513,
      "grad_norm": 0.07938338071107864,
      "learning_rate": 3.152325581395349e-05,
      "loss": 0.0008,
      "step": 4767
    },
    {
      "epoch": 18.48062015503876,
      "grad_norm": 0.003304601414129138,
      "learning_rate": 3.1519379844961245e-05,
      "loss": 0.0003,
      "step": 4768
    },
    {
      "epoch": 18.484496124031008,
      "grad_norm": 0.004145572427660227,
      "learning_rate": 3.151550387596899e-05,
      "loss": 0.0003,
      "step": 4769
    },
    {
      "epoch": 18.488372093023255,
      "grad_norm": 0.006703581660985947,
      "learning_rate": 3.151162790697675e-05,
      "loss": 0.0004,
      "step": 4770
    },
    {
      "epoch": 18.492248062015506,
      "grad_norm": 4.400407314300537,
      "learning_rate": 3.1507751937984495e-05,
      "loss": 0.3507,
      "step": 4771
    },
    {
      "epoch": 18.496124031007753,
      "grad_norm": 0.012462165206670761,
      "learning_rate": 3.150387596899225e-05,
      "loss": 0.0007,
      "step": 4772
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.005833978299051523,
      "learning_rate": 3.15e-05,
      "loss": 0.0004,
      "step": 4773
    },
    {
      "epoch": 18.503875968992247,
      "grad_norm": 0.032254863530397415,
      "learning_rate": 3.149612403100775e-05,
      "loss": 0.0009,
      "step": 4774
    },
    {
      "epoch": 18.507751937984494,
      "grad_norm": 0.04456895962357521,
      "learning_rate": 3.1492248062015505e-05,
      "loss": 0.002,
      "step": 4775
    },
    {
      "epoch": 18.511627906976745,
      "grad_norm": 0.003949203062802553,
      "learning_rate": 3.148837209302326e-05,
      "loss": 0.0003,
      "step": 4776
    },
    {
      "epoch": 18.515503875968992,
      "grad_norm": 0.05605841428041458,
      "learning_rate": 3.148449612403101e-05,
      "loss": 0.0019,
      "step": 4777
    },
    {
      "epoch": 18.51937984496124,
      "grad_norm": 0.005773013457655907,
      "learning_rate": 3.148062015503876e-05,
      "loss": 0.0003,
      "step": 4778
    },
    {
      "epoch": 18.52325581395349,
      "grad_norm": 0.002481666160747409,
      "learning_rate": 3.1476744186046514e-05,
      "loss": 0.0002,
      "step": 4779
    },
    {
      "epoch": 18.527131782945737,
      "grad_norm": 53.68760299682617,
      "learning_rate": 3.147286821705426e-05,
      "loss": 0.2833,
      "step": 4780
    },
    {
      "epoch": 18.531007751937985,
      "grad_norm": 0.013342109508812428,
      "learning_rate": 3.146899224806202e-05,
      "loss": 0.0008,
      "step": 4781
    },
    {
      "epoch": 18.53488372093023,
      "grad_norm": 0.058325476944446564,
      "learning_rate": 3.1465116279069765e-05,
      "loss": 0.0004,
      "step": 4782
    },
    {
      "epoch": 18.53875968992248,
      "grad_norm": 0.0036059857811778784,
      "learning_rate": 3.1461240310077524e-05,
      "loss": 0.0003,
      "step": 4783
    },
    {
      "epoch": 18.54263565891473,
      "grad_norm": 0.0028893842827528715,
      "learning_rate": 3.145736434108527e-05,
      "loss": 0.0003,
      "step": 4784
    },
    {
      "epoch": 18.546511627906977,
      "grad_norm": 0.0021536415442824364,
      "learning_rate": 3.145348837209303e-05,
      "loss": 0.0002,
      "step": 4785
    },
    {
      "epoch": 18.550387596899224,
      "grad_norm": 0.007401950657367706,
      "learning_rate": 3.1449612403100775e-05,
      "loss": 0.0006,
      "step": 4786
    },
    {
      "epoch": 18.55426356589147,
      "grad_norm": 15.964972496032715,
      "learning_rate": 3.144573643410853e-05,
      "loss": 0.0252,
      "step": 4787
    },
    {
      "epoch": 18.558139534883722,
      "grad_norm": 0.05284477025270462,
      "learning_rate": 3.144186046511628e-05,
      "loss": 0.0004,
      "step": 4788
    },
    {
      "epoch": 18.56201550387597,
      "grad_norm": 54.246707916259766,
      "learning_rate": 3.143798449612403e-05,
      "loss": 0.2145,
      "step": 4789
    },
    {
      "epoch": 18.565891472868216,
      "grad_norm": 0.0033229724504053593,
      "learning_rate": 3.1434108527131784e-05,
      "loss": 0.0003,
      "step": 4790
    },
    {
      "epoch": 18.569767441860463,
      "grad_norm": 0.018281448632478714,
      "learning_rate": 3.143023255813954e-05,
      "loss": 0.0008,
      "step": 4791
    },
    {
      "epoch": 18.573643410852714,
      "grad_norm": 0.12972252070903778,
      "learning_rate": 3.142635658914729e-05,
      "loss": 0.0037,
      "step": 4792
    },
    {
      "epoch": 18.57751937984496,
      "grad_norm": 0.0020506775472313166,
      "learning_rate": 3.142248062015504e-05,
      "loss": 0.0002,
      "step": 4793
    },
    {
      "epoch": 18.58139534883721,
      "grad_norm": 0.004636290017515421,
      "learning_rate": 3.1418604651162794e-05,
      "loss": 0.0003,
      "step": 4794
    },
    {
      "epoch": 18.585271317829456,
      "grad_norm": 0.006283481605350971,
      "learning_rate": 3.1414728682170546e-05,
      "loss": 0.0003,
      "step": 4795
    },
    {
      "epoch": 18.589147286821706,
      "grad_norm": 0.009573900140821934,
      "learning_rate": 3.14108527131783e-05,
      "loss": 0.0003,
      "step": 4796
    },
    {
      "epoch": 18.593023255813954,
      "grad_norm": 0.002236049622297287,
      "learning_rate": 3.140697674418605e-05,
      "loss": 0.0002,
      "step": 4797
    },
    {
      "epoch": 18.5968992248062,
      "grad_norm": 0.00254404847510159,
      "learning_rate": 3.14031007751938e-05,
      "loss": 0.0002,
      "step": 4798
    },
    {
      "epoch": 18.600775193798448,
      "grad_norm": 0.0037108587566763163,
      "learning_rate": 3.139922480620155e-05,
      "loss": 0.0002,
      "step": 4799
    },
    {
      "epoch": 18.6046511627907,
      "grad_norm": 0.008840354159474373,
      "learning_rate": 3.13953488372093e-05,
      "loss": 0.0003,
      "step": 4800
    },
    {
      "epoch": 18.608527131782946,
      "grad_norm": 0.010627008974552155,
      "learning_rate": 3.1391472868217054e-05,
      "loss": 0.0007,
      "step": 4801
    },
    {
      "epoch": 18.612403100775193,
      "grad_norm": 0.0046846200712025166,
      "learning_rate": 3.138759689922481e-05,
      "loss": 0.0004,
      "step": 4802
    },
    {
      "epoch": 18.61627906976744,
      "grad_norm": 22.05984878540039,
      "learning_rate": 3.138372093023256e-05,
      "loss": 0.0196,
      "step": 4803
    },
    {
      "epoch": 18.62015503875969,
      "grad_norm": 0.002722816774621606,
      "learning_rate": 3.137984496124031e-05,
      "loss": 0.0003,
      "step": 4804
    },
    {
      "epoch": 18.624031007751938,
      "grad_norm": 1.6006534099578857,
      "learning_rate": 3.1375968992248064e-05,
      "loss": 0.0974,
      "step": 4805
    },
    {
      "epoch": 18.627906976744185,
      "grad_norm": 1.7248262166976929,
      "learning_rate": 3.1372093023255816e-05,
      "loss": 0.0702,
      "step": 4806
    },
    {
      "epoch": 18.631782945736433,
      "grad_norm": 2.5624516010284424,
      "learning_rate": 3.136821705426357e-05,
      "loss": 0.2088,
      "step": 4807
    },
    {
      "epoch": 18.635658914728683,
      "grad_norm": 3.749178647994995,
      "learning_rate": 3.136434108527132e-05,
      "loss": 0.2151,
      "step": 4808
    },
    {
      "epoch": 18.63953488372093,
      "grad_norm": 0.011221688240766525,
      "learning_rate": 3.136046511627907e-05,
      "loss": 0.0005,
      "step": 4809
    },
    {
      "epoch": 18.643410852713178,
      "grad_norm": 0.0765421986579895,
      "learning_rate": 3.1356589147286826e-05,
      "loss": 0.0009,
      "step": 4810
    },
    {
      "epoch": 18.647286821705425,
      "grad_norm": 5.843397617340088,
      "learning_rate": 3.135271317829457e-05,
      "loss": 0.2597,
      "step": 4811
    },
    {
      "epoch": 18.651162790697676,
      "grad_norm": 0.15513718128204346,
      "learning_rate": 3.134883720930233e-05,
      "loss": 0.0013,
      "step": 4812
    },
    {
      "epoch": 18.655038759689923,
      "grad_norm": 0.002583255060017109,
      "learning_rate": 3.1344961240310076e-05,
      "loss": 0.0003,
      "step": 4813
    },
    {
      "epoch": 18.65891472868217,
      "grad_norm": 0.005581213161349297,
      "learning_rate": 3.1341085271317836e-05,
      "loss": 0.0004,
      "step": 4814
    },
    {
      "epoch": 18.662790697674417,
      "grad_norm": 0.005048058461397886,
      "learning_rate": 3.133720930232558e-05,
      "loss": 0.0003,
      "step": 4815
    },
    {
      "epoch": 18.666666666666668,
      "grad_norm": 0.15584197640419006,
      "learning_rate": 3.1333333333333334e-05,
      "loss": 0.0007,
      "step": 4816
    },
    {
      "epoch": 18.670542635658915,
      "grad_norm": 0.04013032093644142,
      "learning_rate": 3.1329457364341086e-05,
      "loss": 0.0015,
      "step": 4817
    },
    {
      "epoch": 18.674418604651162,
      "grad_norm": 0.7203959226608276,
      "learning_rate": 3.132558139534884e-05,
      "loss": 0.0152,
      "step": 4818
    },
    {
      "epoch": 18.67829457364341,
      "grad_norm": 0.0025757267139852047,
      "learning_rate": 3.132170542635659e-05,
      "loss": 0.0002,
      "step": 4819
    },
    {
      "epoch": 18.68217054263566,
      "grad_norm": 0.0026912193279713392,
      "learning_rate": 3.1317829457364343e-05,
      "loss": 0.0002,
      "step": 4820
    },
    {
      "epoch": 18.686046511627907,
      "grad_norm": 0.005388449877500534,
      "learning_rate": 3.1313953488372096e-05,
      "loss": 0.0003,
      "step": 4821
    },
    {
      "epoch": 18.689922480620154,
      "grad_norm": 0.004067422356456518,
      "learning_rate": 3.131007751937985e-05,
      "loss": 0.0003,
      "step": 4822
    },
    {
      "epoch": 18.6937984496124,
      "grad_norm": 0.029808849096298218,
      "learning_rate": 3.13062015503876e-05,
      "loss": 0.0012,
      "step": 4823
    },
    {
      "epoch": 18.697674418604652,
      "grad_norm": 0.003136944491416216,
      "learning_rate": 3.130232558139535e-05,
      "loss": 0.0003,
      "step": 4824
    },
    {
      "epoch": 18.7015503875969,
      "grad_norm": 3.312887668609619,
      "learning_rate": 3.1298449612403106e-05,
      "loss": 0.2128,
      "step": 4825
    },
    {
      "epoch": 18.705426356589147,
      "grad_norm": 0.6617428660392761,
      "learning_rate": 3.129457364341085e-05,
      "loss": 0.0115,
      "step": 4826
    },
    {
      "epoch": 18.709302325581394,
      "grad_norm": 0.015932729467749596,
      "learning_rate": 3.1290697674418604e-05,
      "loss": 0.0003,
      "step": 4827
    },
    {
      "epoch": 18.713178294573645,
      "grad_norm": 0.10174641013145447,
      "learning_rate": 3.1286821705426356e-05,
      "loss": 0.0009,
      "step": 4828
    },
    {
      "epoch": 18.717054263565892,
      "grad_norm": 0.0021359622478485107,
      "learning_rate": 3.128294573643411e-05,
      "loss": 0.0002,
      "step": 4829
    },
    {
      "epoch": 18.72093023255814,
      "grad_norm": 0.0033150382805615664,
      "learning_rate": 3.127906976744186e-05,
      "loss": 0.0002,
      "step": 4830
    },
    {
      "epoch": 18.724806201550386,
      "grad_norm": 0.0032687950879335403,
      "learning_rate": 3.127519379844961e-05,
      "loss": 0.0003,
      "step": 4831
    },
    {
      "epoch": 18.728682170542637,
      "grad_norm": 0.0068634566850960255,
      "learning_rate": 3.1271317829457366e-05,
      "loss": 0.0003,
      "step": 4832
    },
    {
      "epoch": 18.732558139534884,
      "grad_norm": 0.003341543022543192,
      "learning_rate": 3.126744186046512e-05,
      "loss": 0.0003,
      "step": 4833
    },
    {
      "epoch": 18.73643410852713,
      "grad_norm": 0.004386259708553553,
      "learning_rate": 3.126356589147287e-05,
      "loss": 0.0002,
      "step": 4834
    },
    {
      "epoch": 18.74031007751938,
      "grad_norm": 0.002447224920615554,
      "learning_rate": 3.125968992248062e-05,
      "loss": 0.0003,
      "step": 4835
    },
    {
      "epoch": 18.74418604651163,
      "grad_norm": 0.005754775367677212,
      "learning_rate": 3.1255813953488375e-05,
      "loss": 0.0003,
      "step": 4836
    },
    {
      "epoch": 18.748062015503876,
      "grad_norm": 3.76529598236084,
      "learning_rate": 3.125193798449613e-05,
      "loss": 0.012,
      "step": 4837
    },
    {
      "epoch": 18.751937984496124,
      "grad_norm": 6.32900857925415,
      "learning_rate": 3.1248062015503873e-05,
      "loss": 0.4419,
      "step": 4838
    },
    {
      "epoch": 18.75581395348837,
      "grad_norm": 3.0634865760803223,
      "learning_rate": 3.124418604651163e-05,
      "loss": 0.3317,
      "step": 4839
    },
    {
      "epoch": 18.75968992248062,
      "grad_norm": 0.003031706204637885,
      "learning_rate": 3.124031007751938e-05,
      "loss": 0.0003,
      "step": 4840
    },
    {
      "epoch": 18.76356589147287,
      "grad_norm": 0.003824383718892932,
      "learning_rate": 3.123643410852714e-05,
      "loss": 0.0003,
      "step": 4841
    },
    {
      "epoch": 18.767441860465116,
      "grad_norm": 0.014039814472198486,
      "learning_rate": 3.123255813953488e-05,
      "loss": 0.0008,
      "step": 4842
    },
    {
      "epoch": 18.771317829457363,
      "grad_norm": 0.002176952315494418,
      "learning_rate": 3.122868217054264e-05,
      "loss": 0.0002,
      "step": 4843
    },
    {
      "epoch": 18.775193798449614,
      "grad_norm": 0.04554597660899162,
      "learning_rate": 3.122480620155039e-05,
      "loss": 0.0015,
      "step": 4844
    },
    {
      "epoch": 18.77906976744186,
      "grad_norm": 0.008214320056140423,
      "learning_rate": 3.122093023255814e-05,
      "loss": 0.0004,
      "step": 4845
    },
    {
      "epoch": 18.782945736434108,
      "grad_norm": 0.0021683555096387863,
      "learning_rate": 3.121705426356589e-05,
      "loss": 0.0002,
      "step": 4846
    },
    {
      "epoch": 18.786821705426355,
      "grad_norm": 0.0034900407772511244,
      "learning_rate": 3.1213178294573645e-05,
      "loss": 0.0003,
      "step": 4847
    },
    {
      "epoch": 18.790697674418606,
      "grad_norm": 0.0018977614818140864,
      "learning_rate": 3.12093023255814e-05,
      "loss": 0.0002,
      "step": 4848
    },
    {
      "epoch": 18.794573643410853,
      "grad_norm": 0.002744574099779129,
      "learning_rate": 3.120542635658915e-05,
      "loss": 0.0002,
      "step": 4849
    },
    {
      "epoch": 18.7984496124031,
      "grad_norm": 0.0019219573587179184,
      "learning_rate": 3.12015503875969e-05,
      "loss": 0.0002,
      "step": 4850
    },
    {
      "epoch": 18.802325581395348,
      "grad_norm": 0.0032410696148872375,
      "learning_rate": 3.119767441860465e-05,
      "loss": 0.0003,
      "step": 4851
    },
    {
      "epoch": 18.8062015503876,
      "grad_norm": 0.00294367759488523,
      "learning_rate": 3.119379844961241e-05,
      "loss": 0.0003,
      "step": 4852
    },
    {
      "epoch": 18.810077519379846,
      "grad_norm": 0.006427461747080088,
      "learning_rate": 3.118992248062015e-05,
      "loss": 0.0005,
      "step": 4853
    },
    {
      "epoch": 18.813953488372093,
      "grad_norm": 0.003476272337138653,
      "learning_rate": 3.1186046511627905e-05,
      "loss": 0.0003,
      "step": 4854
    },
    {
      "epoch": 18.81782945736434,
      "grad_norm": 0.002178989816457033,
      "learning_rate": 3.118217054263566e-05,
      "loss": 0.0002,
      "step": 4855
    },
    {
      "epoch": 18.82170542635659,
      "grad_norm": 0.0031050248071551323,
      "learning_rate": 3.117829457364341e-05,
      "loss": 0.0002,
      "step": 4856
    },
    {
      "epoch": 18.825581395348838,
      "grad_norm": 0.004472898319363594,
      "learning_rate": 3.117441860465116e-05,
      "loss": 0.0003,
      "step": 4857
    },
    {
      "epoch": 18.829457364341085,
      "grad_norm": 0.008134489879012108,
      "learning_rate": 3.1170542635658915e-05,
      "loss": 0.0006,
      "step": 4858
    },
    {
      "epoch": 18.833333333333332,
      "grad_norm": 0.03630337119102478,
      "learning_rate": 3.116666666666667e-05,
      "loss": 0.0016,
      "step": 4859
    },
    {
      "epoch": 18.837209302325583,
      "grad_norm": 0.003143365727737546,
      "learning_rate": 3.116279069767442e-05,
      "loss": 0.0002,
      "step": 4860
    },
    {
      "epoch": 18.84108527131783,
      "grad_norm": 0.009016268886625767,
      "learning_rate": 3.115891472868217e-05,
      "loss": 0.0003,
      "step": 4861
    },
    {
      "epoch": 18.844961240310077,
      "grad_norm": 0.020340610295534134,
      "learning_rate": 3.1155038759689925e-05,
      "loss": 0.0006,
      "step": 4862
    },
    {
      "epoch": 18.848837209302324,
      "grad_norm": 0.0035025852266699076,
      "learning_rate": 3.115116279069768e-05,
      "loss": 0.0003,
      "step": 4863
    },
    {
      "epoch": 18.852713178294575,
      "grad_norm": 0.004985294304788113,
      "learning_rate": 3.114728682170543e-05,
      "loss": 0.0003,
      "step": 4864
    },
    {
      "epoch": 18.856589147286822,
      "grad_norm": 0.4913463592529297,
      "learning_rate": 3.1143410852713175e-05,
      "loss": 0.0006,
      "step": 4865
    },
    {
      "epoch": 18.86046511627907,
      "grad_norm": 0.01440131850540638,
      "learning_rate": 3.1139534883720935e-05,
      "loss": 0.0008,
      "step": 4866
    },
    {
      "epoch": 18.864341085271317,
      "grad_norm": 0.00197397917509079,
      "learning_rate": 3.113565891472868e-05,
      "loss": 0.0002,
      "step": 4867
    },
    {
      "epoch": 18.868217054263567,
      "grad_norm": 0.0020396956242620945,
      "learning_rate": 3.113178294573644e-05,
      "loss": 0.0002,
      "step": 4868
    },
    {
      "epoch": 18.872093023255815,
      "grad_norm": 0.0020693300757557154,
      "learning_rate": 3.1127906976744185e-05,
      "loss": 0.0002,
      "step": 4869
    },
    {
      "epoch": 18.875968992248062,
      "grad_norm": 0.11111775040626526,
      "learning_rate": 3.1124031007751944e-05,
      "loss": 0.0049,
      "step": 4870
    },
    {
      "epoch": 18.87984496124031,
      "grad_norm": 0.0021174110006541014,
      "learning_rate": 3.112015503875969e-05,
      "loss": 0.0002,
      "step": 4871
    },
    {
      "epoch": 18.88372093023256,
      "grad_norm": 0.002515953965485096,
      "learning_rate": 3.111627906976744e-05,
      "loss": 0.0002,
      "step": 4872
    },
    {
      "epoch": 18.887596899224807,
      "grad_norm": 0.003002731828019023,
      "learning_rate": 3.1112403100775195e-05,
      "loss": 0.0003,
      "step": 4873
    },
    {
      "epoch": 18.891472868217054,
      "grad_norm": 13.005105018615723,
      "learning_rate": 3.110852713178295e-05,
      "loss": 0.4019,
      "step": 4874
    },
    {
      "epoch": 18.8953488372093,
      "grad_norm": 0.10894810408353806,
      "learning_rate": 3.11046511627907e-05,
      "loss": 0.0028,
      "step": 4875
    },
    {
      "epoch": 18.899224806201552,
      "grad_norm": 0.0016431024996563792,
      "learning_rate": 3.110077519379845e-05,
      "loss": 0.0002,
      "step": 4876
    },
    {
      "epoch": 18.9031007751938,
      "grad_norm": 0.0038688532076776028,
      "learning_rate": 3.1096899224806204e-05,
      "loss": 0.0002,
      "step": 4877
    },
    {
      "epoch": 18.906976744186046,
      "grad_norm": 0.0021080952137708664,
      "learning_rate": 3.109302325581395e-05,
      "loss": 0.0002,
      "step": 4878
    },
    {
      "epoch": 18.910852713178294,
      "grad_norm": 14.9470796585083,
      "learning_rate": 3.108914728682171e-05,
      "loss": 0.4711,
      "step": 4879
    },
    {
      "epoch": 18.914728682170544,
      "grad_norm": 0.0024452735669910908,
      "learning_rate": 3.1085271317829455e-05,
      "loss": 0.0003,
      "step": 4880
    },
    {
      "epoch": 18.91860465116279,
      "grad_norm": 0.013227446004748344,
      "learning_rate": 3.1081395348837214e-05,
      "loss": 0.0008,
      "step": 4881
    },
    {
      "epoch": 18.92248062015504,
      "grad_norm": 0.001737535814754665,
      "learning_rate": 3.107751937984496e-05,
      "loss": 0.0002,
      "step": 4882
    },
    {
      "epoch": 18.926356589147286,
      "grad_norm": 0.030546341091394424,
      "learning_rate": 3.107364341085271e-05,
      "loss": 0.0002,
      "step": 4883
    },
    {
      "epoch": 18.930232558139537,
      "grad_norm": 0.004949239548295736,
      "learning_rate": 3.1069767441860465e-05,
      "loss": 0.0004,
      "step": 4884
    },
    {
      "epoch": 18.934108527131784,
      "grad_norm": 3.2451138496398926,
      "learning_rate": 3.106589147286822e-05,
      "loss": 0.256,
      "step": 4885
    },
    {
      "epoch": 18.93798449612403,
      "grad_norm": 0.0028443685732781887,
      "learning_rate": 3.106201550387597e-05,
      "loss": 0.0002,
      "step": 4886
    },
    {
      "epoch": 18.941860465116278,
      "grad_norm": 0.0020959582179784775,
      "learning_rate": 3.105813953488372e-05,
      "loss": 0.0002,
      "step": 4887
    },
    {
      "epoch": 18.94573643410853,
      "grad_norm": 0.004564070608466864,
      "learning_rate": 3.1054263565891474e-05,
      "loss": 0.0004,
      "step": 4888
    },
    {
      "epoch": 18.949612403100776,
      "grad_norm": 0.0019399469019845128,
      "learning_rate": 3.105038759689923e-05,
      "loss": 0.0002,
      "step": 4889
    },
    {
      "epoch": 18.953488372093023,
      "grad_norm": 0.003829702502116561,
      "learning_rate": 3.104651162790698e-05,
      "loss": 0.0003,
      "step": 4890
    },
    {
      "epoch": 18.95736434108527,
      "grad_norm": 0.007658698596060276,
      "learning_rate": 3.104263565891473e-05,
      "loss": 0.0005,
      "step": 4891
    },
    {
      "epoch": 18.96124031007752,
      "grad_norm": 0.0023923052940517664,
      "learning_rate": 3.1038759689922484e-05,
      "loss": 0.0002,
      "step": 4892
    },
    {
      "epoch": 18.96511627906977,
      "grad_norm": 0.0024901805445551872,
      "learning_rate": 3.1034883720930236e-05,
      "loss": 0.0002,
      "step": 4893
    },
    {
      "epoch": 18.968992248062015,
      "grad_norm": 0.6807809472084045,
      "learning_rate": 3.103100775193798e-05,
      "loss": 0.0036,
      "step": 4894
    },
    {
      "epoch": 18.972868217054263,
      "grad_norm": 0.0028368341736495495,
      "learning_rate": 3.102713178294574e-05,
      "loss": 0.0002,
      "step": 4895
    },
    {
      "epoch": 18.97674418604651,
      "grad_norm": 0.022875957190990448,
      "learning_rate": 3.102325581395349e-05,
      "loss": 0.0011,
      "step": 4896
    },
    {
      "epoch": 18.98062015503876,
      "grad_norm": 5.048079490661621,
      "learning_rate": 3.1019379844961246e-05,
      "loss": 0.0077,
      "step": 4897
    },
    {
      "epoch": 18.984496124031008,
      "grad_norm": 0.0025033585261553526,
      "learning_rate": 3.101550387596899e-05,
      "loss": 0.0002,
      "step": 4898
    },
    {
      "epoch": 18.988372093023255,
      "grad_norm": 0.0021819928660988808,
      "learning_rate": 3.101162790697675e-05,
      "loss": 0.0002,
      "step": 4899
    },
    {
      "epoch": 18.992248062015506,
      "grad_norm": 6.030958652496338,
      "learning_rate": 3.1007751937984497e-05,
      "loss": 0.186,
      "step": 4900
    },
    {
      "epoch": 18.996124031007753,
      "grad_norm": 0.003697702195495367,
      "learning_rate": 3.100387596899225e-05,
      "loss": 0.0003,
      "step": 4901
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.0024184773210436106,
      "learning_rate": 3.1e-05,
      "loss": 0.0002,
      "step": 4902
    },
    {
      "epoch": 19.003875968992247,
      "grad_norm": 0.002734738402068615,
      "learning_rate": 3.0996124031007754e-05,
      "loss": 0.0002,
      "step": 4903
    },
    {
      "epoch": 19.007751937984494,
      "grad_norm": 0.002097449963912368,
      "learning_rate": 3.0992248062015506e-05,
      "loss": 0.0002,
      "step": 4904
    },
    {
      "epoch": 19.011627906976745,
      "grad_norm": 0.0025639475788921118,
      "learning_rate": 3.098837209302325e-05,
      "loss": 0.0002,
      "step": 4905
    },
    {
      "epoch": 19.015503875968992,
      "grad_norm": 0.003699846565723419,
      "learning_rate": 3.098449612403101e-05,
      "loss": 0.0003,
      "step": 4906
    },
    {
      "epoch": 19.01937984496124,
      "grad_norm": 0.0029990121256560087,
      "learning_rate": 3.098062015503876e-05,
      "loss": 0.0002,
      "step": 4907
    },
    {
      "epoch": 19.023255813953487,
      "grad_norm": 0.013691123574972153,
      "learning_rate": 3.0976744186046516e-05,
      "loss": 0.0008,
      "step": 4908
    },
    {
      "epoch": 19.027131782945737,
      "grad_norm": 3.091585636138916,
      "learning_rate": 3.097286821705426e-05,
      "loss": 0.2,
      "step": 4909
    },
    {
      "epoch": 19.031007751937985,
      "grad_norm": 0.0027086096815764904,
      "learning_rate": 3.096899224806202e-05,
      "loss": 0.0002,
      "step": 4910
    },
    {
      "epoch": 19.03488372093023,
      "grad_norm": 0.0219072587788105,
      "learning_rate": 3.0965116279069766e-05,
      "loss": 0.0005,
      "step": 4911
    },
    {
      "epoch": 19.03875968992248,
      "grad_norm": 0.0021375350188463926,
      "learning_rate": 3.096124031007752e-05,
      "loss": 0.0002,
      "step": 4912
    },
    {
      "epoch": 19.04263565891473,
      "grad_norm": 0.0017833065940067172,
      "learning_rate": 3.095736434108527e-05,
      "loss": 0.0002,
      "step": 4913
    },
    {
      "epoch": 19.046511627906977,
      "grad_norm": 0.0023865129332989454,
      "learning_rate": 3.0953488372093024e-05,
      "loss": 0.0002,
      "step": 4914
    },
    {
      "epoch": 19.050387596899224,
      "grad_norm": 0.183394655585289,
      "learning_rate": 3.0949612403100776e-05,
      "loss": 0.0072,
      "step": 4915
    },
    {
      "epoch": 19.05426356589147,
      "grad_norm": 2.124723196029663,
      "learning_rate": 3.094573643410853e-05,
      "loss": 0.0422,
      "step": 4916
    },
    {
      "epoch": 19.058139534883722,
      "grad_norm": 0.0027051360812038183,
      "learning_rate": 3.094186046511628e-05,
      "loss": 0.0003,
      "step": 4917
    },
    {
      "epoch": 19.06201550387597,
      "grad_norm": 0.26142632961273193,
      "learning_rate": 3.093798449612403e-05,
      "loss": 0.0032,
      "step": 4918
    },
    {
      "epoch": 19.065891472868216,
      "grad_norm": 3.6871867179870605,
      "learning_rate": 3.0934108527131786e-05,
      "loss": 0.0248,
      "step": 4919
    },
    {
      "epoch": 19.069767441860463,
      "grad_norm": 0.3222617506980896,
      "learning_rate": 3.093023255813954e-05,
      "loss": 0.0068,
      "step": 4920
    },
    {
      "epoch": 19.073643410852714,
      "grad_norm": 0.004248085431754589,
      "learning_rate": 3.092635658914729e-05,
      "loss": 0.0003,
      "step": 4921
    },
    {
      "epoch": 19.07751937984496,
      "grad_norm": 0.004333273973315954,
      "learning_rate": 3.092248062015504e-05,
      "loss": 0.0004,
      "step": 4922
    },
    {
      "epoch": 19.08139534883721,
      "grad_norm": 2.3846304416656494,
      "learning_rate": 3.091860465116279e-05,
      "loss": 0.1998,
      "step": 4923
    },
    {
      "epoch": 19.085271317829456,
      "grad_norm": 0.0023571858182549477,
      "learning_rate": 3.091472868217055e-05,
      "loss": 0.0002,
      "step": 4924
    },
    {
      "epoch": 19.089147286821706,
      "grad_norm": 0.003545752028003335,
      "learning_rate": 3.0910852713178293e-05,
      "loss": 0.0003,
      "step": 4925
    },
    {
      "epoch": 19.093023255813954,
      "grad_norm": 0.0020580554846674204,
      "learning_rate": 3.090697674418605e-05,
      "loss": 0.0002,
      "step": 4926
    },
    {
      "epoch": 19.0968992248062,
      "grad_norm": 0.0024722188245505095,
      "learning_rate": 3.09031007751938e-05,
      "loss": 0.0002,
      "step": 4927
    },
    {
      "epoch": 19.100775193798448,
      "grad_norm": 0.005071630701422691,
      "learning_rate": 3.089922480620156e-05,
      "loss": 0.0003,
      "step": 4928
    },
    {
      "epoch": 19.1046511627907,
      "grad_norm": 0.703731119632721,
      "learning_rate": 3.08953488372093e-05,
      "loss": 0.0062,
      "step": 4929
    },
    {
      "epoch": 19.108527131782946,
      "grad_norm": 0.002631867304444313,
      "learning_rate": 3.0891472868217056e-05,
      "loss": 0.0002,
      "step": 4930
    },
    {
      "epoch": 19.112403100775193,
      "grad_norm": 11.62867259979248,
      "learning_rate": 3.088759689922481e-05,
      "loss": 0.0586,
      "step": 4931
    },
    {
      "epoch": 19.11627906976744,
      "grad_norm": 0.004029464442282915,
      "learning_rate": 3.0883720930232554e-05,
      "loss": 0.0003,
      "step": 4932
    },
    {
      "epoch": 19.12015503875969,
      "grad_norm": 0.0029451395384967327,
      "learning_rate": 3.087984496124031e-05,
      "loss": 0.0002,
      "step": 4933
    },
    {
      "epoch": 19.124031007751938,
      "grad_norm": 0.0023611444048583508,
      "learning_rate": 3.087596899224806e-05,
      "loss": 0.0002,
      "step": 4934
    },
    {
      "epoch": 19.127906976744185,
      "grad_norm": 0.0018281786469742656,
      "learning_rate": 3.087209302325582e-05,
      "loss": 0.0002,
      "step": 4935
    },
    {
      "epoch": 19.131782945736433,
      "grad_norm": 0.1262769103050232,
      "learning_rate": 3.086821705426356e-05,
      "loss": 0.0021,
      "step": 4936
    },
    {
      "epoch": 19.135658914728683,
      "grad_norm": 0.009307565167546272,
      "learning_rate": 3.086434108527132e-05,
      "loss": 0.0004,
      "step": 4937
    },
    {
      "epoch": 19.13953488372093,
      "grad_norm": 0.0019368291832506657,
      "learning_rate": 3.086046511627907e-05,
      "loss": 0.0002,
      "step": 4938
    },
    {
      "epoch": 19.143410852713178,
      "grad_norm": 0.0024092465173453093,
      "learning_rate": 3.085658914728683e-05,
      "loss": 0.0002,
      "step": 4939
    },
    {
      "epoch": 19.147286821705425,
      "grad_norm": 0.0023450918961316347,
      "learning_rate": 3.085271317829457e-05,
      "loss": 0.0002,
      "step": 4940
    },
    {
      "epoch": 19.151162790697676,
      "grad_norm": 0.0028854631818830967,
      "learning_rate": 3.0848837209302325e-05,
      "loss": 0.0002,
      "step": 4941
    },
    {
      "epoch": 19.155038759689923,
      "grad_norm": 0.022518595680594444,
      "learning_rate": 3.084496124031008e-05,
      "loss": 0.001,
      "step": 4942
    },
    {
      "epoch": 19.15891472868217,
      "grad_norm": 0.0028258778620511293,
      "learning_rate": 3.084108527131783e-05,
      "loss": 0.0002,
      "step": 4943
    },
    {
      "epoch": 19.162790697674417,
      "grad_norm": 0.0020777571480721235,
      "learning_rate": 3.083720930232558e-05,
      "loss": 0.0002,
      "step": 4944
    },
    {
      "epoch": 19.166666666666668,
      "grad_norm": 0.14572076499462128,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 0.0018,
      "step": 4945
    },
    {
      "epoch": 19.170542635658915,
      "grad_norm": 0.009640020318329334,
      "learning_rate": 3.082945736434109e-05,
      "loss": 0.0004,
      "step": 4946
    },
    {
      "epoch": 19.174418604651162,
      "grad_norm": 0.00396072119474411,
      "learning_rate": 3.082558139534884e-05,
      "loss": 0.0002,
      "step": 4947
    },
    {
      "epoch": 19.17829457364341,
      "grad_norm": 0.0025252592749893665,
      "learning_rate": 3.082170542635659e-05,
      "loss": 0.0002,
      "step": 4948
    },
    {
      "epoch": 19.18217054263566,
      "grad_norm": 0.002149782842025161,
      "learning_rate": 3.0817829457364345e-05,
      "loss": 0.0002,
      "step": 4949
    },
    {
      "epoch": 19.186046511627907,
      "grad_norm": 80.63165283203125,
      "learning_rate": 3.081395348837209e-05,
      "loss": 0.2119,
      "step": 4950
    },
    {
      "epoch": 19.189922480620154,
      "grad_norm": 0.0024746882263571024,
      "learning_rate": 3.081007751937985e-05,
      "loss": 0.0002,
      "step": 4951
    },
    {
      "epoch": 19.1937984496124,
      "grad_norm": 0.0050916834734380245,
      "learning_rate": 3.0806201550387595e-05,
      "loss": 0.0003,
      "step": 4952
    },
    {
      "epoch": 19.197674418604652,
      "grad_norm": 1.2076243162155151,
      "learning_rate": 3.0802325581395355e-05,
      "loss": 0.0067,
      "step": 4953
    },
    {
      "epoch": 19.2015503875969,
      "grad_norm": 0.002684561535716057,
      "learning_rate": 3.07984496124031e-05,
      "loss": 0.0002,
      "step": 4954
    },
    {
      "epoch": 19.205426356589147,
      "grad_norm": 0.0016885548830032349,
      "learning_rate": 3.079457364341086e-05,
      "loss": 0.0002,
      "step": 4955
    },
    {
      "epoch": 19.209302325581394,
      "grad_norm": 0.0019692389760166407,
      "learning_rate": 3.0790697674418605e-05,
      "loss": 0.0002,
      "step": 4956
    },
    {
      "epoch": 19.213178294573645,
      "grad_norm": 0.004156516399234533,
      "learning_rate": 3.078682170542636e-05,
      "loss": 0.0004,
      "step": 4957
    },
    {
      "epoch": 19.217054263565892,
      "grad_norm": 0.0024937433190643787,
      "learning_rate": 3.078294573643411e-05,
      "loss": 0.0002,
      "step": 4958
    },
    {
      "epoch": 19.22093023255814,
      "grad_norm": 0.005133600905537605,
      "learning_rate": 3.077906976744186e-05,
      "loss": 0.0004,
      "step": 4959
    },
    {
      "epoch": 19.224806201550386,
      "grad_norm": 0.004165151156485081,
      "learning_rate": 3.0775193798449615e-05,
      "loss": 0.0003,
      "step": 4960
    },
    {
      "epoch": 19.228682170542637,
      "grad_norm": 3.9898951053619385,
      "learning_rate": 3.077131782945736e-05,
      "loss": 0.1251,
      "step": 4961
    },
    {
      "epoch": 19.232558139534884,
      "grad_norm": 0.01474460307508707,
      "learning_rate": 3.076744186046512e-05,
      "loss": 0.0007,
      "step": 4962
    },
    {
      "epoch": 19.23643410852713,
      "grad_norm": 0.011865014210343361,
      "learning_rate": 3.0763565891472865e-05,
      "loss": 0.0006,
      "step": 4963
    },
    {
      "epoch": 19.24031007751938,
      "grad_norm": 2.669940233230591,
      "learning_rate": 3.0759689922480624e-05,
      "loss": 0.0025,
      "step": 4964
    },
    {
      "epoch": 19.24418604651163,
      "grad_norm": 0.003397113410755992,
      "learning_rate": 3.075581395348837e-05,
      "loss": 0.0002,
      "step": 4965
    },
    {
      "epoch": 19.248062015503876,
      "grad_norm": 0.19153043627738953,
      "learning_rate": 3.075193798449613e-05,
      "loss": 0.002,
      "step": 4966
    },
    {
      "epoch": 19.251937984496124,
      "grad_norm": 0.07039368152618408,
      "learning_rate": 3.0748062015503875e-05,
      "loss": 0.001,
      "step": 4967
    },
    {
      "epoch": 19.25581395348837,
      "grad_norm": 0.0018230641726404428,
      "learning_rate": 3.074418604651163e-05,
      "loss": 0.0002,
      "step": 4968
    },
    {
      "epoch": 19.25968992248062,
      "grad_norm": 0.003193170763552189,
      "learning_rate": 3.074031007751938e-05,
      "loss": 0.0002,
      "step": 4969
    },
    {
      "epoch": 19.26356589147287,
      "grad_norm": 3.3506760597229004,
      "learning_rate": 3.073643410852713e-05,
      "loss": 0.5238,
      "step": 4970
    },
    {
      "epoch": 19.267441860465116,
      "grad_norm": 0.002565933857113123,
      "learning_rate": 3.0732558139534885e-05,
      "loss": 0.0002,
      "step": 4971
    },
    {
      "epoch": 19.271317829457363,
      "grad_norm": 0.053186871111392975,
      "learning_rate": 3.072868217054264e-05,
      "loss": 0.0021,
      "step": 4972
    },
    {
      "epoch": 19.275193798449614,
      "grad_norm": 0.006288446020334959,
      "learning_rate": 3.072480620155039e-05,
      "loss": 0.0004,
      "step": 4973
    },
    {
      "epoch": 19.27906976744186,
      "grad_norm": 5.098240375518799,
      "learning_rate": 3.072093023255814e-05,
      "loss": 0.189,
      "step": 4974
    },
    {
      "epoch": 19.282945736434108,
      "grad_norm": 0.0025125492829829454,
      "learning_rate": 3.0717054263565894e-05,
      "loss": 0.0002,
      "step": 4975
    },
    {
      "epoch": 19.286821705426355,
      "grad_norm": 0.035635657608509064,
      "learning_rate": 3.071317829457365e-05,
      "loss": 0.0015,
      "step": 4976
    },
    {
      "epoch": 19.290697674418606,
      "grad_norm": 0.06683014333248138,
      "learning_rate": 3.07093023255814e-05,
      "loss": 0.0023,
      "step": 4977
    },
    {
      "epoch": 19.294573643410853,
      "grad_norm": 0.0018607585225254297,
      "learning_rate": 3.070542635658915e-05,
      "loss": 0.0002,
      "step": 4978
    },
    {
      "epoch": 19.2984496124031,
      "grad_norm": 4.651393890380859,
      "learning_rate": 3.07015503875969e-05,
      "loss": 0.3614,
      "step": 4979
    },
    {
      "epoch": 19.302325581395348,
      "grad_norm": 5.155574321746826,
      "learning_rate": 3.0697674418604656e-05,
      "loss": 0.3917,
      "step": 4980
    },
    {
      "epoch": 19.3062015503876,
      "grad_norm": 12.857260704040527,
      "learning_rate": 3.06937984496124e-05,
      "loss": 0.0884,
      "step": 4981
    },
    {
      "epoch": 19.310077519379846,
      "grad_norm": 2.3762047290802,
      "learning_rate": 3.068992248062016e-05,
      "loss": 0.3448,
      "step": 4982
    },
    {
      "epoch": 19.313953488372093,
      "grad_norm": 0.01957639306783676,
      "learning_rate": 3.068604651162791e-05,
      "loss": 0.0009,
      "step": 4983
    },
    {
      "epoch": 19.31782945736434,
      "grad_norm": 31.713407516479492,
      "learning_rate": 3.0682170542635666e-05,
      "loss": 0.4717,
      "step": 4984
    },
    {
      "epoch": 19.32170542635659,
      "grad_norm": 0.006493518128991127,
      "learning_rate": 3.067829457364341e-05,
      "loss": 0.0003,
      "step": 4985
    },
    {
      "epoch": 19.325581395348838,
      "grad_norm": 0.002427841769531369,
      "learning_rate": 3.0674418604651164e-05,
      "loss": 0.0002,
      "step": 4986
    },
    {
      "epoch": 19.329457364341085,
      "grad_norm": 0.013339086435735226,
      "learning_rate": 3.0670542635658917e-05,
      "loss": 0.0003,
      "step": 4987
    },
    {
      "epoch": 19.333333333333332,
      "grad_norm": 0.0036242555361241102,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.0002,
      "step": 4988
    },
    {
      "epoch": 19.337209302325583,
      "grad_norm": 0.012741204351186752,
      "learning_rate": 3.066279069767442e-05,
      "loss": 0.0007,
      "step": 4989
    },
    {
      "epoch": 19.34108527131783,
      "grad_norm": 0.014653317630290985,
      "learning_rate": 3.065891472868217e-05,
      "loss": 0.0007,
      "step": 4990
    },
    {
      "epoch": 19.344961240310077,
      "grad_norm": 12.301634788513184,
      "learning_rate": 3.0655038759689926e-05,
      "loss": 0.1254,
      "step": 4991
    },
    {
      "epoch": 19.348837209302324,
      "grad_norm": 0.0038995323702692986,
      "learning_rate": 3.065116279069767e-05,
      "loss": 0.0003,
      "step": 4992
    },
    {
      "epoch": 19.352713178294575,
      "grad_norm": 0.008308702148497105,
      "learning_rate": 3.064728682170543e-05,
      "loss": 0.0003,
      "step": 4993
    },
    {
      "epoch": 19.356589147286822,
      "grad_norm": 0.004047590773552656,
      "learning_rate": 3.064341085271318e-05,
      "loss": 0.0003,
      "step": 4994
    },
    {
      "epoch": 19.36046511627907,
      "grad_norm": 0.002404535887762904,
      "learning_rate": 3.0639534883720936e-05,
      "loss": 0.0002,
      "step": 4995
    },
    {
      "epoch": 19.364341085271317,
      "grad_norm": 0.003365755081176758,
      "learning_rate": 3.063565891472868e-05,
      "loss": 0.0003,
      "step": 4996
    },
    {
      "epoch": 19.368217054263567,
      "grad_norm": 0.04553922638297081,
      "learning_rate": 3.0631782945736434e-05,
      "loss": 0.0018,
      "step": 4997
    },
    {
      "epoch": 19.372093023255815,
      "grad_norm": 0.022469066083431244,
      "learning_rate": 3.0627906976744186e-05,
      "loss": 0.001,
      "step": 4998
    },
    {
      "epoch": 19.375968992248062,
      "grad_norm": 0.04044147953391075,
      "learning_rate": 3.062403100775194e-05,
      "loss": 0.0014,
      "step": 4999
    },
    {
      "epoch": 19.37984496124031,
      "grad_norm": 2.0189318656921387,
      "learning_rate": 3.062015503875969e-05,
      "loss": 0.0933,
      "step": 5000
    },
    {
      "epoch": 19.38372093023256,
      "grad_norm": 0.0042803590185940266,
      "learning_rate": 3.0616279069767444e-05,
      "loss": 0.0003,
      "step": 5001
    },
    {
      "epoch": 19.387596899224807,
      "grad_norm": 16.426769256591797,
      "learning_rate": 3.0612403100775196e-05,
      "loss": 0.2905,
      "step": 5002
    },
    {
      "epoch": 19.391472868217054,
      "grad_norm": 5.949873924255371,
      "learning_rate": 3.060852713178295e-05,
      "loss": 0.0165,
      "step": 5003
    },
    {
      "epoch": 19.3953488372093,
      "grad_norm": 0.009457604959607124,
      "learning_rate": 3.06046511627907e-05,
      "loss": 0.0003,
      "step": 5004
    },
    {
      "epoch": 19.399224806201552,
      "grad_norm": 0.22930492460727692,
      "learning_rate": 3.060077519379845e-05,
      "loss": 0.0053,
      "step": 5005
    },
    {
      "epoch": 19.4031007751938,
      "grad_norm": 0.014980880543589592,
      "learning_rate": 3.0596899224806206e-05,
      "loss": 0.0003,
      "step": 5006
    },
    {
      "epoch": 19.406976744186046,
      "grad_norm": 0.06248452141880989,
      "learning_rate": 3.059302325581396e-05,
      "loss": 0.0005,
      "step": 5007
    },
    {
      "epoch": 19.410852713178294,
      "grad_norm": 0.08619579672813416,
      "learning_rate": 3.0589147286821704e-05,
      "loss": 0.0035,
      "step": 5008
    },
    {
      "epoch": 19.414728682170544,
      "grad_norm": 0.049256645143032074,
      "learning_rate": 3.058527131782946e-05,
      "loss": 0.0018,
      "step": 5009
    },
    {
      "epoch": 19.41860465116279,
      "grad_norm": 5.7989983558654785,
      "learning_rate": 3.058139534883721e-05,
      "loss": 0.0666,
      "step": 5010
    },
    {
      "epoch": 19.42248062015504,
      "grad_norm": 0.01000246498733759,
      "learning_rate": 3.057751937984496e-05,
      "loss": 0.0003,
      "step": 5011
    },
    {
      "epoch": 19.426356589147286,
      "grad_norm": 0.002823208225890994,
      "learning_rate": 3.0573643410852714e-05,
      "loss": 0.0002,
      "step": 5012
    },
    {
      "epoch": 19.430232558139537,
      "grad_norm": 0.0025483472272753716,
      "learning_rate": 3.0569767441860466e-05,
      "loss": 0.0002,
      "step": 5013
    },
    {
      "epoch": 19.434108527131784,
      "grad_norm": 0.004264818970113993,
      "learning_rate": 3.056589147286822e-05,
      "loss": 0.0002,
      "step": 5014
    },
    {
      "epoch": 19.43798449612403,
      "grad_norm": 0.010883510112762451,
      "learning_rate": 3.056201550387597e-05,
      "loss": 0.0003,
      "step": 5015
    },
    {
      "epoch": 19.441860465116278,
      "grad_norm": 0.8634135723114014,
      "learning_rate": 3.055813953488372e-05,
      "loss": 0.0094,
      "step": 5016
    },
    {
      "epoch": 19.44573643410853,
      "grad_norm": 0.003242997918277979,
      "learning_rate": 3.055426356589147e-05,
      "loss": 0.0002,
      "step": 5017
    },
    {
      "epoch": 19.449612403100776,
      "grad_norm": 0.531163215637207,
      "learning_rate": 3.055038759689923e-05,
      "loss": 0.0117,
      "step": 5018
    },
    {
      "epoch": 19.453488372093023,
      "grad_norm": 0.00424965238198638,
      "learning_rate": 3.0546511627906974e-05,
      "loss": 0.0002,
      "step": 5019
    },
    {
      "epoch": 19.45736434108527,
      "grad_norm": 0.4437871277332306,
      "learning_rate": 3.054263565891473e-05,
      "loss": 0.0178,
      "step": 5020
    },
    {
      "epoch": 19.46124031007752,
      "grad_norm": 0.003382559632882476,
      "learning_rate": 3.053875968992248e-05,
      "loss": 0.0002,
      "step": 5021
    },
    {
      "epoch": 19.46511627906977,
      "grad_norm": 0.012784533202648163,
      "learning_rate": 3.053488372093024e-05,
      "loss": 0.0007,
      "step": 5022
    },
    {
      "epoch": 19.468992248062015,
      "grad_norm": 0.003127861302345991,
      "learning_rate": 3.053100775193798e-05,
      "loss": 0.0002,
      "step": 5023
    },
    {
      "epoch": 19.472868217054263,
      "grad_norm": 0.0069403559900820255,
      "learning_rate": 3.052713178294574e-05,
      "loss": 0.0004,
      "step": 5024
    },
    {
      "epoch": 19.476744186046513,
      "grad_norm": 9.31005859375,
      "learning_rate": 3.052325581395349e-05,
      "loss": 0.6641,
      "step": 5025
    },
    {
      "epoch": 19.48062015503876,
      "grad_norm": 0.003176214871928096,
      "learning_rate": 3.051937984496124e-05,
      "loss": 0.0003,
      "step": 5026
    },
    {
      "epoch": 19.484496124031008,
      "grad_norm": 0.003498934442177415,
      "learning_rate": 3.0515503875968993e-05,
      "loss": 0.0002,
      "step": 5027
    },
    {
      "epoch": 19.488372093023255,
      "grad_norm": 18.78564453125,
      "learning_rate": 3.051162790697675e-05,
      "loss": 1.8334,
      "step": 5028
    },
    {
      "epoch": 19.492248062015506,
      "grad_norm": 0.002091494854539633,
      "learning_rate": 3.0507751937984498e-05,
      "loss": 0.0002,
      "step": 5029
    },
    {
      "epoch": 19.496124031007753,
      "grad_norm": 9.910977363586426,
      "learning_rate": 3.050387596899225e-05,
      "loss": 0.284,
      "step": 5030
    },
    {
      "epoch": 19.5,
      "grad_norm": 8.051811218261719,
      "learning_rate": 3.05e-05,
      "loss": 0.7657,
      "step": 5031
    },
    {
      "epoch": 19.503875968992247,
      "grad_norm": 10.825676918029785,
      "learning_rate": 3.0496124031007755e-05,
      "loss": 0.007,
      "step": 5032
    },
    {
      "epoch": 19.507751937984494,
      "grad_norm": 0.002781094517558813,
      "learning_rate": 3.0492248062015504e-05,
      "loss": 0.0002,
      "step": 5033
    },
    {
      "epoch": 19.511627906976745,
      "grad_norm": 0.001850888947956264,
      "learning_rate": 3.048837209302326e-05,
      "loss": 0.0002,
      "step": 5034
    },
    {
      "epoch": 19.515503875968992,
      "grad_norm": 3.9522457122802734,
      "learning_rate": 3.048449612403101e-05,
      "loss": 0.0068,
      "step": 5035
    },
    {
      "epoch": 19.51937984496124,
      "grad_norm": 0.3514060974121094,
      "learning_rate": 3.0480620155038765e-05,
      "loss": 0.0011,
      "step": 5036
    },
    {
      "epoch": 19.52325581395349,
      "grad_norm": 0.18777842819690704,
      "learning_rate": 3.0476744186046514e-05,
      "loss": 0.0054,
      "step": 5037
    },
    {
      "epoch": 19.527131782945737,
      "grad_norm": 0.006638884544372559,
      "learning_rate": 3.0472868217054263e-05,
      "loss": 0.0003,
      "step": 5038
    },
    {
      "epoch": 19.531007751937985,
      "grad_norm": 0.006014314945787191,
      "learning_rate": 3.046899224806202e-05,
      "loss": 0.0003,
      "step": 5039
    },
    {
      "epoch": 19.53488372093023,
      "grad_norm": 0.06800970435142517,
      "learning_rate": 3.0465116279069768e-05,
      "loss": 0.0015,
      "step": 5040
    },
    {
      "epoch": 19.53875968992248,
      "grad_norm": 6.083119869232178,
      "learning_rate": 3.046124031007752e-05,
      "loss": 0.3206,
      "step": 5041
    },
    {
      "epoch": 19.54263565891473,
      "grad_norm": 0.008064967580139637,
      "learning_rate": 3.045736434108527e-05,
      "loss": 0.0005,
      "step": 5042
    },
    {
      "epoch": 19.546511627906977,
      "grad_norm": 0.002515935804694891,
      "learning_rate": 3.0453488372093025e-05,
      "loss": 0.0002,
      "step": 5043
    },
    {
      "epoch": 19.550387596899224,
      "grad_norm": 0.0028321535792201757,
      "learning_rate": 3.0449612403100774e-05,
      "loss": 0.0002,
      "step": 5044
    },
    {
      "epoch": 19.55426356589147,
      "grad_norm": 1.757545828819275,
      "learning_rate": 3.044573643410853e-05,
      "loss": 0.1715,
      "step": 5045
    },
    {
      "epoch": 19.558139534883722,
      "grad_norm": 0.07575272023677826,
      "learning_rate": 3.044186046511628e-05,
      "loss": 0.0032,
      "step": 5046
    },
    {
      "epoch": 19.56201550387597,
      "grad_norm": 0.12476133555173874,
      "learning_rate": 3.0437984496124035e-05,
      "loss": 0.0026,
      "step": 5047
    },
    {
      "epoch": 19.565891472868216,
      "grad_norm": 0.024330833926796913,
      "learning_rate": 3.0434108527131784e-05,
      "loss": 0.0005,
      "step": 5048
    },
    {
      "epoch": 19.569767441860463,
      "grad_norm": 0.003131697652861476,
      "learning_rate": 3.0430232558139536e-05,
      "loss": 0.0002,
      "step": 5049
    },
    {
      "epoch": 19.573643410852714,
      "grad_norm": 0.3586724102497101,
      "learning_rate": 3.0426356589147285e-05,
      "loss": 0.0069,
      "step": 5050
    },
    {
      "epoch": 19.57751937984496,
      "grad_norm": 0.3737718164920807,
      "learning_rate": 3.042248062015504e-05,
      "loss": 0.0117,
      "step": 5051
    },
    {
      "epoch": 19.58139534883721,
      "grad_norm": 0.3384931981563568,
      "learning_rate": 3.041860465116279e-05,
      "loss": 0.0101,
      "step": 5052
    },
    {
      "epoch": 19.585271317829456,
      "grad_norm": 0.22233186662197113,
      "learning_rate": 3.0414728682170546e-05,
      "loss": 0.0054,
      "step": 5053
    },
    {
      "epoch": 19.589147286821706,
      "grad_norm": 0.1135224923491478,
      "learning_rate": 3.0410852713178295e-05,
      "loss": 0.0028,
      "step": 5054
    },
    {
      "epoch": 19.593023255813954,
      "grad_norm": 0.4972722828388214,
      "learning_rate": 3.040697674418605e-05,
      "loss": 0.0005,
      "step": 5055
    },
    {
      "epoch": 19.5968992248062,
      "grad_norm": 0.05199987441301346,
      "learning_rate": 3.04031007751938e-05,
      "loss": 0.0015,
      "step": 5056
    },
    {
      "epoch": 19.600775193798448,
      "grad_norm": 0.2218945473432541,
      "learning_rate": 3.0399224806201556e-05,
      "loss": 0.0052,
      "step": 5057
    },
    {
      "epoch": 19.6046511627907,
      "grad_norm": 0.03126179054379463,
      "learning_rate": 3.0395348837209305e-05,
      "loss": 0.0011,
      "step": 5058
    },
    {
      "epoch": 19.608527131782946,
      "grad_norm": 0.03226175531744957,
      "learning_rate": 3.0391472868217057e-05,
      "loss": 0.001,
      "step": 5059
    },
    {
      "epoch": 19.612403100775193,
      "grad_norm": 0.023379169404506683,
      "learning_rate": 3.0387596899224806e-05,
      "loss": 0.0007,
      "step": 5060
    },
    {
      "epoch": 19.61627906976744,
      "grad_norm": 0.16319045424461365,
      "learning_rate": 3.0383720930232562e-05,
      "loss": 0.0046,
      "step": 5061
    },
    {
      "epoch": 19.62015503875969,
      "grad_norm": 0.01097860373556614,
      "learning_rate": 3.037984496124031e-05,
      "loss": 0.0005,
      "step": 5062
    },
    {
      "epoch": 19.624031007751938,
      "grad_norm": 0.021014278754591942,
      "learning_rate": 3.0375968992248067e-05,
      "loss": 0.0011,
      "step": 5063
    },
    {
      "epoch": 19.627906976744185,
      "grad_norm": 0.05262831225991249,
      "learning_rate": 3.0372093023255816e-05,
      "loss": 0.0011,
      "step": 5064
    },
    {
      "epoch": 19.631782945736433,
      "grad_norm": 0.005214155651628971,
      "learning_rate": 3.0368217054263565e-05,
      "loss": 0.0003,
      "step": 5065
    },
    {
      "epoch": 19.635658914728683,
      "grad_norm": 0.003951170947402716,
      "learning_rate": 3.036434108527132e-05,
      "loss": 0.0003,
      "step": 5066
    },
    {
      "epoch": 19.63953488372093,
      "grad_norm": 0.019677164033055305,
      "learning_rate": 3.036046511627907e-05,
      "loss": 0.0004,
      "step": 5067
    },
    {
      "epoch": 19.643410852713178,
      "grad_norm": 0.005096342880278826,
      "learning_rate": 3.0356589147286822e-05,
      "loss": 0.0004,
      "step": 5068
    },
    {
      "epoch": 19.647286821705425,
      "grad_norm": 0.005193290300667286,
      "learning_rate": 3.0352713178294574e-05,
      "loss": 0.0003,
      "step": 5069
    },
    {
      "epoch": 19.651162790697676,
      "grad_norm": 0.004647374618798494,
      "learning_rate": 3.0348837209302327e-05,
      "loss": 0.0003,
      "step": 5070
    },
    {
      "epoch": 19.655038759689923,
      "grad_norm": 0.005153956823050976,
      "learning_rate": 3.0344961240310076e-05,
      "loss": 0.0003,
      "step": 5071
    },
    {
      "epoch": 19.65891472868217,
      "grad_norm": 0.1491600126028061,
      "learning_rate": 3.0341085271317832e-05,
      "loss": 0.0027,
      "step": 5072
    },
    {
      "epoch": 19.662790697674417,
      "grad_norm": 0.002462801756337285,
      "learning_rate": 3.033720930232558e-05,
      "loss": 0.0002,
      "step": 5073
    },
    {
      "epoch": 19.666666666666668,
      "grad_norm": 0.0037891785614192486,
      "learning_rate": 3.0333333333333337e-05,
      "loss": 0.0002,
      "step": 5074
    },
    {
      "epoch": 19.670542635658915,
      "grad_norm": 0.003275773487985134,
      "learning_rate": 3.0329457364341086e-05,
      "loss": 0.0003,
      "step": 5075
    },
    {
      "epoch": 19.674418604651162,
      "grad_norm": 3.8376224040985107,
      "learning_rate": 3.032558139534884e-05,
      "loss": 0.2282,
      "step": 5076
    },
    {
      "epoch": 19.67829457364341,
      "grad_norm": 2.7415177822113037,
      "learning_rate": 3.032170542635659e-05,
      "loss": 0.0482,
      "step": 5077
    },
    {
      "epoch": 19.68217054263566,
      "grad_norm": 0.0018184214131906629,
      "learning_rate": 3.0317829457364343e-05,
      "loss": 0.0002,
      "step": 5078
    },
    {
      "epoch": 19.686046511627907,
      "grad_norm": 0.0023080026730895042,
      "learning_rate": 3.0313953488372092e-05,
      "loss": 0.0002,
      "step": 5079
    },
    {
      "epoch": 19.689922480620154,
      "grad_norm": 0.0021722128149122,
      "learning_rate": 3.0310077519379848e-05,
      "loss": 0.0002,
      "step": 5080
    },
    {
      "epoch": 19.6937984496124,
      "grad_norm": 0.004685989581048489,
      "learning_rate": 3.0306201550387597e-05,
      "loss": 0.0002,
      "step": 5081
    },
    {
      "epoch": 19.697674418604652,
      "grad_norm": 0.45234444737434387,
      "learning_rate": 3.0302325581395353e-05,
      "loss": 0.02,
      "step": 5082
    },
    {
      "epoch": 19.7015503875969,
      "grad_norm": 0.0937974825501442,
      "learning_rate": 3.02984496124031e-05,
      "loss": 0.0003,
      "step": 5083
    },
    {
      "epoch": 19.705426356589147,
      "grad_norm": 0.006782536394894123,
      "learning_rate": 3.0294573643410857e-05,
      "loss": 0.0005,
      "step": 5084
    },
    {
      "epoch": 19.709302325581394,
      "grad_norm": 0.001953790197148919,
      "learning_rate": 3.0290697674418606e-05,
      "loss": 0.0002,
      "step": 5085
    },
    {
      "epoch": 19.713178294573645,
      "grad_norm": 0.0027337518986314535,
      "learning_rate": 3.028682170542636e-05,
      "loss": 0.0002,
      "step": 5086
    },
    {
      "epoch": 19.717054263565892,
      "grad_norm": 0.005345944315195084,
      "learning_rate": 3.028294573643411e-05,
      "loss": 0.0004,
      "step": 5087
    },
    {
      "epoch": 19.72093023255814,
      "grad_norm": 0.002088473876938224,
      "learning_rate": 3.0279069767441864e-05,
      "loss": 0.0002,
      "step": 5088
    },
    {
      "epoch": 19.724806201550386,
      "grad_norm": 0.0021067396737635136,
      "learning_rate": 3.0275193798449613e-05,
      "loss": 0.0002,
      "step": 5089
    },
    {
      "epoch": 19.728682170542637,
      "grad_norm": 0.0023256614804267883,
      "learning_rate": 3.027131782945737e-05,
      "loss": 0.0002,
      "step": 5090
    },
    {
      "epoch": 19.732558139534884,
      "grad_norm": 2.159485340118408,
      "learning_rate": 3.0267441860465118e-05,
      "loss": 0.1068,
      "step": 5091
    },
    {
      "epoch": 19.73643410852713,
      "grad_norm": 0.0020140912383794785,
      "learning_rate": 3.0263565891472867e-05,
      "loss": 0.0002,
      "step": 5092
    },
    {
      "epoch": 19.74031007751938,
      "grad_norm": 0.0032731418032199144,
      "learning_rate": 3.0259689922480622e-05,
      "loss": 0.0003,
      "step": 5093
    },
    {
      "epoch": 19.74418604651163,
      "grad_norm": 0.04705286771059036,
      "learning_rate": 3.025581395348837e-05,
      "loss": 0.0013,
      "step": 5094
    },
    {
      "epoch": 19.748062015503876,
      "grad_norm": 0.0101392213255167,
      "learning_rate": 3.0251937984496127e-05,
      "loss": 0.0008,
      "step": 5095
    },
    {
      "epoch": 19.751937984496124,
      "grad_norm": 0.21855226159095764,
      "learning_rate": 3.0248062015503876e-05,
      "loss": 0.0097,
      "step": 5096
    },
    {
      "epoch": 19.75581395348837,
      "grad_norm": 0.010492351837456226,
      "learning_rate": 3.024418604651163e-05,
      "loss": 0.0007,
      "step": 5097
    },
    {
      "epoch": 19.75968992248062,
      "grad_norm": 0.02108212560415268,
      "learning_rate": 3.0240310077519378e-05,
      "loss": 0.0008,
      "step": 5098
    },
    {
      "epoch": 19.76356589147287,
      "grad_norm": 0.007436396088451147,
      "learning_rate": 3.0236434108527134e-05,
      "loss": 0.0004,
      "step": 5099
    },
    {
      "epoch": 19.767441860465116,
      "grad_norm": 0.0020185227040201426,
      "learning_rate": 3.0232558139534883e-05,
      "loss": 0.0002,
      "step": 5100
    },
    {
      "epoch": 19.771317829457363,
      "grad_norm": 0.036769017577171326,
      "learning_rate": 3.022868217054264e-05,
      "loss": 0.0011,
      "step": 5101
    },
    {
      "epoch": 19.775193798449614,
      "grad_norm": 0.010290250182151794,
      "learning_rate": 3.0224806201550387e-05,
      "loss": 0.0006,
      "step": 5102
    },
    {
      "epoch": 19.77906976744186,
      "grad_norm": 0.0027433240320533514,
      "learning_rate": 3.0220930232558143e-05,
      "loss": 0.0002,
      "step": 5103
    },
    {
      "epoch": 19.782945736434108,
      "grad_norm": 0.0022843244951218367,
      "learning_rate": 3.0217054263565892e-05,
      "loss": 0.0002,
      "step": 5104
    },
    {
      "epoch": 19.786821705426355,
      "grad_norm": 0.002248017117381096,
      "learning_rate": 3.0213178294573645e-05,
      "loss": 0.0002,
      "step": 5105
    },
    {
      "epoch": 19.790697674418606,
      "grad_norm": 1.3911689519882202,
      "learning_rate": 3.0209302325581397e-05,
      "loss": 0.1621,
      "step": 5106
    },
    {
      "epoch": 19.794573643410853,
      "grad_norm": 0.0019923998042941093,
      "learning_rate": 3.020542635658915e-05,
      "loss": 0.0002,
      "step": 5107
    },
    {
      "epoch": 19.7984496124031,
      "grad_norm": 0.003004904370754957,
      "learning_rate": 3.02015503875969e-05,
      "loss": 0.0003,
      "step": 5108
    },
    {
      "epoch": 19.802325581395348,
      "grad_norm": 2.3513243198394775,
      "learning_rate": 3.0197674418604654e-05,
      "loss": 0.094,
      "step": 5109
    },
    {
      "epoch": 19.8062015503876,
      "grad_norm": 0.0037643287796527147,
      "learning_rate": 3.0193798449612403e-05,
      "loss": 0.0003,
      "step": 5110
    },
    {
      "epoch": 19.810077519379846,
      "grad_norm": 0.015737878158688545,
      "learning_rate": 3.018992248062016e-05,
      "loss": 0.0005,
      "step": 5111
    },
    {
      "epoch": 19.813953488372093,
      "grad_norm": 5.535243034362793,
      "learning_rate": 3.0186046511627908e-05,
      "loss": 0.5359,
      "step": 5112
    },
    {
      "epoch": 19.81782945736434,
      "grad_norm": 0.006552993785589933,
      "learning_rate": 3.0182170542635664e-05,
      "loss": 0.0005,
      "step": 5113
    },
    {
      "epoch": 19.82170542635659,
      "grad_norm": 5.381101608276367,
      "learning_rate": 3.0178294573643413e-05,
      "loss": 0.4145,
      "step": 5114
    },
    {
      "epoch": 19.825581395348838,
      "grad_norm": 30.71687889099121,
      "learning_rate": 3.0174418604651166e-05,
      "loss": 0.4149,
      "step": 5115
    },
    {
      "epoch": 19.829457364341085,
      "grad_norm": 0.014705904759466648,
      "learning_rate": 3.0170542635658915e-05,
      "loss": 0.001,
      "step": 5116
    },
    {
      "epoch": 19.833333333333332,
      "grad_norm": 0.004118763841688633,
      "learning_rate": 3.016666666666667e-05,
      "loss": 0.0002,
      "step": 5117
    },
    {
      "epoch": 19.837209302325583,
      "grad_norm": 0.0693139061331749,
      "learning_rate": 3.016279069767442e-05,
      "loss": 0.0018,
      "step": 5118
    },
    {
      "epoch": 19.84108527131783,
      "grad_norm": 0.0026762690395116806,
      "learning_rate": 3.015891472868217e-05,
      "loss": 0.0002,
      "step": 5119
    },
    {
      "epoch": 19.844961240310077,
      "grad_norm": 0.003819380421191454,
      "learning_rate": 3.0155038759689924e-05,
      "loss": 0.0003,
      "step": 5120
    },
    {
      "epoch": 19.848837209302324,
      "grad_norm": 0.0026320242322981358,
      "learning_rate": 3.0151162790697673e-05,
      "loss": 0.0002,
      "step": 5121
    },
    {
      "epoch": 19.852713178294575,
      "grad_norm": 0.0033454783260822296,
      "learning_rate": 3.014728682170543e-05,
      "loss": 0.0002,
      "step": 5122
    },
    {
      "epoch": 19.856589147286822,
      "grad_norm": 0.02195925824344158,
      "learning_rate": 3.0143410852713178e-05,
      "loss": 0.0012,
      "step": 5123
    },
    {
      "epoch": 19.86046511627907,
      "grad_norm": 0.006628124974668026,
      "learning_rate": 3.0139534883720934e-05,
      "loss": 0.0003,
      "step": 5124
    },
    {
      "epoch": 19.864341085271317,
      "grad_norm": 0.003460217034444213,
      "learning_rate": 3.0135658914728683e-05,
      "loss": 0.0003,
      "step": 5125
    },
    {
      "epoch": 19.868217054263567,
      "grad_norm": 0.003110739402472973,
      "learning_rate": 3.0131782945736435e-05,
      "loss": 0.0002,
      "step": 5126
    },
    {
      "epoch": 19.872093023255815,
      "grad_norm": 0.00431195879355073,
      "learning_rate": 3.0127906976744184e-05,
      "loss": 0.0004,
      "step": 5127
    },
    {
      "epoch": 19.875968992248062,
      "grad_norm": 0.010218928568065166,
      "learning_rate": 3.012403100775194e-05,
      "loss": 0.0006,
      "step": 5128
    },
    {
      "epoch": 19.87984496124031,
      "grad_norm": 0.024564310908317566,
      "learning_rate": 3.012015503875969e-05,
      "loss": 0.0006,
      "step": 5129
    },
    {
      "epoch": 19.88372093023256,
      "grad_norm": 0.008120225742459297,
      "learning_rate": 3.0116279069767445e-05,
      "loss": 0.0004,
      "step": 5130
    },
    {
      "epoch": 19.887596899224807,
      "grad_norm": 0.151608407497406,
      "learning_rate": 3.0112403100775194e-05,
      "loss": 0.0017,
      "step": 5131
    },
    {
      "epoch": 19.891472868217054,
      "grad_norm": 0.008983735926449299,
      "learning_rate": 3.010852713178295e-05,
      "loss": 0.0004,
      "step": 5132
    },
    {
      "epoch": 19.8953488372093,
      "grad_norm": 0.6282998919487,
      "learning_rate": 3.01046511627907e-05,
      "loss": 0.0168,
      "step": 5133
    },
    {
      "epoch": 19.899224806201552,
      "grad_norm": 0.010242526419460773,
      "learning_rate": 3.010077519379845e-05,
      "loss": 0.0003,
      "step": 5134
    },
    {
      "epoch": 19.9031007751938,
      "grad_norm": 0.003092581406235695,
      "learning_rate": 3.00968992248062e-05,
      "loss": 0.0002,
      "step": 5135
    },
    {
      "epoch": 19.906976744186046,
      "grad_norm": 31.106159210205078,
      "learning_rate": 3.0093023255813956e-05,
      "loss": 0.4008,
      "step": 5136
    },
    {
      "epoch": 19.910852713178294,
      "grad_norm": 0.004618419334292412,
      "learning_rate": 3.0089147286821705e-05,
      "loss": 0.0003,
      "step": 5137
    },
    {
      "epoch": 19.914728682170544,
      "grad_norm": 0.002498179441317916,
      "learning_rate": 3.008527131782946e-05,
      "loss": 0.0002,
      "step": 5138
    },
    {
      "epoch": 19.91860465116279,
      "grad_norm": 0.001932677230797708,
      "learning_rate": 3.008139534883721e-05,
      "loss": 0.0002,
      "step": 5139
    },
    {
      "epoch": 19.92248062015504,
      "grad_norm": 0.017987852916121483,
      "learning_rate": 3.0077519379844966e-05,
      "loss": 0.0003,
      "step": 5140
    },
    {
      "epoch": 19.926356589147286,
      "grad_norm": 0.0026478376239538193,
      "learning_rate": 3.0073643410852715e-05,
      "loss": 0.0002,
      "step": 5141
    },
    {
      "epoch": 19.930232558139537,
      "grad_norm": 2.4349136352539062,
      "learning_rate": 3.006976744186047e-05,
      "loss": 0.1272,
      "step": 5142
    },
    {
      "epoch": 19.934108527131784,
      "grad_norm": 0.0021037126425653696,
      "learning_rate": 3.006589147286822e-05,
      "loss": 0.0002,
      "step": 5143
    },
    {
      "epoch": 19.93798449612403,
      "grad_norm": 0.003288174979388714,
      "learning_rate": 3.0062015503875972e-05,
      "loss": 0.0003,
      "step": 5144
    },
    {
      "epoch": 19.941860465116278,
      "grad_norm": 0.003572267945855856,
      "learning_rate": 3.005813953488372e-05,
      "loss": 0.0003,
      "step": 5145
    },
    {
      "epoch": 19.94573643410853,
      "grad_norm": 0.0022257359232753515,
      "learning_rate": 3.005426356589147e-05,
      "loss": 0.0002,
      "step": 5146
    },
    {
      "epoch": 19.949612403100776,
      "grad_norm": 0.0025144722312688828,
      "learning_rate": 3.0050387596899226e-05,
      "loss": 0.0002,
      "step": 5147
    },
    {
      "epoch": 19.953488372093023,
      "grad_norm": 1.6414093971252441,
      "learning_rate": 3.0046511627906975e-05,
      "loss": 0.1541,
      "step": 5148
    },
    {
      "epoch": 19.95736434108527,
      "grad_norm": 0.10811452567577362,
      "learning_rate": 3.004263565891473e-05,
      "loss": 0.0006,
      "step": 5149
    },
    {
      "epoch": 19.96124031007752,
      "grad_norm": 0.0020551071502268314,
      "learning_rate": 3.003875968992248e-05,
      "loss": 0.0002,
      "step": 5150
    },
    {
      "epoch": 19.96511627906977,
      "grad_norm": 0.0022648985031992197,
      "learning_rate": 3.0034883720930236e-05,
      "loss": 0.0002,
      "step": 5151
    },
    {
      "epoch": 19.968992248062015,
      "grad_norm": 0.049009449779987335,
      "learning_rate": 3.0031007751937985e-05,
      "loss": 0.0004,
      "step": 5152
    },
    {
      "epoch": 19.972868217054263,
      "grad_norm": 0.002686191350221634,
      "learning_rate": 3.0027131782945737e-05,
      "loss": 0.0002,
      "step": 5153
    },
    {
      "epoch": 19.97674418604651,
      "grad_norm": 9.845346450805664,
      "learning_rate": 3.002325581395349e-05,
      "loss": 0.1622,
      "step": 5154
    },
    {
      "epoch": 19.98062015503876,
      "grad_norm": 0.002008408308029175,
      "learning_rate": 3.0019379844961242e-05,
      "loss": 0.0002,
      "step": 5155
    },
    {
      "epoch": 19.984496124031008,
      "grad_norm": 0.013345159590244293,
      "learning_rate": 3.001550387596899e-05,
      "loss": 0.0008,
      "step": 5156
    },
    {
      "epoch": 19.988372093023255,
      "grad_norm": 0.06827260553836823,
      "learning_rate": 3.0011627906976747e-05,
      "loss": 0.0014,
      "step": 5157
    },
    {
      "epoch": 19.992248062015506,
      "grad_norm": 0.008980094455182552,
      "learning_rate": 3.0007751937984496e-05,
      "loss": 0.0005,
      "step": 5158
    },
    {
      "epoch": 19.996124031007753,
      "grad_norm": 0.002254533814266324,
      "learning_rate": 3.0003875968992252e-05,
      "loss": 0.0002,
      "step": 5159
    },
    {
      "epoch": 20.0,
      "grad_norm": 3.509641647338867,
      "learning_rate": 3e-05,
      "loss": 0.3301,
      "step": 5160
    },
    {
      "epoch": 20.003875968992247,
      "grad_norm": 0.001935347798280418,
      "learning_rate": 2.9996124031007757e-05,
      "loss": 0.0002,
      "step": 5161
    },
    {
      "epoch": 20.007751937984494,
      "grad_norm": 0.0019925821106880903,
      "learning_rate": 2.9992248062015506e-05,
      "loss": 0.0002,
      "step": 5162
    },
    {
      "epoch": 20.011627906976745,
      "grad_norm": 0.003140857443213463,
      "learning_rate": 2.9988372093023258e-05,
      "loss": 0.0002,
      "step": 5163
    },
    {
      "epoch": 20.015503875968992,
      "grad_norm": 0.02566155605018139,
      "learning_rate": 2.9984496124031007e-05,
      "loss": 0.0009,
      "step": 5164
    },
    {
      "epoch": 20.01937984496124,
      "grad_norm": 0.002070606919005513,
      "learning_rate": 2.9980620155038763e-05,
      "loss": 0.0002,
      "step": 5165
    },
    {
      "epoch": 20.023255813953487,
      "grad_norm": 88.70649719238281,
      "learning_rate": 2.9976744186046512e-05,
      "loss": 0.1356,
      "step": 5166
    },
    {
      "epoch": 20.027131782945737,
      "grad_norm": 0.003764672437682748,
      "learning_rate": 2.9972868217054268e-05,
      "loss": 0.0003,
      "step": 5167
    },
    {
      "epoch": 20.031007751937985,
      "grad_norm": 0.020414667204022408,
      "learning_rate": 2.9968992248062017e-05,
      "loss": 0.0009,
      "step": 5168
    },
    {
      "epoch": 20.03488372093023,
      "grad_norm": 0.0029694396071135998,
      "learning_rate": 2.9965116279069773e-05,
      "loss": 0.0002,
      "step": 5169
    },
    {
      "epoch": 20.03875968992248,
      "grad_norm": 0.006398944649845362,
      "learning_rate": 2.996124031007752e-05,
      "loss": 0.0003,
      "step": 5170
    },
    {
      "epoch": 20.04263565891473,
      "grad_norm": 0.0022617466747760773,
      "learning_rate": 2.995736434108527e-05,
      "loss": 0.0002,
      "step": 5171
    },
    {
      "epoch": 20.046511627906977,
      "grad_norm": 0.002503111492842436,
      "learning_rate": 2.9953488372093026e-05,
      "loss": 0.0002,
      "step": 5172
    },
    {
      "epoch": 20.050387596899224,
      "grad_norm": 0.004593577701598406,
      "learning_rate": 2.9949612403100775e-05,
      "loss": 0.0002,
      "step": 5173
    },
    {
      "epoch": 20.05426356589147,
      "grad_norm": 0.0036396021023392677,
      "learning_rate": 2.9945736434108528e-05,
      "loss": 0.0002,
      "step": 5174
    },
    {
      "epoch": 20.058139534883722,
      "grad_norm": 0.02343893237411976,
      "learning_rate": 2.9941860465116277e-05,
      "loss": 0.0007,
      "step": 5175
    },
    {
      "epoch": 20.06201550387597,
      "grad_norm": 0.0026050338055938482,
      "learning_rate": 2.9937984496124033e-05,
      "loss": 0.0002,
      "step": 5176
    },
    {
      "epoch": 20.065891472868216,
      "grad_norm": 0.0032200950663536787,
      "learning_rate": 2.9934108527131782e-05,
      "loss": 0.0003,
      "step": 5177
    },
    {
      "epoch": 20.069767441860463,
      "grad_norm": 0.12422836571931839,
      "learning_rate": 2.9930232558139538e-05,
      "loss": 0.0005,
      "step": 5178
    },
    {
      "epoch": 20.073643410852714,
      "grad_norm": 0.00741847837343812,
      "learning_rate": 2.9926356589147287e-05,
      "loss": 0.0003,
      "step": 5179
    },
    {
      "epoch": 20.07751937984496,
      "grad_norm": 0.7133141160011292,
      "learning_rate": 2.9922480620155042e-05,
      "loss": 0.0428,
      "step": 5180
    },
    {
      "epoch": 20.08139534883721,
      "grad_norm": 0.17700769007205963,
      "learning_rate": 2.991860465116279e-05,
      "loss": 0.0033,
      "step": 5181
    },
    {
      "epoch": 20.085271317829456,
      "grad_norm": 3.108053207397461,
      "learning_rate": 2.9914728682170544e-05,
      "loss": 0.0282,
      "step": 5182
    },
    {
      "epoch": 20.089147286821706,
      "grad_norm": 0.0020458840299397707,
      "learning_rate": 2.9910852713178293e-05,
      "loss": 0.0002,
      "step": 5183
    },
    {
      "epoch": 20.093023255813954,
      "grad_norm": 38.46938705444336,
      "learning_rate": 2.990697674418605e-05,
      "loss": 0.0338,
      "step": 5184
    },
    {
      "epoch": 20.0968992248062,
      "grad_norm": 0.012324708513915539,
      "learning_rate": 2.9903100775193798e-05,
      "loss": 0.0007,
      "step": 5185
    },
    {
      "epoch": 20.100775193798448,
      "grad_norm": 0.007845599204301834,
      "learning_rate": 2.9899224806201554e-05,
      "loss": 0.0004,
      "step": 5186
    },
    {
      "epoch": 20.1046511627907,
      "grad_norm": 0.003602870274335146,
      "learning_rate": 2.9895348837209303e-05,
      "loss": 0.0003,
      "step": 5187
    },
    {
      "epoch": 20.108527131782946,
      "grad_norm": 2.9423623085021973,
      "learning_rate": 2.989147286821706e-05,
      "loss": 0.2565,
      "step": 5188
    },
    {
      "epoch": 20.112403100775193,
      "grad_norm": 1.1437547206878662,
      "learning_rate": 2.9887596899224807e-05,
      "loss": 0.0753,
      "step": 5189
    },
    {
      "epoch": 20.11627906976744,
      "grad_norm": 3.0530927181243896,
      "learning_rate": 2.9883720930232563e-05,
      "loss": 0.3034,
      "step": 5190
    },
    {
      "epoch": 20.12015503875969,
      "grad_norm": 0.001972497208043933,
      "learning_rate": 2.9879844961240312e-05,
      "loss": 0.0002,
      "step": 5191
    },
    {
      "epoch": 20.124031007751938,
      "grad_norm": 0.0034691565670073032,
      "learning_rate": 2.9875968992248065e-05,
      "loss": 0.0003,
      "step": 5192
    },
    {
      "epoch": 20.127906976744185,
      "grad_norm": 0.0018263095989823341,
      "learning_rate": 2.9872093023255814e-05,
      "loss": 0.0002,
      "step": 5193
    },
    {
      "epoch": 20.131782945736433,
      "grad_norm": 0.0051515675149858,
      "learning_rate": 2.986821705426357e-05,
      "loss": 0.0004,
      "step": 5194
    },
    {
      "epoch": 20.135658914728683,
      "grad_norm": 0.0028141040820628405,
      "learning_rate": 2.986434108527132e-05,
      "loss": 0.0003,
      "step": 5195
    },
    {
      "epoch": 20.13953488372093,
      "grad_norm": 0.006562395952641964,
      "learning_rate": 2.9860465116279074e-05,
      "loss": 0.0005,
      "step": 5196
    },
    {
      "epoch": 20.143410852713178,
      "grad_norm": 0.00240021338686347,
      "learning_rate": 2.9856589147286823e-05,
      "loss": 0.0002,
      "step": 5197
    },
    {
      "epoch": 20.147286821705425,
      "grad_norm": 0.003988465294241905,
      "learning_rate": 2.9852713178294572e-05,
      "loss": 0.0003,
      "step": 5198
    },
    {
      "epoch": 20.151162790697676,
      "grad_norm": 0.019221946597099304,
      "learning_rate": 2.9848837209302328e-05,
      "loss": 0.0005,
      "step": 5199
    },
    {
      "epoch": 20.155038759689923,
      "grad_norm": 0.0021627501118928194,
      "learning_rate": 2.9844961240310077e-05,
      "loss": 0.0002,
      "step": 5200
    },
    {
      "epoch": 20.15891472868217,
      "grad_norm": 0.005148699041455984,
      "learning_rate": 2.984108527131783e-05,
      "loss": 0.0004,
      "step": 5201
    },
    {
      "epoch": 20.162790697674417,
      "grad_norm": 0.5700039267539978,
      "learning_rate": 2.9837209302325582e-05,
      "loss": 0.0275,
      "step": 5202
    },
    {
      "epoch": 20.166666666666668,
      "grad_norm": 0.001701757195405662,
      "learning_rate": 2.9833333333333335e-05,
      "loss": 0.0002,
      "step": 5203
    },
    {
      "epoch": 20.170542635658915,
      "grad_norm": 0.0016860939795151353,
      "learning_rate": 2.9829457364341084e-05,
      "loss": 0.0002,
      "step": 5204
    },
    {
      "epoch": 20.174418604651162,
      "grad_norm": 0.002120079705491662,
      "learning_rate": 2.982558139534884e-05,
      "loss": 0.0002,
      "step": 5205
    },
    {
      "epoch": 20.17829457364341,
      "grad_norm": 0.0020457282662391663,
      "learning_rate": 2.982170542635659e-05,
      "loss": 0.0002,
      "step": 5206
    },
    {
      "epoch": 20.18217054263566,
      "grad_norm": 0.006205136422067881,
      "learning_rate": 2.9817829457364344e-05,
      "loss": 0.0003,
      "step": 5207
    },
    {
      "epoch": 20.186046511627907,
      "grad_norm": 0.0019806798081845045,
      "learning_rate": 2.9813953488372093e-05,
      "loss": 0.0002,
      "step": 5208
    },
    {
      "epoch": 20.189922480620154,
      "grad_norm": 0.5436382293701172,
      "learning_rate": 2.981007751937985e-05,
      "loss": 0.002,
      "step": 5209
    },
    {
      "epoch": 20.1937984496124,
      "grad_norm": 0.96006840467453,
      "learning_rate": 2.9806201550387598e-05,
      "loss": 0.0372,
      "step": 5210
    },
    {
      "epoch": 20.197674418604652,
      "grad_norm": 0.02447913959622383,
      "learning_rate": 2.980232558139535e-05,
      "loss": 0.0013,
      "step": 5211
    },
    {
      "epoch": 20.2015503875969,
      "grad_norm": 0.012971187010407448,
      "learning_rate": 2.97984496124031e-05,
      "loss": 0.0006,
      "step": 5212
    },
    {
      "epoch": 20.205426356589147,
      "grad_norm": 0.0017590309726074338,
      "learning_rate": 2.9794573643410855e-05,
      "loss": 0.0002,
      "step": 5213
    },
    {
      "epoch": 20.209302325581394,
      "grad_norm": 2.2771992683410645,
      "learning_rate": 2.9790697674418604e-05,
      "loss": 0.1479,
      "step": 5214
    },
    {
      "epoch": 20.213178294573645,
      "grad_norm": 0.002168063074350357,
      "learning_rate": 2.978682170542636e-05,
      "loss": 0.0002,
      "step": 5215
    },
    {
      "epoch": 20.217054263565892,
      "grad_norm": 0.0015509487129747868,
      "learning_rate": 2.978294573643411e-05,
      "loss": 0.0002,
      "step": 5216
    },
    {
      "epoch": 20.22093023255814,
      "grad_norm": 0.0017471296014264226,
      "learning_rate": 2.9779069767441865e-05,
      "loss": 0.0002,
      "step": 5217
    },
    {
      "epoch": 20.224806201550386,
      "grad_norm": 0.0021415387745946646,
      "learning_rate": 2.9775193798449614e-05,
      "loss": 0.0002,
      "step": 5218
    },
    {
      "epoch": 20.228682170542637,
      "grad_norm": 0.004754722584038973,
      "learning_rate": 2.9771317829457367e-05,
      "loss": 0.0004,
      "step": 5219
    },
    {
      "epoch": 20.232558139534884,
      "grad_norm": 0.0017068384913727641,
      "learning_rate": 2.976744186046512e-05,
      "loss": 0.0002,
      "step": 5220
    },
    {
      "epoch": 20.23643410852713,
      "grad_norm": 3.2926270961761475,
      "learning_rate": 2.976356589147287e-05,
      "loss": 0.005,
      "step": 5221
    },
    {
      "epoch": 20.24031007751938,
      "grad_norm": 0.003518171375617385,
      "learning_rate": 2.975968992248062e-05,
      "loss": 0.0002,
      "step": 5222
    },
    {
      "epoch": 20.24418604651163,
      "grad_norm": 12.117494583129883,
      "learning_rate": 2.9755813953488376e-05,
      "loss": 0.2933,
      "step": 5223
    },
    {
      "epoch": 20.248062015503876,
      "grad_norm": 0.0016516110626980662,
      "learning_rate": 2.9751937984496125e-05,
      "loss": 0.0002,
      "step": 5224
    },
    {
      "epoch": 20.251937984496124,
      "grad_norm": 0.0016536701004952192,
      "learning_rate": 2.9748062015503874e-05,
      "loss": 0.0002,
      "step": 5225
    },
    {
      "epoch": 20.25581395348837,
      "grad_norm": 0.3352138102054596,
      "learning_rate": 2.974418604651163e-05,
      "loss": 0.0023,
      "step": 5226
    },
    {
      "epoch": 20.25968992248062,
      "grad_norm": 0.001976811094209552,
      "learning_rate": 2.974031007751938e-05,
      "loss": 0.0002,
      "step": 5227
    },
    {
      "epoch": 20.26356589147287,
      "grad_norm": 0.004035183694213629,
      "learning_rate": 2.9736434108527135e-05,
      "loss": 0.0003,
      "step": 5228
    },
    {
      "epoch": 20.267441860465116,
      "grad_norm": 0.0034047793596982956,
      "learning_rate": 2.9732558139534884e-05,
      "loss": 0.0003,
      "step": 5229
    },
    {
      "epoch": 20.271317829457363,
      "grad_norm": 0.001687275362201035,
      "learning_rate": 2.9728682170542636e-05,
      "loss": 0.0002,
      "step": 5230
    },
    {
      "epoch": 20.275193798449614,
      "grad_norm": 0.0018385933944955468,
      "learning_rate": 2.9724806201550385e-05,
      "loss": 0.0002,
      "step": 5231
    },
    {
      "epoch": 20.27906976744186,
      "grad_norm": 0.0019229716854169965,
      "learning_rate": 2.972093023255814e-05,
      "loss": 0.0002,
      "step": 5232
    },
    {
      "epoch": 20.282945736434108,
      "grad_norm": 0.0051756626926362514,
      "learning_rate": 2.971705426356589e-05,
      "loss": 0.0002,
      "step": 5233
    },
    {
      "epoch": 20.286821705426355,
      "grad_norm": 0.9227673411369324,
      "learning_rate": 2.9713178294573646e-05,
      "loss": 0.0297,
      "step": 5234
    },
    {
      "epoch": 20.290697674418606,
      "grad_norm": 0.0019068485125899315,
      "learning_rate": 2.9709302325581395e-05,
      "loss": 0.0002,
      "step": 5235
    },
    {
      "epoch": 20.294573643410853,
      "grad_norm": 1.8909125328063965,
      "learning_rate": 2.970542635658915e-05,
      "loss": 0.0303,
      "step": 5236
    },
    {
      "epoch": 20.2984496124031,
      "grad_norm": 40.19755935668945,
      "learning_rate": 2.97015503875969e-05,
      "loss": 0.1903,
      "step": 5237
    },
    {
      "epoch": 20.302325581395348,
      "grad_norm": 0.03853771835565567,
      "learning_rate": 2.9697674418604652e-05,
      "loss": 0.0017,
      "step": 5238
    },
    {
      "epoch": 20.3062015503876,
      "grad_norm": 0.0027098036371171474,
      "learning_rate": 2.9693798449612405e-05,
      "loss": 0.0002,
      "step": 5239
    },
    {
      "epoch": 20.310077519379846,
      "grad_norm": 0.002418016316369176,
      "learning_rate": 2.9689922480620157e-05,
      "loss": 0.0002,
      "step": 5240
    },
    {
      "epoch": 20.313953488372093,
      "grad_norm": 0.004256687127053738,
      "learning_rate": 2.9686046511627906e-05,
      "loss": 0.0003,
      "step": 5241
    },
    {
      "epoch": 20.31782945736434,
      "grad_norm": 0.0022516511380672455,
      "learning_rate": 2.9682170542635662e-05,
      "loss": 0.0002,
      "step": 5242
    },
    {
      "epoch": 20.32170542635659,
      "grad_norm": 0.0029012206941843033,
      "learning_rate": 2.967829457364341e-05,
      "loss": 0.0003,
      "step": 5243
    },
    {
      "epoch": 20.325581395348838,
      "grad_norm": 89.11689758300781,
      "learning_rate": 2.9674418604651167e-05,
      "loss": 0.0622,
      "step": 5244
    },
    {
      "epoch": 20.329457364341085,
      "grad_norm": 6.6432576179504395,
      "learning_rate": 2.9670542635658916e-05,
      "loss": 0.0752,
      "step": 5245
    },
    {
      "epoch": 20.333333333333332,
      "grad_norm": 0.0018455981044098735,
      "learning_rate": 2.9666666666666672e-05,
      "loss": 0.0002,
      "step": 5246
    },
    {
      "epoch": 20.337209302325583,
      "grad_norm": 0.00211604917421937,
      "learning_rate": 2.966279069767442e-05,
      "loss": 0.0002,
      "step": 5247
    },
    {
      "epoch": 20.34108527131783,
      "grad_norm": 0.0014746333472430706,
      "learning_rate": 2.9658914728682173e-05,
      "loss": 0.0001,
      "step": 5248
    },
    {
      "epoch": 20.344961240310077,
      "grad_norm": 0.01148082222789526,
      "learning_rate": 2.9655038759689922e-05,
      "loss": 0.0002,
      "step": 5249
    },
    {
      "epoch": 20.348837209302324,
      "grad_norm": 13.362065315246582,
      "learning_rate": 2.9651162790697678e-05,
      "loss": 0.4335,
      "step": 5250
    },
    {
      "epoch": 20.352713178294575,
      "grad_norm": 0.001583601231686771,
      "learning_rate": 2.9647286821705427e-05,
      "loss": 0.0002,
      "step": 5251
    },
    {
      "epoch": 20.356589147286822,
      "grad_norm": 0.11687073856592178,
      "learning_rate": 2.9643410852713176e-05,
      "loss": 0.0025,
      "step": 5252
    },
    {
      "epoch": 20.36046511627907,
      "grad_norm": 0.0018059347057715058,
      "learning_rate": 2.9639534883720932e-05,
      "loss": 0.0002,
      "step": 5253
    },
    {
      "epoch": 20.364341085271317,
      "grad_norm": 0.0018451244104653597,
      "learning_rate": 2.963565891472868e-05,
      "loss": 0.0002,
      "step": 5254
    },
    {
      "epoch": 20.368217054263567,
      "grad_norm": 0.0021125569473952055,
      "learning_rate": 2.9631782945736437e-05,
      "loss": 0.0002,
      "step": 5255
    },
    {
      "epoch": 20.372093023255815,
      "grad_norm": 3.405460834503174,
      "learning_rate": 2.9627906976744186e-05,
      "loss": 0.3347,
      "step": 5256
    },
    {
      "epoch": 20.375968992248062,
      "grad_norm": 0.20036844909191132,
      "learning_rate": 2.962403100775194e-05,
      "loss": 0.0043,
      "step": 5257
    },
    {
      "epoch": 20.37984496124031,
      "grad_norm": 19.414682388305664,
      "learning_rate": 2.962015503875969e-05,
      "loss": 0.1069,
      "step": 5258
    },
    {
      "epoch": 20.38372093023256,
      "grad_norm": 0.010116473771631718,
      "learning_rate": 2.9616279069767443e-05,
      "loss": 0.0006,
      "step": 5259
    },
    {
      "epoch": 20.387596899224807,
      "grad_norm": 0.0017195919062942266,
      "learning_rate": 2.9612403100775192e-05,
      "loss": 0.0002,
      "step": 5260
    },
    {
      "epoch": 20.391472868217054,
      "grad_norm": 0.00196980987675488,
      "learning_rate": 2.9608527131782948e-05,
      "loss": 0.0002,
      "step": 5261
    },
    {
      "epoch": 20.3953488372093,
      "grad_norm": 0.00244344724342227,
      "learning_rate": 2.9604651162790697e-05,
      "loss": 0.0002,
      "step": 5262
    },
    {
      "epoch": 20.399224806201552,
      "grad_norm": 0.0016009599203243852,
      "learning_rate": 2.9600775193798453e-05,
      "loss": 0.0002,
      "step": 5263
    },
    {
      "epoch": 20.4031007751938,
      "grad_norm": 0.0885087102651596,
      "learning_rate": 2.9596899224806202e-05,
      "loss": 0.0024,
      "step": 5264
    },
    {
      "epoch": 20.406976744186046,
      "grad_norm": 0.001896179630421102,
      "learning_rate": 2.9593023255813958e-05,
      "loss": 0.0002,
      "step": 5265
    },
    {
      "epoch": 20.410852713178294,
      "grad_norm": 5.484099388122559,
      "learning_rate": 2.9589147286821707e-05,
      "loss": 0.0898,
      "step": 5266
    },
    {
      "epoch": 20.414728682170544,
      "grad_norm": 0.002763195428997278,
      "learning_rate": 2.958527131782946e-05,
      "loss": 0.0002,
      "step": 5267
    },
    {
      "epoch": 20.41860465116279,
      "grad_norm": 0.002751355990767479,
      "learning_rate": 2.9581395348837208e-05,
      "loss": 0.0002,
      "step": 5268
    },
    {
      "epoch": 20.42248062015504,
      "grad_norm": 0.002364248735830188,
      "learning_rate": 2.9577519379844964e-05,
      "loss": 0.0002,
      "step": 5269
    },
    {
      "epoch": 20.426356589147286,
      "grad_norm": 0.002436496550217271,
      "learning_rate": 2.9573643410852713e-05,
      "loss": 0.0002,
      "step": 5270
    },
    {
      "epoch": 20.430232558139537,
      "grad_norm": 1.9596067667007446,
      "learning_rate": 2.956976744186047e-05,
      "loss": 0.1799,
      "step": 5271
    },
    {
      "epoch": 20.434108527131784,
      "grad_norm": 0.00616210512816906,
      "learning_rate": 2.9565891472868218e-05,
      "loss": 0.0003,
      "step": 5272
    },
    {
      "epoch": 20.43798449612403,
      "grad_norm": 0.0028113541193306446,
      "learning_rate": 2.9562015503875974e-05,
      "loss": 0.0002,
      "step": 5273
    },
    {
      "epoch": 20.441860465116278,
      "grad_norm": 0.0019846828654408455,
      "learning_rate": 2.9558139534883723e-05,
      "loss": 0.0002,
      "step": 5274
    },
    {
      "epoch": 20.44573643410853,
      "grad_norm": 0.002858515130355954,
      "learning_rate": 2.955426356589148e-05,
      "loss": 0.0002,
      "step": 5275
    },
    {
      "epoch": 20.449612403100776,
      "grad_norm": 0.008926065638661385,
      "learning_rate": 2.9550387596899227e-05,
      "loss": 0.0005,
      "step": 5276
    },
    {
      "epoch": 20.453488372093023,
      "grad_norm": 0.001875486341305077,
      "learning_rate": 2.954651162790698e-05,
      "loss": 0.0002,
      "step": 5277
    },
    {
      "epoch": 20.45736434108527,
      "grad_norm": 0.002061272971332073,
      "learning_rate": 2.954263565891473e-05,
      "loss": 0.0002,
      "step": 5278
    },
    {
      "epoch": 20.46124031007752,
      "grad_norm": 0.0033248940017074347,
      "learning_rate": 2.9538759689922478e-05,
      "loss": 0.0002,
      "step": 5279
    },
    {
      "epoch": 20.46511627906977,
      "grad_norm": 0.004166581202298403,
      "learning_rate": 2.9534883720930234e-05,
      "loss": 0.0003,
      "step": 5280
    },
    {
      "epoch": 20.468992248062015,
      "grad_norm": 0.033670417964458466,
      "learning_rate": 2.9531007751937983e-05,
      "loss": 0.0014,
      "step": 5281
    },
    {
      "epoch": 20.472868217054263,
      "grad_norm": 0.0023067498113960028,
      "learning_rate": 2.952713178294574e-05,
      "loss": 0.0002,
      "step": 5282
    },
    {
      "epoch": 20.476744186046513,
      "grad_norm": 1.6471779346466064,
      "learning_rate": 2.9523255813953488e-05,
      "loss": 0.0863,
      "step": 5283
    },
    {
      "epoch": 20.48062015503876,
      "grad_norm": 0.011079911142587662,
      "learning_rate": 2.9519379844961243e-05,
      "loss": 0.0005,
      "step": 5284
    },
    {
      "epoch": 20.484496124031008,
      "grad_norm": 0.03250965476036072,
      "learning_rate": 2.9515503875968992e-05,
      "loss": 0.0012,
      "step": 5285
    },
    {
      "epoch": 20.488372093023255,
      "grad_norm": 0.008622410707175732,
      "learning_rate": 2.9511627906976745e-05,
      "loss": 0.0002,
      "step": 5286
    },
    {
      "epoch": 20.492248062015506,
      "grad_norm": 0.002178050810471177,
      "learning_rate": 2.9507751937984497e-05,
      "loss": 0.0002,
      "step": 5287
    },
    {
      "epoch": 20.496124031007753,
      "grad_norm": 0.00753360940143466,
      "learning_rate": 2.950387596899225e-05,
      "loss": 0.0004,
      "step": 5288
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.02187192812561989,
      "learning_rate": 2.95e-05,
      "loss": 0.0004,
      "step": 5289
    },
    {
      "epoch": 20.503875968992247,
      "grad_norm": 0.0028475781437009573,
      "learning_rate": 2.9496124031007755e-05,
      "loss": 0.0002,
      "step": 5290
    },
    {
      "epoch": 20.507751937984494,
      "grad_norm": 0.002709127962589264,
      "learning_rate": 2.9492248062015504e-05,
      "loss": 0.0002,
      "step": 5291
    },
    {
      "epoch": 20.511627906976745,
      "grad_norm": 0.9493108987808228,
      "learning_rate": 2.948837209302326e-05,
      "loss": 0.0174,
      "step": 5292
    },
    {
      "epoch": 20.515503875968992,
      "grad_norm": 0.006711628753691912,
      "learning_rate": 2.948449612403101e-05,
      "loss": 0.0005,
      "step": 5293
    },
    {
      "epoch": 20.51937984496124,
      "grad_norm": 91.400634765625,
      "learning_rate": 2.9480620155038764e-05,
      "loss": 0.1215,
      "step": 5294
    },
    {
      "epoch": 20.52325581395349,
      "grad_norm": 0.0031409712973982096,
      "learning_rate": 2.9476744186046513e-05,
      "loss": 0.0002,
      "step": 5295
    },
    {
      "epoch": 20.527131782945737,
      "grad_norm": 0.002444322220981121,
      "learning_rate": 2.9472868217054266e-05,
      "loss": 0.0002,
      "step": 5296
    },
    {
      "epoch": 20.531007751937985,
      "grad_norm": 0.0018596767913550138,
      "learning_rate": 2.9468992248062015e-05,
      "loss": 0.0002,
      "step": 5297
    },
    {
      "epoch": 20.53488372093023,
      "grad_norm": 0.002344802487641573,
      "learning_rate": 2.946511627906977e-05,
      "loss": 0.0002,
      "step": 5298
    },
    {
      "epoch": 20.53875968992248,
      "grad_norm": 30.36397933959961,
      "learning_rate": 2.946124031007752e-05,
      "loss": 0.6019,
      "step": 5299
    },
    {
      "epoch": 20.54263565891473,
      "grad_norm": 10.589509010314941,
      "learning_rate": 2.9457364341085275e-05,
      "loss": 0.3658,
      "step": 5300
    },
    {
      "epoch": 20.546511627906977,
      "grad_norm": 0.0017847964772954583,
      "learning_rate": 2.9453488372093024e-05,
      "loss": 0.0002,
      "step": 5301
    },
    {
      "epoch": 20.550387596899224,
      "grad_norm": 0.009752314537763596,
      "learning_rate": 2.944961240310078e-05,
      "loss": 0.0005,
      "step": 5302
    },
    {
      "epoch": 20.55426356589147,
      "grad_norm": 0.0033105460461229086,
      "learning_rate": 2.944573643410853e-05,
      "loss": 0.0003,
      "step": 5303
    },
    {
      "epoch": 20.558139534883722,
      "grad_norm": 0.0023223741445690393,
      "learning_rate": 2.944186046511628e-05,
      "loss": 0.0002,
      "step": 5304
    },
    {
      "epoch": 20.56201550387597,
      "grad_norm": 0.0023628100752830505,
      "learning_rate": 2.9437984496124034e-05,
      "loss": 0.0002,
      "step": 5305
    },
    {
      "epoch": 20.565891472868216,
      "grad_norm": 0.002553898375481367,
      "learning_rate": 2.9434108527131783e-05,
      "loss": 0.0002,
      "step": 5306
    },
    {
      "epoch": 20.569767441860463,
      "grad_norm": 0.003050159430131316,
      "learning_rate": 2.9430232558139536e-05,
      "loss": 0.0003,
      "step": 5307
    },
    {
      "epoch": 20.573643410852714,
      "grad_norm": 0.0024608303792774677,
      "learning_rate": 2.9426356589147285e-05,
      "loss": 0.0002,
      "step": 5308
    },
    {
      "epoch": 20.57751937984496,
      "grad_norm": 0.003635907545685768,
      "learning_rate": 2.942248062015504e-05,
      "loss": 0.0002,
      "step": 5309
    },
    {
      "epoch": 20.58139534883721,
      "grad_norm": 0.004851719364523888,
      "learning_rate": 2.941860465116279e-05,
      "loss": 0.0003,
      "step": 5310
    },
    {
      "epoch": 20.585271317829456,
      "grad_norm": 0.0029079471714794636,
      "learning_rate": 2.9414728682170545e-05,
      "loss": 0.0002,
      "step": 5311
    },
    {
      "epoch": 20.589147286821706,
      "grad_norm": 0.3772950768470764,
      "learning_rate": 2.9410852713178294e-05,
      "loss": 0.0167,
      "step": 5312
    },
    {
      "epoch": 20.593023255813954,
      "grad_norm": 0.003006988437846303,
      "learning_rate": 2.940697674418605e-05,
      "loss": 0.0002,
      "step": 5313
    },
    {
      "epoch": 20.5968992248062,
      "grad_norm": 0.03836517781019211,
      "learning_rate": 2.94031007751938e-05,
      "loss": 0.0018,
      "step": 5314
    },
    {
      "epoch": 20.600775193798448,
      "grad_norm": 0.0022598246578127146,
      "learning_rate": 2.939922480620155e-05,
      "loss": 0.0002,
      "step": 5315
    },
    {
      "epoch": 20.6046511627907,
      "grad_norm": 0.0030236714519560337,
      "learning_rate": 2.93953488372093e-05,
      "loss": 0.0003,
      "step": 5316
    },
    {
      "epoch": 20.608527131782946,
      "grad_norm": 0.33833763003349304,
      "learning_rate": 2.9391472868217056e-05,
      "loss": 0.0104,
      "step": 5317
    },
    {
      "epoch": 20.612403100775193,
      "grad_norm": 0.0025929228868335485,
      "learning_rate": 2.9387596899224805e-05,
      "loss": 0.0002,
      "step": 5318
    },
    {
      "epoch": 20.61627906976744,
      "grad_norm": 0.0022181435488164425,
      "learning_rate": 2.938372093023256e-05,
      "loss": 0.0002,
      "step": 5319
    },
    {
      "epoch": 20.62015503875969,
      "grad_norm": 0.002440827200189233,
      "learning_rate": 2.937984496124031e-05,
      "loss": 0.0002,
      "step": 5320
    },
    {
      "epoch": 20.624031007751938,
      "grad_norm": 0.010808160528540611,
      "learning_rate": 2.9375968992248066e-05,
      "loss": 0.0006,
      "step": 5321
    },
    {
      "epoch": 20.627906976744185,
      "grad_norm": 0.0021086218766868114,
      "learning_rate": 2.9372093023255815e-05,
      "loss": 0.0002,
      "step": 5322
    },
    {
      "epoch": 20.631782945736433,
      "grad_norm": 3.9050984382629395,
      "learning_rate": 2.936821705426357e-05,
      "loss": 0.2369,
      "step": 5323
    },
    {
      "epoch": 20.635658914728683,
      "grad_norm": 0.0021796845830976963,
      "learning_rate": 2.936434108527132e-05,
      "loss": 0.0002,
      "step": 5324
    },
    {
      "epoch": 20.63953488372093,
      "grad_norm": 0.1159219965338707,
      "learning_rate": 2.9360465116279072e-05,
      "loss": 0.0012,
      "step": 5325
    },
    {
      "epoch": 20.643410852713178,
      "grad_norm": 0.0024761073291301727,
      "learning_rate": 2.935658914728682e-05,
      "loss": 0.0002,
      "step": 5326
    },
    {
      "epoch": 20.647286821705425,
      "grad_norm": 0.04581214115023613,
      "learning_rate": 2.9352713178294577e-05,
      "loss": 0.0013,
      "step": 5327
    },
    {
      "epoch": 20.651162790697676,
      "grad_norm": 0.003054611152037978,
      "learning_rate": 2.9348837209302326e-05,
      "loss": 0.0003,
      "step": 5328
    },
    {
      "epoch": 20.655038759689923,
      "grad_norm": 0.00214241910725832,
      "learning_rate": 2.9344961240310082e-05,
      "loss": 0.0002,
      "step": 5329
    },
    {
      "epoch": 20.65891472868217,
      "grad_norm": 0.0039147911593317986,
      "learning_rate": 2.934108527131783e-05,
      "loss": 0.0003,
      "step": 5330
    },
    {
      "epoch": 20.662790697674417,
      "grad_norm": 0.006901327054947615,
      "learning_rate": 2.933720930232558e-05,
      "loss": 0.0005,
      "step": 5331
    },
    {
      "epoch": 20.666666666666668,
      "grad_norm": 136.07191467285156,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.0859,
      "step": 5332
    },
    {
      "epoch": 20.670542635658915,
      "grad_norm": 0.00208788993768394,
      "learning_rate": 2.9329457364341085e-05,
      "loss": 0.0002,
      "step": 5333
    },
    {
      "epoch": 20.674418604651162,
      "grad_norm": 4.112693786621094,
      "learning_rate": 2.9325581395348837e-05,
      "loss": 0.2804,
      "step": 5334
    },
    {
      "epoch": 20.67829457364341,
      "grad_norm": 1.822774887084961,
      "learning_rate": 2.932170542635659e-05,
      "loss": 0.0098,
      "step": 5335
    },
    {
      "epoch": 20.68217054263566,
      "grad_norm": 0.0023644643370062113,
      "learning_rate": 2.9317829457364342e-05,
      "loss": 0.0002,
      "step": 5336
    },
    {
      "epoch": 20.686046511627907,
      "grad_norm": 0.002059267135336995,
      "learning_rate": 2.931395348837209e-05,
      "loss": 0.0002,
      "step": 5337
    },
    {
      "epoch": 20.689922480620154,
      "grad_norm": 0.12491577863693237,
      "learning_rate": 2.9310077519379847e-05,
      "loss": 0.005,
      "step": 5338
    },
    {
      "epoch": 20.6937984496124,
      "grad_norm": 0.0022836606949567795,
      "learning_rate": 2.9306201550387596e-05,
      "loss": 0.0002,
      "step": 5339
    },
    {
      "epoch": 20.697674418604652,
      "grad_norm": 0.002291399985551834,
      "learning_rate": 2.9302325581395352e-05,
      "loss": 0.0002,
      "step": 5340
    },
    {
      "epoch": 20.7015503875969,
      "grad_norm": 0.5540735721588135,
      "learning_rate": 2.92984496124031e-05,
      "loss": 0.0048,
      "step": 5341
    },
    {
      "epoch": 20.705426356589147,
      "grad_norm": 0.004516105633229017,
      "learning_rate": 2.9294573643410857e-05,
      "loss": 0.0002,
      "step": 5342
    },
    {
      "epoch": 20.709302325581394,
      "grad_norm": 0.014929953962564468,
      "learning_rate": 2.9290697674418606e-05,
      "loss": 0.0002,
      "step": 5343
    },
    {
      "epoch": 20.713178294573645,
      "grad_norm": 0.003167581046000123,
      "learning_rate": 2.9286821705426358e-05,
      "loss": 0.0003,
      "step": 5344
    },
    {
      "epoch": 20.717054263565892,
      "grad_norm": 0.00181843270547688,
      "learning_rate": 2.9282945736434107e-05,
      "loss": 0.0002,
      "step": 5345
    },
    {
      "epoch": 20.72093023255814,
      "grad_norm": 0.01406749989837408,
      "learning_rate": 2.9279069767441863e-05,
      "loss": 0.0008,
      "step": 5346
    },
    {
      "epoch": 20.724806201550386,
      "grad_norm": 10.561568260192871,
      "learning_rate": 2.9275193798449612e-05,
      "loss": 0.0401,
      "step": 5347
    },
    {
      "epoch": 20.728682170542637,
      "grad_norm": 0.0016626314027234912,
      "learning_rate": 2.9271317829457368e-05,
      "loss": 0.0002,
      "step": 5348
    },
    {
      "epoch": 20.732558139534884,
      "grad_norm": 0.10556375980377197,
      "learning_rate": 2.9267441860465117e-05,
      "loss": 0.0021,
      "step": 5349
    },
    {
      "epoch": 20.73643410852713,
      "grad_norm": 0.0039503308944404125,
      "learning_rate": 2.9263565891472873e-05,
      "loss": 0.0002,
      "step": 5350
    },
    {
      "epoch": 20.74031007751938,
      "grad_norm": 0.0024118106812238693,
      "learning_rate": 2.9259689922480622e-05,
      "loss": 0.0002,
      "step": 5351
    },
    {
      "epoch": 20.74418604651163,
      "grad_norm": 0.0018483884632587433,
      "learning_rate": 2.9255813953488374e-05,
      "loss": 0.0002,
      "step": 5352
    },
    {
      "epoch": 20.748062015503876,
      "grad_norm": 0.18544527888298035,
      "learning_rate": 2.9251937984496127e-05,
      "loss": 0.0084,
      "step": 5353
    },
    {
      "epoch": 20.751937984496124,
      "grad_norm": 0.0019389452645555139,
      "learning_rate": 2.924806201550388e-05,
      "loss": 0.0002,
      "step": 5354
    },
    {
      "epoch": 20.75581395348837,
      "grad_norm": 3.0232651233673096,
      "learning_rate": 2.9244186046511628e-05,
      "loss": 0.2542,
      "step": 5355
    },
    {
      "epoch": 20.75968992248062,
      "grad_norm": 0.00220027775503695,
      "learning_rate": 2.9240310077519384e-05,
      "loss": 0.0002,
      "step": 5356
    },
    {
      "epoch": 20.76356589147287,
      "grad_norm": 0.003910948056727648,
      "learning_rate": 2.9236434108527133e-05,
      "loss": 0.0003,
      "step": 5357
    },
    {
      "epoch": 20.767441860465116,
      "grad_norm": 0.13467009365558624,
      "learning_rate": 2.9232558139534882e-05,
      "loss": 0.0062,
      "step": 5358
    },
    {
      "epoch": 20.771317829457363,
      "grad_norm": 0.14649176597595215,
      "learning_rate": 2.9228682170542638e-05,
      "loss": 0.0058,
      "step": 5359
    },
    {
      "epoch": 20.775193798449614,
      "grad_norm": 0.0026428711134940386,
      "learning_rate": 2.9224806201550387e-05,
      "loss": 0.0002,
      "step": 5360
    },
    {
      "epoch": 20.77906976744186,
      "grad_norm": 7.046006202697754,
      "learning_rate": 2.9220930232558143e-05,
      "loss": 0.27,
      "step": 5361
    },
    {
      "epoch": 20.782945736434108,
      "grad_norm": 0.10215035825967789,
      "learning_rate": 2.921705426356589e-05,
      "loss": 0.0012,
      "step": 5362
    },
    {
      "epoch": 20.786821705426355,
      "grad_norm": 0.0020988858304917812,
      "learning_rate": 2.9213178294573644e-05,
      "loss": 0.0002,
      "step": 5363
    },
    {
      "epoch": 20.790697674418606,
      "grad_norm": 0.0020876682829111814,
      "learning_rate": 2.9209302325581393e-05,
      "loss": 0.0002,
      "step": 5364
    },
    {
      "epoch": 20.794573643410853,
      "grad_norm": 0.002173331333324313,
      "learning_rate": 2.920542635658915e-05,
      "loss": 0.0002,
      "step": 5365
    },
    {
      "epoch": 20.7984496124031,
      "grad_norm": 0.0042387209832668304,
      "learning_rate": 2.9201550387596898e-05,
      "loss": 0.0003,
      "step": 5366
    },
    {
      "epoch": 20.802325581395348,
      "grad_norm": 0.021593699231743813,
      "learning_rate": 2.9197674418604654e-05,
      "loss": 0.0004,
      "step": 5367
    },
    {
      "epoch": 20.8062015503876,
      "grad_norm": 0.13466902077198029,
      "learning_rate": 2.9193798449612403e-05,
      "loss": 0.0021,
      "step": 5368
    },
    {
      "epoch": 20.810077519379846,
      "grad_norm": 0.0019432160770520568,
      "learning_rate": 2.918992248062016e-05,
      "loss": 0.0002,
      "step": 5369
    },
    {
      "epoch": 20.813953488372093,
      "grad_norm": 3.890993356704712,
      "learning_rate": 2.9186046511627908e-05,
      "loss": 0.0022,
      "step": 5370
    },
    {
      "epoch": 20.81782945736434,
      "grad_norm": 0.0024468174669891596,
      "learning_rate": 2.918217054263566e-05,
      "loss": 0.0002,
      "step": 5371
    },
    {
      "epoch": 20.82170542635659,
      "grad_norm": 2.8546667098999023,
      "learning_rate": 2.9178294573643412e-05,
      "loss": 0.3321,
      "step": 5372
    },
    {
      "epoch": 20.825581395348838,
      "grad_norm": 0.016597669571638107,
      "learning_rate": 2.9174418604651165e-05,
      "loss": 0.0007,
      "step": 5373
    },
    {
      "epoch": 20.829457364341085,
      "grad_norm": 0.004595321603119373,
      "learning_rate": 2.9170542635658914e-05,
      "loss": 0.0002,
      "step": 5374
    },
    {
      "epoch": 20.833333333333332,
      "grad_norm": 0.0020151317585259676,
      "learning_rate": 2.916666666666667e-05,
      "loss": 0.0002,
      "step": 5375
    },
    {
      "epoch": 20.837209302325583,
      "grad_norm": 0.002199474722146988,
      "learning_rate": 2.916279069767442e-05,
      "loss": 0.0002,
      "step": 5376
    },
    {
      "epoch": 20.84108527131783,
      "grad_norm": 6.005899906158447,
      "learning_rate": 2.9158914728682175e-05,
      "loss": 0.2406,
      "step": 5377
    },
    {
      "epoch": 20.844961240310077,
      "grad_norm": 0.13675466179847717,
      "learning_rate": 2.9155038759689924e-05,
      "loss": 0.0014,
      "step": 5378
    },
    {
      "epoch": 20.848837209302324,
      "grad_norm": 0.006251442711800337,
      "learning_rate": 2.915116279069768e-05,
      "loss": 0.0004,
      "step": 5379
    },
    {
      "epoch": 20.852713178294575,
      "grad_norm": 0.002256782492622733,
      "learning_rate": 2.914728682170543e-05,
      "loss": 0.0002,
      "step": 5380
    },
    {
      "epoch": 20.856589147286822,
      "grad_norm": 2.883861541748047,
      "learning_rate": 2.914341085271318e-05,
      "loss": 0.1412,
      "step": 5381
    },
    {
      "epoch": 20.86046511627907,
      "grad_norm": 2.0579938888549805,
      "learning_rate": 2.913953488372093e-05,
      "loss": 0.2432,
      "step": 5382
    },
    {
      "epoch": 20.864341085271317,
      "grad_norm": 0.002176675945520401,
      "learning_rate": 2.9135658914728686e-05,
      "loss": 0.0002,
      "step": 5383
    },
    {
      "epoch": 20.868217054263567,
      "grad_norm": 0.0021913594100624323,
      "learning_rate": 2.9131782945736435e-05,
      "loss": 0.0002,
      "step": 5384
    },
    {
      "epoch": 20.872093023255815,
      "grad_norm": 0.006524680182337761,
      "learning_rate": 2.9127906976744184e-05,
      "loss": 0.0005,
      "step": 5385
    },
    {
      "epoch": 20.875968992248062,
      "grad_norm": 3.931460380554199,
      "learning_rate": 2.912403100775194e-05,
      "loss": 0.0294,
      "step": 5386
    },
    {
      "epoch": 20.87984496124031,
      "grad_norm": 12.698055267333984,
      "learning_rate": 2.912015503875969e-05,
      "loss": 0.0096,
      "step": 5387
    },
    {
      "epoch": 20.88372093023256,
      "grad_norm": 19.83538055419922,
      "learning_rate": 2.9116279069767444e-05,
      "loss": 1.154,
      "step": 5388
    },
    {
      "epoch": 20.887596899224807,
      "grad_norm": 6.025554180145264,
      "learning_rate": 2.9112403100775193e-05,
      "loss": 0.6149,
      "step": 5389
    },
    {
      "epoch": 20.891472868217054,
      "grad_norm": 0.002480576280504465,
      "learning_rate": 2.910852713178295e-05,
      "loss": 0.0002,
      "step": 5390
    },
    {
      "epoch": 20.8953488372093,
      "grad_norm": 0.0026143852155655622,
      "learning_rate": 2.91046511627907e-05,
      "loss": 0.0002,
      "step": 5391
    },
    {
      "epoch": 20.899224806201552,
      "grad_norm": 0.004517815541476011,
      "learning_rate": 2.910077519379845e-05,
      "loss": 0.0002,
      "step": 5392
    },
    {
      "epoch": 20.9031007751938,
      "grad_norm": 0.00247157271951437,
      "learning_rate": 2.90968992248062e-05,
      "loss": 0.0002,
      "step": 5393
    },
    {
      "epoch": 20.906976744186046,
      "grad_norm": 0.00298743206076324,
      "learning_rate": 2.9093023255813956e-05,
      "loss": 0.0002,
      "step": 5394
    },
    {
      "epoch": 20.910852713178294,
      "grad_norm": 0.002522833179682493,
      "learning_rate": 2.9089147286821705e-05,
      "loss": 0.0002,
      "step": 5395
    },
    {
      "epoch": 20.914728682170544,
      "grad_norm": 0.0031531918793916702,
      "learning_rate": 2.908527131782946e-05,
      "loss": 0.0002,
      "step": 5396
    },
    {
      "epoch": 20.91860465116279,
      "grad_norm": 0.004655546974390745,
      "learning_rate": 2.908139534883721e-05,
      "loss": 0.0002,
      "step": 5397
    },
    {
      "epoch": 20.92248062015504,
      "grad_norm": 0.002595598576590419,
      "learning_rate": 2.9077519379844965e-05,
      "loss": 0.0002,
      "step": 5398
    },
    {
      "epoch": 20.926356589147286,
      "grad_norm": 0.00278541655279696,
      "learning_rate": 2.9073643410852714e-05,
      "loss": 0.0002,
      "step": 5399
    },
    {
      "epoch": 20.930232558139537,
      "grad_norm": 0.002256580628454685,
      "learning_rate": 2.9069767441860467e-05,
      "loss": 0.0002,
      "step": 5400
    },
    {
      "epoch": 20.934108527131784,
      "grad_norm": 4.225016117095947,
      "learning_rate": 2.9065891472868216e-05,
      "loss": 0.1712,
      "step": 5401
    },
    {
      "epoch": 20.93798449612403,
      "grad_norm": 0.002514307387173176,
      "learning_rate": 2.906201550387597e-05,
      "loss": 0.0002,
      "step": 5402
    },
    {
      "epoch": 20.941860465116278,
      "grad_norm": 0.0029165390878915787,
      "learning_rate": 2.905813953488372e-05,
      "loss": 0.0002,
      "step": 5403
    },
    {
      "epoch": 20.94573643410853,
      "grad_norm": 0.0025980169884860516,
      "learning_rate": 2.9054263565891476e-05,
      "loss": 0.0002,
      "step": 5404
    },
    {
      "epoch": 20.949612403100776,
      "grad_norm": 0.0022773637901991606,
      "learning_rate": 2.9050387596899225e-05,
      "loss": 0.0002,
      "step": 5405
    },
    {
      "epoch": 20.953488372093023,
      "grad_norm": 0.002652907744050026,
      "learning_rate": 2.904651162790698e-05,
      "loss": 0.0002,
      "step": 5406
    },
    {
      "epoch": 20.95736434108527,
      "grad_norm": 3.005075216293335,
      "learning_rate": 2.904263565891473e-05,
      "loss": 0.3117,
      "step": 5407
    },
    {
      "epoch": 20.96124031007752,
      "grad_norm": 0.7264273166656494,
      "learning_rate": 2.9038759689922486e-05,
      "loss": 0.0378,
      "step": 5408
    },
    {
      "epoch": 20.96511627906977,
      "grad_norm": 0.007626168429851532,
      "learning_rate": 2.9034883720930235e-05,
      "loss": 0.0003,
      "step": 5409
    },
    {
      "epoch": 20.968992248062015,
      "grad_norm": 0.18718361854553223,
      "learning_rate": 2.9031007751937988e-05,
      "loss": 0.0051,
      "step": 5410
    },
    {
      "epoch": 20.972868217054263,
      "grad_norm": 1.6537026166915894,
      "learning_rate": 2.9027131782945737e-05,
      "loss": 0.0134,
      "step": 5411
    },
    {
      "epoch": 20.97674418604651,
      "grad_norm": 0.009439736604690552,
      "learning_rate": 2.9023255813953486e-05,
      "loss": 0.0005,
      "step": 5412
    },
    {
      "epoch": 20.98062015503876,
      "grad_norm": 0.0033319261856377125,
      "learning_rate": 2.901937984496124e-05,
      "loss": 0.0002,
      "step": 5413
    },
    {
      "epoch": 20.984496124031008,
      "grad_norm": 0.0041138967499136925,
      "learning_rate": 2.901550387596899e-05,
      "loss": 0.0003,
      "step": 5414
    },
    {
      "epoch": 20.988372093023255,
      "grad_norm": 0.00501502538099885,
      "learning_rate": 2.9011627906976746e-05,
      "loss": 0.0003,
      "step": 5415
    },
    {
      "epoch": 20.992248062015506,
      "grad_norm": 0.0818106010556221,
      "learning_rate": 2.9007751937984495e-05,
      "loss": 0.0025,
      "step": 5416
    },
    {
      "epoch": 20.996124031007753,
      "grad_norm": 0.0044047157280147076,
      "learning_rate": 2.900387596899225e-05,
      "loss": 0.0002,
      "step": 5417
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.0025447066873311996,
      "learning_rate": 2.9e-05,
      "loss": 0.0002,
      "step": 5418
    },
    {
      "epoch": 21.003875968992247,
      "grad_norm": 0.208333358168602,
      "learning_rate": 2.8996124031007753e-05,
      "loss": 0.0094,
      "step": 5419
    },
    {
      "epoch": 21.007751937984494,
      "grad_norm": 0.002759451512247324,
      "learning_rate": 2.8992248062015505e-05,
      "loss": 0.0002,
      "step": 5420
    },
    {
      "epoch": 21.011627906976745,
      "grad_norm": 1.852604866027832,
      "learning_rate": 2.8988372093023257e-05,
      "loss": 0.262,
      "step": 5421
    },
    {
      "epoch": 21.015503875968992,
      "grad_norm": 0.2791030704975128,
      "learning_rate": 2.8984496124031006e-05,
      "loss": 0.0128,
      "step": 5422
    },
    {
      "epoch": 21.01937984496124,
      "grad_norm": 0.0025274339132010937,
      "learning_rate": 2.8980620155038762e-05,
      "loss": 0.0002,
      "step": 5423
    },
    {
      "epoch": 21.023255813953487,
      "grad_norm": 0.005730003584176302,
      "learning_rate": 2.897674418604651e-05,
      "loss": 0.0004,
      "step": 5424
    },
    {
      "epoch": 21.027131782945737,
      "grad_norm": 0.002401561476290226,
      "learning_rate": 2.8972868217054267e-05,
      "loss": 0.0002,
      "step": 5425
    },
    {
      "epoch": 21.031007751937985,
      "grad_norm": 0.004698305390775204,
      "learning_rate": 2.8968992248062016e-05,
      "loss": 0.0003,
      "step": 5426
    },
    {
      "epoch": 21.03488372093023,
      "grad_norm": 1.3928945064544678,
      "learning_rate": 2.8965116279069772e-05,
      "loss": 0.0346,
      "step": 5427
    },
    {
      "epoch": 21.03875968992248,
      "grad_norm": 1.2925922870635986,
      "learning_rate": 2.896124031007752e-05,
      "loss": 0.0011,
      "step": 5428
    },
    {
      "epoch": 21.04263565891473,
      "grad_norm": 0.18118374049663544,
      "learning_rate": 2.8957364341085273e-05,
      "loss": 0.0083,
      "step": 5429
    },
    {
      "epoch": 21.046511627906977,
      "grad_norm": 0.0031235741917043924,
      "learning_rate": 2.8953488372093022e-05,
      "loss": 0.0002,
      "step": 5430
    },
    {
      "epoch": 21.050387596899224,
      "grad_norm": 0.002233868697658181,
      "learning_rate": 2.8949612403100778e-05,
      "loss": 0.0002,
      "step": 5431
    },
    {
      "epoch": 21.05426356589147,
      "grad_norm": 0.0027831161860376596,
      "learning_rate": 2.8945736434108527e-05,
      "loss": 0.0002,
      "step": 5432
    },
    {
      "epoch": 21.058139534883722,
      "grad_norm": 0.001965470379218459,
      "learning_rate": 2.8941860465116283e-05,
      "loss": 0.0002,
      "step": 5433
    },
    {
      "epoch": 21.06201550387597,
      "grad_norm": 20.92338752746582,
      "learning_rate": 2.8937984496124032e-05,
      "loss": 0.1218,
      "step": 5434
    },
    {
      "epoch": 21.065891472868216,
      "grad_norm": 0.025208961218595505,
      "learning_rate": 2.8934108527131788e-05,
      "loss": 0.0006,
      "step": 5435
    },
    {
      "epoch": 21.069767441860463,
      "grad_norm": 0.002670594025403261,
      "learning_rate": 2.8930232558139537e-05,
      "loss": 0.0002,
      "step": 5436
    },
    {
      "epoch": 21.073643410852714,
      "grad_norm": 0.0020591202192008495,
      "learning_rate": 2.892635658914729e-05,
      "loss": 0.0002,
      "step": 5437
    },
    {
      "epoch": 21.07751937984496,
      "grad_norm": 0.0218826811760664,
      "learning_rate": 2.8922480620155042e-05,
      "loss": 0.0006,
      "step": 5438
    },
    {
      "epoch": 21.08139534883721,
      "grad_norm": 0.0032081741373986006,
      "learning_rate": 2.891860465116279e-05,
      "loss": 0.0002,
      "step": 5439
    },
    {
      "epoch": 21.085271317829456,
      "grad_norm": 0.0017462255200371146,
      "learning_rate": 2.8914728682170543e-05,
      "loss": 0.0002,
      "step": 5440
    },
    {
      "epoch": 21.089147286821706,
      "grad_norm": 0.0024387198500335217,
      "learning_rate": 2.8910852713178292e-05,
      "loss": 0.0002,
      "step": 5441
    },
    {
      "epoch": 21.093023255813954,
      "grad_norm": 0.590829610824585,
      "learning_rate": 2.8906976744186048e-05,
      "loss": 0.0006,
      "step": 5442
    },
    {
      "epoch": 21.0968992248062,
      "grad_norm": 1.8566155433654785,
      "learning_rate": 2.8903100775193797e-05,
      "loss": 0.1955,
      "step": 5443
    },
    {
      "epoch": 21.100775193798448,
      "grad_norm": 0.0018845614977180958,
      "learning_rate": 2.8899224806201553e-05,
      "loss": 0.0002,
      "step": 5444
    },
    {
      "epoch": 21.1046511627907,
      "grad_norm": 0.002912522992119193,
      "learning_rate": 2.8895348837209302e-05,
      "loss": 0.0002,
      "step": 5445
    },
    {
      "epoch": 21.108527131782946,
      "grad_norm": 0.006461492273956537,
      "learning_rate": 2.8891472868217058e-05,
      "loss": 0.0003,
      "step": 5446
    },
    {
      "epoch": 21.112403100775193,
      "grad_norm": 0.007943646982312202,
      "learning_rate": 2.8887596899224807e-05,
      "loss": 0.0003,
      "step": 5447
    },
    {
      "epoch": 21.11627906976744,
      "grad_norm": 2.426741123199463,
      "learning_rate": 2.888372093023256e-05,
      "loss": 0.1609,
      "step": 5448
    },
    {
      "epoch": 21.12015503875969,
      "grad_norm": 0.0026363881770521402,
      "learning_rate": 2.8879844961240308e-05,
      "loss": 0.0003,
      "step": 5449
    },
    {
      "epoch": 21.124031007751938,
      "grad_norm": 2.1178817749023438,
      "learning_rate": 2.8875968992248064e-05,
      "loss": 0.2546,
      "step": 5450
    },
    {
      "epoch": 21.127906976744185,
      "grad_norm": 0.0031274217180907726,
      "learning_rate": 2.8872093023255813e-05,
      "loss": 0.0003,
      "step": 5451
    },
    {
      "epoch": 21.131782945736433,
      "grad_norm": 1.8962572813034058,
      "learning_rate": 2.886821705426357e-05,
      "loss": 0.1301,
      "step": 5452
    },
    {
      "epoch": 21.135658914728683,
      "grad_norm": 0.052579961717128754,
      "learning_rate": 2.8864341085271318e-05,
      "loss": 0.0004,
      "step": 5453
    },
    {
      "epoch": 21.13953488372093,
      "grad_norm": 0.04751944541931152,
      "learning_rate": 2.8860465116279074e-05,
      "loss": 0.0003,
      "step": 5454
    },
    {
      "epoch": 21.143410852713178,
      "grad_norm": 0.0036152433604002,
      "learning_rate": 2.8856589147286823e-05,
      "loss": 0.0003,
      "step": 5455
    },
    {
      "epoch": 21.147286821705425,
      "grad_norm": 0.08403026312589645,
      "learning_rate": 2.885271317829458e-05,
      "loss": 0.0016,
      "step": 5456
    },
    {
      "epoch": 21.151162790697676,
      "grad_norm": 0.002973091322928667,
      "learning_rate": 2.8848837209302328e-05,
      "loss": 0.0002,
      "step": 5457
    },
    {
      "epoch": 21.155038759689923,
      "grad_norm": 0.003424131777137518,
      "learning_rate": 2.884496124031008e-05,
      "loss": 0.0003,
      "step": 5458
    },
    {
      "epoch": 21.15891472868217,
      "grad_norm": 0.0032919705845415592,
      "learning_rate": 2.884108527131783e-05,
      "loss": 0.0003,
      "step": 5459
    },
    {
      "epoch": 21.162790697674417,
      "grad_norm": 0.19841119647026062,
      "learning_rate": 2.8837209302325585e-05,
      "loss": 0.0082,
      "step": 5460
    },
    {
      "epoch": 21.166666666666668,
      "grad_norm": 0.012985583394765854,
      "learning_rate": 2.8833333333333334e-05,
      "loss": 0.0005,
      "step": 5461
    },
    {
      "epoch": 21.170542635658915,
      "grad_norm": 0.00646549928933382,
      "learning_rate": 2.882945736434109e-05,
      "loss": 0.0005,
      "step": 5462
    },
    {
      "epoch": 21.174418604651162,
      "grad_norm": 0.0051134442910552025,
      "learning_rate": 2.882558139534884e-05,
      "loss": 0.0003,
      "step": 5463
    },
    {
      "epoch": 21.17829457364341,
      "grad_norm": 4.783786296844482,
      "learning_rate": 2.8821705426356588e-05,
      "loss": 0.1767,
      "step": 5464
    },
    {
      "epoch": 21.18217054263566,
      "grad_norm": 4.845865249633789,
      "learning_rate": 2.8817829457364344e-05,
      "loss": 0.1968,
      "step": 5465
    },
    {
      "epoch": 21.186046511627907,
      "grad_norm": 0.007664947304874659,
      "learning_rate": 2.8813953488372093e-05,
      "loss": 0.0004,
      "step": 5466
    },
    {
      "epoch": 21.189922480620154,
      "grad_norm": 0.007636635098606348,
      "learning_rate": 2.8810077519379845e-05,
      "loss": 0.0005,
      "step": 5467
    },
    {
      "epoch": 21.1937984496124,
      "grad_norm": 0.012195422314107418,
      "learning_rate": 2.8806201550387598e-05,
      "loss": 0.0007,
      "step": 5468
    },
    {
      "epoch": 21.197674418604652,
      "grad_norm": 0.004354505334049463,
      "learning_rate": 2.880232558139535e-05,
      "loss": 0.0003,
      "step": 5469
    },
    {
      "epoch": 21.2015503875969,
      "grad_norm": 0.005786602385342121,
      "learning_rate": 2.87984496124031e-05,
      "loss": 0.0003,
      "step": 5470
    },
    {
      "epoch": 21.205426356589147,
      "grad_norm": 0.6319368481636047,
      "learning_rate": 2.8794573643410855e-05,
      "loss": 0.0297,
      "step": 5471
    },
    {
      "epoch": 21.209302325581394,
      "grad_norm": 0.004893089644610882,
      "learning_rate": 2.8790697674418604e-05,
      "loss": 0.0003,
      "step": 5472
    },
    {
      "epoch": 21.213178294573645,
      "grad_norm": 1.7026673555374146,
      "learning_rate": 2.878682170542636e-05,
      "loss": 0.111,
      "step": 5473
    },
    {
      "epoch": 21.217054263565892,
      "grad_norm": 0.0038251057267189026,
      "learning_rate": 2.878294573643411e-05,
      "loss": 0.0003,
      "step": 5474
    },
    {
      "epoch": 21.22093023255814,
      "grad_norm": 0.36560335755348206,
      "learning_rate": 2.8779069767441864e-05,
      "loss": 0.0142,
      "step": 5475
    },
    {
      "epoch": 21.224806201550386,
      "grad_norm": 0.0034779321867972612,
      "learning_rate": 2.8775193798449614e-05,
      "loss": 0.0002,
      "step": 5476
    },
    {
      "epoch": 21.228682170542637,
      "grad_norm": 0.14028306305408478,
      "learning_rate": 2.8771317829457366e-05,
      "loss": 0.0025,
      "step": 5477
    },
    {
      "epoch": 21.232558139534884,
      "grad_norm": 0.011998110450804234,
      "learning_rate": 2.8767441860465115e-05,
      "loss": 0.0005,
      "step": 5478
    },
    {
      "epoch": 21.23643410852713,
      "grad_norm": 0.006151730194687843,
      "learning_rate": 2.876356589147287e-05,
      "loss": 0.0004,
      "step": 5479
    },
    {
      "epoch": 21.24031007751938,
      "grad_norm": 0.0363052561879158,
      "learning_rate": 2.875968992248062e-05,
      "loss": 0.0015,
      "step": 5480
    },
    {
      "epoch": 21.24418604651163,
      "grad_norm": 2.6183183193206787,
      "learning_rate": 2.8755813953488376e-05,
      "loss": 0.2142,
      "step": 5481
    },
    {
      "epoch": 21.248062015503876,
      "grad_norm": 1.5304763317108154,
      "learning_rate": 2.8751937984496125e-05,
      "loss": 0.1327,
      "step": 5482
    },
    {
      "epoch": 21.251937984496124,
      "grad_norm": 0.0038141992408782244,
      "learning_rate": 2.874806201550388e-05,
      "loss": 0.0003,
      "step": 5483
    },
    {
      "epoch": 21.25581395348837,
      "grad_norm": 2.062784433364868,
      "learning_rate": 2.874418604651163e-05,
      "loss": 0.0643,
      "step": 5484
    },
    {
      "epoch": 21.25968992248062,
      "grad_norm": 0.04512898251414299,
      "learning_rate": 2.8740310077519382e-05,
      "loss": 0.0016,
      "step": 5485
    },
    {
      "epoch": 21.26356589147287,
      "grad_norm": 0.003513059113174677,
      "learning_rate": 2.8736434108527134e-05,
      "loss": 0.0002,
      "step": 5486
    },
    {
      "epoch": 21.267441860465116,
      "grad_norm": 0.003027249127626419,
      "learning_rate": 2.8732558139534887e-05,
      "loss": 0.0002,
      "step": 5487
    },
    {
      "epoch": 21.271317829457363,
      "grad_norm": 8.673188209533691,
      "learning_rate": 2.8728682170542636e-05,
      "loss": 0.0316,
      "step": 5488
    },
    {
      "epoch": 21.275193798449614,
      "grad_norm": 0.02027236856520176,
      "learning_rate": 2.872480620155039e-05,
      "loss": 0.0006,
      "step": 5489
    },
    {
      "epoch": 21.27906976744186,
      "grad_norm": 0.002500923117622733,
      "learning_rate": 2.872093023255814e-05,
      "loss": 0.0002,
      "step": 5490
    },
    {
      "epoch": 21.282945736434108,
      "grad_norm": 0.006228720303624868,
      "learning_rate": 2.871705426356589e-05,
      "loss": 0.0003,
      "step": 5491
    },
    {
      "epoch": 21.286821705426355,
      "grad_norm": 0.005427477415651083,
      "learning_rate": 2.8713178294573645e-05,
      "loss": 0.0004,
      "step": 5492
    },
    {
      "epoch": 21.290697674418606,
      "grad_norm": 0.002372306538745761,
      "learning_rate": 2.8709302325581395e-05,
      "loss": 0.0002,
      "step": 5493
    },
    {
      "epoch": 21.294573643410853,
      "grad_norm": 0.009092334657907486,
      "learning_rate": 2.870542635658915e-05,
      "loss": 0.0004,
      "step": 5494
    },
    {
      "epoch": 21.2984496124031,
      "grad_norm": 0.0030229550320655107,
      "learning_rate": 2.87015503875969e-05,
      "loss": 0.0002,
      "step": 5495
    },
    {
      "epoch": 21.302325581395348,
      "grad_norm": 4.8254594802856445,
      "learning_rate": 2.8697674418604652e-05,
      "loss": 0.0693,
      "step": 5496
    },
    {
      "epoch": 21.3062015503876,
      "grad_norm": 0.0029192736838012934,
      "learning_rate": 2.86937984496124e-05,
      "loss": 0.0003,
      "step": 5497
    },
    {
      "epoch": 21.310077519379846,
      "grad_norm": 1.5059036016464233,
      "learning_rate": 2.8689922480620157e-05,
      "loss": 0.0739,
      "step": 5498
    },
    {
      "epoch": 21.313953488372093,
      "grad_norm": 0.00335282483138144,
      "learning_rate": 2.8686046511627906e-05,
      "loss": 0.0002,
      "step": 5499
    },
    {
      "epoch": 21.31782945736434,
      "grad_norm": 0.002800552174448967,
      "learning_rate": 2.868217054263566e-05,
      "loss": 0.0002,
      "step": 5500
    },
    {
      "epoch": 21.32170542635659,
      "grad_norm": 0.002187443897128105,
      "learning_rate": 2.867829457364341e-05,
      "loss": 0.0002,
      "step": 5501
    },
    {
      "epoch": 21.325581395348838,
      "grad_norm": 0.0440753810107708,
      "learning_rate": 2.8674418604651166e-05,
      "loss": 0.0009,
      "step": 5502
    },
    {
      "epoch": 21.329457364341085,
      "grad_norm": 2.9828121662139893,
      "learning_rate": 2.8670542635658915e-05,
      "loss": 0.0056,
      "step": 5503
    },
    {
      "epoch": 21.333333333333332,
      "grad_norm": 0.055069420486688614,
      "learning_rate": 2.8666666666666668e-05,
      "loss": 0.0003,
      "step": 5504
    },
    {
      "epoch": 21.337209302325583,
      "grad_norm": 1.7852346897125244,
      "learning_rate": 2.866279069767442e-05,
      "loss": 0.0057,
      "step": 5505
    },
    {
      "epoch": 21.34108527131783,
      "grad_norm": 0.3033544719219208,
      "learning_rate": 2.8658914728682173e-05,
      "loss": 0.0076,
      "step": 5506
    },
    {
      "epoch": 21.344961240310077,
      "grad_norm": 0.00377978989854455,
      "learning_rate": 2.865503875968992e-05,
      "loss": 0.0003,
      "step": 5507
    },
    {
      "epoch": 21.348837209302324,
      "grad_norm": 0.0024230980779975653,
      "learning_rate": 2.8651162790697677e-05,
      "loss": 0.0002,
      "step": 5508
    },
    {
      "epoch": 21.352713178294575,
      "grad_norm": 0.028163259848952293,
      "learning_rate": 2.8647286821705426e-05,
      "loss": 0.0015,
      "step": 5509
    },
    {
      "epoch": 21.356589147286822,
      "grad_norm": 0.0023628580383956432,
      "learning_rate": 2.8643410852713182e-05,
      "loss": 0.0002,
      "step": 5510
    },
    {
      "epoch": 21.36046511627907,
      "grad_norm": 0.0022760869469493628,
      "learning_rate": 2.863953488372093e-05,
      "loss": 0.0002,
      "step": 5511
    },
    {
      "epoch": 21.364341085271317,
      "grad_norm": 0.0018729764269664884,
      "learning_rate": 2.8635658914728687e-05,
      "loss": 0.0002,
      "step": 5512
    },
    {
      "epoch": 21.368217054263567,
      "grad_norm": 0.0023778534960001707,
      "learning_rate": 2.8631782945736436e-05,
      "loss": 0.0002,
      "step": 5513
    },
    {
      "epoch": 21.372093023255815,
      "grad_norm": 0.0024378709495067596,
      "learning_rate": 2.862790697674419e-05,
      "loss": 0.0002,
      "step": 5514
    },
    {
      "epoch": 21.375968992248062,
      "grad_norm": 0.004224806558340788,
      "learning_rate": 2.8624031007751938e-05,
      "loss": 0.0003,
      "step": 5515
    },
    {
      "epoch": 21.37984496124031,
      "grad_norm": 0.0020116306841373444,
      "learning_rate": 2.8620155038759693e-05,
      "loss": 0.0002,
      "step": 5516
    },
    {
      "epoch": 21.38372093023256,
      "grad_norm": 1.8611524105072021,
      "learning_rate": 2.8616279069767442e-05,
      "loss": 0.0121,
      "step": 5517
    },
    {
      "epoch": 21.387596899224807,
      "grad_norm": 1.952120304107666,
      "learning_rate": 2.861240310077519e-05,
      "loss": 0.0325,
      "step": 5518
    },
    {
      "epoch": 21.391472868217054,
      "grad_norm": 0.004096167162060738,
      "learning_rate": 2.8608527131782947e-05,
      "loss": 0.0003,
      "step": 5519
    },
    {
      "epoch": 21.3953488372093,
      "grad_norm": 0.008646330796182156,
      "learning_rate": 2.8604651162790696e-05,
      "loss": 0.0004,
      "step": 5520
    },
    {
      "epoch": 21.399224806201552,
      "grad_norm": 0.0031481157056987286,
      "learning_rate": 2.8600775193798452e-05,
      "loss": 0.0002,
      "step": 5521
    },
    {
      "epoch": 21.4031007751938,
      "grad_norm": 1.0090187788009644,
      "learning_rate": 2.85968992248062e-05,
      "loss": 0.0797,
      "step": 5522
    },
    {
      "epoch": 21.406976744186046,
      "grad_norm": 11.236515045166016,
      "learning_rate": 2.8593023255813957e-05,
      "loss": 0.0943,
      "step": 5523
    },
    {
      "epoch": 21.410852713178294,
      "grad_norm": 0.0030328109860420227,
      "learning_rate": 2.8589147286821706e-05,
      "loss": 0.0002,
      "step": 5524
    },
    {
      "epoch": 21.414728682170544,
      "grad_norm": 0.0033430340699851513,
      "learning_rate": 2.858527131782946e-05,
      "loss": 0.0003,
      "step": 5525
    },
    {
      "epoch": 21.41860465116279,
      "grad_norm": 0.0019240116234868765,
      "learning_rate": 2.8581395348837207e-05,
      "loss": 0.0002,
      "step": 5526
    },
    {
      "epoch": 21.42248062015504,
      "grad_norm": 0.002736615715548396,
      "learning_rate": 2.8577519379844963e-05,
      "loss": 0.0002,
      "step": 5527
    },
    {
      "epoch": 21.426356589147286,
      "grad_norm": 0.0020119722466915846,
      "learning_rate": 2.8573643410852712e-05,
      "loss": 0.0002,
      "step": 5528
    },
    {
      "epoch": 21.430232558139537,
      "grad_norm": 0.0018279640935361385,
      "learning_rate": 2.8569767441860468e-05,
      "loss": 0.0002,
      "step": 5529
    },
    {
      "epoch": 21.434108527131784,
      "grad_norm": 0.32620546221733093,
      "learning_rate": 2.8565891472868217e-05,
      "loss": 0.0037,
      "step": 5530
    },
    {
      "epoch": 21.43798449612403,
      "grad_norm": 0.004059395752847195,
      "learning_rate": 2.8562015503875973e-05,
      "loss": 0.0002,
      "step": 5531
    },
    {
      "epoch": 21.441860465116278,
      "grad_norm": 0.0024957589339464903,
      "learning_rate": 2.8558139534883722e-05,
      "loss": 0.0002,
      "step": 5532
    },
    {
      "epoch": 21.44573643410853,
      "grad_norm": 0.0019894985016435385,
      "learning_rate": 2.8554263565891474e-05,
      "loss": 0.0002,
      "step": 5533
    },
    {
      "epoch": 21.449612403100776,
      "grad_norm": 0.004339058417826891,
      "learning_rate": 2.8550387596899223e-05,
      "loss": 0.0002,
      "step": 5534
    },
    {
      "epoch": 21.453488372093023,
      "grad_norm": 0.0032804468646645546,
      "learning_rate": 2.854651162790698e-05,
      "loss": 0.0002,
      "step": 5535
    },
    {
      "epoch": 21.45736434108527,
      "grad_norm": 0.005090917926281691,
      "learning_rate": 2.854263565891473e-05,
      "loss": 0.0002,
      "step": 5536
    },
    {
      "epoch": 21.46124031007752,
      "grad_norm": 0.002599496627226472,
      "learning_rate": 2.8538759689922484e-05,
      "loss": 0.0002,
      "step": 5537
    },
    {
      "epoch": 21.46511627906977,
      "grad_norm": 0.019247982650995255,
      "learning_rate": 2.8534883720930233e-05,
      "loss": 0.0007,
      "step": 5538
    },
    {
      "epoch": 21.468992248062015,
      "grad_norm": 0.0019834358245134354,
      "learning_rate": 2.853100775193799e-05,
      "loss": 0.0002,
      "step": 5539
    },
    {
      "epoch": 21.472868217054263,
      "grad_norm": 0.003660500282421708,
      "learning_rate": 2.8527131782945738e-05,
      "loss": 0.0002,
      "step": 5540
    },
    {
      "epoch": 21.476744186046513,
      "grad_norm": 15.739970207214355,
      "learning_rate": 2.8523255813953494e-05,
      "loss": 0.5304,
      "step": 5541
    },
    {
      "epoch": 21.48062015503876,
      "grad_norm": 0.993574321269989,
      "learning_rate": 2.8519379844961243e-05,
      "loss": 0.0873,
      "step": 5542
    },
    {
      "epoch": 21.484496124031008,
      "grad_norm": 0.002421703888103366,
      "learning_rate": 2.8515503875968995e-05,
      "loss": 0.0002,
      "step": 5543
    },
    {
      "epoch": 21.488372093023255,
      "grad_norm": 0.0023660266306251287,
      "learning_rate": 2.8511627906976744e-05,
      "loss": 0.0002,
      "step": 5544
    },
    {
      "epoch": 21.492248062015506,
      "grad_norm": 0.0028391212690621614,
      "learning_rate": 2.8507751937984493e-05,
      "loss": 0.0002,
      "step": 5545
    },
    {
      "epoch": 21.496124031007753,
      "grad_norm": 0.0030739896465092897,
      "learning_rate": 2.850387596899225e-05,
      "loss": 0.0002,
      "step": 5546
    },
    {
      "epoch": 21.5,
      "grad_norm": 0.0019094826420769095,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0002,
      "step": 5547
    },
    {
      "epoch": 21.503875968992247,
      "grad_norm": 0.001877435832284391,
      "learning_rate": 2.8496124031007754e-05,
      "loss": 0.0002,
      "step": 5548
    },
    {
      "epoch": 21.507751937984494,
      "grad_norm": 1.564720869064331,
      "learning_rate": 2.8492248062015503e-05,
      "loss": 0.1235,
      "step": 5549
    },
    {
      "epoch": 21.511627906976745,
      "grad_norm": 0.0021312953904271126,
      "learning_rate": 2.848837209302326e-05,
      "loss": 0.0002,
      "step": 5550
    },
    {
      "epoch": 21.515503875968992,
      "grad_norm": 0.013483530841767788,
      "learning_rate": 2.8484496124031008e-05,
      "loss": 0.0003,
      "step": 5551
    },
    {
      "epoch": 21.51937984496124,
      "grad_norm": 0.0027453815564513206,
      "learning_rate": 2.848062015503876e-05,
      "loss": 0.0002,
      "step": 5552
    },
    {
      "epoch": 21.52325581395349,
      "grad_norm": 0.9483575820922852,
      "learning_rate": 2.8476744186046513e-05,
      "loss": 0.0466,
      "step": 5553
    },
    {
      "epoch": 21.527131782945737,
      "grad_norm": 1.407872200012207,
      "learning_rate": 2.8472868217054265e-05,
      "loss": 0.1127,
      "step": 5554
    },
    {
      "epoch": 21.531007751937985,
      "grad_norm": 5.5479416847229,
      "learning_rate": 2.8468992248062014e-05,
      "loss": 0.4151,
      "step": 5555
    },
    {
      "epoch": 21.53488372093023,
      "grad_norm": 0.0035613595973700285,
      "learning_rate": 2.846511627906977e-05,
      "loss": 0.0003,
      "step": 5556
    },
    {
      "epoch": 21.53875968992248,
      "grad_norm": 0.002676568925380707,
      "learning_rate": 2.846124031007752e-05,
      "loss": 0.0002,
      "step": 5557
    },
    {
      "epoch": 21.54263565891473,
      "grad_norm": 0.003536126809194684,
      "learning_rate": 2.8457364341085275e-05,
      "loss": 0.0002,
      "step": 5558
    },
    {
      "epoch": 21.546511627906977,
      "grad_norm": 0.004623514134436846,
      "learning_rate": 2.8453488372093024e-05,
      "loss": 0.0003,
      "step": 5559
    },
    {
      "epoch": 21.550387596899224,
      "grad_norm": 0.0024851749185472727,
      "learning_rate": 2.844961240310078e-05,
      "loss": 0.0002,
      "step": 5560
    },
    {
      "epoch": 21.55426356589147,
      "grad_norm": 0.009554156102240086,
      "learning_rate": 2.844573643410853e-05,
      "loss": 0.0005,
      "step": 5561
    },
    {
      "epoch": 21.558139534883722,
      "grad_norm": 13.796152114868164,
      "learning_rate": 2.844186046511628e-05,
      "loss": 0.2955,
      "step": 5562
    },
    {
      "epoch": 21.56201550387597,
      "grad_norm": 0.7363454699516296,
      "learning_rate": 2.843798449612403e-05,
      "loss": 0.0028,
      "step": 5563
    },
    {
      "epoch": 21.565891472868216,
      "grad_norm": 0.0023000037763267756,
      "learning_rate": 2.8434108527131786e-05,
      "loss": 0.0002,
      "step": 5564
    },
    {
      "epoch": 21.569767441860463,
      "grad_norm": 0.003325595986098051,
      "learning_rate": 2.8430232558139535e-05,
      "loss": 0.0002,
      "step": 5565
    },
    {
      "epoch": 21.573643410852714,
      "grad_norm": 0.18908898532390594,
      "learning_rate": 2.842635658914729e-05,
      "loss": 0.0006,
      "step": 5566
    },
    {
      "epoch": 21.57751937984496,
      "grad_norm": 0.34745877981185913,
      "learning_rate": 2.842248062015504e-05,
      "loss": 0.0027,
      "step": 5567
    },
    {
      "epoch": 21.58139534883721,
      "grad_norm": 0.0018107971409335732,
      "learning_rate": 2.8418604651162796e-05,
      "loss": 0.0002,
      "step": 5568
    },
    {
      "epoch": 21.585271317829456,
      "grad_norm": 0.4530407190322876,
      "learning_rate": 2.8414728682170545e-05,
      "loss": 0.0077,
      "step": 5569
    },
    {
      "epoch": 21.589147286821706,
      "grad_norm": 0.0020040024537593126,
      "learning_rate": 2.8410852713178297e-05,
      "loss": 0.0002,
      "step": 5570
    },
    {
      "epoch": 21.593023255813954,
      "grad_norm": 0.02128661423921585,
      "learning_rate": 2.840697674418605e-05,
      "loss": 0.0008,
      "step": 5571
    },
    {
      "epoch": 21.5968992248062,
      "grad_norm": 0.005210560280829668,
      "learning_rate": 2.84031007751938e-05,
      "loss": 0.0004,
      "step": 5572
    },
    {
      "epoch": 21.600775193798448,
      "grad_norm": 0.00528495479375124,
      "learning_rate": 2.839922480620155e-05,
      "loss": 0.0003,
      "step": 5573
    },
    {
      "epoch": 21.6046511627907,
      "grad_norm": 2.8047196865081787,
      "learning_rate": 2.83953488372093e-05,
      "loss": 0.3534,
      "step": 5574
    },
    {
      "epoch": 21.608527131782946,
      "grad_norm": 0.0053230575285851955,
      "learning_rate": 2.8391472868217056e-05,
      "loss": 0.0003,
      "step": 5575
    },
    {
      "epoch": 21.612403100775193,
      "grad_norm": 0.0017469078302383423,
      "learning_rate": 2.8387596899224805e-05,
      "loss": 0.0002,
      "step": 5576
    },
    {
      "epoch": 21.61627906976744,
      "grad_norm": 0.0017747556557878852,
      "learning_rate": 2.838372093023256e-05,
      "loss": 0.0002,
      "step": 5577
    },
    {
      "epoch": 21.62015503875969,
      "grad_norm": 0.001634168322198093,
      "learning_rate": 2.837984496124031e-05,
      "loss": 0.0002,
      "step": 5578
    },
    {
      "epoch": 21.624031007751938,
      "grad_norm": 0.00471652764827013,
      "learning_rate": 2.8375968992248066e-05,
      "loss": 0.0002,
      "step": 5579
    },
    {
      "epoch": 21.627906976744185,
      "grad_norm": 1.6430928707122803,
      "learning_rate": 2.8372093023255815e-05,
      "loss": 0.0403,
      "step": 5580
    },
    {
      "epoch": 21.631782945736433,
      "grad_norm": 0.004345245659351349,
      "learning_rate": 2.8368217054263567e-05,
      "loss": 0.0002,
      "step": 5581
    },
    {
      "epoch": 21.635658914728683,
      "grad_norm": 0.0015640412457287312,
      "learning_rate": 2.8364341085271316e-05,
      "loss": 0.0002,
      "step": 5582
    },
    {
      "epoch": 21.63953488372093,
      "grad_norm": 0.010218576528131962,
      "learning_rate": 2.8360465116279072e-05,
      "loss": 0.0003,
      "step": 5583
    },
    {
      "epoch": 21.643410852713178,
      "grad_norm": 0.003247995162382722,
      "learning_rate": 2.835658914728682e-05,
      "loss": 0.0003,
      "step": 5584
    },
    {
      "epoch": 21.647286821705425,
      "grad_norm": 0.00820778775960207,
      "learning_rate": 2.8352713178294577e-05,
      "loss": 0.0005,
      "step": 5585
    },
    {
      "epoch": 21.651162790697676,
      "grad_norm": 0.001762567088007927,
      "learning_rate": 2.8348837209302326e-05,
      "loss": 0.0002,
      "step": 5586
    },
    {
      "epoch": 21.655038759689923,
      "grad_norm": 0.0015568743692710996,
      "learning_rate": 2.834496124031008e-05,
      "loss": 0.0002,
      "step": 5587
    },
    {
      "epoch": 21.65891472868217,
      "grad_norm": 0.026138363406062126,
      "learning_rate": 2.834108527131783e-05,
      "loss": 0.0012,
      "step": 5588
    },
    {
      "epoch": 21.662790697674417,
      "grad_norm": 0.5446421504020691,
      "learning_rate": 2.8337209302325586e-05,
      "loss": 0.0205,
      "step": 5589
    },
    {
      "epoch": 21.666666666666668,
      "grad_norm": 0.003901581047102809,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.0002,
      "step": 5590
    },
    {
      "epoch": 21.670542635658915,
      "grad_norm": 0.0017798031913116574,
      "learning_rate": 2.8329457364341088e-05,
      "loss": 0.0002,
      "step": 5591
    },
    {
      "epoch": 21.674418604651162,
      "grad_norm": 8.600224494934082,
      "learning_rate": 2.8325581395348837e-05,
      "loss": 0.4628,
      "step": 5592
    },
    {
      "epoch": 21.67829457364341,
      "grad_norm": 0.0015713619068264961,
      "learning_rate": 2.8321705426356593e-05,
      "loss": 0.0002,
      "step": 5593
    },
    {
      "epoch": 21.68217054263566,
      "grad_norm": 2.288106918334961,
      "learning_rate": 2.831782945736434e-05,
      "loss": 0.2203,
      "step": 5594
    },
    {
      "epoch": 21.686046511627907,
      "grad_norm": 0.0033116298727691174,
      "learning_rate": 2.8313953488372097e-05,
      "loss": 0.0002,
      "step": 5595
    },
    {
      "epoch": 21.689922480620154,
      "grad_norm": 0.1023305356502533,
      "learning_rate": 2.8310077519379847e-05,
      "loss": 0.0027,
      "step": 5596
    },
    {
      "epoch": 21.6937984496124,
      "grad_norm": 1.3704911470413208,
      "learning_rate": 2.8306201550387602e-05,
      "loss": 0.0476,
      "step": 5597
    },
    {
      "epoch": 21.697674418604652,
      "grad_norm": 0.030264031141996384,
      "learning_rate": 2.830232558139535e-05,
      "loss": 0.0005,
      "step": 5598
    },
    {
      "epoch": 21.7015503875969,
      "grad_norm": 0.10341912508010864,
      "learning_rate": 2.82984496124031e-05,
      "loss": 0.0022,
      "step": 5599
    },
    {
      "epoch": 21.705426356589147,
      "grad_norm": 0.05025964230298996,
      "learning_rate": 2.8294573643410853e-05,
      "loss": 0.0013,
      "step": 5600
    },
    {
      "epoch": 21.709302325581394,
      "grad_norm": 0.0026228169444948435,
      "learning_rate": 2.8290697674418605e-05,
      "loss": 0.0002,
      "step": 5601
    },
    {
      "epoch": 21.713178294573645,
      "grad_norm": 14.467105865478516,
      "learning_rate": 2.8286821705426358e-05,
      "loss": 0.2267,
      "step": 5602
    },
    {
      "epoch": 21.717054263565892,
      "grad_norm": 0.0044831871055066586,
      "learning_rate": 2.8282945736434107e-05,
      "loss": 0.0004,
      "step": 5603
    },
    {
      "epoch": 21.72093023255814,
      "grad_norm": 0.0019021111074835062,
      "learning_rate": 2.8279069767441862e-05,
      "loss": 0.0002,
      "step": 5604
    },
    {
      "epoch": 21.724806201550386,
      "grad_norm": 9.005732536315918,
      "learning_rate": 2.827519379844961e-05,
      "loss": 0.2059,
      "step": 5605
    },
    {
      "epoch": 21.728682170542637,
      "grad_norm": 2.6661696434020996,
      "learning_rate": 2.8271317829457367e-05,
      "loss": 0.1093,
      "step": 5606
    },
    {
      "epoch": 21.732558139534884,
      "grad_norm": 0.007608054671436548,
      "learning_rate": 2.8267441860465116e-05,
      "loss": 0.0004,
      "step": 5607
    },
    {
      "epoch": 21.73643410852713,
      "grad_norm": 0.005334186367690563,
      "learning_rate": 2.8263565891472872e-05,
      "loss": 0.0003,
      "step": 5608
    },
    {
      "epoch": 21.74031007751938,
      "grad_norm": 0.0029544460121542215,
      "learning_rate": 2.825968992248062e-05,
      "loss": 0.0002,
      "step": 5609
    },
    {
      "epoch": 21.74418604651163,
      "grad_norm": 4.172381401062012,
      "learning_rate": 2.8255813953488374e-05,
      "loss": 0.0694,
      "step": 5610
    },
    {
      "epoch": 21.748062015503876,
      "grad_norm": 0.005537298042327166,
      "learning_rate": 2.8251937984496123e-05,
      "loss": 0.0004,
      "step": 5611
    },
    {
      "epoch": 21.751937984496124,
      "grad_norm": 0.003545626299455762,
      "learning_rate": 2.824806201550388e-05,
      "loss": 0.0002,
      "step": 5612
    },
    {
      "epoch": 21.75581395348837,
      "grad_norm": 0.00402759900316596,
      "learning_rate": 2.8244186046511628e-05,
      "loss": 0.0003,
      "step": 5613
    },
    {
      "epoch": 21.75968992248062,
      "grad_norm": 0.008379146456718445,
      "learning_rate": 2.8240310077519383e-05,
      "loss": 0.0004,
      "step": 5614
    },
    {
      "epoch": 21.76356589147287,
      "grad_norm": 0.026354288682341576,
      "learning_rate": 2.8236434108527132e-05,
      "loss": 0.0008,
      "step": 5615
    },
    {
      "epoch": 21.767441860465116,
      "grad_norm": 0.006128911394625902,
      "learning_rate": 2.8232558139534888e-05,
      "loss": 0.0004,
      "step": 5616
    },
    {
      "epoch": 21.771317829457363,
      "grad_norm": 0.0034824537578970194,
      "learning_rate": 2.8228682170542637e-05,
      "loss": 0.0002,
      "step": 5617
    },
    {
      "epoch": 21.775193798449614,
      "grad_norm": 0.001825872459448874,
      "learning_rate": 2.822480620155039e-05,
      "loss": 0.0002,
      "step": 5618
    },
    {
      "epoch": 21.77906976744186,
      "grad_norm": 0.003291759639978409,
      "learning_rate": 2.8220930232558142e-05,
      "loss": 0.0002,
      "step": 5619
    },
    {
      "epoch": 21.782945736434108,
      "grad_norm": 0.0016887570964172482,
      "learning_rate": 2.8217054263565894e-05,
      "loss": 0.0002,
      "step": 5620
    },
    {
      "epoch": 21.786821705426355,
      "grad_norm": 0.010415541008114815,
      "learning_rate": 2.8213178294573643e-05,
      "loss": 0.0005,
      "step": 5621
    },
    {
      "epoch": 21.790697674418606,
      "grad_norm": 1.0738976001739502,
      "learning_rate": 2.82093023255814e-05,
      "loss": 0.174,
      "step": 5622
    },
    {
      "epoch": 21.794573643410853,
      "grad_norm": 5.021731376647949,
      "learning_rate": 2.820542635658915e-05,
      "loss": 0.8092,
      "step": 5623
    },
    {
      "epoch": 21.7984496124031,
      "grad_norm": 2.992936611175537,
      "learning_rate": 2.8201550387596897e-05,
      "loss": 0.2752,
      "step": 5624
    },
    {
      "epoch": 21.802325581395348,
      "grad_norm": 2.0986247062683105,
      "learning_rate": 2.8197674418604653e-05,
      "loss": 0.199,
      "step": 5625
    },
    {
      "epoch": 21.8062015503876,
      "grad_norm": 0.3302452564239502,
      "learning_rate": 2.8193798449612402e-05,
      "loss": 0.0011,
      "step": 5626
    },
    {
      "epoch": 21.810077519379846,
      "grad_norm": 0.001463491003960371,
      "learning_rate": 2.8189922480620158e-05,
      "loss": 0.0002,
      "step": 5627
    },
    {
      "epoch": 21.813953488372093,
      "grad_norm": 0.0021218606270849705,
      "learning_rate": 2.8186046511627907e-05,
      "loss": 0.0002,
      "step": 5628
    },
    {
      "epoch": 21.81782945736434,
      "grad_norm": 0.0031929153483361006,
      "learning_rate": 2.818217054263566e-05,
      "loss": 0.0003,
      "step": 5629
    },
    {
      "epoch": 21.82170542635659,
      "grad_norm": 0.0028977268375456333,
      "learning_rate": 2.817829457364341e-05,
      "loss": 0.0002,
      "step": 5630
    },
    {
      "epoch": 21.825581395348838,
      "grad_norm": 3.856548309326172,
      "learning_rate": 2.8174418604651164e-05,
      "loss": 0.063,
      "step": 5631
    },
    {
      "epoch": 21.829457364341085,
      "grad_norm": 0.0026420974172651768,
      "learning_rate": 2.8170542635658913e-05,
      "loss": 0.0002,
      "step": 5632
    },
    {
      "epoch": 21.833333333333332,
      "grad_norm": 0.0018336846260353923,
      "learning_rate": 2.816666666666667e-05,
      "loss": 0.0002,
      "step": 5633
    },
    {
      "epoch": 21.837209302325583,
      "grad_norm": 0.001725269015878439,
      "learning_rate": 2.8162790697674418e-05,
      "loss": 0.0002,
      "step": 5634
    },
    {
      "epoch": 21.84108527131783,
      "grad_norm": 0.0019054916920140386,
      "learning_rate": 2.8158914728682174e-05,
      "loss": 0.0002,
      "step": 5635
    },
    {
      "epoch": 21.844961240310077,
      "grad_norm": 2.896371603012085,
      "learning_rate": 2.8155038759689923e-05,
      "loss": 0.1253,
      "step": 5636
    },
    {
      "epoch": 21.848837209302324,
      "grad_norm": 30.179157257080078,
      "learning_rate": 2.8151162790697675e-05,
      "loss": 0.8934,
      "step": 5637
    },
    {
      "epoch": 21.852713178294575,
      "grad_norm": 0.008502921089529991,
      "learning_rate": 2.8147286821705428e-05,
      "loss": 0.0003,
      "step": 5638
    },
    {
      "epoch": 21.856589147286822,
      "grad_norm": 0.0024608599487692118,
      "learning_rate": 2.814341085271318e-05,
      "loss": 0.0002,
      "step": 5639
    },
    {
      "epoch": 21.86046511627907,
      "grad_norm": 0.007763145491480827,
      "learning_rate": 2.813953488372093e-05,
      "loss": 0.0005,
      "step": 5640
    },
    {
      "epoch": 21.864341085271317,
      "grad_norm": 0.009156160987913609,
      "learning_rate": 2.8135658914728685e-05,
      "loss": 0.0003,
      "step": 5641
    },
    {
      "epoch": 21.868217054263567,
      "grad_norm": 0.002240122528746724,
      "learning_rate": 2.8131782945736434e-05,
      "loss": 0.0002,
      "step": 5642
    },
    {
      "epoch": 21.872093023255815,
      "grad_norm": 0.0031072567217051983,
      "learning_rate": 2.812790697674419e-05,
      "loss": 0.0002,
      "step": 5643
    },
    {
      "epoch": 21.875968992248062,
      "grad_norm": 0.0126169603317976,
      "learning_rate": 2.812403100775194e-05,
      "loss": 0.0005,
      "step": 5644
    },
    {
      "epoch": 21.87984496124031,
      "grad_norm": 0.0021659142803400755,
      "learning_rate": 2.8120155038759695e-05,
      "loss": 0.0002,
      "step": 5645
    },
    {
      "epoch": 21.88372093023256,
      "grad_norm": 0.00459686666727066,
      "learning_rate": 2.8116279069767444e-05,
      "loss": 0.0002,
      "step": 5646
    },
    {
      "epoch": 21.887596899224807,
      "grad_norm": 0.01996712014079094,
      "learning_rate": 2.8112403100775196e-05,
      "loss": 0.0004,
      "step": 5647
    },
    {
      "epoch": 21.891472868217054,
      "grad_norm": 0.017300033941864967,
      "learning_rate": 2.8108527131782945e-05,
      "loss": 0.0007,
      "step": 5648
    },
    {
      "epoch": 21.8953488372093,
      "grad_norm": 0.023930104449391365,
      "learning_rate": 2.81046511627907e-05,
      "loss": 0.0006,
      "step": 5649
    },
    {
      "epoch": 21.899224806201552,
      "grad_norm": 0.008348077535629272,
      "learning_rate": 2.810077519379845e-05,
      "loss": 0.0003,
      "step": 5650
    },
    {
      "epoch": 21.9031007751938,
      "grad_norm": 0.07517102360725403,
      "learning_rate": 2.80968992248062e-05,
      "loss": 0.0014,
      "step": 5651
    },
    {
      "epoch": 21.906976744186046,
      "grad_norm": 0.03289160877466202,
      "learning_rate": 2.8093023255813955e-05,
      "loss": 0.0005,
      "step": 5652
    },
    {
      "epoch": 21.910852713178294,
      "grad_norm": 0.00432570232078433,
      "learning_rate": 2.8089147286821704e-05,
      "loss": 0.0003,
      "step": 5653
    },
    {
      "epoch": 21.914728682170544,
      "grad_norm": 0.05240391194820404,
      "learning_rate": 2.808527131782946e-05,
      "loss": 0.0005,
      "step": 5654
    },
    {
      "epoch": 21.91860465116279,
      "grad_norm": 0.018113436177372932,
      "learning_rate": 2.808139534883721e-05,
      "loss": 0.0004,
      "step": 5655
    },
    {
      "epoch": 21.92248062015504,
      "grad_norm": 0.05514649301767349,
      "learning_rate": 2.8077519379844965e-05,
      "loss": 0.0007,
      "step": 5656
    },
    {
      "epoch": 21.926356589147286,
      "grad_norm": 0.005198645405471325,
      "learning_rate": 2.8073643410852714e-05,
      "loss": 0.0003,
      "step": 5657
    },
    {
      "epoch": 21.930232558139537,
      "grad_norm": 0.018233664333820343,
      "learning_rate": 2.8069767441860466e-05,
      "loss": 0.0004,
      "step": 5658
    },
    {
      "epoch": 21.934108527131784,
      "grad_norm": 0.02397054247558117,
      "learning_rate": 2.8065891472868215e-05,
      "loss": 0.0004,
      "step": 5659
    },
    {
      "epoch": 21.93798449612403,
      "grad_norm": 0.3304133713245392,
      "learning_rate": 2.806201550387597e-05,
      "loss": 0.0049,
      "step": 5660
    },
    {
      "epoch": 21.941860465116278,
      "grad_norm": 0.0037638128269463778,
      "learning_rate": 2.805813953488372e-05,
      "loss": 0.0003,
      "step": 5661
    },
    {
      "epoch": 21.94573643410853,
      "grad_norm": 0.021726835519075394,
      "learning_rate": 2.8054263565891476e-05,
      "loss": 0.0005,
      "step": 5662
    },
    {
      "epoch": 21.949612403100776,
      "grad_norm": 0.2739477753639221,
      "learning_rate": 2.8050387596899225e-05,
      "loss": 0.003,
      "step": 5663
    },
    {
      "epoch": 21.953488372093023,
      "grad_norm": 0.010700170882046223,
      "learning_rate": 2.804651162790698e-05,
      "loss": 0.0003,
      "step": 5664
    },
    {
      "epoch": 21.95736434108527,
      "grad_norm": 0.010587561875581741,
      "learning_rate": 2.804263565891473e-05,
      "loss": 0.0003,
      "step": 5665
    },
    {
      "epoch": 21.96124031007752,
      "grad_norm": 0.006268846802413464,
      "learning_rate": 2.8038759689922482e-05,
      "loss": 0.0003,
      "step": 5666
    },
    {
      "epoch": 21.96511627906977,
      "grad_norm": 0.002625711727887392,
      "learning_rate": 2.803488372093023e-05,
      "loss": 0.0002,
      "step": 5667
    },
    {
      "epoch": 21.968992248062015,
      "grad_norm": 3.3590242862701416,
      "learning_rate": 2.8031007751937987e-05,
      "loss": 0.0771,
      "step": 5668
    },
    {
      "epoch": 21.972868217054263,
      "grad_norm": 0.03668240085244179,
      "learning_rate": 2.8027131782945736e-05,
      "loss": 0.0007,
      "step": 5669
    },
    {
      "epoch": 21.97674418604651,
      "grad_norm": 0.25634264945983887,
      "learning_rate": 2.8023255813953492e-05,
      "loss": 0.0034,
      "step": 5670
    },
    {
      "epoch": 21.98062015503876,
      "grad_norm": 0.007520873099565506,
      "learning_rate": 2.801937984496124e-05,
      "loss": 0.0003,
      "step": 5671
    },
    {
      "epoch": 21.984496124031008,
      "grad_norm": 0.0026984582655131817,
      "learning_rate": 2.8015503875968997e-05,
      "loss": 0.0002,
      "step": 5672
    },
    {
      "epoch": 21.988372093023255,
      "grad_norm": 0.020019803196191788,
      "learning_rate": 2.8011627906976746e-05,
      "loss": 0.0008,
      "step": 5673
    },
    {
      "epoch": 21.992248062015506,
      "grad_norm": 0.008082577027380466,
      "learning_rate": 2.80077519379845e-05,
      "loss": 0.0004,
      "step": 5674
    },
    {
      "epoch": 21.996124031007753,
      "grad_norm": 0.006732154171913862,
      "learning_rate": 2.800387596899225e-05,
      "loss": 0.0002,
      "step": 5675
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.004837900400161743,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0003,
      "step": 5676
    },
    {
      "epoch": 22.003875968992247,
      "grad_norm": 0.2936221957206726,
      "learning_rate": 2.7996124031007752e-05,
      "loss": 0.0073,
      "step": 5677
    },
    {
      "epoch": 22.007751937984494,
      "grad_norm": 0.002921762876212597,
      "learning_rate": 2.79922480620155e-05,
      "loss": 0.0002,
      "step": 5678
    },
    {
      "epoch": 22.011627906976745,
      "grad_norm": 0.0017556778620928526,
      "learning_rate": 2.7988372093023257e-05,
      "loss": 0.0002,
      "step": 5679
    },
    {
      "epoch": 22.015503875968992,
      "grad_norm": 0.004269451834261417,
      "learning_rate": 2.7984496124031006e-05,
      "loss": 0.0003,
      "step": 5680
    },
    {
      "epoch": 22.01937984496124,
      "grad_norm": 7.35493803024292,
      "learning_rate": 2.798062015503876e-05,
      "loss": 0.0826,
      "step": 5681
    },
    {
      "epoch": 22.023255813953487,
      "grad_norm": 0.002355216071009636,
      "learning_rate": 2.797674418604651e-05,
      "loss": 0.0002,
      "step": 5682
    },
    {
      "epoch": 22.027131782945737,
      "grad_norm": 0.007472232915461063,
      "learning_rate": 2.7972868217054267e-05,
      "loss": 0.0004,
      "step": 5683
    },
    {
      "epoch": 22.031007751937985,
      "grad_norm": 1.0841388702392578,
      "learning_rate": 2.7968992248062016e-05,
      "loss": 0.0617,
      "step": 5684
    },
    {
      "epoch": 22.03488372093023,
      "grad_norm": 0.5545451641082764,
      "learning_rate": 2.7965116279069768e-05,
      "loss": 0.0071,
      "step": 5685
    },
    {
      "epoch": 22.03875968992248,
      "grad_norm": 0.002332026371732354,
      "learning_rate": 2.796124031007752e-05,
      "loss": 0.0002,
      "step": 5686
    },
    {
      "epoch": 22.04263565891473,
      "grad_norm": 0.008063438348472118,
      "learning_rate": 2.7957364341085273e-05,
      "loss": 0.0005,
      "step": 5687
    },
    {
      "epoch": 22.046511627906977,
      "grad_norm": 0.0030826167203485966,
      "learning_rate": 2.7953488372093022e-05,
      "loss": 0.0002,
      "step": 5688
    },
    {
      "epoch": 22.050387596899224,
      "grad_norm": 0.0018418801482766867,
      "learning_rate": 2.7949612403100778e-05,
      "loss": 0.0002,
      "step": 5689
    },
    {
      "epoch": 22.05426356589147,
      "grad_norm": 0.0022106608375906944,
      "learning_rate": 2.7945736434108527e-05,
      "loss": 0.0002,
      "step": 5690
    },
    {
      "epoch": 22.058139534883722,
      "grad_norm": 2.869455099105835,
      "learning_rate": 2.7941860465116283e-05,
      "loss": 0.0895,
      "step": 5691
    },
    {
      "epoch": 22.06201550387597,
      "grad_norm": 0.022410141304135323,
      "learning_rate": 2.793798449612403e-05,
      "loss": 0.001,
      "step": 5692
    },
    {
      "epoch": 22.065891472868216,
      "grad_norm": 0.0018748535076156259,
      "learning_rate": 2.7934108527131787e-05,
      "loss": 0.0002,
      "step": 5693
    },
    {
      "epoch": 22.069767441860463,
      "grad_norm": 0.002145258476957679,
      "learning_rate": 2.7930232558139536e-05,
      "loss": 0.0002,
      "step": 5694
    },
    {
      "epoch": 22.073643410852714,
      "grad_norm": 0.001989736221730709,
      "learning_rate": 2.792635658914729e-05,
      "loss": 0.0002,
      "step": 5695
    },
    {
      "epoch": 22.07751937984496,
      "grad_norm": 0.0020811972208321095,
      "learning_rate": 2.7922480620155038e-05,
      "loss": 0.0002,
      "step": 5696
    },
    {
      "epoch": 22.08139534883721,
      "grad_norm": 0.0021388516761362553,
      "learning_rate": 2.7918604651162794e-05,
      "loss": 0.0002,
      "step": 5697
    },
    {
      "epoch": 22.085271317829456,
      "grad_norm": 0.0021297549828886986,
      "learning_rate": 2.7914728682170543e-05,
      "loss": 0.0002,
      "step": 5698
    },
    {
      "epoch": 22.089147286821706,
      "grad_norm": 0.0024709124118089676,
      "learning_rate": 2.79108527131783e-05,
      "loss": 0.0002,
      "step": 5699
    },
    {
      "epoch": 22.093023255813954,
      "grad_norm": 0.019294219091534615,
      "learning_rate": 2.7906976744186048e-05,
      "loss": 0.0009,
      "step": 5700
    },
    {
      "epoch": 22.0968992248062,
      "grad_norm": 0.002860254840925336,
      "learning_rate": 2.7903100775193803e-05,
      "loss": 0.0002,
      "step": 5701
    },
    {
      "epoch": 22.100775193798448,
      "grad_norm": 0.16881605982780457,
      "learning_rate": 2.7899224806201552e-05,
      "loss": 0.0034,
      "step": 5702
    },
    {
      "epoch": 22.1046511627907,
      "grad_norm": 0.0017258541192859411,
      "learning_rate": 2.7895348837209305e-05,
      "loss": 0.0002,
      "step": 5703
    },
    {
      "epoch": 22.108527131782946,
      "grad_norm": 0.0031573104206472635,
      "learning_rate": 2.7891472868217057e-05,
      "loss": 0.0003,
      "step": 5704
    },
    {
      "epoch": 22.112403100775193,
      "grad_norm": 0.011495107784867287,
      "learning_rate": 2.7887596899224806e-05,
      "loss": 0.0005,
      "step": 5705
    },
    {
      "epoch": 22.11627906976744,
      "grad_norm": 0.0306328684091568,
      "learning_rate": 2.788372093023256e-05,
      "loss": 0.001,
      "step": 5706
    },
    {
      "epoch": 22.12015503875969,
      "grad_norm": 0.002861018292605877,
      "learning_rate": 2.7879844961240308e-05,
      "loss": 0.0002,
      "step": 5707
    },
    {
      "epoch": 22.124031007751938,
      "grad_norm": 1.7922276258468628,
      "learning_rate": 2.7875968992248064e-05,
      "loss": 0.0775,
      "step": 5708
    },
    {
      "epoch": 22.127906976744185,
      "grad_norm": 1.0628513097763062,
      "learning_rate": 2.7872093023255813e-05,
      "loss": 0.086,
      "step": 5709
    },
    {
      "epoch": 22.131782945736433,
      "grad_norm": 0.0029581584967672825,
      "learning_rate": 2.786821705426357e-05,
      "loss": 0.0002,
      "step": 5710
    },
    {
      "epoch": 22.135658914728683,
      "grad_norm": 0.003390556899830699,
      "learning_rate": 2.7864341085271317e-05,
      "loss": 0.0002,
      "step": 5711
    },
    {
      "epoch": 22.13953488372093,
      "grad_norm": 0.0015981661854311824,
      "learning_rate": 2.7860465116279073e-05,
      "loss": 0.0002,
      "step": 5712
    },
    {
      "epoch": 22.143410852713178,
      "grad_norm": 0.00188756687566638,
      "learning_rate": 2.7856589147286822e-05,
      "loss": 0.0002,
      "step": 5713
    },
    {
      "epoch": 22.147286821705425,
      "grad_norm": 0.002115513663738966,
      "learning_rate": 2.7852713178294575e-05,
      "loss": 0.0002,
      "step": 5714
    },
    {
      "epoch": 22.151162790697676,
      "grad_norm": 0.001881664153188467,
      "learning_rate": 2.7848837209302324e-05,
      "loss": 0.0002,
      "step": 5715
    },
    {
      "epoch": 22.155038759689923,
      "grad_norm": 0.0023186372127383947,
      "learning_rate": 2.784496124031008e-05,
      "loss": 0.0002,
      "step": 5716
    },
    {
      "epoch": 22.15891472868217,
      "grad_norm": 0.003417499829083681,
      "learning_rate": 2.784108527131783e-05,
      "loss": 0.0002,
      "step": 5717
    },
    {
      "epoch": 22.162790697674417,
      "grad_norm": 0.5522717833518982,
      "learning_rate": 2.7837209302325584e-05,
      "loss": 0.0317,
      "step": 5718
    },
    {
      "epoch": 22.166666666666668,
      "grad_norm": 6.332208156585693,
      "learning_rate": 2.7833333333333333e-05,
      "loss": 0.1039,
      "step": 5719
    },
    {
      "epoch": 22.170542635658915,
      "grad_norm": 0.0025509046390652657,
      "learning_rate": 2.782945736434109e-05,
      "loss": 0.0002,
      "step": 5720
    },
    {
      "epoch": 22.174418604651162,
      "grad_norm": 1.473825216293335,
      "learning_rate": 2.7825581395348838e-05,
      "loss": 0.0003,
      "step": 5721
    },
    {
      "epoch": 22.17829457364341,
      "grad_norm": 0.003538672812283039,
      "learning_rate": 2.7821705426356594e-05,
      "loss": 0.0002,
      "step": 5722
    },
    {
      "epoch": 22.18217054263566,
      "grad_norm": 0.0019476594170555472,
      "learning_rate": 2.7817829457364343e-05,
      "loss": 0.0002,
      "step": 5723
    },
    {
      "epoch": 22.186046511627907,
      "grad_norm": 0.004842766094952822,
      "learning_rate": 2.7813953488372095e-05,
      "loss": 0.0003,
      "step": 5724
    },
    {
      "epoch": 22.189922480620154,
      "grad_norm": 0.0023033979814499617,
      "learning_rate": 2.7810077519379845e-05,
      "loss": 0.0002,
      "step": 5725
    },
    {
      "epoch": 22.1937984496124,
      "grad_norm": 0.002024655696004629,
      "learning_rate": 2.78062015503876e-05,
      "loss": 0.0002,
      "step": 5726
    },
    {
      "epoch": 22.197674418604652,
      "grad_norm": 0.021240776404738426,
      "learning_rate": 2.780232558139535e-05,
      "loss": 0.0006,
      "step": 5727
    },
    {
      "epoch": 22.2015503875969,
      "grad_norm": 0.0027711016591638327,
      "learning_rate": 2.7798449612403105e-05,
      "loss": 0.0002,
      "step": 5728
    },
    {
      "epoch": 22.205426356589147,
      "grad_norm": 2.877101421356201,
      "learning_rate": 2.7794573643410854e-05,
      "loss": 0.2816,
      "step": 5729
    },
    {
      "epoch": 22.209302325581394,
      "grad_norm": 0.005317891947925091,
      "learning_rate": 2.779069767441861e-05,
      "loss": 0.0004,
      "step": 5730
    },
    {
      "epoch": 22.213178294573645,
      "grad_norm": 0.45662960410118103,
      "learning_rate": 2.778682170542636e-05,
      "loss": 0.0221,
      "step": 5731
    },
    {
      "epoch": 22.217054263565892,
      "grad_norm": 5.805454730987549,
      "learning_rate": 2.7782945736434108e-05,
      "loss": 0.0075,
      "step": 5732
    },
    {
      "epoch": 22.22093023255814,
      "grad_norm": 0.002059422666206956,
      "learning_rate": 2.777906976744186e-05,
      "loss": 0.0002,
      "step": 5733
    },
    {
      "epoch": 22.224806201550386,
      "grad_norm": 1.5634478330612183,
      "learning_rate": 2.7775193798449613e-05,
      "loss": 0.0064,
      "step": 5734
    },
    {
      "epoch": 22.228682170542637,
      "grad_norm": 0.0021051946096122265,
      "learning_rate": 2.7771317829457365e-05,
      "loss": 0.0002,
      "step": 5735
    },
    {
      "epoch": 22.232558139534884,
      "grad_norm": 0.0016974444733932614,
      "learning_rate": 2.7767441860465114e-05,
      "loss": 0.0002,
      "step": 5736
    },
    {
      "epoch": 22.23643410852713,
      "grad_norm": 0.0019849506206810474,
      "learning_rate": 2.776356589147287e-05,
      "loss": 0.0002,
      "step": 5737
    },
    {
      "epoch": 22.24031007751938,
      "grad_norm": 3.008333444595337,
      "learning_rate": 2.775968992248062e-05,
      "loss": 0.2299,
      "step": 5738
    },
    {
      "epoch": 22.24418604651163,
      "grad_norm": 0.0020435883197933435,
      "learning_rate": 2.7755813953488375e-05,
      "loss": 0.0002,
      "step": 5739
    },
    {
      "epoch": 22.248062015503876,
      "grad_norm": 0.0018669201526790857,
      "learning_rate": 2.7751937984496124e-05,
      "loss": 0.0002,
      "step": 5740
    },
    {
      "epoch": 22.251937984496124,
      "grad_norm": 0.0016976570477709174,
      "learning_rate": 2.774806201550388e-05,
      "loss": 0.0002,
      "step": 5741
    },
    {
      "epoch": 22.25581395348837,
      "grad_norm": 0.0015095684211701155,
      "learning_rate": 2.774418604651163e-05,
      "loss": 0.0002,
      "step": 5742
    },
    {
      "epoch": 22.25968992248062,
      "grad_norm": 0.0020280734170228243,
      "learning_rate": 2.774031007751938e-05,
      "loss": 0.0002,
      "step": 5743
    },
    {
      "epoch": 22.26356589147287,
      "grad_norm": 0.7810481190681458,
      "learning_rate": 2.773643410852713e-05,
      "loss": 0.0289,
      "step": 5744
    },
    {
      "epoch": 22.267441860465116,
      "grad_norm": 10.023905754089355,
      "learning_rate": 2.7732558139534886e-05,
      "loss": 0.0731,
      "step": 5745
    },
    {
      "epoch": 22.271317829457363,
      "grad_norm": 0.0017147386679425836,
      "learning_rate": 2.7728682170542635e-05,
      "loss": 0.0002,
      "step": 5746
    },
    {
      "epoch": 22.275193798449614,
      "grad_norm": 0.005515279248356819,
      "learning_rate": 2.772480620155039e-05,
      "loss": 0.0004,
      "step": 5747
    },
    {
      "epoch": 22.27906976744186,
      "grad_norm": 0.0014613332459703088,
      "learning_rate": 2.772093023255814e-05,
      "loss": 0.0002,
      "step": 5748
    },
    {
      "epoch": 22.282945736434108,
      "grad_norm": 0.002397670643404126,
      "learning_rate": 2.7717054263565896e-05,
      "loss": 0.0002,
      "step": 5749
    },
    {
      "epoch": 22.286821705426355,
      "grad_norm": 0.0024402602575719357,
      "learning_rate": 2.7713178294573645e-05,
      "loss": 0.0002,
      "step": 5750
    },
    {
      "epoch": 22.290697674418606,
      "grad_norm": 0.0020782339852303267,
      "learning_rate": 2.7709302325581397e-05,
      "loss": 0.0002,
      "step": 5751
    },
    {
      "epoch": 22.294573643410853,
      "grad_norm": 14.28020191192627,
      "learning_rate": 2.770542635658915e-05,
      "loss": 0.2045,
      "step": 5752
    },
    {
      "epoch": 22.2984496124031,
      "grad_norm": 1.0314737558364868,
      "learning_rate": 2.7701550387596902e-05,
      "loss": 0.0611,
      "step": 5753
    },
    {
      "epoch": 22.302325581395348,
      "grad_norm": 0.0013639669632539153,
      "learning_rate": 2.769767441860465e-05,
      "loss": 0.0001,
      "step": 5754
    },
    {
      "epoch": 22.3062015503876,
      "grad_norm": 4.691043853759766,
      "learning_rate": 2.7693798449612407e-05,
      "loss": 0.0799,
      "step": 5755
    },
    {
      "epoch": 22.310077519379846,
      "grad_norm": 0.005110975820571184,
      "learning_rate": 2.7689922480620156e-05,
      "loss": 0.0003,
      "step": 5756
    },
    {
      "epoch": 22.313953488372093,
      "grad_norm": 0.004175794310867786,
      "learning_rate": 2.7686046511627912e-05,
      "loss": 0.0003,
      "step": 5757
    },
    {
      "epoch": 22.31782945736434,
      "grad_norm": 0.001442797714844346,
      "learning_rate": 2.768217054263566e-05,
      "loss": 0.0002,
      "step": 5758
    },
    {
      "epoch": 22.32170542635659,
      "grad_norm": 0.775790810585022,
      "learning_rate": 2.767829457364341e-05,
      "loss": 0.0425,
      "step": 5759
    },
    {
      "epoch": 22.325581395348838,
      "grad_norm": 0.002955049742013216,
      "learning_rate": 2.7674418604651166e-05,
      "loss": 0.0002,
      "step": 5760
    },
    {
      "epoch": 22.329457364341085,
      "grad_norm": 0.003449640003964305,
      "learning_rate": 2.7670542635658915e-05,
      "loss": 0.0002,
      "step": 5761
    },
    {
      "epoch": 22.333333333333332,
      "grad_norm": 0.001451070886105299,
      "learning_rate": 2.7666666666666667e-05,
      "loss": 0.0002,
      "step": 5762
    },
    {
      "epoch": 22.337209302325583,
      "grad_norm": 1.6290035247802734,
      "learning_rate": 2.7662790697674416e-05,
      "loss": 0.1001,
      "step": 5763
    },
    {
      "epoch": 22.34108527131783,
      "grad_norm": 13.970890998840332,
      "learning_rate": 2.7658914728682172e-05,
      "loss": 0.095,
      "step": 5764
    },
    {
      "epoch": 22.344961240310077,
      "grad_norm": 0.00927087850868702,
      "learning_rate": 2.765503875968992e-05,
      "loss": 0.0005,
      "step": 5765
    },
    {
      "epoch": 22.348837209302324,
      "grad_norm": 0.0014539780095219612,
      "learning_rate": 2.7651162790697677e-05,
      "loss": 0.0002,
      "step": 5766
    },
    {
      "epoch": 22.352713178294575,
      "grad_norm": 1.2640677690505981,
      "learning_rate": 2.7647286821705426e-05,
      "loss": 0.0545,
      "step": 5767
    },
    {
      "epoch": 22.356589147286822,
      "grad_norm": 0.002680875826627016,
      "learning_rate": 2.7643410852713182e-05,
      "loss": 0.0002,
      "step": 5768
    },
    {
      "epoch": 22.36046511627907,
      "grad_norm": 0.22126223146915436,
      "learning_rate": 2.763953488372093e-05,
      "loss": 0.0004,
      "step": 5769
    },
    {
      "epoch": 22.364341085271317,
      "grad_norm": 8.720928192138672,
      "learning_rate": 2.7635658914728683e-05,
      "loss": 0.3835,
      "step": 5770
    },
    {
      "epoch": 22.368217054263567,
      "grad_norm": 0.0014448786387220025,
      "learning_rate": 2.7631782945736436e-05,
      "loss": 0.0002,
      "step": 5771
    },
    {
      "epoch": 22.372093023255815,
      "grad_norm": 0.0025259386748075485,
      "learning_rate": 2.7627906976744188e-05,
      "loss": 0.0003,
      "step": 5772
    },
    {
      "epoch": 22.375968992248062,
      "grad_norm": 1.0387002229690552,
      "learning_rate": 2.7624031007751937e-05,
      "loss": 0.0974,
      "step": 5773
    },
    {
      "epoch": 22.37984496124031,
      "grad_norm": 0.0018050947692245245,
      "learning_rate": 2.7620155038759693e-05,
      "loss": 0.0002,
      "step": 5774
    },
    {
      "epoch": 22.38372093023256,
      "grad_norm": 0.043801918625831604,
      "learning_rate": 2.7616279069767442e-05,
      "loss": 0.0013,
      "step": 5775
    },
    {
      "epoch": 22.387596899224807,
      "grad_norm": 0.016296789050102234,
      "learning_rate": 2.7612403100775198e-05,
      "loss": 0.0004,
      "step": 5776
    },
    {
      "epoch": 22.391472868217054,
      "grad_norm": 0.0024209737312048674,
      "learning_rate": 2.7608527131782947e-05,
      "loss": 0.0002,
      "step": 5777
    },
    {
      "epoch": 22.3953488372093,
      "grad_norm": 0.0014844754477962852,
      "learning_rate": 2.7604651162790703e-05,
      "loss": 0.0002,
      "step": 5778
    },
    {
      "epoch": 22.399224806201552,
      "grad_norm": 0.42035362124443054,
      "learning_rate": 2.760077519379845e-05,
      "loss": 0.0165,
      "step": 5779
    },
    {
      "epoch": 22.4031007751938,
      "grad_norm": 1.5605340003967285,
      "learning_rate": 2.7596899224806204e-05,
      "loss": 0.1167,
      "step": 5780
    },
    {
      "epoch": 22.406976744186046,
      "grad_norm": 0.00589918764308095,
      "learning_rate": 2.7593023255813953e-05,
      "loss": 0.0003,
      "step": 5781
    },
    {
      "epoch": 22.410852713178294,
      "grad_norm": 0.013508716598153114,
      "learning_rate": 2.758914728682171e-05,
      "loss": 0.0007,
      "step": 5782
    },
    {
      "epoch": 22.414728682170544,
      "grad_norm": 0.0037477987352758646,
      "learning_rate": 2.7585271317829458e-05,
      "loss": 0.0002,
      "step": 5783
    },
    {
      "epoch": 22.41860465116279,
      "grad_norm": 0.0058386242017149925,
      "learning_rate": 2.7581395348837207e-05,
      "loss": 0.0004,
      "step": 5784
    },
    {
      "epoch": 22.42248062015504,
      "grad_norm": 1.6194061040878296,
      "learning_rate": 2.7577519379844963e-05,
      "loss": 0.0688,
      "step": 5785
    },
    {
      "epoch": 22.426356589147286,
      "grad_norm": 0.0014512119814753532,
      "learning_rate": 2.7573643410852712e-05,
      "loss": 0.0002,
      "step": 5786
    },
    {
      "epoch": 22.430232558139537,
      "grad_norm": 0.0015024063177406788,
      "learning_rate": 2.7569767441860468e-05,
      "loss": 0.0002,
      "step": 5787
    },
    {
      "epoch": 22.434108527131784,
      "grad_norm": 0.0029520229436457157,
      "learning_rate": 2.7565891472868217e-05,
      "loss": 0.0003,
      "step": 5788
    },
    {
      "epoch": 22.43798449612403,
      "grad_norm": 0.00599623192101717,
      "learning_rate": 2.7562015503875972e-05,
      "loss": 0.0004,
      "step": 5789
    },
    {
      "epoch": 22.441860465116278,
      "grad_norm": 0.0019018655875697732,
      "learning_rate": 2.755813953488372e-05,
      "loss": 0.0002,
      "step": 5790
    },
    {
      "epoch": 22.44573643410853,
      "grad_norm": 0.0016788531793281436,
      "learning_rate": 2.7554263565891474e-05,
      "loss": 0.0002,
      "step": 5791
    },
    {
      "epoch": 22.449612403100776,
      "grad_norm": 0.0016719335690140724,
      "learning_rate": 2.7550387596899223e-05,
      "loss": 0.0002,
      "step": 5792
    },
    {
      "epoch": 22.453488372093023,
      "grad_norm": 0.0032528324518352747,
      "learning_rate": 2.754651162790698e-05,
      "loss": 0.0002,
      "step": 5793
    },
    {
      "epoch": 22.45736434108527,
      "grad_norm": 0.006705436855554581,
      "learning_rate": 2.7542635658914728e-05,
      "loss": 0.0003,
      "step": 5794
    },
    {
      "epoch": 22.46124031007752,
      "grad_norm": 0.0024871863424777985,
      "learning_rate": 2.7538759689922484e-05,
      "loss": 0.0002,
      "step": 5795
    },
    {
      "epoch": 22.46511627906977,
      "grad_norm": 0.002776872366666794,
      "learning_rate": 2.7534883720930233e-05,
      "loss": 0.0003,
      "step": 5796
    },
    {
      "epoch": 22.468992248062015,
      "grad_norm": 0.0018086273921653628,
      "learning_rate": 2.753100775193799e-05,
      "loss": 0.0002,
      "step": 5797
    },
    {
      "epoch": 22.472868217054263,
      "grad_norm": 0.0036184522323310375,
      "learning_rate": 2.7527131782945737e-05,
      "loss": 0.0002,
      "step": 5798
    },
    {
      "epoch": 22.476744186046513,
      "grad_norm": 0.001507667126134038,
      "learning_rate": 2.752325581395349e-05,
      "loss": 0.0002,
      "step": 5799
    },
    {
      "epoch": 22.48062015503876,
      "grad_norm": 0.0017945090075954795,
      "learning_rate": 2.751937984496124e-05,
      "loss": 0.0002,
      "step": 5800
    },
    {
      "epoch": 22.484496124031008,
      "grad_norm": 0.0019109788117930293,
      "learning_rate": 2.7515503875968995e-05,
      "loss": 0.0002,
      "step": 5801
    },
    {
      "epoch": 22.488372093023255,
      "grad_norm": 0.004573894664645195,
      "learning_rate": 2.7511627906976744e-05,
      "loss": 0.0002,
      "step": 5802
    },
    {
      "epoch": 22.492248062015506,
      "grad_norm": 0.0015104867052286863,
      "learning_rate": 2.75077519379845e-05,
      "loss": 0.0002,
      "step": 5803
    },
    {
      "epoch": 22.496124031007753,
      "grad_norm": 0.0017481934046372771,
      "learning_rate": 2.750387596899225e-05,
      "loss": 0.0002,
      "step": 5804
    },
    {
      "epoch": 22.5,
      "grad_norm": 0.010624551214277744,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.0003,
      "step": 5805
    },
    {
      "epoch": 22.503875968992247,
      "grad_norm": 2.642733097076416,
      "learning_rate": 2.7496124031007753e-05,
      "loss": 0.0497,
      "step": 5806
    },
    {
      "epoch": 22.507751937984494,
      "grad_norm": 0.0016903744544833899,
      "learning_rate": 2.749224806201551e-05,
      "loss": 0.0002,
      "step": 5807
    },
    {
      "epoch": 22.511627906976745,
      "grad_norm": 0.0018042929004877806,
      "learning_rate": 2.7488372093023258e-05,
      "loss": 0.0002,
      "step": 5808
    },
    {
      "epoch": 22.515503875968992,
      "grad_norm": 0.049396954476833344,
      "learning_rate": 2.748449612403101e-05,
      "loss": 0.0013,
      "step": 5809
    },
    {
      "epoch": 22.51937984496124,
      "grad_norm": 0.0017631344962865114,
      "learning_rate": 2.748062015503876e-05,
      "loss": 0.0002,
      "step": 5810
    },
    {
      "epoch": 22.52325581395349,
      "grad_norm": 3.8654181957244873,
      "learning_rate": 2.747674418604651e-05,
      "loss": 0.2249,
      "step": 5811
    },
    {
      "epoch": 22.527131782945737,
      "grad_norm": 0.0015589826507493854,
      "learning_rate": 2.7472868217054265e-05,
      "loss": 0.0002,
      "step": 5812
    },
    {
      "epoch": 22.531007751937985,
      "grad_norm": 0.0016636678483337164,
      "learning_rate": 2.7468992248062014e-05,
      "loss": 0.0002,
      "step": 5813
    },
    {
      "epoch": 22.53488372093023,
      "grad_norm": 0.001751220435835421,
      "learning_rate": 2.746511627906977e-05,
      "loss": 0.0002,
      "step": 5814
    },
    {
      "epoch": 22.53875968992248,
      "grad_norm": 0.001980184344574809,
      "learning_rate": 2.746124031007752e-05,
      "loss": 0.0002,
      "step": 5815
    },
    {
      "epoch": 22.54263565891473,
      "grad_norm": 0.0023292889818549156,
      "learning_rate": 2.7457364341085274e-05,
      "loss": 0.0002,
      "step": 5816
    },
    {
      "epoch": 22.546511627906977,
      "grad_norm": 0.002116163494065404,
      "learning_rate": 2.7453488372093023e-05,
      "loss": 0.0002,
      "step": 5817
    },
    {
      "epoch": 22.550387596899224,
      "grad_norm": 13.492302894592285,
      "learning_rate": 2.7449612403100776e-05,
      "loss": 0.7581,
      "step": 5818
    },
    {
      "epoch": 22.55426356589147,
      "grad_norm": 0.0014364616945385933,
      "learning_rate": 2.7445736434108528e-05,
      "loss": 0.0002,
      "step": 5819
    },
    {
      "epoch": 22.558139534883722,
      "grad_norm": 0.2704866826534271,
      "learning_rate": 2.744186046511628e-05,
      "loss": 0.0093,
      "step": 5820
    },
    {
      "epoch": 22.56201550387597,
      "grad_norm": 0.0019152745371684432,
      "learning_rate": 2.743798449612403e-05,
      "loss": 0.0002,
      "step": 5821
    },
    {
      "epoch": 22.565891472868216,
      "grad_norm": 0.0013630074681714177,
      "learning_rate": 2.7434108527131785e-05,
      "loss": 0.0002,
      "step": 5822
    },
    {
      "epoch": 22.569767441860463,
      "grad_norm": 0.9108420014381409,
      "learning_rate": 2.7430232558139534e-05,
      "loss": 0.0524,
      "step": 5823
    },
    {
      "epoch": 22.573643410852714,
      "grad_norm": 0.0014998604310676455,
      "learning_rate": 2.742635658914729e-05,
      "loss": 0.0002,
      "step": 5824
    },
    {
      "epoch": 22.57751937984496,
      "grad_norm": 0.0019594321493059397,
      "learning_rate": 2.742248062015504e-05,
      "loss": 0.0002,
      "step": 5825
    },
    {
      "epoch": 22.58139534883721,
      "grad_norm": 0.0014291784027591348,
      "learning_rate": 2.7418604651162795e-05,
      "loss": 0.0002,
      "step": 5826
    },
    {
      "epoch": 22.585271317829456,
      "grad_norm": 0.003916311543434858,
      "learning_rate": 2.7414728682170544e-05,
      "loss": 0.0002,
      "step": 5827
    },
    {
      "epoch": 22.589147286821706,
      "grad_norm": 0.0014294626889750361,
      "learning_rate": 2.7410852713178297e-05,
      "loss": 0.0001,
      "step": 5828
    },
    {
      "epoch": 22.593023255813954,
      "grad_norm": 0.001460197032429278,
      "learning_rate": 2.7406976744186046e-05,
      "loss": 0.0001,
      "step": 5829
    },
    {
      "epoch": 22.5968992248062,
      "grad_norm": 0.8092787861824036,
      "learning_rate": 2.74031007751938e-05,
      "loss": 0.0269,
      "step": 5830
    },
    {
      "epoch": 22.600775193798448,
      "grad_norm": 58.927879333496094,
      "learning_rate": 2.739922480620155e-05,
      "loss": 0.0644,
      "step": 5831
    },
    {
      "epoch": 22.6046511627907,
      "grad_norm": 0.0021283242385834455,
      "learning_rate": 2.7395348837209306e-05,
      "loss": 0.0002,
      "step": 5832
    },
    {
      "epoch": 22.608527131782946,
      "grad_norm": 0.001569526270031929,
      "learning_rate": 2.7391472868217055e-05,
      "loss": 0.0002,
      "step": 5833
    },
    {
      "epoch": 22.612403100775193,
      "grad_norm": 0.956601619720459,
      "learning_rate": 2.738759689922481e-05,
      "loss": 0.002,
      "step": 5834
    },
    {
      "epoch": 22.61627906976744,
      "grad_norm": 0.0016163471154868603,
      "learning_rate": 2.738372093023256e-05,
      "loss": 0.0002,
      "step": 5835
    },
    {
      "epoch": 22.62015503875969,
      "grad_norm": 0.9704793691635132,
      "learning_rate": 2.7379844961240312e-05,
      "loss": 0.0081,
      "step": 5836
    },
    {
      "epoch": 22.624031007751938,
      "grad_norm": 14.242202758789062,
      "learning_rate": 2.7375968992248065e-05,
      "loss": 1.3219,
      "step": 5837
    },
    {
      "epoch": 22.627906976744185,
      "grad_norm": 0.9468109607696533,
      "learning_rate": 2.7372093023255814e-05,
      "loss": 0.0031,
      "step": 5838
    },
    {
      "epoch": 22.631782945736433,
      "grad_norm": 0.002132782246917486,
      "learning_rate": 2.7368217054263566e-05,
      "loss": 0.0002,
      "step": 5839
    },
    {
      "epoch": 22.635658914728683,
      "grad_norm": 0.0013408261584118009,
      "learning_rate": 2.7364341085271315e-05,
      "loss": 0.0001,
      "step": 5840
    },
    {
      "epoch": 22.63953488372093,
      "grad_norm": 0.002502565737813711,
      "learning_rate": 2.736046511627907e-05,
      "loss": 0.0002,
      "step": 5841
    },
    {
      "epoch": 22.643410852713178,
      "grad_norm": 0.0020397258922457695,
      "learning_rate": 2.735658914728682e-05,
      "loss": 0.0002,
      "step": 5842
    },
    {
      "epoch": 22.647286821705425,
      "grad_norm": 3.140011787414551,
      "learning_rate": 2.7352713178294576e-05,
      "loss": 0.2667,
      "step": 5843
    },
    {
      "epoch": 22.651162790697676,
      "grad_norm": 1.6740667819976807,
      "learning_rate": 2.7348837209302325e-05,
      "loss": 0.1373,
      "step": 5844
    },
    {
      "epoch": 22.655038759689923,
      "grad_norm": 0.005841881036758423,
      "learning_rate": 2.734496124031008e-05,
      "loss": 0.0002,
      "step": 5845
    },
    {
      "epoch": 22.65891472868217,
      "grad_norm": 0.00382885686121881,
      "learning_rate": 2.734108527131783e-05,
      "loss": 0.0002,
      "step": 5846
    },
    {
      "epoch": 22.662790697674417,
      "grad_norm": 0.0014343071961775422,
      "learning_rate": 2.7337209302325582e-05,
      "loss": 0.0002,
      "step": 5847
    },
    {
      "epoch": 22.666666666666668,
      "grad_norm": 0.22364409267902374,
      "learning_rate": 2.733333333333333e-05,
      "loss": 0.0096,
      "step": 5848
    },
    {
      "epoch": 22.670542635658915,
      "grad_norm": 3.9412784576416016,
      "learning_rate": 2.7329457364341087e-05,
      "loss": 0.1423,
      "step": 5849
    },
    {
      "epoch": 22.674418604651162,
      "grad_norm": 2.7847814559936523,
      "learning_rate": 2.7325581395348836e-05,
      "loss": 0.0405,
      "step": 5850
    },
    {
      "epoch": 22.67829457364341,
      "grad_norm": 0.008184286765754223,
      "learning_rate": 2.7321705426356592e-05,
      "loss": 0.0005,
      "step": 5851
    },
    {
      "epoch": 22.68217054263566,
      "grad_norm": 0.0026922691613435745,
      "learning_rate": 2.731782945736434e-05,
      "loss": 0.0002,
      "step": 5852
    },
    {
      "epoch": 22.686046511627907,
      "grad_norm": 0.002879725769162178,
      "learning_rate": 2.7313953488372097e-05,
      "loss": 0.0002,
      "step": 5853
    },
    {
      "epoch": 22.689922480620154,
      "grad_norm": 0.0022179430816322565,
      "learning_rate": 2.7310077519379846e-05,
      "loss": 0.0002,
      "step": 5854
    },
    {
      "epoch": 22.6937984496124,
      "grad_norm": 0.0028550350107252598,
      "learning_rate": 2.7306201550387602e-05,
      "loss": 0.0002,
      "step": 5855
    },
    {
      "epoch": 22.697674418604652,
      "grad_norm": 0.0065973964519798756,
      "learning_rate": 2.730232558139535e-05,
      "loss": 0.0005,
      "step": 5856
    },
    {
      "epoch": 22.7015503875969,
      "grad_norm": 0.0023047993890941143,
      "learning_rate": 2.7298449612403103e-05,
      "loss": 0.0002,
      "step": 5857
    },
    {
      "epoch": 22.705426356589147,
      "grad_norm": 0.01377673540264368,
      "learning_rate": 2.7294573643410852e-05,
      "loss": 0.0003,
      "step": 5858
    },
    {
      "epoch": 22.709302325581394,
      "grad_norm": 0.002269759774208069,
      "learning_rate": 2.7290697674418608e-05,
      "loss": 0.0002,
      "step": 5859
    },
    {
      "epoch": 22.713178294573645,
      "grad_norm": 0.0029876376502215862,
      "learning_rate": 2.7286821705426357e-05,
      "loss": 0.0002,
      "step": 5860
    },
    {
      "epoch": 22.717054263565892,
      "grad_norm": 4.714718341827393,
      "learning_rate": 2.7282945736434113e-05,
      "loss": 0.7496,
      "step": 5861
    },
    {
      "epoch": 22.72093023255814,
      "grad_norm": 9.61309814453125,
      "learning_rate": 2.7279069767441862e-05,
      "loss": 0.2415,
      "step": 5862
    },
    {
      "epoch": 22.724806201550386,
      "grad_norm": 0.9500806331634521,
      "learning_rate": 2.7275193798449618e-05,
      "loss": 0.0754,
      "step": 5863
    },
    {
      "epoch": 22.728682170542637,
      "grad_norm": 0.01803293265402317,
      "learning_rate": 2.7271317829457367e-05,
      "loss": 0.0006,
      "step": 5864
    },
    {
      "epoch": 22.732558139534884,
      "grad_norm": 0.007724360562860966,
      "learning_rate": 2.7267441860465116e-05,
      "loss": 0.0003,
      "step": 5865
    },
    {
      "epoch": 22.73643410852713,
      "grad_norm": 0.04694311320781708,
      "learning_rate": 2.7263565891472868e-05,
      "loss": 0.001,
      "step": 5866
    },
    {
      "epoch": 22.74031007751938,
      "grad_norm": 0.17670787870883942,
      "learning_rate": 2.725968992248062e-05,
      "loss": 0.0014,
      "step": 5867
    },
    {
      "epoch": 22.74418604651163,
      "grad_norm": 0.024021407589316368,
      "learning_rate": 2.7255813953488373e-05,
      "loss": 0.0008,
      "step": 5868
    },
    {
      "epoch": 22.748062015503876,
      "grad_norm": 0.010018997825682163,
      "learning_rate": 2.7251937984496122e-05,
      "loss": 0.0005,
      "step": 5869
    },
    {
      "epoch": 22.751937984496124,
      "grad_norm": 0.5984612107276917,
      "learning_rate": 2.7248062015503878e-05,
      "loss": 0.007,
      "step": 5870
    },
    {
      "epoch": 22.75581395348837,
      "grad_norm": 1.3015402555465698,
      "learning_rate": 2.7244186046511627e-05,
      "loss": 0.0274,
      "step": 5871
    },
    {
      "epoch": 22.75968992248062,
      "grad_norm": 0.00879294890910387,
      "learning_rate": 2.7240310077519383e-05,
      "loss": 0.0003,
      "step": 5872
    },
    {
      "epoch": 22.76356589147287,
      "grad_norm": 0.027703125029802322,
      "learning_rate": 2.7236434108527132e-05,
      "loss": 0.001,
      "step": 5873
    },
    {
      "epoch": 22.767441860465116,
      "grad_norm": 0.03441208600997925,
      "learning_rate": 2.7232558139534888e-05,
      "loss": 0.0014,
      "step": 5874
    },
    {
      "epoch": 22.771317829457363,
      "grad_norm": 1.449498176574707,
      "learning_rate": 2.7228682170542637e-05,
      "loss": 0.11,
      "step": 5875
    },
    {
      "epoch": 22.775193798449614,
      "grad_norm": 0.02076844871044159,
      "learning_rate": 2.722480620155039e-05,
      "loss": 0.0007,
      "step": 5876
    },
    {
      "epoch": 22.77906976744186,
      "grad_norm": 0.01770450733602047,
      "learning_rate": 2.7220930232558138e-05,
      "loss": 0.0007,
      "step": 5877
    },
    {
      "epoch": 22.782945736434108,
      "grad_norm": 0.009992334991693497,
      "learning_rate": 2.7217054263565894e-05,
      "loss": 0.0005,
      "step": 5878
    },
    {
      "epoch": 22.786821705426355,
      "grad_norm": 0.007983150891959667,
      "learning_rate": 2.7213178294573643e-05,
      "loss": 0.0004,
      "step": 5879
    },
    {
      "epoch": 22.790697674418606,
      "grad_norm": 0.014722608029842377,
      "learning_rate": 2.72093023255814e-05,
      "loss": 0.0006,
      "step": 5880
    },
    {
      "epoch": 22.794573643410853,
      "grad_norm": 0.019179565832018852,
      "learning_rate": 2.7205426356589148e-05,
      "loss": 0.001,
      "step": 5881
    },
    {
      "epoch": 22.7984496124031,
      "grad_norm": 0.005884263664484024,
      "learning_rate": 2.7201550387596904e-05,
      "loss": 0.0003,
      "step": 5882
    },
    {
      "epoch": 22.802325581395348,
      "grad_norm": 6.663638114929199,
      "learning_rate": 2.7197674418604653e-05,
      "loss": 0.4156,
      "step": 5883
    },
    {
      "epoch": 22.8062015503876,
      "grad_norm": 0.006124911829829216,
      "learning_rate": 2.7193798449612405e-05,
      "loss": 0.0004,
      "step": 5884
    },
    {
      "epoch": 22.810077519379846,
      "grad_norm": 0.012291780672967434,
      "learning_rate": 2.7189922480620157e-05,
      "loss": 0.0006,
      "step": 5885
    },
    {
      "epoch": 22.813953488372093,
      "grad_norm": 0.019688768312335014,
      "learning_rate": 2.718604651162791e-05,
      "loss": 0.0007,
      "step": 5886
    },
    {
      "epoch": 22.81782945736434,
      "grad_norm": 0.00488896993920207,
      "learning_rate": 2.718217054263566e-05,
      "loss": 0.0003,
      "step": 5887
    },
    {
      "epoch": 22.82170542635659,
      "grad_norm": 0.0082834018394351,
      "learning_rate": 2.7178294573643415e-05,
      "loss": 0.0004,
      "step": 5888
    },
    {
      "epoch": 22.825581395348838,
      "grad_norm": 0.013403698801994324,
      "learning_rate": 2.7174418604651164e-05,
      "loss": 0.0005,
      "step": 5889
    },
    {
      "epoch": 22.829457364341085,
      "grad_norm": 0.02521856687963009,
      "learning_rate": 2.717054263565892e-05,
      "loss": 0.0006,
      "step": 5890
    },
    {
      "epoch": 22.833333333333332,
      "grad_norm": 0.005571932531893253,
      "learning_rate": 2.716666666666667e-05,
      "loss": 0.0004,
      "step": 5891
    },
    {
      "epoch": 22.837209302325583,
      "grad_norm": 0.007953180000185966,
      "learning_rate": 2.7162790697674418e-05,
      "loss": 0.0004,
      "step": 5892
    },
    {
      "epoch": 22.84108527131783,
      "grad_norm": 0.8094109892845154,
      "learning_rate": 2.7158914728682173e-05,
      "loss": 0.0009,
      "step": 5893
    },
    {
      "epoch": 22.844961240310077,
      "grad_norm": 0.019744060933589935,
      "learning_rate": 2.7155038759689922e-05,
      "loss": 0.0006,
      "step": 5894
    },
    {
      "epoch": 22.848837209302324,
      "grad_norm": 0.0077973706647753716,
      "learning_rate": 2.7151162790697675e-05,
      "loss": 0.0004,
      "step": 5895
    },
    {
      "epoch": 22.852713178294575,
      "grad_norm": 0.004967974498867989,
      "learning_rate": 2.7147286821705424e-05,
      "loss": 0.0003,
      "step": 5896
    },
    {
      "epoch": 22.856589147286822,
      "grad_norm": 0.0046332040801644325,
      "learning_rate": 2.714341085271318e-05,
      "loss": 0.0003,
      "step": 5897
    },
    {
      "epoch": 22.86046511627907,
      "grad_norm": 0.005032161716371775,
      "learning_rate": 2.713953488372093e-05,
      "loss": 0.0004,
      "step": 5898
    },
    {
      "epoch": 22.864341085271317,
      "grad_norm": 6.2844719886779785,
      "learning_rate": 2.7135658914728685e-05,
      "loss": 0.4265,
      "step": 5899
    },
    {
      "epoch": 22.868217054263567,
      "grad_norm": 0.08243883401155472,
      "learning_rate": 2.7131782945736434e-05,
      "loss": 0.0019,
      "step": 5900
    },
    {
      "epoch": 22.872093023255815,
      "grad_norm": 0.04242677241563797,
      "learning_rate": 2.712790697674419e-05,
      "loss": 0.001,
      "step": 5901
    },
    {
      "epoch": 22.875968992248062,
      "grad_norm": 0.0034302682615816593,
      "learning_rate": 2.712403100775194e-05,
      "loss": 0.0003,
      "step": 5902
    },
    {
      "epoch": 22.87984496124031,
      "grad_norm": 0.005609602201730013,
      "learning_rate": 2.712015503875969e-05,
      "loss": 0.0003,
      "step": 5903
    },
    {
      "epoch": 22.88372093023256,
      "grad_norm": 0.004304368048906326,
      "learning_rate": 2.7116279069767443e-05,
      "loss": 0.0003,
      "step": 5904
    },
    {
      "epoch": 22.887596899224807,
      "grad_norm": 0.006464920938014984,
      "learning_rate": 2.7112403100775196e-05,
      "loss": 0.0003,
      "step": 5905
    },
    {
      "epoch": 22.891472868217054,
      "grad_norm": 0.011890735477209091,
      "learning_rate": 2.7108527131782945e-05,
      "loss": 0.0003,
      "step": 5906
    },
    {
      "epoch": 22.8953488372093,
      "grad_norm": 0.002671370981261134,
      "learning_rate": 2.71046511627907e-05,
      "loss": 0.0002,
      "step": 5907
    },
    {
      "epoch": 22.899224806201552,
      "grad_norm": 0.0025779465213418007,
      "learning_rate": 2.710077519379845e-05,
      "loss": 0.0002,
      "step": 5908
    },
    {
      "epoch": 22.9031007751938,
      "grad_norm": 0.00396826071664691,
      "learning_rate": 2.7096899224806205e-05,
      "loss": 0.0003,
      "step": 5909
    },
    {
      "epoch": 22.906976744186046,
      "grad_norm": 0.007030885200947523,
      "learning_rate": 2.7093023255813954e-05,
      "loss": 0.0003,
      "step": 5910
    },
    {
      "epoch": 22.910852713178294,
      "grad_norm": 0.007345786318182945,
      "learning_rate": 2.708914728682171e-05,
      "loss": 0.0003,
      "step": 5911
    },
    {
      "epoch": 22.914728682170544,
      "grad_norm": 0.004777334630489349,
      "learning_rate": 2.708527131782946e-05,
      "loss": 0.0003,
      "step": 5912
    },
    {
      "epoch": 22.91860465116279,
      "grad_norm": 0.005892620421946049,
      "learning_rate": 2.708139534883721e-05,
      "loss": 0.0002,
      "step": 5913
    },
    {
      "epoch": 22.92248062015504,
      "grad_norm": 0.0037387784104794264,
      "learning_rate": 2.707751937984496e-05,
      "loss": 0.0002,
      "step": 5914
    },
    {
      "epoch": 22.926356589147286,
      "grad_norm": 0.008843527175486088,
      "learning_rate": 2.7073643410852717e-05,
      "loss": 0.0003,
      "step": 5915
    },
    {
      "epoch": 22.930232558139537,
      "grad_norm": 0.1575010120868683,
      "learning_rate": 2.7069767441860466e-05,
      "loss": 0.0062,
      "step": 5916
    },
    {
      "epoch": 22.934108527131784,
      "grad_norm": 0.002145485021173954,
      "learning_rate": 2.7065891472868215e-05,
      "loss": 0.0002,
      "step": 5917
    },
    {
      "epoch": 22.93798449612403,
      "grad_norm": 0.8664149641990662,
      "learning_rate": 2.706201550387597e-05,
      "loss": 0.0099,
      "step": 5918
    },
    {
      "epoch": 22.941860465116278,
      "grad_norm": 0.003966920077800751,
      "learning_rate": 2.705813953488372e-05,
      "loss": 0.0002,
      "step": 5919
    },
    {
      "epoch": 22.94573643410853,
      "grad_norm": 0.002407080726698041,
      "learning_rate": 2.7054263565891475e-05,
      "loss": 0.0002,
      "step": 5920
    },
    {
      "epoch": 22.949612403100776,
      "grad_norm": 0.035569243133068085,
      "learning_rate": 2.7050387596899224e-05,
      "loss": 0.0011,
      "step": 5921
    },
    {
      "epoch": 22.953488372093023,
      "grad_norm": 0.00493451626971364,
      "learning_rate": 2.704651162790698e-05,
      "loss": 0.0003,
      "step": 5922
    },
    {
      "epoch": 22.95736434108527,
      "grad_norm": 0.0017351169371977448,
      "learning_rate": 2.704263565891473e-05,
      "loss": 0.0002,
      "step": 5923
    },
    {
      "epoch": 22.96124031007752,
      "grad_norm": 0.002767881378531456,
      "learning_rate": 2.703875968992248e-05,
      "loss": 0.0002,
      "step": 5924
    },
    {
      "epoch": 22.96511627906977,
      "grad_norm": 0.002270947676151991,
      "learning_rate": 2.703488372093023e-05,
      "loss": 0.0002,
      "step": 5925
    },
    {
      "epoch": 22.968992248062015,
      "grad_norm": 1.181481122970581,
      "learning_rate": 2.7031007751937986e-05,
      "loss": 0.0455,
      "step": 5926
    },
    {
      "epoch": 22.972868217054263,
      "grad_norm": 0.0029974915087223053,
      "learning_rate": 2.7027131782945735e-05,
      "loss": 0.0003,
      "step": 5927
    },
    {
      "epoch": 22.97674418604651,
      "grad_norm": 0.002621182706207037,
      "learning_rate": 2.702325581395349e-05,
      "loss": 0.0003,
      "step": 5928
    },
    {
      "epoch": 22.98062015503876,
      "grad_norm": 0.011947812512516975,
      "learning_rate": 2.701937984496124e-05,
      "loss": 0.0006,
      "step": 5929
    },
    {
      "epoch": 22.984496124031008,
      "grad_norm": 0.004618125036358833,
      "learning_rate": 2.7015503875968996e-05,
      "loss": 0.0002,
      "step": 5930
    },
    {
      "epoch": 22.988372093023255,
      "grad_norm": 0.062190089374780655,
      "learning_rate": 2.7011627906976745e-05,
      "loss": 0.0015,
      "step": 5931
    },
    {
      "epoch": 22.992248062015506,
      "grad_norm": 64.46749877929688,
      "learning_rate": 2.7007751937984498e-05,
      "loss": 0.0493,
      "step": 5932
    },
    {
      "epoch": 22.996124031007753,
      "grad_norm": 0.00240229326300323,
      "learning_rate": 2.7003875968992247e-05,
      "loss": 0.0002,
      "step": 5933
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.008966679684817791,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0005,
      "step": 5934
    },
    {
      "epoch": 23.003875968992247,
      "grad_norm": 0.003492468036711216,
      "learning_rate": 2.699612403100775e-05,
      "loss": 0.0003,
      "step": 5935
    },
    {
      "epoch": 23.007751937984494,
      "grad_norm": 0.0028128023259341717,
      "learning_rate": 2.6992248062015507e-05,
      "loss": 0.0002,
      "step": 5936
    },
    {
      "epoch": 23.011627906976745,
      "grad_norm": 0.0034816705156117678,
      "learning_rate": 2.6988372093023256e-05,
      "loss": 0.0003,
      "step": 5937
    },
    {
      "epoch": 23.015503875968992,
      "grad_norm": 0.0025043177884072065,
      "learning_rate": 2.6984496124031012e-05,
      "loss": 0.0002,
      "step": 5938
    },
    {
      "epoch": 23.01937984496124,
      "grad_norm": 0.4393158555030823,
      "learning_rate": 2.698062015503876e-05,
      "loss": 0.0085,
      "step": 5939
    },
    {
      "epoch": 23.023255813953487,
      "grad_norm": 0.0016051363199949265,
      "learning_rate": 2.6976744186046517e-05,
      "loss": 0.0002,
      "step": 5940
    },
    {
      "epoch": 23.027131782945737,
      "grad_norm": 0.007670320104807615,
      "learning_rate": 2.6972868217054266e-05,
      "loss": 0.0004,
      "step": 5941
    },
    {
      "epoch": 23.031007751937985,
      "grad_norm": 0.018402399495244026,
      "learning_rate": 2.696899224806202e-05,
      "loss": 0.0004,
      "step": 5942
    },
    {
      "epoch": 23.03488372093023,
      "grad_norm": 0.0035687340423464775,
      "learning_rate": 2.6965116279069767e-05,
      "loss": 0.0002,
      "step": 5943
    },
    {
      "epoch": 23.03875968992248,
      "grad_norm": 2.241771697998047,
      "learning_rate": 2.6961240310077516e-05,
      "loss": 0.0541,
      "step": 5944
    },
    {
      "epoch": 23.04263565891473,
      "grad_norm": 0.0022804138716310263,
      "learning_rate": 2.6957364341085272e-05,
      "loss": 0.0002,
      "step": 5945
    },
    {
      "epoch": 23.046511627906977,
      "grad_norm": 0.0030206660740077496,
      "learning_rate": 2.695348837209302e-05,
      "loss": 0.0002,
      "step": 5946
    },
    {
      "epoch": 23.050387596899224,
      "grad_norm": 0.002966448897495866,
      "learning_rate": 2.6949612403100777e-05,
      "loss": 0.0003,
      "step": 5947
    },
    {
      "epoch": 23.05426356589147,
      "grad_norm": 0.0024842736311256886,
      "learning_rate": 2.6945736434108526e-05,
      "loss": 0.0002,
      "step": 5948
    },
    {
      "epoch": 23.058139534883722,
      "grad_norm": 0.15932905673980713,
      "learning_rate": 2.6941860465116282e-05,
      "loss": 0.0067,
      "step": 5949
    },
    {
      "epoch": 23.06201550387597,
      "grad_norm": 0.004837826360017061,
      "learning_rate": 2.693798449612403e-05,
      "loss": 0.0004,
      "step": 5950
    },
    {
      "epoch": 23.065891472868216,
      "grad_norm": 0.004376491531729698,
      "learning_rate": 2.6934108527131783e-05,
      "loss": 0.0002,
      "step": 5951
    },
    {
      "epoch": 23.069767441860463,
      "grad_norm": 0.004591678734868765,
      "learning_rate": 2.6930232558139536e-05,
      "loss": 0.0002,
      "step": 5952
    },
    {
      "epoch": 23.073643410852714,
      "grad_norm": 0.0019731398206204176,
      "learning_rate": 2.6926356589147288e-05,
      "loss": 0.0002,
      "step": 5953
    },
    {
      "epoch": 23.07751937984496,
      "grad_norm": 0.0017692552646622062,
      "learning_rate": 2.6922480620155037e-05,
      "loss": 0.0002,
      "step": 5954
    },
    {
      "epoch": 23.08139534883721,
      "grad_norm": 2.287980794906616,
      "learning_rate": 2.6918604651162793e-05,
      "loss": 0.1212,
      "step": 5955
    },
    {
      "epoch": 23.085271317829456,
      "grad_norm": 0.0024424255825579166,
      "learning_rate": 2.6914728682170542e-05,
      "loss": 0.0002,
      "step": 5956
    },
    {
      "epoch": 23.089147286821706,
      "grad_norm": 0.007582072634249926,
      "learning_rate": 2.6910852713178298e-05,
      "loss": 0.0003,
      "step": 5957
    },
    {
      "epoch": 23.093023255813954,
      "grad_norm": 0.0018945424817502499,
      "learning_rate": 2.6906976744186047e-05,
      "loss": 0.0001,
      "step": 5958
    },
    {
      "epoch": 23.0968992248062,
      "grad_norm": 0.002312521683052182,
      "learning_rate": 2.6903100775193803e-05,
      "loss": 0.0002,
      "step": 5959
    },
    {
      "epoch": 23.100775193798448,
      "grad_norm": 0.002318508690223098,
      "learning_rate": 2.6899224806201552e-05,
      "loss": 0.0002,
      "step": 5960
    },
    {
      "epoch": 23.1046511627907,
      "grad_norm": 0.00419697817414999,
      "learning_rate": 2.6895348837209304e-05,
      "loss": 0.0002,
      "step": 5961
    },
    {
      "epoch": 23.108527131782946,
      "grad_norm": 0.004737894516438246,
      "learning_rate": 2.6891472868217053e-05,
      "loss": 0.0004,
      "step": 5962
    },
    {
      "epoch": 23.112403100775193,
      "grad_norm": 0.002145088044926524,
      "learning_rate": 2.688759689922481e-05,
      "loss": 0.0002,
      "step": 5963
    },
    {
      "epoch": 23.11627906976744,
      "grad_norm": 0.0021563232876360416,
      "learning_rate": 2.6883720930232558e-05,
      "loss": 0.0002,
      "step": 5964
    },
    {
      "epoch": 23.12015503875969,
      "grad_norm": 0.0018250528955832124,
      "learning_rate": 2.6879844961240314e-05,
      "loss": 0.0002,
      "step": 5965
    },
    {
      "epoch": 23.124031007751938,
      "grad_norm": 0.0017628563800826669,
      "learning_rate": 2.6875968992248063e-05,
      "loss": 0.0002,
      "step": 5966
    },
    {
      "epoch": 23.127906976744185,
      "grad_norm": 0.964078426361084,
      "learning_rate": 2.687209302325582e-05,
      "loss": 0.0022,
      "step": 5967
    },
    {
      "epoch": 23.131782945736433,
      "grad_norm": 0.00223605171777308,
      "learning_rate": 2.6868217054263568e-05,
      "loss": 0.0002,
      "step": 5968
    },
    {
      "epoch": 23.135658914728683,
      "grad_norm": 0.0018747985595837235,
      "learning_rate": 2.686434108527132e-05,
      "loss": 0.0002,
      "step": 5969
    },
    {
      "epoch": 23.13953488372093,
      "grad_norm": 0.007437907159328461,
      "learning_rate": 2.6860465116279073e-05,
      "loss": 0.0005,
      "step": 5970
    },
    {
      "epoch": 23.143410852713178,
      "grad_norm": 0.18100950121879578,
      "learning_rate": 2.685658914728682e-05,
      "loss": 0.0076,
      "step": 5971
    },
    {
      "epoch": 23.147286821705425,
      "grad_norm": 0.0017117108218371868,
      "learning_rate": 2.6852713178294574e-05,
      "loss": 0.0002,
      "step": 5972
    },
    {
      "epoch": 23.151162790697676,
      "grad_norm": 0.00527561130002141,
      "learning_rate": 2.6848837209302323e-05,
      "loss": 0.0002,
      "step": 5973
    },
    {
      "epoch": 23.155038759689923,
      "grad_norm": 4.040595054626465,
      "learning_rate": 2.684496124031008e-05,
      "loss": 0.3928,
      "step": 5974
    },
    {
      "epoch": 23.15891472868217,
      "grad_norm": 0.22699090838432312,
      "learning_rate": 2.6841085271317828e-05,
      "loss": 0.0093,
      "step": 5975
    },
    {
      "epoch": 23.162790697674417,
      "grad_norm": 0.001587309525348246,
      "learning_rate": 2.6837209302325584e-05,
      "loss": 0.0002,
      "step": 5976
    },
    {
      "epoch": 23.166666666666668,
      "grad_norm": 3.0216064453125,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 0.0708,
      "step": 5977
    },
    {
      "epoch": 23.170542635658915,
      "grad_norm": 0.002277347957715392,
      "learning_rate": 2.682945736434109e-05,
      "loss": 0.0002,
      "step": 5978
    },
    {
      "epoch": 23.174418604651162,
      "grad_norm": 0.21252405643463135,
      "learning_rate": 2.6825581395348838e-05,
      "loss": 0.0018,
      "step": 5979
    },
    {
      "epoch": 23.17829457364341,
      "grad_norm": 0.0014555428642779589,
      "learning_rate": 2.682170542635659e-05,
      "loss": 0.0002,
      "step": 5980
    },
    {
      "epoch": 23.18217054263566,
      "grad_norm": 0.01107942033559084,
      "learning_rate": 2.681782945736434e-05,
      "loss": 0.0003,
      "step": 5981
    },
    {
      "epoch": 23.186046511627907,
      "grad_norm": 1.9228793382644653,
      "learning_rate": 2.6813953488372095e-05,
      "loss": 0.1607,
      "step": 5982
    },
    {
      "epoch": 23.189922480620154,
      "grad_norm": 0.005552262999117374,
      "learning_rate": 2.6810077519379844e-05,
      "loss": 0.0004,
      "step": 5983
    },
    {
      "epoch": 23.1937984496124,
      "grad_norm": 0.005154769401997328,
      "learning_rate": 2.68062015503876e-05,
      "loss": 0.0002,
      "step": 5984
    },
    {
      "epoch": 23.197674418604652,
      "grad_norm": 0.014205023646354675,
      "learning_rate": 2.680232558139535e-05,
      "loss": 0.0007,
      "step": 5985
    },
    {
      "epoch": 23.2015503875969,
      "grad_norm": 0.003601877251639962,
      "learning_rate": 2.6798449612403105e-05,
      "loss": 0.0002,
      "step": 5986
    },
    {
      "epoch": 23.205426356589147,
      "grad_norm": 0.0016792877577245235,
      "learning_rate": 2.6794573643410854e-05,
      "loss": 0.0002,
      "step": 5987
    },
    {
      "epoch": 23.209302325581394,
      "grad_norm": 0.002580022905021906,
      "learning_rate": 2.679069767441861e-05,
      "loss": 0.0002,
      "step": 5988
    },
    {
      "epoch": 23.213178294573645,
      "grad_norm": 0.01316928956657648,
      "learning_rate": 2.678682170542636e-05,
      "loss": 0.0007,
      "step": 5989
    },
    {
      "epoch": 23.217054263565892,
      "grad_norm": 0.0017191104125231504,
      "learning_rate": 2.678294573643411e-05,
      "loss": 0.0002,
      "step": 5990
    },
    {
      "epoch": 23.22093023255814,
      "grad_norm": 0.22026032209396362,
      "learning_rate": 2.677906976744186e-05,
      "loss": 0.0011,
      "step": 5991
    },
    {
      "epoch": 23.224806201550386,
      "grad_norm": 0.0019274024525657296,
      "learning_rate": 2.6775193798449616e-05,
      "loss": 0.0002,
      "step": 5992
    },
    {
      "epoch": 23.228682170542637,
      "grad_norm": 0.005461051594465971,
      "learning_rate": 2.6771317829457365e-05,
      "loss": 0.0004,
      "step": 5993
    },
    {
      "epoch": 23.232558139534884,
      "grad_norm": 0.0019637392833828926,
      "learning_rate": 2.676744186046512e-05,
      "loss": 0.0002,
      "step": 5994
    },
    {
      "epoch": 23.23643410852713,
      "grad_norm": 0.0026966179721057415,
      "learning_rate": 2.676356589147287e-05,
      "loss": 0.0002,
      "step": 5995
    },
    {
      "epoch": 23.24031007751938,
      "grad_norm": 0.001289979089051485,
      "learning_rate": 2.6759689922480625e-05,
      "loss": 0.0001,
      "step": 5996
    },
    {
      "epoch": 23.24418604651163,
      "grad_norm": 0.0033236669842153788,
      "learning_rate": 2.6755813953488374e-05,
      "loss": 0.0003,
      "step": 5997
    },
    {
      "epoch": 23.248062015503876,
      "grad_norm": 0.08443278819322586,
      "learning_rate": 2.6751937984496123e-05,
      "loss": 0.0005,
      "step": 5998
    },
    {
      "epoch": 23.251937984496124,
      "grad_norm": 0.002509162761271,
      "learning_rate": 2.6748062015503876e-05,
      "loss": 0.0002,
      "step": 5999
    },
    {
      "epoch": 23.25581395348837,
      "grad_norm": 0.0031420201994478703,
      "learning_rate": 2.674418604651163e-05,
      "loss": 0.0002,
      "step": 6000
    },
    {
      "epoch": 23.25968992248062,
      "grad_norm": 0.0082912128418684,
      "learning_rate": 2.674031007751938e-05,
      "loss": 0.0002,
      "step": 6001
    },
    {
      "epoch": 23.26356589147287,
      "grad_norm": 0.001576711772941053,
      "learning_rate": 2.673643410852713e-05,
      "loss": 0.0002,
      "step": 6002
    },
    {
      "epoch": 23.267441860465116,
      "grad_norm": 3.636545181274414,
      "learning_rate": 2.6732558139534886e-05,
      "loss": 0.0516,
      "step": 6003
    },
    {
      "epoch": 23.271317829457363,
      "grad_norm": 0.09617212414741516,
      "learning_rate": 2.6728682170542635e-05,
      "loss": 0.0038,
      "step": 6004
    },
    {
      "epoch": 23.275193798449614,
      "grad_norm": 2.6017134189605713,
      "learning_rate": 2.672480620155039e-05,
      "loss": 0.2145,
      "step": 6005
    },
    {
      "epoch": 23.27906976744186,
      "grad_norm": 0.4244338274002075,
      "learning_rate": 2.672093023255814e-05,
      "loss": 0.0056,
      "step": 6006
    },
    {
      "epoch": 23.282945736434108,
      "grad_norm": 0.001455850200727582,
      "learning_rate": 2.6717054263565895e-05,
      "loss": 0.0002,
      "step": 6007
    },
    {
      "epoch": 23.286821705426355,
      "grad_norm": 0.0014406463596969843,
      "learning_rate": 2.6713178294573644e-05,
      "loss": 0.0002,
      "step": 6008
    },
    {
      "epoch": 23.290697674418606,
      "grad_norm": 0.008257119916379452,
      "learning_rate": 2.6709302325581397e-05,
      "loss": 0.0005,
      "step": 6009
    },
    {
      "epoch": 23.294573643410853,
      "grad_norm": 19.11590003967285,
      "learning_rate": 2.6705426356589146e-05,
      "loss": 0.0762,
      "step": 6010
    },
    {
      "epoch": 23.2984496124031,
      "grad_norm": 0.001575831905938685,
      "learning_rate": 2.67015503875969e-05,
      "loss": 0.0002,
      "step": 6011
    },
    {
      "epoch": 23.302325581395348,
      "grad_norm": 0.0017360617639496922,
      "learning_rate": 2.669767441860465e-05,
      "loss": 0.0002,
      "step": 6012
    },
    {
      "epoch": 23.3062015503876,
      "grad_norm": 0.004722159821540117,
      "learning_rate": 2.6693798449612406e-05,
      "loss": 0.0002,
      "step": 6013
    },
    {
      "epoch": 23.310077519379846,
      "grad_norm": 7.25770902633667,
      "learning_rate": 2.6689922480620155e-05,
      "loss": 0.2557,
      "step": 6014
    },
    {
      "epoch": 23.313953488372093,
      "grad_norm": 5.127374649047852,
      "learning_rate": 2.668604651162791e-05,
      "loss": 0.0582,
      "step": 6015
    },
    {
      "epoch": 23.31782945736434,
      "grad_norm": 0.0019851080141961575,
      "learning_rate": 2.668217054263566e-05,
      "loss": 0.0002,
      "step": 6016
    },
    {
      "epoch": 23.32170542635659,
      "grad_norm": 0.011569080874323845,
      "learning_rate": 2.6678294573643413e-05,
      "loss": 0.0005,
      "step": 6017
    },
    {
      "epoch": 23.325581395348838,
      "grad_norm": 0.0015657030744478106,
      "learning_rate": 2.6674418604651165e-05,
      "loss": 0.0001,
      "step": 6018
    },
    {
      "epoch": 23.329457364341085,
      "grad_norm": 0.0013989844592288136,
      "learning_rate": 2.6670542635658918e-05,
      "loss": 0.0001,
      "step": 6019
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 0.0018183342181146145,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0002,
      "step": 6020
    },
    {
      "epoch": 23.337209302325583,
      "grad_norm": 0.0016742910956963897,
      "learning_rate": 2.6662790697674422e-05,
      "loss": 0.0002,
      "step": 6021
    },
    {
      "epoch": 23.34108527131783,
      "grad_norm": 0.0020787750836461782,
      "learning_rate": 2.665891472868217e-05,
      "loss": 0.0002,
      "step": 6022
    },
    {
      "epoch": 23.344961240310077,
      "grad_norm": 0.0014155932003632188,
      "learning_rate": 2.6655038759689927e-05,
      "loss": 0.0001,
      "step": 6023
    },
    {
      "epoch": 23.348837209302324,
      "grad_norm": 0.36553990840911865,
      "learning_rate": 2.6651162790697676e-05,
      "loss": 0.0115,
      "step": 6024
    },
    {
      "epoch": 23.352713178294575,
      "grad_norm": 0.003252278780564666,
      "learning_rate": 2.6647286821705425e-05,
      "loss": 0.0002,
      "step": 6025
    },
    {
      "epoch": 23.356589147286822,
      "grad_norm": 0.0075554498471319675,
      "learning_rate": 2.664341085271318e-05,
      "loss": 0.0004,
      "step": 6026
    },
    {
      "epoch": 23.36046511627907,
      "grad_norm": 0.0017022042302414775,
      "learning_rate": 2.663953488372093e-05,
      "loss": 0.0001,
      "step": 6027
    },
    {
      "epoch": 23.364341085271317,
      "grad_norm": 2.276200532913208,
      "learning_rate": 2.6635658914728683e-05,
      "loss": 0.0303,
      "step": 6028
    },
    {
      "epoch": 23.368217054263567,
      "grad_norm": 0.0014313324354588985,
      "learning_rate": 2.663178294573643e-05,
      "loss": 0.0002,
      "step": 6029
    },
    {
      "epoch": 23.372093023255815,
      "grad_norm": 0.0015536026330664754,
      "learning_rate": 2.6627906976744187e-05,
      "loss": 0.0002,
      "step": 6030
    },
    {
      "epoch": 23.375968992248062,
      "grad_norm": 0.007855875417590141,
      "learning_rate": 2.6624031007751936e-05,
      "loss": 0.0003,
      "step": 6031
    },
    {
      "epoch": 23.37984496124031,
      "grad_norm": 0.0014658495783805847,
      "learning_rate": 2.6620155038759692e-05,
      "loss": 0.0002,
      "step": 6032
    },
    {
      "epoch": 23.38372093023256,
      "grad_norm": 0.060335222631692886,
      "learning_rate": 2.661627906976744e-05,
      "loss": 0.0014,
      "step": 6033
    },
    {
      "epoch": 23.387596899224807,
      "grad_norm": 0.0019250907935202122,
      "learning_rate": 2.6612403100775197e-05,
      "loss": 0.0002,
      "step": 6034
    },
    {
      "epoch": 23.391472868217054,
      "grad_norm": 0.0020200242288410664,
      "learning_rate": 2.6608527131782946e-05,
      "loss": 0.0002,
      "step": 6035
    },
    {
      "epoch": 23.3953488372093,
      "grad_norm": 0.0013376985443755984,
      "learning_rate": 2.66046511627907e-05,
      "loss": 0.0002,
      "step": 6036
    },
    {
      "epoch": 23.399224806201552,
      "grad_norm": 0.0015257762279361486,
      "learning_rate": 2.660077519379845e-05,
      "loss": 0.0002,
      "step": 6037
    },
    {
      "epoch": 23.4031007751938,
      "grad_norm": 0.5752509832382202,
      "learning_rate": 2.6596899224806203e-05,
      "loss": 0.0137,
      "step": 6038
    },
    {
      "epoch": 23.406976744186046,
      "grad_norm": 0.00268347910605371,
      "learning_rate": 2.6593023255813952e-05,
      "loss": 0.0002,
      "step": 6039
    },
    {
      "epoch": 23.410852713178294,
      "grad_norm": 1.9801534414291382,
      "learning_rate": 2.6589147286821708e-05,
      "loss": 0.0532,
      "step": 6040
    },
    {
      "epoch": 23.414728682170544,
      "grad_norm": 1.1513261795043945,
      "learning_rate": 2.6585271317829457e-05,
      "loss": 0.0902,
      "step": 6041
    },
    {
      "epoch": 23.41860465116279,
      "grad_norm": 0.004075703676789999,
      "learning_rate": 2.6581395348837213e-05,
      "loss": 0.0003,
      "step": 6042
    },
    {
      "epoch": 23.42248062015504,
      "grad_norm": 0.005550668109208345,
      "learning_rate": 2.6577519379844962e-05,
      "loss": 0.0004,
      "step": 6043
    },
    {
      "epoch": 23.426356589147286,
      "grad_norm": 0.0015822382410988212,
      "learning_rate": 2.6573643410852718e-05,
      "loss": 0.0002,
      "step": 6044
    },
    {
      "epoch": 23.430232558139537,
      "grad_norm": 0.001988782547414303,
      "learning_rate": 2.6569767441860467e-05,
      "loss": 0.0002,
      "step": 6045
    },
    {
      "epoch": 23.434108527131784,
      "grad_norm": 0.0020657216664403677,
      "learning_rate": 2.656589147286822e-05,
      "loss": 0.0002,
      "step": 6046
    },
    {
      "epoch": 23.43798449612403,
      "grad_norm": 0.0014437601203098893,
      "learning_rate": 2.656201550387597e-05,
      "loss": 0.0002,
      "step": 6047
    },
    {
      "epoch": 23.441860465116278,
      "grad_norm": 0.0014971758937463164,
      "learning_rate": 2.6558139534883724e-05,
      "loss": 0.0002,
      "step": 6048
    },
    {
      "epoch": 23.44573643410853,
      "grad_norm": 0.003134157508611679,
      "learning_rate": 2.6554263565891473e-05,
      "loss": 0.0003,
      "step": 6049
    },
    {
      "epoch": 23.449612403100776,
      "grad_norm": 0.001340345712378621,
      "learning_rate": 2.655038759689923e-05,
      "loss": 0.0001,
      "step": 6050
    },
    {
      "epoch": 23.453488372093023,
      "grad_norm": 0.0014434042386710644,
      "learning_rate": 2.6546511627906978e-05,
      "loss": 0.0001,
      "step": 6051
    },
    {
      "epoch": 23.45736434108527,
      "grad_norm": 9.168900489807129,
      "learning_rate": 2.6542635658914727e-05,
      "loss": 0.2892,
      "step": 6052
    },
    {
      "epoch": 23.46124031007752,
      "grad_norm": 0.002323850989341736,
      "learning_rate": 2.6538759689922483e-05,
      "loss": 0.0002,
      "step": 6053
    },
    {
      "epoch": 23.46511627906977,
      "grad_norm": 0.0020188819617033005,
      "learning_rate": 2.6534883720930232e-05,
      "loss": 0.0002,
      "step": 6054
    },
    {
      "epoch": 23.468992248062015,
      "grad_norm": 0.04712966829538345,
      "learning_rate": 2.6531007751937988e-05,
      "loss": 0.0019,
      "step": 6055
    },
    {
      "epoch": 23.472868217054263,
      "grad_norm": 0.002211472485214472,
      "learning_rate": 2.6527131782945737e-05,
      "loss": 0.0002,
      "step": 6056
    },
    {
      "epoch": 23.476744186046513,
      "grad_norm": 0.002165254671126604,
      "learning_rate": 2.652325581395349e-05,
      "loss": 0.0002,
      "step": 6057
    },
    {
      "epoch": 23.48062015503876,
      "grad_norm": 0.0022723486181348562,
      "learning_rate": 2.6519379844961238e-05,
      "loss": 0.0002,
      "step": 6058
    },
    {
      "epoch": 23.484496124031008,
      "grad_norm": 3.5813486576080322,
      "learning_rate": 2.6515503875968994e-05,
      "loss": 0.0178,
      "step": 6059
    },
    {
      "epoch": 23.488372093023255,
      "grad_norm": 0.0026896928902715445,
      "learning_rate": 2.6511627906976743e-05,
      "loss": 0.0002,
      "step": 6060
    },
    {
      "epoch": 23.492248062015506,
      "grad_norm": 0.002535281702876091,
      "learning_rate": 2.65077519379845e-05,
      "loss": 0.0002,
      "step": 6061
    },
    {
      "epoch": 23.496124031007753,
      "grad_norm": 0.008229964412748814,
      "learning_rate": 2.6503875968992248e-05,
      "loss": 0.0003,
      "step": 6062
    },
    {
      "epoch": 23.5,
      "grad_norm": 0.002161971293389797,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.0002,
      "step": 6063
    },
    {
      "epoch": 23.503875968992247,
      "grad_norm": 0.0016401298344135284,
      "learning_rate": 2.6496124031007753e-05,
      "loss": 0.0002,
      "step": 6064
    },
    {
      "epoch": 23.507751937984494,
      "grad_norm": 0.7541604042053223,
      "learning_rate": 2.6492248062015505e-05,
      "loss": 0.003,
      "step": 6065
    },
    {
      "epoch": 23.511627906976745,
      "grad_norm": 7.123148441314697,
      "learning_rate": 2.6488372093023254e-05,
      "loss": 0.8357,
      "step": 6066
    },
    {
      "epoch": 23.515503875968992,
      "grad_norm": 0.0399860218167305,
      "learning_rate": 2.648449612403101e-05,
      "loss": 0.0009,
      "step": 6067
    },
    {
      "epoch": 23.51937984496124,
      "grad_norm": 0.004670112393796444,
      "learning_rate": 2.648062015503876e-05,
      "loss": 0.0004,
      "step": 6068
    },
    {
      "epoch": 23.52325581395349,
      "grad_norm": 3.027644395828247,
      "learning_rate": 2.6476744186046515e-05,
      "loss": 0.2067,
      "step": 6069
    },
    {
      "epoch": 23.527131782945737,
      "grad_norm": 0.04822229593992233,
      "learning_rate": 2.6472868217054264e-05,
      "loss": 0.0008,
      "step": 6070
    },
    {
      "epoch": 23.531007751937985,
      "grad_norm": 0.0019067780813202262,
      "learning_rate": 2.646899224806202e-05,
      "loss": 0.0002,
      "step": 6071
    },
    {
      "epoch": 23.53488372093023,
      "grad_norm": 0.005880170967429876,
      "learning_rate": 2.646511627906977e-05,
      "loss": 0.0002,
      "step": 6072
    },
    {
      "epoch": 23.53875968992248,
      "grad_norm": 0.0016524818493053317,
      "learning_rate": 2.6461240310077525e-05,
      "loss": 0.0002,
      "step": 6073
    },
    {
      "epoch": 23.54263565891473,
      "grad_norm": 0.0017787591787055135,
      "learning_rate": 2.6457364341085274e-05,
      "loss": 0.0002,
      "step": 6074
    },
    {
      "epoch": 23.546511627906977,
      "grad_norm": 0.002972994465380907,
      "learning_rate": 2.6453488372093026e-05,
      "loss": 0.0002,
      "step": 6075
    },
    {
      "epoch": 23.550387596899224,
      "grad_norm": 0.001545355306006968,
      "learning_rate": 2.6449612403100775e-05,
      "loss": 0.0002,
      "step": 6076
    },
    {
      "epoch": 23.55426356589147,
      "grad_norm": 0.5275906920433044,
      "learning_rate": 2.6445736434108524e-05,
      "loss": 0.0025,
      "step": 6077
    },
    {
      "epoch": 23.558139534883722,
      "grad_norm": 0.08381494134664536,
      "learning_rate": 2.644186046511628e-05,
      "loss": 0.0007,
      "step": 6078
    },
    {
      "epoch": 23.56201550387597,
      "grad_norm": 0.012418956495821476,
      "learning_rate": 2.643798449612403e-05,
      "loss": 0.0002,
      "step": 6079
    },
    {
      "epoch": 23.565891472868216,
      "grad_norm": 0.019262803718447685,
      "learning_rate": 2.6434108527131785e-05,
      "loss": 0.0008,
      "step": 6080
    },
    {
      "epoch": 23.569767441860463,
      "grad_norm": 3.7158491611480713,
      "learning_rate": 2.6430232558139534e-05,
      "loss": 0.1921,
      "step": 6081
    },
    {
      "epoch": 23.573643410852714,
      "grad_norm": 0.003863027086481452,
      "learning_rate": 2.642635658914729e-05,
      "loss": 0.0002,
      "step": 6082
    },
    {
      "epoch": 23.57751937984496,
      "grad_norm": 0.0038306519854813814,
      "learning_rate": 2.642248062015504e-05,
      "loss": 0.0003,
      "step": 6083
    },
    {
      "epoch": 23.58139534883721,
      "grad_norm": 0.011174580082297325,
      "learning_rate": 2.641860465116279e-05,
      "loss": 0.0004,
      "step": 6084
    },
    {
      "epoch": 23.585271317829456,
      "grad_norm": 0.006806423421949148,
      "learning_rate": 2.6414728682170543e-05,
      "loss": 0.0002,
      "step": 6085
    },
    {
      "epoch": 23.589147286821706,
      "grad_norm": 0.0029331243131309748,
      "learning_rate": 2.6410852713178296e-05,
      "loss": 0.0003,
      "step": 6086
    },
    {
      "epoch": 23.593023255813954,
      "grad_norm": 0.0019160737283527851,
      "learning_rate": 2.6406976744186045e-05,
      "loss": 0.0002,
      "step": 6087
    },
    {
      "epoch": 23.5968992248062,
      "grad_norm": 0.0018111270619556308,
      "learning_rate": 2.64031007751938e-05,
      "loss": 0.0002,
      "step": 6088
    },
    {
      "epoch": 23.600775193798448,
      "grad_norm": 0.0018672324949875474,
      "learning_rate": 2.639922480620155e-05,
      "loss": 0.0002,
      "step": 6089
    },
    {
      "epoch": 23.6046511627907,
      "grad_norm": 0.0014296862063929439,
      "learning_rate": 2.6395348837209306e-05,
      "loss": 0.0002,
      "step": 6090
    },
    {
      "epoch": 23.608527131782946,
      "grad_norm": 0.0021163399796932936,
      "learning_rate": 2.6391472868217055e-05,
      "loss": 0.0001,
      "step": 6091
    },
    {
      "epoch": 23.612403100775193,
      "grad_norm": 0.0016583389369770885,
      "learning_rate": 2.638759689922481e-05,
      "loss": 0.0002,
      "step": 6092
    },
    {
      "epoch": 23.61627906976744,
      "grad_norm": 1.9139131307601929,
      "learning_rate": 2.638372093023256e-05,
      "loss": 0.1802,
      "step": 6093
    },
    {
      "epoch": 23.62015503875969,
      "grad_norm": 0.0028670181054621935,
      "learning_rate": 2.6379844961240312e-05,
      "loss": 0.0002,
      "step": 6094
    },
    {
      "epoch": 23.624031007751938,
      "grad_norm": 0.0018279320793226361,
      "learning_rate": 2.637596899224806e-05,
      "loss": 0.0002,
      "step": 6095
    },
    {
      "epoch": 23.627906976744185,
      "grad_norm": 7.973400592803955,
      "learning_rate": 2.6372093023255817e-05,
      "loss": 0.0239,
      "step": 6096
    },
    {
      "epoch": 23.631782945736433,
      "grad_norm": 0.0019458640599623322,
      "learning_rate": 2.6368217054263566e-05,
      "loss": 0.0002,
      "step": 6097
    },
    {
      "epoch": 23.635658914728683,
      "grad_norm": 0.051714517176151276,
      "learning_rate": 2.636434108527132e-05,
      "loss": 0.001,
      "step": 6098
    },
    {
      "epoch": 23.63953488372093,
      "grad_norm": 0.0015651005087420344,
      "learning_rate": 2.636046511627907e-05,
      "loss": 0.0002,
      "step": 6099
    },
    {
      "epoch": 23.643410852713178,
      "grad_norm": 0.0015562508488073945,
      "learning_rate": 2.6356589147286826e-05,
      "loss": 0.0002,
      "step": 6100
    },
    {
      "epoch": 23.647286821705425,
      "grad_norm": 0.018696974962949753,
      "learning_rate": 2.6352713178294575e-05,
      "loss": 0.0006,
      "step": 6101
    },
    {
      "epoch": 23.651162790697676,
      "grad_norm": 0.0016590793384239078,
      "learning_rate": 2.6348837209302328e-05,
      "loss": 0.0002,
      "step": 6102
    },
    {
      "epoch": 23.655038759689923,
      "grad_norm": 0.0015612229472026229,
      "learning_rate": 2.634496124031008e-05,
      "loss": 0.0002,
      "step": 6103
    },
    {
      "epoch": 23.65891472868217,
      "grad_norm": 0.0025316940154880285,
      "learning_rate": 2.634108527131783e-05,
      "loss": 0.0002,
      "step": 6104
    },
    {
      "epoch": 23.662790697674417,
      "grad_norm": 0.0015609984984621406,
      "learning_rate": 2.6337209302325582e-05,
      "loss": 0.0002,
      "step": 6105
    },
    {
      "epoch": 23.666666666666668,
      "grad_norm": 1.3390281200408936,
      "learning_rate": 2.633333333333333e-05,
      "loss": 0.0042,
      "step": 6106
    },
    {
      "epoch": 23.670542635658915,
      "grad_norm": 70.09569549560547,
      "learning_rate": 2.6329457364341087e-05,
      "loss": 0.0234,
      "step": 6107
    },
    {
      "epoch": 23.674418604651162,
      "grad_norm": 0.018153106793761253,
      "learning_rate": 2.6325581395348836e-05,
      "loss": 0.0002,
      "step": 6108
    },
    {
      "epoch": 23.67829457364341,
      "grad_norm": 0.11885730922222137,
      "learning_rate": 2.632170542635659e-05,
      "loss": 0.005,
      "step": 6109
    },
    {
      "epoch": 23.68217054263566,
      "grad_norm": 0.06223432347178459,
      "learning_rate": 2.631782945736434e-05,
      "loss": 0.0014,
      "step": 6110
    },
    {
      "epoch": 23.686046511627907,
      "grad_norm": 3.233786106109619,
      "learning_rate": 2.6313953488372096e-05,
      "loss": 0.1268,
      "step": 6111
    },
    {
      "epoch": 23.689922480620154,
      "grad_norm": 0.0031635162886232138,
      "learning_rate": 2.6310077519379845e-05,
      "loss": 0.0002,
      "step": 6112
    },
    {
      "epoch": 23.6937984496124,
      "grad_norm": 0.001767570967786014,
      "learning_rate": 2.6306201550387598e-05,
      "loss": 0.0001,
      "step": 6113
    },
    {
      "epoch": 23.697674418604652,
      "grad_norm": 0.0028840515296906233,
      "learning_rate": 2.6302325581395347e-05,
      "loss": 0.0002,
      "step": 6114
    },
    {
      "epoch": 23.7015503875969,
      "grad_norm": 0.1322649121284485,
      "learning_rate": 2.6298449612403103e-05,
      "loss": 0.0025,
      "step": 6115
    },
    {
      "epoch": 23.705426356589147,
      "grad_norm": 0.0030466467142105103,
      "learning_rate": 2.629457364341085e-05,
      "loss": 0.0003,
      "step": 6116
    },
    {
      "epoch": 23.709302325581394,
      "grad_norm": 0.0017664266051724553,
      "learning_rate": 2.6290697674418607e-05,
      "loss": 0.0002,
      "step": 6117
    },
    {
      "epoch": 23.713178294573645,
      "grad_norm": 0.039966315031051636,
      "learning_rate": 2.6286821705426356e-05,
      "loss": 0.001,
      "step": 6118
    },
    {
      "epoch": 23.717054263565892,
      "grad_norm": 1.3631188869476318,
      "learning_rate": 2.6282945736434112e-05,
      "loss": 0.1006,
      "step": 6119
    },
    {
      "epoch": 23.72093023255814,
      "grad_norm": 0.12643437087535858,
      "learning_rate": 2.627906976744186e-05,
      "loss": 0.0052,
      "step": 6120
    },
    {
      "epoch": 23.724806201550386,
      "grad_norm": 1.072815179824829,
      "learning_rate": 2.6275193798449617e-05,
      "loss": 0.0759,
      "step": 6121
    },
    {
      "epoch": 23.728682170542637,
      "grad_norm": 0.0015040308935567737,
      "learning_rate": 2.6271317829457366e-05,
      "loss": 0.0002,
      "step": 6122
    },
    {
      "epoch": 23.732558139534884,
      "grad_norm": 3.831374168395996,
      "learning_rate": 2.626744186046512e-05,
      "loss": 0.4915,
      "step": 6123
    },
    {
      "epoch": 23.73643410852713,
      "grad_norm": 0.0026401260402053595,
      "learning_rate": 2.6263565891472868e-05,
      "loss": 0.0002,
      "step": 6124
    },
    {
      "epoch": 23.74031007751938,
      "grad_norm": 0.003940277267247438,
      "learning_rate": 2.6259689922480623e-05,
      "loss": 0.0002,
      "step": 6125
    },
    {
      "epoch": 23.74418604651163,
      "grad_norm": 4.252048969268799,
      "learning_rate": 2.6255813953488372e-05,
      "loss": 0.0523,
      "step": 6126
    },
    {
      "epoch": 23.748062015503876,
      "grad_norm": 0.002998015843331814,
      "learning_rate": 2.6251937984496128e-05,
      "loss": 0.0002,
      "step": 6127
    },
    {
      "epoch": 23.751937984496124,
      "grad_norm": 0.0015719839138910174,
      "learning_rate": 2.6248062015503877e-05,
      "loss": 0.0002,
      "step": 6128
    },
    {
      "epoch": 23.75581395348837,
      "grad_norm": 0.030820325016975403,
      "learning_rate": 2.6244186046511633e-05,
      "loss": 0.0004,
      "step": 6129
    },
    {
      "epoch": 23.75968992248062,
      "grad_norm": 0.0019340395228937268,
      "learning_rate": 2.6240310077519382e-05,
      "loss": 0.0002,
      "step": 6130
    },
    {
      "epoch": 23.76356589147287,
      "grad_norm": 0.47348839044570923,
      "learning_rate": 2.623643410852713e-05,
      "loss": 0.0029,
      "step": 6131
    },
    {
      "epoch": 23.767441860465116,
      "grad_norm": 0.0014873550971969962,
      "learning_rate": 2.6232558139534884e-05,
      "loss": 0.0002,
      "step": 6132
    },
    {
      "epoch": 23.771317829457363,
      "grad_norm": 0.0028594890609383583,
      "learning_rate": 2.6228682170542636e-05,
      "loss": 0.0003,
      "step": 6133
    },
    {
      "epoch": 23.775193798449614,
      "grad_norm": 0.016264621168375015,
      "learning_rate": 2.622480620155039e-05,
      "loss": 0.0005,
      "step": 6134
    },
    {
      "epoch": 23.77906976744186,
      "grad_norm": 0.020475707948207855,
      "learning_rate": 2.6220930232558137e-05,
      "loss": 0.0006,
      "step": 6135
    },
    {
      "epoch": 23.782945736434108,
      "grad_norm": 0.0019841287285089493,
      "learning_rate": 2.6217054263565893e-05,
      "loss": 0.0002,
      "step": 6136
    },
    {
      "epoch": 23.786821705426355,
      "grad_norm": 2.016627550125122,
      "learning_rate": 2.6213178294573642e-05,
      "loss": 0.1411,
      "step": 6137
    },
    {
      "epoch": 23.790697674418606,
      "grad_norm": 0.001919401460327208,
      "learning_rate": 2.6209302325581398e-05,
      "loss": 0.0002,
      "step": 6138
    },
    {
      "epoch": 23.794573643410853,
      "grad_norm": 0.0019373841350898147,
      "learning_rate": 2.6205426356589147e-05,
      "loss": 0.0002,
      "step": 6139
    },
    {
      "epoch": 23.7984496124031,
      "grad_norm": 0.002488810569047928,
      "learning_rate": 2.6201550387596903e-05,
      "loss": 0.0002,
      "step": 6140
    },
    {
      "epoch": 23.802325581395348,
      "grad_norm": 0.008197835646569729,
      "learning_rate": 2.6197674418604652e-05,
      "loss": 0.0002,
      "step": 6141
    },
    {
      "epoch": 23.8062015503876,
      "grad_norm": 0.0024316729977726936,
      "learning_rate": 2.6193798449612404e-05,
      "loss": 0.0002,
      "step": 6142
    },
    {
      "epoch": 23.810077519379846,
      "grad_norm": 0.0136242201551795,
      "learning_rate": 2.6189922480620153e-05,
      "loss": 0.0005,
      "step": 6143
    },
    {
      "epoch": 23.813953488372093,
      "grad_norm": 0.40951037406921387,
      "learning_rate": 2.618604651162791e-05,
      "loss": 0.017,
      "step": 6144
    },
    {
      "epoch": 23.81782945736434,
      "grad_norm": 0.0036546424962580204,
      "learning_rate": 2.6182170542635658e-05,
      "loss": 0.0002,
      "step": 6145
    },
    {
      "epoch": 23.82170542635659,
      "grad_norm": 0.046903058886528015,
      "learning_rate": 2.6178294573643414e-05,
      "loss": 0.0005,
      "step": 6146
    },
    {
      "epoch": 23.825581395348838,
      "grad_norm": 0.010040068998932838,
      "learning_rate": 2.6174418604651163e-05,
      "loss": 0.0005,
      "step": 6147
    },
    {
      "epoch": 23.829457364341085,
      "grad_norm": 1.5446009635925293,
      "learning_rate": 2.617054263565892e-05,
      "loss": 0.0863,
      "step": 6148
    },
    {
      "epoch": 23.833333333333332,
      "grad_norm": 2.6529431343078613,
      "learning_rate": 2.6166666666666668e-05,
      "loss": 0.1408,
      "step": 6149
    },
    {
      "epoch": 23.837209302325583,
      "grad_norm": 0.0020911141764372587,
      "learning_rate": 2.616279069767442e-05,
      "loss": 0.0002,
      "step": 6150
    },
    {
      "epoch": 23.84108527131783,
      "grad_norm": 0.00956347119063139,
      "learning_rate": 2.6158914728682173e-05,
      "loss": 0.0004,
      "step": 6151
    },
    {
      "epoch": 23.844961240310077,
      "grad_norm": 0.00628101360052824,
      "learning_rate": 2.6155038759689925e-05,
      "loss": 0.0002,
      "step": 6152
    },
    {
      "epoch": 23.848837209302324,
      "grad_norm": 0.0018050839425995946,
      "learning_rate": 2.6151162790697674e-05,
      "loss": 0.0002,
      "step": 6153
    },
    {
      "epoch": 23.852713178294575,
      "grad_norm": 0.0014479780802503228,
      "learning_rate": 2.614728682170543e-05,
      "loss": 0.0002,
      "step": 6154
    },
    {
      "epoch": 23.856589147286822,
      "grad_norm": 0.0021417236421257257,
      "learning_rate": 2.614341085271318e-05,
      "loss": 0.0002,
      "step": 6155
    },
    {
      "epoch": 23.86046511627907,
      "grad_norm": 0.0023194034583866596,
      "learning_rate": 2.6139534883720935e-05,
      "loss": 0.0002,
      "step": 6156
    },
    {
      "epoch": 23.864341085271317,
      "grad_norm": 0.0017203808529302478,
      "learning_rate": 2.6135658914728684e-05,
      "loss": 0.0002,
      "step": 6157
    },
    {
      "epoch": 23.868217054263567,
      "grad_norm": 0.0020989535842090845,
      "learning_rate": 2.6131782945736433e-05,
      "loss": 0.0002,
      "step": 6158
    },
    {
      "epoch": 23.872093023255815,
      "grad_norm": 5.710489749908447,
      "learning_rate": 2.612790697674419e-05,
      "loss": 0.1155,
      "step": 6159
    },
    {
      "epoch": 23.875968992248062,
      "grad_norm": 0.5004584789276123,
      "learning_rate": 2.6124031007751938e-05,
      "loss": 0.022,
      "step": 6160
    },
    {
      "epoch": 23.87984496124031,
      "grad_norm": 0.0014425189001485705,
      "learning_rate": 2.612015503875969e-05,
      "loss": 0.0002,
      "step": 6161
    },
    {
      "epoch": 23.88372093023256,
      "grad_norm": 0.0014049812452867627,
      "learning_rate": 2.611627906976744e-05,
      "loss": 0.0002,
      "step": 6162
    },
    {
      "epoch": 23.887596899224807,
      "grad_norm": 0.0018183008069172502,
      "learning_rate": 2.6112403100775195e-05,
      "loss": 0.0002,
      "step": 6163
    },
    {
      "epoch": 23.891472868217054,
      "grad_norm": 1.1558241844177246,
      "learning_rate": 2.6108527131782944e-05,
      "loss": 0.115,
      "step": 6164
    },
    {
      "epoch": 23.8953488372093,
      "grad_norm": 1.769180417060852,
      "learning_rate": 2.61046511627907e-05,
      "loss": 0.0462,
      "step": 6165
    },
    {
      "epoch": 23.899224806201552,
      "grad_norm": 0.0016762325540184975,
      "learning_rate": 2.610077519379845e-05,
      "loss": 0.0002,
      "step": 6166
    },
    {
      "epoch": 23.9031007751938,
      "grad_norm": 0.0037761034909635782,
      "learning_rate": 2.6096899224806205e-05,
      "loss": 0.0003,
      "step": 6167
    },
    {
      "epoch": 23.906976744186046,
      "grad_norm": 0.0016847153892740607,
      "learning_rate": 2.6093023255813954e-05,
      "loss": 0.0002,
      "step": 6168
    },
    {
      "epoch": 23.910852713178294,
      "grad_norm": 0.002981161465868354,
      "learning_rate": 2.6089147286821706e-05,
      "loss": 0.0002,
      "step": 6169
    },
    {
      "epoch": 23.914728682170544,
      "grad_norm": 0.001587810693308711,
      "learning_rate": 2.608527131782946e-05,
      "loss": 0.0002,
      "step": 6170
    },
    {
      "epoch": 23.91860465116279,
      "grad_norm": 0.0021425627637654543,
      "learning_rate": 2.608139534883721e-05,
      "loss": 0.0002,
      "step": 6171
    },
    {
      "epoch": 23.92248062015504,
      "grad_norm": 0.032510433346033096,
      "learning_rate": 2.607751937984496e-05,
      "loss": 0.0008,
      "step": 6172
    },
    {
      "epoch": 23.926356589147286,
      "grad_norm": 0.0015696376794949174,
      "learning_rate": 2.6073643410852716e-05,
      "loss": 0.0002,
      "step": 6173
    },
    {
      "epoch": 23.930232558139537,
      "grad_norm": 0.002153978915885091,
      "learning_rate": 2.6069767441860465e-05,
      "loss": 0.0002,
      "step": 6174
    },
    {
      "epoch": 23.934108527131784,
      "grad_norm": 0.001874873647466302,
      "learning_rate": 2.606589147286822e-05,
      "loss": 0.0002,
      "step": 6175
    },
    {
      "epoch": 23.93798449612403,
      "grad_norm": 10.838052749633789,
      "learning_rate": 2.606201550387597e-05,
      "loss": 0.032,
      "step": 6176
    },
    {
      "epoch": 23.941860465116278,
      "grad_norm": 0.0052872574888169765,
      "learning_rate": 2.6058139534883726e-05,
      "loss": 0.0003,
      "step": 6177
    },
    {
      "epoch": 23.94573643410853,
      "grad_norm": 0.0028213122859597206,
      "learning_rate": 2.6054263565891475e-05,
      "loss": 0.0002,
      "step": 6178
    },
    {
      "epoch": 23.949612403100776,
      "grad_norm": 0.4090317487716675,
      "learning_rate": 2.6050387596899227e-05,
      "loss": 0.0069,
      "step": 6179
    },
    {
      "epoch": 23.953488372093023,
      "grad_norm": 0.008164719678461552,
      "learning_rate": 2.6046511627906976e-05,
      "loss": 0.0004,
      "step": 6180
    },
    {
      "epoch": 23.95736434108527,
      "grad_norm": 0.002506077289581299,
      "learning_rate": 2.6042635658914732e-05,
      "loss": 0.0002,
      "step": 6181
    },
    {
      "epoch": 23.96124031007752,
      "grad_norm": 0.0029613517690449953,
      "learning_rate": 2.603875968992248e-05,
      "loss": 0.0002,
      "step": 6182
    },
    {
      "epoch": 23.96511627906977,
      "grad_norm": 0.0019954554736614227,
      "learning_rate": 2.6034883720930237e-05,
      "loss": 0.0002,
      "step": 6183
    },
    {
      "epoch": 23.968992248062015,
      "grad_norm": 0.003907733131200075,
      "learning_rate": 2.6031007751937986e-05,
      "loss": 0.0002,
      "step": 6184
    },
    {
      "epoch": 23.972868217054263,
      "grad_norm": 0.001969657139852643,
      "learning_rate": 2.6027131782945735e-05,
      "loss": 0.0002,
      "step": 6185
    },
    {
      "epoch": 23.97674418604651,
      "grad_norm": 0.0018942330498248339,
      "learning_rate": 2.602325581395349e-05,
      "loss": 0.0002,
      "step": 6186
    },
    {
      "epoch": 23.98062015503876,
      "grad_norm": 0.0016318189445883036,
      "learning_rate": 2.601937984496124e-05,
      "loss": 0.0002,
      "step": 6187
    },
    {
      "epoch": 23.984496124031008,
      "grad_norm": 0.5866501927375793,
      "learning_rate": 2.6015503875968995e-05,
      "loss": 0.0305,
      "step": 6188
    },
    {
      "epoch": 23.988372093023255,
      "grad_norm": 0.0018127793446183205,
      "learning_rate": 2.6011627906976745e-05,
      "loss": 0.0002,
      "step": 6189
    },
    {
      "epoch": 23.992248062015506,
      "grad_norm": 0.06686006486415863,
      "learning_rate": 2.6007751937984497e-05,
      "loss": 0.0003,
      "step": 6190
    },
    {
      "epoch": 23.996124031007753,
      "grad_norm": 0.0016709844348952174,
      "learning_rate": 2.6003875968992246e-05,
      "loss": 0.0002,
      "step": 6191
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.0021497926209121943,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0002,
      "step": 6192
    },
    {
      "epoch": 24.003875968992247,
      "grad_norm": 0.001813714625313878,
      "learning_rate": 2.599612403100775e-05,
      "loss": 0.0002,
      "step": 6193
    },
    {
      "epoch": 24.007751937984494,
      "grad_norm": 0.002367650391533971,
      "learning_rate": 2.5992248062015507e-05,
      "loss": 0.0002,
      "step": 6194
    },
    {
      "epoch": 24.011627906976745,
      "grad_norm": 0.0027043793816119432,
      "learning_rate": 2.5988372093023256e-05,
      "loss": 0.0002,
      "step": 6195
    },
    {
      "epoch": 24.015503875968992,
      "grad_norm": 2.8627610206604004,
      "learning_rate": 2.598449612403101e-05,
      "loss": 0.2684,
      "step": 6196
    },
    {
      "epoch": 24.01937984496124,
      "grad_norm": 0.0016678444808349013,
      "learning_rate": 2.598062015503876e-05,
      "loss": 0.0002,
      "step": 6197
    },
    {
      "epoch": 24.023255813953487,
      "grad_norm": 0.0017284302739426494,
      "learning_rate": 2.5976744186046513e-05,
      "loss": 0.0002,
      "step": 6198
    },
    {
      "epoch": 24.027131782945737,
      "grad_norm": 0.002128706080839038,
      "learning_rate": 2.5972868217054262e-05,
      "loss": 0.0002,
      "step": 6199
    },
    {
      "epoch": 24.031007751937985,
      "grad_norm": 0.002074464922770858,
      "learning_rate": 2.5968992248062018e-05,
      "loss": 0.0002,
      "step": 6200
    },
    {
      "epoch": 24.03488372093023,
      "grad_norm": 0.002811366692185402,
      "learning_rate": 2.5965116279069767e-05,
      "loss": 0.0002,
      "step": 6201
    },
    {
      "epoch": 24.03875968992248,
      "grad_norm": 0.0016569491708651185,
      "learning_rate": 2.5961240310077523e-05,
      "loss": 0.0002,
      "step": 6202
    },
    {
      "epoch": 24.04263565891473,
      "grad_norm": 0.0027022191789001226,
      "learning_rate": 2.595736434108527e-05,
      "loss": 0.0002,
      "step": 6203
    },
    {
      "epoch": 24.046511627906977,
      "grad_norm": 0.001735267578624189,
      "learning_rate": 2.5953488372093027e-05,
      "loss": 0.0002,
      "step": 6204
    },
    {
      "epoch": 24.050387596899224,
      "grad_norm": 0.011882638558745384,
      "learning_rate": 2.5949612403100776e-05,
      "loss": 0.0004,
      "step": 6205
    },
    {
      "epoch": 24.05426356589147,
      "grad_norm": 0.002776910550892353,
      "learning_rate": 2.5945736434108532e-05,
      "loss": 0.0003,
      "step": 6206
    },
    {
      "epoch": 24.058139534883722,
      "grad_norm": 0.0028129492420703173,
      "learning_rate": 2.594186046511628e-05,
      "loss": 0.0002,
      "step": 6207
    },
    {
      "epoch": 24.06201550387597,
      "grad_norm": 0.0015924221370369196,
      "learning_rate": 2.5937984496124034e-05,
      "loss": 0.0002,
      "step": 6208
    },
    {
      "epoch": 24.065891472868216,
      "grad_norm": 0.0025893591810017824,
      "learning_rate": 2.5934108527131783e-05,
      "loss": 0.0002,
      "step": 6209
    },
    {
      "epoch": 24.069767441860463,
      "grad_norm": 1.25588858127594,
      "learning_rate": 2.593023255813954e-05,
      "loss": 0.0948,
      "step": 6210
    },
    {
      "epoch": 24.073643410852714,
      "grad_norm": 0.0014534419169649482,
      "learning_rate": 2.5926356589147288e-05,
      "loss": 0.0002,
      "step": 6211
    },
    {
      "epoch": 24.07751937984496,
      "grad_norm": 0.004249291494488716,
      "learning_rate": 2.5922480620155037e-05,
      "loss": 0.0002,
      "step": 6212
    },
    {
      "epoch": 24.08139534883721,
      "grad_norm": 2.246027946472168,
      "learning_rate": 2.5918604651162792e-05,
      "loss": 0.2061,
      "step": 6213
    },
    {
      "epoch": 24.085271317829456,
      "grad_norm": 0.002257342915982008,
      "learning_rate": 2.591472868217054e-05,
      "loss": 0.0002,
      "step": 6214
    },
    {
      "epoch": 24.089147286821706,
      "grad_norm": 0.004119997378438711,
      "learning_rate": 2.5910852713178297e-05,
      "loss": 0.0003,
      "step": 6215
    },
    {
      "epoch": 24.093023255813954,
      "grad_norm": 1.8140177726745605,
      "learning_rate": 2.5906976744186046e-05,
      "loss": 0.0842,
      "step": 6216
    },
    {
      "epoch": 24.0968992248062,
      "grad_norm": 0.00181292905472219,
      "learning_rate": 2.59031007751938e-05,
      "loss": 0.0002,
      "step": 6217
    },
    {
      "epoch": 24.100775193798448,
      "grad_norm": 0.01024902705103159,
      "learning_rate": 2.589922480620155e-05,
      "loss": 0.0006,
      "step": 6218
    },
    {
      "epoch": 24.1046511627907,
      "grad_norm": 0.006694344338029623,
      "learning_rate": 2.5895348837209304e-05,
      "loss": 0.0003,
      "step": 6219
    },
    {
      "epoch": 24.108527131782946,
      "grad_norm": 0.003169117495417595,
      "learning_rate": 2.5891472868217053e-05,
      "loss": 0.0002,
      "step": 6220
    },
    {
      "epoch": 24.112403100775193,
      "grad_norm": 0.00195591663941741,
      "learning_rate": 2.588759689922481e-05,
      "loss": 0.0002,
      "step": 6221
    },
    {
      "epoch": 24.11627906976744,
      "grad_norm": 3.2574234008789062,
      "learning_rate": 2.5883720930232557e-05,
      "loss": 0.1406,
      "step": 6222
    },
    {
      "epoch": 24.12015503875969,
      "grad_norm": 0.0018080722074955702,
      "learning_rate": 2.5879844961240313e-05,
      "loss": 0.0002,
      "step": 6223
    },
    {
      "epoch": 24.124031007751938,
      "grad_norm": 0.0016683930298313498,
      "learning_rate": 2.5875968992248062e-05,
      "loss": 0.0002,
      "step": 6224
    },
    {
      "epoch": 24.127906976744185,
      "grad_norm": 0.0018994329730048776,
      "learning_rate": 2.5872093023255818e-05,
      "loss": 0.0002,
      "step": 6225
    },
    {
      "epoch": 24.131782945736433,
      "grad_norm": 0.0019758562557399273,
      "learning_rate": 2.5868217054263567e-05,
      "loss": 0.0002,
      "step": 6226
    },
    {
      "epoch": 24.135658914728683,
      "grad_norm": 0.0020340506453067064,
      "learning_rate": 2.586434108527132e-05,
      "loss": 0.0002,
      "step": 6227
    },
    {
      "epoch": 24.13953488372093,
      "grad_norm": 0.0030577934812754393,
      "learning_rate": 2.586046511627907e-05,
      "loss": 0.0002,
      "step": 6228
    },
    {
      "epoch": 24.143410852713178,
      "grad_norm": 0.0016929635312408209,
      "learning_rate": 2.5856589147286824e-05,
      "loss": 0.0002,
      "step": 6229
    },
    {
      "epoch": 24.147286821705425,
      "grad_norm": 0.001711961580440402,
      "learning_rate": 2.5852713178294573e-05,
      "loss": 0.0002,
      "step": 6230
    },
    {
      "epoch": 24.151162790697676,
      "grad_norm": 0.0012361041735857725,
      "learning_rate": 2.584883720930233e-05,
      "loss": 0.0001,
      "step": 6231
    },
    {
      "epoch": 24.155038759689923,
      "grad_norm": 0.0022757488768547773,
      "learning_rate": 2.584496124031008e-05,
      "loss": 0.0002,
      "step": 6232
    },
    {
      "epoch": 24.15891472868217,
      "grad_norm": 0.0024476945400238037,
      "learning_rate": 2.5841085271317834e-05,
      "loss": 0.0002,
      "step": 6233
    },
    {
      "epoch": 24.162790697674417,
      "grad_norm": 6.54319429397583,
      "learning_rate": 2.5837209302325583e-05,
      "loss": 0.1441,
      "step": 6234
    },
    {
      "epoch": 24.166666666666668,
      "grad_norm": 0.42068564891815186,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 0.0182,
      "step": 6235
    },
    {
      "epoch": 24.170542635658915,
      "grad_norm": 12.168414115905762,
      "learning_rate": 2.5829457364341088e-05,
      "loss": 0.0853,
      "step": 6236
    },
    {
      "epoch": 24.174418604651162,
      "grad_norm": 0.001651219790801406,
      "learning_rate": 2.5825581395348837e-05,
      "loss": 0.0002,
      "step": 6237
    },
    {
      "epoch": 24.17829457364341,
      "grad_norm": 0.0019980280194431543,
      "learning_rate": 2.582170542635659e-05,
      "loss": 0.0002,
      "step": 6238
    },
    {
      "epoch": 24.18217054263566,
      "grad_norm": 0.29781052470207214,
      "learning_rate": 2.581782945736434e-05,
      "loss": 0.006,
      "step": 6239
    },
    {
      "epoch": 24.186046511627907,
      "grad_norm": 0.0017462772084400058,
      "learning_rate": 2.5813953488372094e-05,
      "loss": 0.0002,
      "step": 6240
    },
    {
      "epoch": 24.189922480620154,
      "grad_norm": 0.0020599733106791973,
      "learning_rate": 2.5810077519379843e-05,
      "loss": 0.0002,
      "step": 6241
    },
    {
      "epoch": 24.1937984496124,
      "grad_norm": 0.0026482953689992428,
      "learning_rate": 2.58062015503876e-05,
      "loss": 0.0002,
      "step": 6242
    },
    {
      "epoch": 24.197674418604652,
      "grad_norm": 0.002259128261357546,
      "learning_rate": 2.5802325581395348e-05,
      "loss": 0.0002,
      "step": 6243
    },
    {
      "epoch": 24.2015503875969,
      "grad_norm": 0.0015844719018787146,
      "learning_rate": 2.5798449612403104e-05,
      "loss": 0.0002,
      "step": 6244
    },
    {
      "epoch": 24.205426356589147,
      "grad_norm": 0.012924054637551308,
      "learning_rate": 2.5794573643410853e-05,
      "loss": 0.0005,
      "step": 6245
    },
    {
      "epoch": 24.209302325581394,
      "grad_norm": 0.001877258880995214,
      "learning_rate": 2.5790697674418605e-05,
      "loss": 0.0002,
      "step": 6246
    },
    {
      "epoch": 24.213178294573645,
      "grad_norm": 2.4230527877807617,
      "learning_rate": 2.5786821705426354e-05,
      "loss": 0.0343,
      "step": 6247
    },
    {
      "epoch": 24.217054263565892,
      "grad_norm": 0.003034236840903759,
      "learning_rate": 2.578294573643411e-05,
      "loss": 0.0002,
      "step": 6248
    },
    {
      "epoch": 24.22093023255814,
      "grad_norm": 3.4151365756988525,
      "learning_rate": 2.577906976744186e-05,
      "loss": 0.0996,
      "step": 6249
    },
    {
      "epoch": 24.224806201550386,
      "grad_norm": 0.004493995103985071,
      "learning_rate": 2.5775193798449615e-05,
      "loss": 0.0002,
      "step": 6250
    },
    {
      "epoch": 24.228682170542637,
      "grad_norm": 0.028152013197541237,
      "learning_rate": 2.5771317829457364e-05,
      "loss": 0.0002,
      "step": 6251
    },
    {
      "epoch": 24.232558139534884,
      "grad_norm": 0.002637913217768073,
      "learning_rate": 2.576744186046512e-05,
      "loss": 0.0002,
      "step": 6252
    },
    {
      "epoch": 24.23643410852713,
      "grad_norm": 0.0018032247899100184,
      "learning_rate": 2.576356589147287e-05,
      "loss": 0.0002,
      "step": 6253
    },
    {
      "epoch": 24.24031007751938,
      "grad_norm": 0.0024304373655468225,
      "learning_rate": 2.5759689922480625e-05,
      "loss": 0.0002,
      "step": 6254
    },
    {
      "epoch": 24.24418604651163,
      "grad_norm": 0.0026676845736801624,
      "learning_rate": 2.5755813953488374e-05,
      "loss": 0.0002,
      "step": 6255
    },
    {
      "epoch": 24.248062015503876,
      "grad_norm": 8.685163497924805,
      "learning_rate": 2.5751937984496126e-05,
      "loss": 0.0434,
      "step": 6256
    },
    {
      "epoch": 24.251937984496124,
      "grad_norm": 0.002538247499614954,
      "learning_rate": 2.5748062015503875e-05,
      "loss": 0.0002,
      "step": 6257
    },
    {
      "epoch": 24.25581395348837,
      "grad_norm": 0.0017553032375872135,
      "learning_rate": 2.574418604651163e-05,
      "loss": 0.0002,
      "step": 6258
    },
    {
      "epoch": 24.25968992248062,
      "grad_norm": 0.0035402686335146427,
      "learning_rate": 2.574031007751938e-05,
      "loss": 0.0002,
      "step": 6259
    },
    {
      "epoch": 24.26356589147287,
      "grad_norm": 0.013087984174489975,
      "learning_rate": 2.5736434108527136e-05,
      "loss": 0.0006,
      "step": 6260
    },
    {
      "epoch": 24.267441860465116,
      "grad_norm": 0.04662596806883812,
      "learning_rate": 2.5732558139534885e-05,
      "loss": 0.0005,
      "step": 6261
    },
    {
      "epoch": 24.271317829457363,
      "grad_norm": 0.0023013895843178034,
      "learning_rate": 2.572868217054264e-05,
      "loss": 0.0002,
      "step": 6262
    },
    {
      "epoch": 24.275193798449614,
      "grad_norm": 0.002101060003042221,
      "learning_rate": 2.572480620155039e-05,
      "loss": 0.0002,
      "step": 6263
    },
    {
      "epoch": 24.27906976744186,
      "grad_norm": 0.007744498550891876,
      "learning_rate": 2.572093023255814e-05,
      "loss": 0.0003,
      "step": 6264
    },
    {
      "epoch": 24.282945736434108,
      "grad_norm": 0.053828973323106766,
      "learning_rate": 2.571705426356589e-05,
      "loss": 0.001,
      "step": 6265
    },
    {
      "epoch": 24.286821705426355,
      "grad_norm": 0.008900630287826061,
      "learning_rate": 2.5713178294573644e-05,
      "loss": 0.0002,
      "step": 6266
    },
    {
      "epoch": 24.290697674418606,
      "grad_norm": 0.0036371296737343073,
      "learning_rate": 2.5709302325581396e-05,
      "loss": 0.0002,
      "step": 6267
    },
    {
      "epoch": 24.294573643410853,
      "grad_norm": 0.002946156309917569,
      "learning_rate": 2.5705426356589145e-05,
      "loss": 0.0003,
      "step": 6268
    },
    {
      "epoch": 24.2984496124031,
      "grad_norm": 0.0037061860784888268,
      "learning_rate": 2.57015503875969e-05,
      "loss": 0.0002,
      "step": 6269
    },
    {
      "epoch": 24.302325581395348,
      "grad_norm": 0.002441702876240015,
      "learning_rate": 2.569767441860465e-05,
      "loss": 0.0002,
      "step": 6270
    },
    {
      "epoch": 24.3062015503876,
      "grad_norm": 0.003688048105686903,
      "learning_rate": 2.5693798449612406e-05,
      "loss": 0.0002,
      "step": 6271
    },
    {
      "epoch": 24.310077519379846,
      "grad_norm": 0.002961633028462529,
      "learning_rate": 2.5689922480620155e-05,
      "loss": 0.0002,
      "step": 6272
    },
    {
      "epoch": 24.313953488372093,
      "grad_norm": 0.002184296492487192,
      "learning_rate": 2.568604651162791e-05,
      "loss": 0.0002,
      "step": 6273
    },
    {
      "epoch": 24.31782945736434,
      "grad_norm": 0.0020275532733649015,
      "learning_rate": 2.568217054263566e-05,
      "loss": 0.0002,
      "step": 6274
    },
    {
      "epoch": 24.32170542635659,
      "grad_norm": 0.0018636168679222465,
      "learning_rate": 2.5678294573643412e-05,
      "loss": 0.0002,
      "step": 6275
    },
    {
      "epoch": 24.325581395348838,
      "grad_norm": 0.0014590657083317637,
      "learning_rate": 2.567441860465116e-05,
      "loss": 0.0002,
      "step": 6276
    },
    {
      "epoch": 24.329457364341085,
      "grad_norm": 0.0032132987398654222,
      "learning_rate": 2.5670542635658917e-05,
      "loss": 0.0002,
      "step": 6277
    },
    {
      "epoch": 24.333333333333332,
      "grad_norm": 0.001379497116431594,
      "learning_rate": 2.5666666666666666e-05,
      "loss": 0.0001,
      "step": 6278
    },
    {
      "epoch": 24.337209302325583,
      "grad_norm": 0.001801140489988029,
      "learning_rate": 2.5662790697674422e-05,
      "loss": 0.0001,
      "step": 6279
    },
    {
      "epoch": 24.34108527131783,
      "grad_norm": 0.001677494845353067,
      "learning_rate": 2.565891472868217e-05,
      "loss": 0.0002,
      "step": 6280
    },
    {
      "epoch": 24.344961240310077,
      "grad_norm": 2.9835336208343506,
      "learning_rate": 2.5655038759689927e-05,
      "loss": 0.0781,
      "step": 6281
    },
    {
      "epoch": 24.348837209302324,
      "grad_norm": 0.002064623637124896,
      "learning_rate": 2.5651162790697676e-05,
      "loss": 0.0002,
      "step": 6282
    },
    {
      "epoch": 24.352713178294575,
      "grad_norm": 1.1428515911102295,
      "learning_rate": 2.5647286821705428e-05,
      "loss": 0.0646,
      "step": 6283
    },
    {
      "epoch": 24.356589147286822,
      "grad_norm": 0.003036813111975789,
      "learning_rate": 2.564341085271318e-05,
      "loss": 0.0002,
      "step": 6284
    },
    {
      "epoch": 24.36046511627907,
      "grad_norm": 0.0033037872053682804,
      "learning_rate": 2.5639534883720933e-05,
      "loss": 0.0003,
      "step": 6285
    },
    {
      "epoch": 24.364341085271317,
      "grad_norm": 0.0033086067996919155,
      "learning_rate": 2.5635658914728682e-05,
      "loss": 0.0002,
      "step": 6286
    },
    {
      "epoch": 24.368217054263567,
      "grad_norm": 0.0024673643056303263,
      "learning_rate": 2.5631782945736438e-05,
      "loss": 0.0002,
      "step": 6287
    },
    {
      "epoch": 24.372093023255815,
      "grad_norm": 0.005880121607333422,
      "learning_rate": 2.5627906976744187e-05,
      "loss": 0.0004,
      "step": 6288
    },
    {
      "epoch": 24.375968992248062,
      "grad_norm": 0.0016596319619566202,
      "learning_rate": 2.5624031007751943e-05,
      "loss": 0.0002,
      "step": 6289
    },
    {
      "epoch": 24.37984496124031,
      "grad_norm": 0.0019419309683144093,
      "learning_rate": 2.562015503875969e-05,
      "loss": 0.0002,
      "step": 6290
    },
    {
      "epoch": 24.38372093023256,
      "grad_norm": 0.0023024724796414375,
      "learning_rate": 2.561627906976744e-05,
      "loss": 0.0002,
      "step": 6291
    },
    {
      "epoch": 24.387596899224807,
      "grad_norm": 0.0015975285787135363,
      "learning_rate": 2.5612403100775197e-05,
      "loss": 0.0002,
      "step": 6292
    },
    {
      "epoch": 24.391472868217054,
      "grad_norm": 0.9362418055534363,
      "learning_rate": 2.5608527131782946e-05,
      "loss": 0.0651,
      "step": 6293
    },
    {
      "epoch": 24.3953488372093,
      "grad_norm": 0.0026464893016964197,
      "learning_rate": 2.5604651162790698e-05,
      "loss": 0.0002,
      "step": 6294
    },
    {
      "epoch": 24.399224806201552,
      "grad_norm": 0.002669315319508314,
      "learning_rate": 2.5600775193798447e-05,
      "loss": 0.0002,
      "step": 6295
    },
    {
      "epoch": 24.4031007751938,
      "grad_norm": 0.9750964045524597,
      "learning_rate": 2.5596899224806203e-05,
      "loss": 0.0049,
      "step": 6296
    },
    {
      "epoch": 24.406976744186046,
      "grad_norm": 0.0018699138890951872,
      "learning_rate": 2.5593023255813952e-05,
      "loss": 0.0002,
      "step": 6297
    },
    {
      "epoch": 24.410852713178294,
      "grad_norm": 0.0019923646468669176,
      "learning_rate": 2.5589147286821708e-05,
      "loss": 0.0002,
      "step": 6298
    },
    {
      "epoch": 24.414728682170544,
      "grad_norm": 0.002534344792366028,
      "learning_rate": 2.5585271317829457e-05,
      "loss": 0.0002,
      "step": 6299
    },
    {
      "epoch": 24.41860465116279,
      "grad_norm": 0.0038081996608525515,
      "learning_rate": 2.5581395348837212e-05,
      "loss": 0.0002,
      "step": 6300
    },
    {
      "epoch": 24.42248062015504,
      "grad_norm": 0.0014040784444659948,
      "learning_rate": 2.557751937984496e-05,
      "loss": 0.0001,
      "step": 6301
    },
    {
      "epoch": 24.426356589147286,
      "grad_norm": 0.0013275319943204522,
      "learning_rate": 2.5573643410852714e-05,
      "loss": 0.0001,
      "step": 6302
    },
    {
      "epoch": 24.430232558139537,
      "grad_norm": 0.11989104002714157,
      "learning_rate": 2.5569767441860466e-05,
      "loss": 0.0005,
      "step": 6303
    },
    {
      "epoch": 24.434108527131784,
      "grad_norm": 0.0014022471150383353,
      "learning_rate": 2.556589147286822e-05,
      "loss": 0.0001,
      "step": 6304
    },
    {
      "epoch": 24.43798449612403,
      "grad_norm": 0.002520204521715641,
      "learning_rate": 2.5562015503875968e-05,
      "loss": 0.0002,
      "step": 6305
    },
    {
      "epoch": 24.441860465116278,
      "grad_norm": 0.005303000099956989,
      "learning_rate": 2.5558139534883724e-05,
      "loss": 0.0004,
      "step": 6306
    },
    {
      "epoch": 24.44573643410853,
      "grad_norm": 0.0015089641092345119,
      "learning_rate": 2.5554263565891473e-05,
      "loss": 0.0001,
      "step": 6307
    },
    {
      "epoch": 24.449612403100776,
      "grad_norm": 0.0014774641022086143,
      "learning_rate": 2.555038759689923e-05,
      "loss": 0.0001,
      "step": 6308
    },
    {
      "epoch": 24.453488372093023,
      "grad_norm": 0.0016018697060644627,
      "learning_rate": 2.5546511627906978e-05,
      "loss": 0.0002,
      "step": 6309
    },
    {
      "epoch": 24.45736434108527,
      "grad_norm": 11.396415710449219,
      "learning_rate": 2.5542635658914733e-05,
      "loss": 0.2114,
      "step": 6310
    },
    {
      "epoch": 24.46124031007752,
      "grad_norm": 0.0013943620724603534,
      "learning_rate": 2.5538759689922482e-05,
      "loss": 0.0001,
      "step": 6311
    },
    {
      "epoch": 24.46511627906977,
      "grad_norm": 0.004721118602901697,
      "learning_rate": 2.5534883720930235e-05,
      "loss": 0.0003,
      "step": 6312
    },
    {
      "epoch": 24.468992248062015,
      "grad_norm": 0.9664857387542725,
      "learning_rate": 2.5531007751937984e-05,
      "loss": 0.066,
      "step": 6313
    },
    {
      "epoch": 24.472868217054263,
      "grad_norm": 0.0025207626167684793,
      "learning_rate": 2.552713178294574e-05,
      "loss": 0.0002,
      "step": 6314
    },
    {
      "epoch": 24.476744186046513,
      "grad_norm": 0.0023819920606911182,
      "learning_rate": 2.552325581395349e-05,
      "loss": 0.0002,
      "step": 6315
    },
    {
      "epoch": 24.48062015503876,
      "grad_norm": 0.0016332281520590186,
      "learning_rate": 2.5519379844961244e-05,
      "loss": 0.0001,
      "step": 6316
    },
    {
      "epoch": 24.484496124031008,
      "grad_norm": 0.001330673461779952,
      "learning_rate": 2.5515503875968994e-05,
      "loss": 0.0001,
      "step": 6317
    },
    {
      "epoch": 24.488372093023255,
      "grad_norm": 0.0035041244700551033,
      "learning_rate": 2.5511627906976743e-05,
      "loss": 0.0003,
      "step": 6318
    },
    {
      "epoch": 24.492248062015506,
      "grad_norm": 0.0014922304544597864,
      "learning_rate": 2.55077519379845e-05,
      "loss": 0.0002,
      "step": 6319
    },
    {
      "epoch": 24.496124031007753,
      "grad_norm": 0.0013112215092405677,
      "learning_rate": 2.5503875968992247e-05,
      "loss": 0.0001,
      "step": 6320
    },
    {
      "epoch": 24.5,
      "grad_norm": 0.0054178484715521336,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 0.0003,
      "step": 6321
    },
    {
      "epoch": 24.503875968992247,
      "grad_norm": 0.011552108451724052,
      "learning_rate": 2.5496124031007752e-05,
      "loss": 0.0003,
      "step": 6322
    },
    {
      "epoch": 24.507751937984494,
      "grad_norm": 0.005764850880950689,
      "learning_rate": 2.5492248062015505e-05,
      "loss": 0.0004,
      "step": 6323
    },
    {
      "epoch": 24.511627906976745,
      "grad_norm": 0.006143640261143446,
      "learning_rate": 2.5488372093023254e-05,
      "loss": 0.0003,
      "step": 6324
    },
    {
      "epoch": 24.515503875968992,
      "grad_norm": 0.0013655873481184244,
      "learning_rate": 2.548449612403101e-05,
      "loss": 0.0001,
      "step": 6325
    },
    {
      "epoch": 24.51937984496124,
      "grad_norm": 0.0014311771374195814,
      "learning_rate": 2.548062015503876e-05,
      "loss": 0.0001,
      "step": 6326
    },
    {
      "epoch": 24.52325581395349,
      "grad_norm": 0.0013382903998717666,
      "learning_rate": 2.5476744186046514e-05,
      "loss": 0.0001,
      "step": 6327
    },
    {
      "epoch": 24.527131782945737,
      "grad_norm": 0.010333899408578873,
      "learning_rate": 2.5472868217054263e-05,
      "loss": 0.0002,
      "step": 6328
    },
    {
      "epoch": 24.531007751937985,
      "grad_norm": 4.963358402252197,
      "learning_rate": 2.546899224806202e-05,
      "loss": 0.7337,
      "step": 6329
    },
    {
      "epoch": 24.53488372093023,
      "grad_norm": 0.001457161153666675,
      "learning_rate": 2.5465116279069768e-05,
      "loss": 0.0001,
      "step": 6330
    },
    {
      "epoch": 24.53875968992248,
      "grad_norm": 0.0017069304594770074,
      "learning_rate": 2.546124031007752e-05,
      "loss": 0.0002,
      "step": 6331
    },
    {
      "epoch": 24.54263565891473,
      "grad_norm": 0.00887507013976574,
      "learning_rate": 2.545736434108527e-05,
      "loss": 0.0003,
      "step": 6332
    },
    {
      "epoch": 24.546511627906977,
      "grad_norm": 0.0013806013157591224,
      "learning_rate": 2.5453488372093025e-05,
      "loss": 0.0001,
      "step": 6333
    },
    {
      "epoch": 24.550387596899224,
      "grad_norm": 8.173869132995605,
      "learning_rate": 2.5449612403100775e-05,
      "loss": 0.1927,
      "step": 6334
    },
    {
      "epoch": 24.55426356589147,
      "grad_norm": 0.004716032184660435,
      "learning_rate": 2.544573643410853e-05,
      "loss": 0.0002,
      "step": 6335
    },
    {
      "epoch": 24.558139534883722,
      "grad_norm": 0.2187763750553131,
      "learning_rate": 2.544186046511628e-05,
      "loss": 0.0009,
      "step": 6336
    },
    {
      "epoch": 24.56201550387597,
      "grad_norm": 0.001415893668308854,
      "learning_rate": 2.5437984496124035e-05,
      "loss": 0.0001,
      "step": 6337
    },
    {
      "epoch": 24.565891472868216,
      "grad_norm": 0.0016938048647716641,
      "learning_rate": 2.5434108527131784e-05,
      "loss": 0.0002,
      "step": 6338
    },
    {
      "epoch": 24.569767441860463,
      "grad_norm": 0.0013459710171446204,
      "learning_rate": 2.543023255813954e-05,
      "loss": 0.0001,
      "step": 6339
    },
    {
      "epoch": 24.573643410852714,
      "grad_norm": 0.006476123817265034,
      "learning_rate": 2.542635658914729e-05,
      "loss": 0.0002,
      "step": 6340
    },
    {
      "epoch": 24.57751937984496,
      "grad_norm": 0.03333777189254761,
      "learning_rate": 2.542248062015504e-05,
      "loss": 0.0002,
      "step": 6341
    },
    {
      "epoch": 24.58139534883721,
      "grad_norm": 0.0015732579631730914,
      "learning_rate": 2.541860465116279e-05,
      "loss": 0.0002,
      "step": 6342
    },
    {
      "epoch": 24.585271317829456,
      "grad_norm": 26.205915451049805,
      "learning_rate": 2.5414728682170546e-05,
      "loss": 0.1878,
      "step": 6343
    },
    {
      "epoch": 24.589147286821706,
      "grad_norm": 1.370061993598938,
      "learning_rate": 2.5410852713178295e-05,
      "loss": 0.1275,
      "step": 6344
    },
    {
      "epoch": 24.593023255813954,
      "grad_norm": 0.0016717989929020405,
      "learning_rate": 2.5406976744186044e-05,
      "loss": 0.0002,
      "step": 6345
    },
    {
      "epoch": 24.5968992248062,
      "grad_norm": 1.3216148614883423,
      "learning_rate": 2.54031007751938e-05,
      "loss": 0.0634,
      "step": 6346
    },
    {
      "epoch": 24.600775193798448,
      "grad_norm": 0.007901116274297237,
      "learning_rate": 2.539922480620155e-05,
      "loss": 0.0004,
      "step": 6347
    },
    {
      "epoch": 24.6046511627907,
      "grad_norm": 0.07839613407850266,
      "learning_rate": 2.5395348837209305e-05,
      "loss": 0.0003,
      "step": 6348
    },
    {
      "epoch": 24.608527131782946,
      "grad_norm": 0.0020889074075967073,
      "learning_rate": 2.5391472868217054e-05,
      "loss": 0.0002,
      "step": 6349
    },
    {
      "epoch": 24.612403100775193,
      "grad_norm": 0.0016432078555226326,
      "learning_rate": 2.5387596899224806e-05,
      "loss": 0.0002,
      "step": 6350
    },
    {
      "epoch": 24.61627906976744,
      "grad_norm": 2.7901859283447266,
      "learning_rate": 2.538372093023256e-05,
      "loss": 0.3232,
      "step": 6351
    },
    {
      "epoch": 24.62015503875969,
      "grad_norm": 0.0025665941648185253,
      "learning_rate": 2.537984496124031e-05,
      "loss": 0.0002,
      "step": 6352
    },
    {
      "epoch": 24.624031007751938,
      "grad_norm": 0.002439890056848526,
      "learning_rate": 2.537596899224806e-05,
      "loss": 0.0002,
      "step": 6353
    },
    {
      "epoch": 24.627906976744185,
      "grad_norm": 0.0018202824285253882,
      "learning_rate": 2.5372093023255816e-05,
      "loss": 0.0002,
      "step": 6354
    },
    {
      "epoch": 24.631782945736433,
      "grad_norm": 0.36953264474868774,
      "learning_rate": 2.5368217054263565e-05,
      "loss": 0.0047,
      "step": 6355
    },
    {
      "epoch": 24.635658914728683,
      "grad_norm": 0.0016682191053405404,
      "learning_rate": 2.536434108527132e-05,
      "loss": 0.0001,
      "step": 6356
    },
    {
      "epoch": 24.63953488372093,
      "grad_norm": 0.002116309478878975,
      "learning_rate": 2.536046511627907e-05,
      "loss": 0.0002,
      "step": 6357
    },
    {
      "epoch": 24.643410852713178,
      "grad_norm": 0.0019150783773511648,
      "learning_rate": 2.5356589147286826e-05,
      "loss": 0.0002,
      "step": 6358
    },
    {
      "epoch": 24.647286821705425,
      "grad_norm": 0.0021670309361070395,
      "learning_rate": 2.5352713178294575e-05,
      "loss": 0.0002,
      "step": 6359
    },
    {
      "epoch": 24.651162790697676,
      "grad_norm": 0.0016087403055280447,
      "learning_rate": 2.5348837209302327e-05,
      "loss": 0.0002,
      "step": 6360
    },
    {
      "epoch": 24.655038759689923,
      "grad_norm": 0.0016502278158441186,
      "learning_rate": 2.5344961240310076e-05,
      "loss": 0.0002,
      "step": 6361
    },
    {
      "epoch": 24.65891472868217,
      "grad_norm": 0.0018543178448453546,
      "learning_rate": 2.5341085271317832e-05,
      "loss": 0.0002,
      "step": 6362
    },
    {
      "epoch": 24.662790697674417,
      "grad_norm": 0.0014281029580160975,
      "learning_rate": 2.533720930232558e-05,
      "loss": 0.0002,
      "step": 6363
    },
    {
      "epoch": 24.666666666666668,
      "grad_norm": 0.0020485182758420706,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.0002,
      "step": 6364
    },
    {
      "epoch": 24.670542635658915,
      "grad_norm": 10.921221733093262,
      "learning_rate": 2.5329457364341086e-05,
      "loss": 0.2884,
      "step": 6365
    },
    {
      "epoch": 24.674418604651162,
      "grad_norm": 0.003988443873822689,
      "learning_rate": 2.5325581395348842e-05,
      "loss": 0.0003,
      "step": 6366
    },
    {
      "epoch": 24.67829457364341,
      "grad_norm": 0.00909180287271738,
      "learning_rate": 2.532170542635659e-05,
      "loss": 0.0005,
      "step": 6367
    },
    {
      "epoch": 24.68217054263566,
      "grad_norm": 0.0017676294082775712,
      "learning_rate": 2.5317829457364343e-05,
      "loss": 0.0002,
      "step": 6368
    },
    {
      "epoch": 24.686046511627907,
      "grad_norm": 3.351175308227539,
      "learning_rate": 2.5313953488372096e-05,
      "loss": 0.2707,
      "step": 6369
    },
    {
      "epoch": 24.689922480620154,
      "grad_norm": 0.003567179897800088,
      "learning_rate": 2.5310077519379848e-05,
      "loss": 0.0002,
      "step": 6370
    },
    {
      "epoch": 24.6937984496124,
      "grad_norm": 0.010967065580189228,
      "learning_rate": 2.5306201550387597e-05,
      "loss": 0.0005,
      "step": 6371
    },
    {
      "epoch": 24.697674418604652,
      "grad_norm": 0.16436590254306793,
      "learning_rate": 2.5302325581395346e-05,
      "loss": 0.0071,
      "step": 6372
    },
    {
      "epoch": 24.7015503875969,
      "grad_norm": 0.0013870028778910637,
      "learning_rate": 2.5298449612403102e-05,
      "loss": 0.0001,
      "step": 6373
    },
    {
      "epoch": 24.705426356589147,
      "grad_norm": 0.0011949458857998252,
      "learning_rate": 2.529457364341085e-05,
      "loss": 0.0001,
      "step": 6374
    },
    {
      "epoch": 24.709302325581394,
      "grad_norm": 0.8535420298576355,
      "learning_rate": 2.5290697674418607e-05,
      "loss": 0.1071,
      "step": 6375
    },
    {
      "epoch": 24.713178294573645,
      "grad_norm": 0.00146110903006047,
      "learning_rate": 2.5286821705426356e-05,
      "loss": 0.0002,
      "step": 6376
    },
    {
      "epoch": 24.717054263565892,
      "grad_norm": 0.0025405515916645527,
      "learning_rate": 2.528294573643411e-05,
      "loss": 0.0002,
      "step": 6377
    },
    {
      "epoch": 24.72093023255814,
      "grad_norm": 0.0034563124645501375,
      "learning_rate": 2.527906976744186e-05,
      "loss": 0.0003,
      "step": 6378
    },
    {
      "epoch": 24.724806201550386,
      "grad_norm": 0.0031585018150508404,
      "learning_rate": 2.5275193798449613e-05,
      "loss": 0.0003,
      "step": 6379
    },
    {
      "epoch": 24.728682170542637,
      "grad_norm": 0.008151655085384846,
      "learning_rate": 2.5271317829457362e-05,
      "loss": 0.0002,
      "step": 6380
    },
    {
      "epoch": 24.732558139534884,
      "grad_norm": 0.001874007168225944,
      "learning_rate": 2.5267441860465118e-05,
      "loss": 0.0002,
      "step": 6381
    },
    {
      "epoch": 24.73643410852713,
      "grad_norm": 0.37338605523109436,
      "learning_rate": 2.5263565891472867e-05,
      "loss": 0.0024,
      "step": 6382
    },
    {
      "epoch": 24.74031007751938,
      "grad_norm": 0.001075608772225678,
      "learning_rate": 2.5259689922480623e-05,
      "loss": 0.0001,
      "step": 6383
    },
    {
      "epoch": 24.74418604651163,
      "grad_norm": 0.001388621749356389,
      "learning_rate": 2.5255813953488372e-05,
      "loss": 0.0001,
      "step": 6384
    },
    {
      "epoch": 24.748062015503876,
      "grad_norm": 0.002045610686764121,
      "learning_rate": 2.5251937984496128e-05,
      "loss": 0.0001,
      "step": 6385
    },
    {
      "epoch": 24.751937984496124,
      "grad_norm": 1.3326656818389893,
      "learning_rate": 2.5248062015503877e-05,
      "loss": 0.096,
      "step": 6386
    },
    {
      "epoch": 24.75581395348837,
      "grad_norm": 0.003030611900612712,
      "learning_rate": 2.5244186046511633e-05,
      "loss": 0.0002,
      "step": 6387
    },
    {
      "epoch": 24.75968992248062,
      "grad_norm": 0.5801228880882263,
      "learning_rate": 2.524031007751938e-05,
      "loss": 0.0227,
      "step": 6388
    },
    {
      "epoch": 24.76356589147287,
      "grad_norm": 0.001501157646998763,
      "learning_rate": 2.5236434108527134e-05,
      "loss": 0.0001,
      "step": 6389
    },
    {
      "epoch": 24.767441860465116,
      "grad_norm": 0.0048947082832455635,
      "learning_rate": 2.5232558139534883e-05,
      "loss": 0.0003,
      "step": 6390
    },
    {
      "epoch": 24.771317829457363,
      "grad_norm": 0.0015759296948090196,
      "learning_rate": 2.522868217054264e-05,
      "loss": 0.0002,
      "step": 6391
    },
    {
      "epoch": 24.775193798449614,
      "grad_norm": 0.001161182764917612,
      "learning_rate": 2.5224806201550388e-05,
      "loss": 0.0001,
      "step": 6392
    },
    {
      "epoch": 24.77906976744186,
      "grad_norm": 0.8929676413536072,
      "learning_rate": 2.5220930232558144e-05,
      "loss": 0.0429,
      "step": 6393
    },
    {
      "epoch": 24.782945736434108,
      "grad_norm": 37.8738899230957,
      "learning_rate": 2.5217054263565893e-05,
      "loss": 0.3355,
      "step": 6394
    },
    {
      "epoch": 24.786821705426355,
      "grad_norm": 13.043750762939453,
      "learning_rate": 2.521317829457365e-05,
      "loss": 0.133,
      "step": 6395
    },
    {
      "epoch": 24.790697674418606,
      "grad_norm": 0.2535441815853119,
      "learning_rate": 2.5209302325581398e-05,
      "loss": 0.0025,
      "step": 6396
    },
    {
      "epoch": 24.794573643410853,
      "grad_norm": 0.03290422260761261,
      "learning_rate": 2.5205426356589147e-05,
      "loss": 0.0009,
      "step": 6397
    },
    {
      "epoch": 24.7984496124031,
      "grad_norm": 0.0014319720212370157,
      "learning_rate": 2.52015503875969e-05,
      "loss": 0.0002,
      "step": 6398
    },
    {
      "epoch": 24.802325581395348,
      "grad_norm": 5.522847652435303,
      "learning_rate": 2.519767441860465e-05,
      "loss": 0.0505,
      "step": 6399
    },
    {
      "epoch": 24.8062015503876,
      "grad_norm": 1.8698850870132446,
      "learning_rate": 2.5193798449612404e-05,
      "loss": 0.1334,
      "step": 6400
    },
    {
      "epoch": 24.810077519379846,
      "grad_norm": 0.002595562720671296,
      "learning_rate": 2.5189922480620153e-05,
      "loss": 0.0002,
      "step": 6401
    },
    {
      "epoch": 24.813953488372093,
      "grad_norm": 0.003578818403184414,
      "learning_rate": 2.518604651162791e-05,
      "loss": 0.0003,
      "step": 6402
    },
    {
      "epoch": 24.81782945736434,
      "grad_norm": 1.3334683179855347,
      "learning_rate": 2.5182170542635658e-05,
      "loss": 0.0459,
      "step": 6403
    },
    {
      "epoch": 24.82170542635659,
      "grad_norm": 0.19327738881111145,
      "learning_rate": 2.5178294573643414e-05,
      "loss": 0.0084,
      "step": 6404
    },
    {
      "epoch": 24.825581395348838,
      "grad_norm": 0.0015678879572078586,
      "learning_rate": 2.5174418604651163e-05,
      "loss": 0.0002,
      "step": 6405
    },
    {
      "epoch": 24.829457364341085,
      "grad_norm": 0.11461734026670456,
      "learning_rate": 2.517054263565892e-05,
      "loss": 0.0012,
      "step": 6406
    },
    {
      "epoch": 24.833333333333332,
      "grad_norm": 0.001410254742950201,
      "learning_rate": 2.5166666666666667e-05,
      "loss": 0.0001,
      "step": 6407
    },
    {
      "epoch": 24.837209302325583,
      "grad_norm": 0.002216256456449628,
      "learning_rate": 2.516279069767442e-05,
      "loss": 0.0002,
      "step": 6408
    },
    {
      "epoch": 24.84108527131783,
      "grad_norm": 0.015619221143424511,
      "learning_rate": 2.515891472868217e-05,
      "loss": 0.0004,
      "step": 6409
    },
    {
      "epoch": 24.844961240310077,
      "grad_norm": 0.0028266587760299444,
      "learning_rate": 2.5155038759689925e-05,
      "loss": 0.0002,
      "step": 6410
    },
    {
      "epoch": 24.848837209302324,
      "grad_norm": 0.599673867225647,
      "learning_rate": 2.5151162790697674e-05,
      "loss": 0.0249,
      "step": 6411
    },
    {
      "epoch": 24.852713178294575,
      "grad_norm": 0.005326500628143549,
      "learning_rate": 2.514728682170543e-05,
      "loss": 0.0003,
      "step": 6412
    },
    {
      "epoch": 24.856589147286822,
      "grad_norm": 0.0021205851808190346,
      "learning_rate": 2.514341085271318e-05,
      "loss": 0.0002,
      "step": 6413
    },
    {
      "epoch": 24.86046511627907,
      "grad_norm": 0.007718425709754229,
      "learning_rate": 2.5139534883720934e-05,
      "loss": 0.0004,
      "step": 6414
    },
    {
      "epoch": 24.864341085271317,
      "grad_norm": 0.1573076844215393,
      "learning_rate": 2.5135658914728683e-05,
      "loss": 0.0067,
      "step": 6415
    },
    {
      "epoch": 24.868217054263567,
      "grad_norm": 0.0018048902275040746,
      "learning_rate": 2.5131782945736436e-05,
      "loss": 0.0002,
      "step": 6416
    },
    {
      "epoch": 24.872093023255815,
      "grad_norm": 0.0019037936581298709,
      "learning_rate": 2.5127906976744188e-05,
      "loss": 0.0002,
      "step": 6417
    },
    {
      "epoch": 24.875968992248062,
      "grad_norm": 0.0015477144625037909,
      "learning_rate": 2.512403100775194e-05,
      "loss": 0.0001,
      "step": 6418
    },
    {
      "epoch": 24.87984496124031,
      "grad_norm": 0.012504315935075283,
      "learning_rate": 2.512015503875969e-05,
      "loss": 0.0003,
      "step": 6419
    },
    {
      "epoch": 24.88372093023256,
      "grad_norm": 0.040945783257484436,
      "learning_rate": 2.5116279069767445e-05,
      "loss": 0.0003,
      "step": 6420
    },
    {
      "epoch": 24.887596899224807,
      "grad_norm": 0.4919951856136322,
      "learning_rate": 2.5112403100775195e-05,
      "loss": 0.0206,
      "step": 6421
    },
    {
      "epoch": 24.891472868217054,
      "grad_norm": 0.007625634782016277,
      "learning_rate": 2.510852713178295e-05,
      "loss": 0.0005,
      "step": 6422
    },
    {
      "epoch": 24.8953488372093,
      "grad_norm": 0.0017256452701985836,
      "learning_rate": 2.51046511627907e-05,
      "loss": 0.0002,
      "step": 6423
    },
    {
      "epoch": 24.899224806201552,
      "grad_norm": 0.0018330392194911838,
      "learning_rate": 2.510077519379845e-05,
      "loss": 0.0002,
      "step": 6424
    },
    {
      "epoch": 24.9031007751938,
      "grad_norm": 0.0019201183458790183,
      "learning_rate": 2.5096899224806204e-05,
      "loss": 0.0001,
      "step": 6425
    },
    {
      "epoch": 24.906976744186046,
      "grad_norm": 0.010576793923974037,
      "learning_rate": 2.5093023255813953e-05,
      "loss": 0.0004,
      "step": 6426
    },
    {
      "epoch": 24.910852713178294,
      "grad_norm": 3.8035953044891357,
      "learning_rate": 2.5089147286821706e-05,
      "loss": 0.0076,
      "step": 6427
    },
    {
      "epoch": 24.914728682170544,
      "grad_norm": 0.0019943364895880222,
      "learning_rate": 2.5085271317829455e-05,
      "loss": 0.0002,
      "step": 6428
    },
    {
      "epoch": 24.91860465116279,
      "grad_norm": 0.0016021712217479944,
      "learning_rate": 2.508139534883721e-05,
      "loss": 0.0002,
      "step": 6429
    },
    {
      "epoch": 24.92248062015504,
      "grad_norm": 6.127594470977783,
      "learning_rate": 2.507751937984496e-05,
      "loss": 0.0883,
      "step": 6430
    },
    {
      "epoch": 24.926356589147286,
      "grad_norm": 0.0035551954060792923,
      "learning_rate": 2.5073643410852715e-05,
      "loss": 0.0002,
      "step": 6431
    },
    {
      "epoch": 24.930232558139537,
      "grad_norm": 0.0032837872859090567,
      "learning_rate": 2.5069767441860464e-05,
      "loss": 0.0002,
      "step": 6432
    },
    {
      "epoch": 24.934108527131784,
      "grad_norm": 0.0018690391443669796,
      "learning_rate": 2.506589147286822e-05,
      "loss": 0.0002,
      "step": 6433
    },
    {
      "epoch": 24.93798449612403,
      "grad_norm": 0.0015804505674168468,
      "learning_rate": 2.506201550387597e-05,
      "loss": 0.0001,
      "step": 6434
    },
    {
      "epoch": 24.941860465116278,
      "grad_norm": 0.004937858786433935,
      "learning_rate": 2.5058139534883725e-05,
      "loss": 0.0003,
      "step": 6435
    },
    {
      "epoch": 24.94573643410853,
      "grad_norm": 0.7542495727539062,
      "learning_rate": 2.5054263565891474e-05,
      "loss": 0.0025,
      "step": 6436
    },
    {
      "epoch": 24.949612403100776,
      "grad_norm": 0.0030653970316052437,
      "learning_rate": 2.5050387596899226e-05,
      "loss": 0.0002,
      "step": 6437
    },
    {
      "epoch": 24.953488372093023,
      "grad_norm": 0.001923304283991456,
      "learning_rate": 2.5046511627906976e-05,
      "loss": 0.0002,
      "step": 6438
    },
    {
      "epoch": 24.95736434108527,
      "grad_norm": 0.013999505899846554,
      "learning_rate": 2.504263565891473e-05,
      "loss": 0.0005,
      "step": 6439
    },
    {
      "epoch": 24.96124031007752,
      "grad_norm": 0.01723906397819519,
      "learning_rate": 2.503875968992248e-05,
      "loss": 0.0006,
      "step": 6440
    },
    {
      "epoch": 24.96511627906977,
      "grad_norm": 0.0018200298072770238,
      "learning_rate": 2.5034883720930236e-05,
      "loss": 0.0002,
      "step": 6441
    },
    {
      "epoch": 24.968992248062015,
      "grad_norm": 0.0027672424912452698,
      "learning_rate": 2.5031007751937985e-05,
      "loss": 0.0002,
      "step": 6442
    },
    {
      "epoch": 24.972868217054263,
      "grad_norm": 0.0018413359066471457,
      "learning_rate": 2.502713178294574e-05,
      "loss": 0.0002,
      "step": 6443
    },
    {
      "epoch": 24.97674418604651,
      "grad_norm": 0.0013025834923610091,
      "learning_rate": 2.502325581395349e-05,
      "loss": 0.0001,
      "step": 6444
    },
    {
      "epoch": 24.98062015503876,
      "grad_norm": 12.896788597106934,
      "learning_rate": 2.5019379844961242e-05,
      "loss": 0.0525,
      "step": 6445
    },
    {
      "epoch": 24.984496124031008,
      "grad_norm": 0.004411610774695873,
      "learning_rate": 2.501550387596899e-05,
      "loss": 0.0003,
      "step": 6446
    },
    {
      "epoch": 24.988372093023255,
      "grad_norm": 0.3901127576828003,
      "learning_rate": 2.5011627906976747e-05,
      "loss": 0.0178,
      "step": 6447
    },
    {
      "epoch": 24.992248062015506,
      "grad_norm": 0.894203782081604,
      "learning_rate": 2.5007751937984496e-05,
      "loss": 0.0184,
      "step": 6448
    },
    {
      "epoch": 24.996124031007753,
      "grad_norm": 0.002264720853418112,
      "learning_rate": 2.5003875968992252e-05,
      "loss": 0.0002,
      "step": 6449
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.001296062720939517,
      "learning_rate": 2.5e-05,
      "loss": 0.0001,
      "step": 6450
    },
    {
      "epoch": 25.003875968992247,
      "grad_norm": 1.4947669506072998,
      "learning_rate": 2.4996124031007754e-05,
      "loss": 0.1224,
      "step": 6451
    },
    {
      "epoch": 25.007751937984494,
      "grad_norm": 2.4031383991241455,
      "learning_rate": 2.4992248062015506e-05,
      "loss": 0.0187,
      "step": 6452
    },
    {
      "epoch": 25.011627906976745,
      "grad_norm": 0.0021215348970144987,
      "learning_rate": 2.498837209302326e-05,
      "loss": 0.0002,
      "step": 6453
    },
    {
      "epoch": 25.015503875968992,
      "grad_norm": 0.0016612119507044554,
      "learning_rate": 2.498449612403101e-05,
      "loss": 0.0002,
      "step": 6454
    },
    {
      "epoch": 25.01937984496124,
      "grad_norm": 0.0021497562993317842,
      "learning_rate": 2.498062015503876e-05,
      "loss": 0.0002,
      "step": 6455
    },
    {
      "epoch": 25.023255813953487,
      "grad_norm": 0.2112213522195816,
      "learning_rate": 2.4976744186046512e-05,
      "loss": 0.0085,
      "step": 6456
    },
    {
      "epoch": 25.027131782945737,
      "grad_norm": 0.001449977862648666,
      "learning_rate": 2.4972868217054265e-05,
      "loss": 0.0001,
      "step": 6457
    },
    {
      "epoch": 25.031007751937985,
      "grad_norm": 0.0017046917928382754,
      "learning_rate": 2.4968992248062017e-05,
      "loss": 0.0002,
      "step": 6458
    },
    {
      "epoch": 25.03488372093023,
      "grad_norm": 0.002238362329080701,
      "learning_rate": 2.496511627906977e-05,
      "loss": 0.0002,
      "step": 6459
    },
    {
      "epoch": 25.03875968992248,
      "grad_norm": 0.0015807844465598464,
      "learning_rate": 2.4961240310077522e-05,
      "loss": 0.0002,
      "step": 6460
    },
    {
      "epoch": 25.04263565891473,
      "grad_norm": 0.15300992131233215,
      "learning_rate": 2.4957364341085274e-05,
      "loss": 0.0062,
      "step": 6461
    },
    {
      "epoch": 25.046511627906977,
      "grad_norm": 0.002079912694171071,
      "learning_rate": 2.4953488372093027e-05,
      "loss": 0.0001,
      "step": 6462
    },
    {
      "epoch": 25.050387596899224,
      "grad_norm": 0.002163493074476719,
      "learning_rate": 2.494961240310078e-05,
      "loss": 0.0002,
      "step": 6463
    },
    {
      "epoch": 25.05426356589147,
      "grad_norm": 0.061164215207099915,
      "learning_rate": 2.494573643410853e-05,
      "loss": 0.0025,
      "step": 6464
    },
    {
      "epoch": 25.058139534883722,
      "grad_norm": 0.0016198672819882631,
      "learning_rate": 2.4941860465116277e-05,
      "loss": 0.0001,
      "step": 6465
    },
    {
      "epoch": 25.06201550387597,
      "grad_norm": 0.0025314991362392902,
      "learning_rate": 2.493798449612403e-05,
      "loss": 0.0002,
      "step": 6466
    },
    {
      "epoch": 25.065891472868216,
      "grad_norm": 0.002724042860791087,
      "learning_rate": 2.4934108527131782e-05,
      "loss": 0.0002,
      "step": 6467
    },
    {
      "epoch": 25.069767441860463,
      "grad_norm": 0.003015478141605854,
      "learning_rate": 2.4930232558139535e-05,
      "loss": 0.0002,
      "step": 6468
    },
    {
      "epoch": 25.073643410852714,
      "grad_norm": 0.0019476617453619838,
      "learning_rate": 2.4926356589147287e-05,
      "loss": 0.0002,
      "step": 6469
    },
    {
      "epoch": 25.07751937984496,
      "grad_norm": 0.0032854764722287655,
      "learning_rate": 2.492248062015504e-05,
      "loss": 0.0002,
      "step": 6470
    },
    {
      "epoch": 25.08139534883721,
      "grad_norm": 13.049257278442383,
      "learning_rate": 2.4918604651162792e-05,
      "loss": 0.3772,
      "step": 6471
    },
    {
      "epoch": 25.085271317829456,
      "grad_norm": 0.7795360684394836,
      "learning_rate": 2.4914728682170544e-05,
      "loss": 0.038,
      "step": 6472
    },
    {
      "epoch": 25.089147286821706,
      "grad_norm": 0.001528979279100895,
      "learning_rate": 2.4910852713178297e-05,
      "loss": 0.0002,
      "step": 6473
    },
    {
      "epoch": 25.093023255813954,
      "grad_norm": 0.0016735887620598078,
      "learning_rate": 2.4906976744186046e-05,
      "loss": 0.0002,
      "step": 6474
    },
    {
      "epoch": 25.0968992248062,
      "grad_norm": 0.0017278564628213644,
      "learning_rate": 2.4903100775193798e-05,
      "loss": 0.0002,
      "step": 6475
    },
    {
      "epoch": 25.100775193798448,
      "grad_norm": 0.002489570528268814,
      "learning_rate": 2.489922480620155e-05,
      "loss": 0.0002,
      "step": 6476
    },
    {
      "epoch": 25.1046511627907,
      "grad_norm": 0.0017825954128056765,
      "learning_rate": 2.4895348837209303e-05,
      "loss": 0.0001,
      "step": 6477
    },
    {
      "epoch": 25.108527131782946,
      "grad_norm": 7.7627339363098145,
      "learning_rate": 2.4891472868217055e-05,
      "loss": 0.9977,
      "step": 6478
    },
    {
      "epoch": 25.112403100775193,
      "grad_norm": 0.0015261409571394324,
      "learning_rate": 2.4887596899224808e-05,
      "loss": 0.0002,
      "step": 6479
    },
    {
      "epoch": 25.11627906976744,
      "grad_norm": 0.002127022249624133,
      "learning_rate": 2.488372093023256e-05,
      "loss": 0.0002,
      "step": 6480
    },
    {
      "epoch": 25.12015503875969,
      "grad_norm": 0.0030234702862799168,
      "learning_rate": 2.4879844961240313e-05,
      "loss": 0.0002,
      "step": 6481
    },
    {
      "epoch": 25.124031007751938,
      "grad_norm": 0.03189622610807419,
      "learning_rate": 2.4875968992248065e-05,
      "loss": 0.001,
      "step": 6482
    },
    {
      "epoch": 25.127906976744185,
      "grad_norm": 0.02974214032292366,
      "learning_rate": 2.4872093023255814e-05,
      "loss": 0.0003,
      "step": 6483
    },
    {
      "epoch": 25.131782945736433,
      "grad_norm": 6.4576239585876465,
      "learning_rate": 2.4868217054263567e-05,
      "loss": 0.4513,
      "step": 6484
    },
    {
      "epoch": 25.135658914728683,
      "grad_norm": 0.001306389458477497,
      "learning_rate": 2.486434108527132e-05,
      "loss": 0.0001,
      "step": 6485
    },
    {
      "epoch": 25.13953488372093,
      "grad_norm": 0.001602275762706995,
      "learning_rate": 2.486046511627907e-05,
      "loss": 0.0002,
      "step": 6486
    },
    {
      "epoch": 25.143410852713178,
      "grad_norm": 0.0036056055687367916,
      "learning_rate": 2.4856589147286824e-05,
      "loss": 0.0002,
      "step": 6487
    },
    {
      "epoch": 25.147286821705425,
      "grad_norm": 0.0011552444193512201,
      "learning_rate": 2.4852713178294576e-05,
      "loss": 0.0001,
      "step": 6488
    },
    {
      "epoch": 25.151162790697676,
      "grad_norm": 0.0015081261517480016,
      "learning_rate": 2.484883720930233e-05,
      "loss": 0.0001,
      "step": 6489
    },
    {
      "epoch": 25.155038759689923,
      "grad_norm": 0.004044142551720142,
      "learning_rate": 2.4844961240310078e-05,
      "loss": 0.0003,
      "step": 6490
    },
    {
      "epoch": 25.15891472868217,
      "grad_norm": 0.0016258638352155685,
      "learning_rate": 2.484108527131783e-05,
      "loss": 0.0002,
      "step": 6491
    },
    {
      "epoch": 25.162790697674417,
      "grad_norm": 0.0015661142533645034,
      "learning_rate": 2.4837209302325583e-05,
      "loss": 0.0002,
      "step": 6492
    },
    {
      "epoch": 25.166666666666668,
      "grad_norm": 0.0014925376744940877,
      "learning_rate": 2.4833333333333335e-05,
      "loss": 0.0001,
      "step": 6493
    },
    {
      "epoch": 25.170542635658915,
      "grad_norm": 0.001979562919586897,
      "learning_rate": 2.4829457364341084e-05,
      "loss": 0.0002,
      "step": 6494
    },
    {
      "epoch": 25.174418604651162,
      "grad_norm": 0.011451826430857182,
      "learning_rate": 2.4825581395348836e-05,
      "loss": 0.0005,
      "step": 6495
    },
    {
      "epoch": 25.17829457364341,
      "grad_norm": 0.003266220912337303,
      "learning_rate": 2.482170542635659e-05,
      "loss": 0.0002,
      "step": 6496
    },
    {
      "epoch": 25.18217054263566,
      "grad_norm": 0.003380357753485441,
      "learning_rate": 2.481782945736434e-05,
      "loss": 0.0003,
      "step": 6497
    },
    {
      "epoch": 25.186046511627907,
      "grad_norm": 0.014177502132952213,
      "learning_rate": 2.4813953488372094e-05,
      "loss": 0.0006,
      "step": 6498
    },
    {
      "epoch": 25.189922480620154,
      "grad_norm": 0.02221972495317459,
      "learning_rate": 2.4810077519379846e-05,
      "loss": 0.0007,
      "step": 6499
    },
    {
      "epoch": 25.1937984496124,
      "grad_norm": 0.001823339844122529,
      "learning_rate": 2.48062015503876e-05,
      "loss": 0.0002,
      "step": 6500
    },
    {
      "epoch": 25.197674418604652,
      "grad_norm": 0.0015937902498990297,
      "learning_rate": 2.480232558139535e-05,
      "loss": 0.0002,
      "step": 6501
    },
    {
      "epoch": 25.2015503875969,
      "grad_norm": 0.002444454003125429,
      "learning_rate": 2.4798449612403103e-05,
      "loss": 0.0002,
      "step": 6502
    },
    {
      "epoch": 25.205426356589147,
      "grad_norm": 0.01962718553841114,
      "learning_rate": 2.4794573643410852e-05,
      "loss": 0.0007,
      "step": 6503
    },
    {
      "epoch": 25.209302325581394,
      "grad_norm": 0.0018139018211513758,
      "learning_rate": 2.4790697674418605e-05,
      "loss": 0.0002,
      "step": 6504
    },
    {
      "epoch": 25.213178294573645,
      "grad_norm": 0.005353614222258329,
      "learning_rate": 2.4786821705426357e-05,
      "loss": 0.0002,
      "step": 6505
    },
    {
      "epoch": 25.217054263565892,
      "grad_norm": 0.002318525919690728,
      "learning_rate": 2.478294573643411e-05,
      "loss": 0.0002,
      "step": 6506
    },
    {
      "epoch": 25.22093023255814,
      "grad_norm": 0.0038815103471279144,
      "learning_rate": 2.4779069767441862e-05,
      "loss": 0.0002,
      "step": 6507
    },
    {
      "epoch": 25.224806201550386,
      "grad_norm": 0.00306898495182395,
      "learning_rate": 2.4775193798449615e-05,
      "loss": 0.0002,
      "step": 6508
    },
    {
      "epoch": 25.228682170542637,
      "grad_norm": 0.0023114923387765884,
      "learning_rate": 2.4771317829457367e-05,
      "loss": 0.0002,
      "step": 6509
    },
    {
      "epoch": 25.232558139534884,
      "grad_norm": 0.0017164578894153237,
      "learning_rate": 2.476744186046512e-05,
      "loss": 0.0002,
      "step": 6510
    },
    {
      "epoch": 25.23643410852713,
      "grad_norm": 0.08475592732429504,
      "learning_rate": 2.4763565891472872e-05,
      "loss": 0.0027,
      "step": 6511
    },
    {
      "epoch": 25.24031007751938,
      "grad_norm": 0.0018258674535900354,
      "learning_rate": 2.475968992248062e-05,
      "loss": 0.0002,
      "step": 6512
    },
    {
      "epoch": 25.24418604651163,
      "grad_norm": 0.00784017238765955,
      "learning_rate": 2.4755813953488373e-05,
      "loss": 0.0004,
      "step": 6513
    },
    {
      "epoch": 25.248062015503876,
      "grad_norm": 0.0036252280697226524,
      "learning_rate": 2.4751937984496126e-05,
      "loss": 0.0002,
      "step": 6514
    },
    {
      "epoch": 25.251937984496124,
      "grad_norm": 77.48672485351562,
      "learning_rate": 2.4748062015503878e-05,
      "loss": 0.0249,
      "step": 6515
    },
    {
      "epoch": 25.25581395348837,
      "grad_norm": 0.01174257043749094,
      "learning_rate": 2.474418604651163e-05,
      "loss": 0.0007,
      "step": 6516
    },
    {
      "epoch": 25.25968992248062,
      "grad_norm": 0.0024285847321152687,
      "learning_rate": 2.474031007751938e-05,
      "loss": 0.0002,
      "step": 6517
    },
    {
      "epoch": 25.26356589147287,
      "grad_norm": 0.0022020384203642607,
      "learning_rate": 2.4736434108527132e-05,
      "loss": 0.0002,
      "step": 6518
    },
    {
      "epoch": 25.267441860465116,
      "grad_norm": 0.006532889790832996,
      "learning_rate": 2.4732558139534884e-05,
      "loss": 0.0003,
      "step": 6519
    },
    {
      "epoch": 25.271317829457363,
      "grad_norm": 0.0057607474736869335,
      "learning_rate": 2.4728682170542637e-05,
      "loss": 0.0003,
      "step": 6520
    },
    {
      "epoch": 25.275193798449614,
      "grad_norm": 0.007409665733575821,
      "learning_rate": 2.472480620155039e-05,
      "loss": 0.0004,
      "step": 6521
    },
    {
      "epoch": 25.27906976744186,
      "grad_norm": 13.450605392456055,
      "learning_rate": 2.4720930232558138e-05,
      "loss": 0.2622,
      "step": 6522
    },
    {
      "epoch": 25.282945736434108,
      "grad_norm": 3.393051862716675,
      "learning_rate": 2.471705426356589e-05,
      "loss": 0.2087,
      "step": 6523
    },
    {
      "epoch": 25.286821705426355,
      "grad_norm": 0.001908602425828576,
      "learning_rate": 2.4713178294573643e-05,
      "loss": 0.0002,
      "step": 6524
    },
    {
      "epoch": 25.290697674418606,
      "grad_norm": 0.002571303164586425,
      "learning_rate": 2.4709302325581396e-05,
      "loss": 0.0002,
      "step": 6525
    },
    {
      "epoch": 25.294573643410853,
      "grad_norm": 0.0017611642833799124,
      "learning_rate": 2.4705426356589148e-05,
      "loss": 0.0002,
      "step": 6526
    },
    {
      "epoch": 25.2984496124031,
      "grad_norm": 3.031522274017334,
      "learning_rate": 2.47015503875969e-05,
      "loss": 0.1816,
      "step": 6527
    },
    {
      "epoch": 25.302325581395348,
      "grad_norm": 0.08235131204128265,
      "learning_rate": 2.4697674418604653e-05,
      "loss": 0.0027,
      "step": 6528
    },
    {
      "epoch": 25.3062015503876,
      "grad_norm": 0.0034423668403178453,
      "learning_rate": 2.4693798449612405e-05,
      "loss": 0.0003,
      "step": 6529
    },
    {
      "epoch": 25.310077519379846,
      "grad_norm": 0.00715102581307292,
      "learning_rate": 2.4689922480620158e-05,
      "loss": 0.0003,
      "step": 6530
    },
    {
      "epoch": 25.313953488372093,
      "grad_norm": 0.0017527504824101925,
      "learning_rate": 2.4686046511627907e-05,
      "loss": 0.0002,
      "step": 6531
    },
    {
      "epoch": 25.31782945736434,
      "grad_norm": 0.011281485669314861,
      "learning_rate": 2.468217054263566e-05,
      "loss": 0.0007,
      "step": 6532
    },
    {
      "epoch": 25.32170542635659,
      "grad_norm": 0.019854895770549774,
      "learning_rate": 2.467829457364341e-05,
      "loss": 0.0002,
      "step": 6533
    },
    {
      "epoch": 25.325581395348838,
      "grad_norm": 0.0017973996000364423,
      "learning_rate": 2.4674418604651164e-05,
      "loss": 0.0002,
      "step": 6534
    },
    {
      "epoch": 25.329457364341085,
      "grad_norm": 0.0018490646034479141,
      "learning_rate": 2.4670542635658916e-05,
      "loss": 0.0002,
      "step": 6535
    },
    {
      "epoch": 25.333333333333332,
      "grad_norm": 14.258218765258789,
      "learning_rate": 2.466666666666667e-05,
      "loss": 0.0963,
      "step": 6536
    },
    {
      "epoch": 25.337209302325583,
      "grad_norm": 0.001516522723250091,
      "learning_rate": 2.466279069767442e-05,
      "loss": 0.0002,
      "step": 6537
    },
    {
      "epoch": 25.34108527131783,
      "grad_norm": 0.0016775791300460696,
      "learning_rate": 2.4658914728682174e-05,
      "loss": 0.0001,
      "step": 6538
    },
    {
      "epoch": 25.344961240310077,
      "grad_norm": 0.0018481947481632233,
      "learning_rate": 2.4655038759689926e-05,
      "loss": 0.0002,
      "step": 6539
    },
    {
      "epoch": 25.348837209302324,
      "grad_norm": 0.030611535534262657,
      "learning_rate": 2.4651162790697675e-05,
      "loss": 0.001,
      "step": 6540
    },
    {
      "epoch": 25.352713178294575,
      "grad_norm": 0.002034996636211872,
      "learning_rate": 2.4647286821705428e-05,
      "loss": 0.0002,
      "step": 6541
    },
    {
      "epoch": 25.356589147286822,
      "grad_norm": 0.0018497566925361753,
      "learning_rate": 2.464341085271318e-05,
      "loss": 0.0002,
      "step": 6542
    },
    {
      "epoch": 25.36046511627907,
      "grad_norm": 0.0014099420513957739,
      "learning_rate": 2.4639534883720932e-05,
      "loss": 0.0001,
      "step": 6543
    },
    {
      "epoch": 25.364341085271317,
      "grad_norm": 0.003011175664141774,
      "learning_rate": 2.463565891472868e-05,
      "loss": 0.0002,
      "step": 6544
    },
    {
      "epoch": 25.368217054263567,
      "grad_norm": 4.758810043334961,
      "learning_rate": 2.4631782945736434e-05,
      "loss": 0.1063,
      "step": 6545
    },
    {
      "epoch": 25.372093023255815,
      "grad_norm": 0.04592355340719223,
      "learning_rate": 2.4627906976744186e-05,
      "loss": 0.0019,
      "step": 6546
    },
    {
      "epoch": 25.375968992248062,
      "grad_norm": 0.0010367537615820765,
      "learning_rate": 2.462403100775194e-05,
      "loss": 0.0001,
      "step": 6547
    },
    {
      "epoch": 25.37984496124031,
      "grad_norm": 13.785696983337402,
      "learning_rate": 2.462015503875969e-05,
      "loss": 0.5932,
      "step": 6548
    },
    {
      "epoch": 25.38372093023256,
      "grad_norm": 1.6093084812164307,
      "learning_rate": 2.4616279069767444e-05,
      "loss": 0.1531,
      "step": 6549
    },
    {
      "epoch": 25.387596899224807,
      "grad_norm": 0.012086820788681507,
      "learning_rate": 2.4612403100775196e-05,
      "loss": 0.0006,
      "step": 6550
    },
    {
      "epoch": 25.391472868217054,
      "grad_norm": 0.005043468438088894,
      "learning_rate": 2.4608527131782945e-05,
      "loss": 0.0002,
      "step": 6551
    },
    {
      "epoch": 25.3953488372093,
      "grad_norm": 0.0016209242166951299,
      "learning_rate": 2.4604651162790697e-05,
      "loss": 0.0001,
      "step": 6552
    },
    {
      "epoch": 25.399224806201552,
      "grad_norm": 0.0027278889901936054,
      "learning_rate": 2.460077519379845e-05,
      "loss": 0.0002,
      "step": 6553
    },
    {
      "epoch": 25.4031007751938,
      "grad_norm": 0.0013051454443484545,
      "learning_rate": 2.4596899224806202e-05,
      "loss": 0.0001,
      "step": 6554
    },
    {
      "epoch": 25.406976744186046,
      "grad_norm": 0.0015623659128323197,
      "learning_rate": 2.4593023255813955e-05,
      "loss": 0.0001,
      "step": 6555
    },
    {
      "epoch": 25.410852713178294,
      "grad_norm": 0.004915100988000631,
      "learning_rate": 2.4589147286821707e-05,
      "loss": 0.0003,
      "step": 6556
    },
    {
      "epoch": 25.414728682170544,
      "grad_norm": 0.00290263956412673,
      "learning_rate": 2.458527131782946e-05,
      "loss": 0.0002,
      "step": 6557
    },
    {
      "epoch": 25.41860465116279,
      "grad_norm": 0.01571037620306015,
      "learning_rate": 2.4581395348837212e-05,
      "loss": 0.0006,
      "step": 6558
    },
    {
      "epoch": 25.42248062015504,
      "grad_norm": 0.0014990947674959898,
      "learning_rate": 2.4577519379844964e-05,
      "loss": 0.0002,
      "step": 6559
    },
    {
      "epoch": 25.426356589147286,
      "grad_norm": 0.004187928047031164,
      "learning_rate": 2.4573643410852713e-05,
      "loss": 0.0002,
      "step": 6560
    },
    {
      "epoch": 25.430232558139537,
      "grad_norm": 0.0017438301583752036,
      "learning_rate": 2.4569767441860466e-05,
      "loss": 0.0002,
      "step": 6561
    },
    {
      "epoch": 25.434108527131784,
      "grad_norm": 0.0017329857219010592,
      "learning_rate": 2.4565891472868218e-05,
      "loss": 0.0001,
      "step": 6562
    },
    {
      "epoch": 25.43798449612403,
      "grad_norm": 0.001751723699271679,
      "learning_rate": 2.456201550387597e-05,
      "loss": 0.0001,
      "step": 6563
    },
    {
      "epoch": 25.441860465116278,
      "grad_norm": 0.001475740224123001,
      "learning_rate": 2.4558139534883723e-05,
      "loss": 0.0001,
      "step": 6564
    },
    {
      "epoch": 25.44573643410853,
      "grad_norm": 2.108464241027832,
      "learning_rate": 2.4554263565891475e-05,
      "loss": 0.1162,
      "step": 6565
    },
    {
      "epoch": 25.449612403100776,
      "grad_norm": 0.004909934476017952,
      "learning_rate": 2.4550387596899228e-05,
      "loss": 0.0004,
      "step": 6566
    },
    {
      "epoch": 25.453488372093023,
      "grad_norm": 0.006481031887233257,
      "learning_rate": 2.454651162790698e-05,
      "loss": 0.0005,
      "step": 6567
    },
    {
      "epoch": 25.45736434108527,
      "grad_norm": 0.7485458850860596,
      "learning_rate": 2.4542635658914733e-05,
      "loss": 0.0416,
      "step": 6568
    },
    {
      "epoch": 25.46124031007752,
      "grad_norm": 0.001228265929967165,
      "learning_rate": 2.4538759689922482e-05,
      "loss": 0.0001,
      "step": 6569
    },
    {
      "epoch": 25.46511627906977,
      "grad_norm": 0.017151912674307823,
      "learning_rate": 2.453488372093023e-05,
      "loss": 0.0005,
      "step": 6570
    },
    {
      "epoch": 25.468992248062015,
      "grad_norm": 0.0017595066456124187,
      "learning_rate": 2.4531007751937983e-05,
      "loss": 0.0001,
      "step": 6571
    },
    {
      "epoch": 25.472868217054263,
      "grad_norm": 0.0014929678291082382,
      "learning_rate": 2.4527131782945736e-05,
      "loss": 0.0002,
      "step": 6572
    },
    {
      "epoch": 25.476744186046513,
      "grad_norm": 0.7749389410018921,
      "learning_rate": 2.4523255813953488e-05,
      "loss": 0.0205,
      "step": 6573
    },
    {
      "epoch": 25.48062015503876,
      "grad_norm": 0.4148186445236206,
      "learning_rate": 2.451937984496124e-05,
      "loss": 0.0021,
      "step": 6574
    },
    {
      "epoch": 25.484496124031008,
      "grad_norm": 0.0032637175172567368,
      "learning_rate": 2.4515503875968993e-05,
      "loss": 0.0002,
      "step": 6575
    },
    {
      "epoch": 25.488372093023255,
      "grad_norm": 0.0017368157859891653,
      "learning_rate": 2.4511627906976745e-05,
      "loss": 0.0001,
      "step": 6576
    },
    {
      "epoch": 25.492248062015506,
      "grad_norm": 0.0020061172544956207,
      "learning_rate": 2.4507751937984498e-05,
      "loss": 0.0001,
      "step": 6577
    },
    {
      "epoch": 25.496124031007753,
      "grad_norm": 0.19699077308177948,
      "learning_rate": 2.450387596899225e-05,
      "loss": 0.0004,
      "step": 6578
    },
    {
      "epoch": 25.5,
      "grad_norm": 0.0014618103159591556,
      "learning_rate": 2.45e-05,
      "loss": 0.0001,
      "step": 6579
    },
    {
      "epoch": 25.503875968992247,
      "grad_norm": 2.028902769088745,
      "learning_rate": 2.449612403100775e-05,
      "loss": 0.2582,
      "step": 6580
    },
    {
      "epoch": 25.507751937984494,
      "grad_norm": 0.0017632063245400786,
      "learning_rate": 2.4492248062015504e-05,
      "loss": 0.0002,
      "step": 6581
    },
    {
      "epoch": 25.511627906976745,
      "grad_norm": 0.003791987895965576,
      "learning_rate": 2.4488372093023256e-05,
      "loss": 0.0003,
      "step": 6582
    },
    {
      "epoch": 25.515503875968992,
      "grad_norm": 0.015498495660722256,
      "learning_rate": 2.448449612403101e-05,
      "loss": 0.0008,
      "step": 6583
    },
    {
      "epoch": 25.51937984496124,
      "grad_norm": 0.002068141009658575,
      "learning_rate": 2.448062015503876e-05,
      "loss": 0.0002,
      "step": 6584
    },
    {
      "epoch": 25.52325581395349,
      "grad_norm": 0.3875662684440613,
      "learning_rate": 2.4476744186046514e-05,
      "loss": 0.0075,
      "step": 6585
    },
    {
      "epoch": 25.527131782945737,
      "grad_norm": 0.00269093899987638,
      "learning_rate": 2.4472868217054266e-05,
      "loss": 0.0002,
      "step": 6586
    },
    {
      "epoch": 25.531007751937985,
      "grad_norm": 0.003740789834409952,
      "learning_rate": 2.446899224806202e-05,
      "loss": 0.0002,
      "step": 6587
    },
    {
      "epoch": 25.53488372093023,
      "grad_norm": 0.0012171374401077628,
      "learning_rate": 2.4465116279069768e-05,
      "loss": 0.0001,
      "step": 6588
    },
    {
      "epoch": 25.53875968992248,
      "grad_norm": 0.0022914183791726828,
      "learning_rate": 2.446124031007752e-05,
      "loss": 0.0001,
      "step": 6589
    },
    {
      "epoch": 25.54263565891473,
      "grad_norm": 6.939513206481934,
      "learning_rate": 2.4457364341085272e-05,
      "loss": 0.3679,
      "step": 6590
    },
    {
      "epoch": 25.546511627906977,
      "grad_norm": 0.0013746257172897458,
      "learning_rate": 2.4453488372093025e-05,
      "loss": 0.0001,
      "step": 6591
    },
    {
      "epoch": 25.550387596899224,
      "grad_norm": 0.0048462445847690105,
      "learning_rate": 2.4449612403100777e-05,
      "loss": 0.0003,
      "step": 6592
    },
    {
      "epoch": 25.55426356589147,
      "grad_norm": 0.0038184914737939835,
      "learning_rate": 2.444573643410853e-05,
      "loss": 0.0003,
      "step": 6593
    },
    {
      "epoch": 25.558139534883722,
      "grad_norm": 0.03530406951904297,
      "learning_rate": 2.4441860465116282e-05,
      "loss": 0.0009,
      "step": 6594
    },
    {
      "epoch": 25.56201550387597,
      "grad_norm": 0.002151536289602518,
      "learning_rate": 2.4437984496124035e-05,
      "loss": 0.0002,
      "step": 6595
    },
    {
      "epoch": 25.565891472868216,
      "grad_norm": 0.02091558463871479,
      "learning_rate": 2.4434108527131787e-05,
      "loss": 0.0002,
      "step": 6596
    },
    {
      "epoch": 25.569767441860463,
      "grad_norm": 0.006531889550387859,
      "learning_rate": 2.4430232558139536e-05,
      "loss": 0.0003,
      "step": 6597
    },
    {
      "epoch": 25.573643410852714,
      "grad_norm": 0.0015019744168967009,
      "learning_rate": 2.442635658914729e-05,
      "loss": 0.0001,
      "step": 6598
    },
    {
      "epoch": 25.57751937984496,
      "grad_norm": 0.0016738821286708117,
      "learning_rate": 2.4422480620155037e-05,
      "loss": 0.0002,
      "step": 6599
    },
    {
      "epoch": 25.58139534883721,
      "grad_norm": 0.002301887609064579,
      "learning_rate": 2.441860465116279e-05,
      "loss": 0.0002,
      "step": 6600
    },
    {
      "epoch": 25.585271317829456,
      "grad_norm": 0.0019858237355947495,
      "learning_rate": 2.4414728682170542e-05,
      "loss": 0.0002,
      "step": 6601
    },
    {
      "epoch": 25.589147286821706,
      "grad_norm": 0.00260667665861547,
      "learning_rate": 2.4410852713178295e-05,
      "loss": 0.0002,
      "step": 6602
    },
    {
      "epoch": 25.593023255813954,
      "grad_norm": 0.0018286681734025478,
      "learning_rate": 2.4406976744186047e-05,
      "loss": 0.0001,
      "step": 6603
    },
    {
      "epoch": 25.5968992248062,
      "grad_norm": 0.0015215273015201092,
      "learning_rate": 2.44031007751938e-05,
      "loss": 0.0002,
      "step": 6604
    },
    {
      "epoch": 25.600775193798448,
      "grad_norm": 0.006542393006384373,
      "learning_rate": 2.4399224806201552e-05,
      "loss": 0.0003,
      "step": 6605
    },
    {
      "epoch": 25.6046511627907,
      "grad_norm": 0.00593682611361146,
      "learning_rate": 2.4395348837209304e-05,
      "loss": 0.0004,
      "step": 6606
    },
    {
      "epoch": 25.608527131782946,
      "grad_norm": 0.0020474856719374657,
      "learning_rate": 2.4391472868217053e-05,
      "loss": 0.0002,
      "step": 6607
    },
    {
      "epoch": 25.612403100775193,
      "grad_norm": 0.0012916655978187919,
      "learning_rate": 2.4387596899224806e-05,
      "loss": 0.0001,
      "step": 6608
    },
    {
      "epoch": 25.61627906976744,
      "grad_norm": 0.0013270230265334249,
      "learning_rate": 2.4383720930232558e-05,
      "loss": 0.0001,
      "step": 6609
    },
    {
      "epoch": 25.62015503875969,
      "grad_norm": 0.0016498302575200796,
      "learning_rate": 2.437984496124031e-05,
      "loss": 0.0002,
      "step": 6610
    },
    {
      "epoch": 25.624031007751938,
      "grad_norm": 0.005504846107214689,
      "learning_rate": 2.4375968992248063e-05,
      "loss": 0.0004,
      "step": 6611
    },
    {
      "epoch": 25.627906976744185,
      "grad_norm": 0.002023563254624605,
      "learning_rate": 2.4372093023255816e-05,
      "loss": 0.0001,
      "step": 6612
    },
    {
      "epoch": 25.631782945736433,
      "grad_norm": 0.0013590484159067273,
      "learning_rate": 2.4368217054263568e-05,
      "loss": 0.0001,
      "step": 6613
    },
    {
      "epoch": 25.635658914728683,
      "grad_norm": 2.3967010974884033,
      "learning_rate": 2.436434108527132e-05,
      "loss": 0.2426,
      "step": 6614
    },
    {
      "epoch": 25.63953488372093,
      "grad_norm": 0.34868454933166504,
      "learning_rate": 2.4360465116279073e-05,
      "loss": 0.0017,
      "step": 6615
    },
    {
      "epoch": 25.643410852713178,
      "grad_norm": 0.0016367088537663221,
      "learning_rate": 2.4356589147286822e-05,
      "loss": 0.0002,
      "step": 6616
    },
    {
      "epoch": 25.647286821705425,
      "grad_norm": 0.0021918124984949827,
      "learning_rate": 2.4352713178294574e-05,
      "loss": 0.0002,
      "step": 6617
    },
    {
      "epoch": 25.651162790697676,
      "grad_norm": 0.24251818656921387,
      "learning_rate": 2.4348837209302327e-05,
      "loss": 0.0004,
      "step": 6618
    },
    {
      "epoch": 25.655038759689923,
      "grad_norm": 0.009332362562417984,
      "learning_rate": 2.434496124031008e-05,
      "loss": 0.0003,
      "step": 6619
    },
    {
      "epoch": 25.65891472868217,
      "grad_norm": 0.0033787600696086884,
      "learning_rate": 2.434108527131783e-05,
      "loss": 0.0002,
      "step": 6620
    },
    {
      "epoch": 25.662790697674417,
      "grad_norm": 0.0030974678229540586,
      "learning_rate": 2.4337209302325584e-05,
      "loss": 0.0002,
      "step": 6621
    },
    {
      "epoch": 25.666666666666668,
      "grad_norm": 0.00956991408020258,
      "learning_rate": 2.4333333333333336e-05,
      "loss": 0.0005,
      "step": 6622
    },
    {
      "epoch": 25.670542635658915,
      "grad_norm": 0.0016422484768554568,
      "learning_rate": 2.432945736434109e-05,
      "loss": 0.0002,
      "step": 6623
    },
    {
      "epoch": 25.674418604651162,
      "grad_norm": 0.0012425474124029279,
      "learning_rate": 2.4325581395348838e-05,
      "loss": 0.0001,
      "step": 6624
    },
    {
      "epoch": 25.67829457364341,
      "grad_norm": 0.00906726811081171,
      "learning_rate": 2.432170542635659e-05,
      "loss": 0.0002,
      "step": 6625
    },
    {
      "epoch": 25.68217054263566,
      "grad_norm": 0.001994530903175473,
      "learning_rate": 2.4317829457364343e-05,
      "loss": 0.0002,
      "step": 6626
    },
    {
      "epoch": 25.686046511627907,
      "grad_norm": 0.0020351477432996035,
      "learning_rate": 2.4313953488372092e-05,
      "loss": 0.0002,
      "step": 6627
    },
    {
      "epoch": 25.689922480620154,
      "grad_norm": 0.704850435256958,
      "learning_rate": 2.4310077519379844e-05,
      "loss": 0.0062,
      "step": 6628
    },
    {
      "epoch": 25.6937984496124,
      "grad_norm": 0.2796572148799896,
      "learning_rate": 2.4306201550387597e-05,
      "loss": 0.001,
      "step": 6629
    },
    {
      "epoch": 25.697674418604652,
      "grad_norm": 0.0012449106434360147,
      "learning_rate": 2.430232558139535e-05,
      "loss": 0.0001,
      "step": 6630
    },
    {
      "epoch": 25.7015503875969,
      "grad_norm": 1.9921433925628662,
      "learning_rate": 2.42984496124031e-05,
      "loss": 0.1767,
      "step": 6631
    },
    {
      "epoch": 25.705426356589147,
      "grad_norm": 0.013416278176009655,
      "learning_rate": 2.4294573643410854e-05,
      "loss": 0.0007,
      "step": 6632
    },
    {
      "epoch": 25.709302325581394,
      "grad_norm": 0.0016131064621731639,
      "learning_rate": 2.4290697674418606e-05,
      "loss": 0.0002,
      "step": 6633
    },
    {
      "epoch": 25.713178294573645,
      "grad_norm": 0.0017734727589413524,
      "learning_rate": 2.428682170542636e-05,
      "loss": 0.0002,
      "step": 6634
    },
    {
      "epoch": 25.717054263565892,
      "grad_norm": 0.09482637792825699,
      "learning_rate": 2.428294573643411e-05,
      "loss": 0.004,
      "step": 6635
    },
    {
      "epoch": 25.72093023255814,
      "grad_norm": 0.0021836129017174244,
      "learning_rate": 2.427906976744186e-05,
      "loss": 0.0002,
      "step": 6636
    },
    {
      "epoch": 25.724806201550386,
      "grad_norm": 0.002537672407925129,
      "learning_rate": 2.4275193798449613e-05,
      "loss": 0.0002,
      "step": 6637
    },
    {
      "epoch": 25.728682170542637,
      "grad_norm": 0.005554739385843277,
      "learning_rate": 2.4271317829457365e-05,
      "loss": 0.0002,
      "step": 6638
    },
    {
      "epoch": 25.732558139534884,
      "grad_norm": 0.0012323122937232256,
      "learning_rate": 2.4267441860465117e-05,
      "loss": 0.0001,
      "step": 6639
    },
    {
      "epoch": 25.73643410852713,
      "grad_norm": 10.295598030090332,
      "learning_rate": 2.426356589147287e-05,
      "loss": 0.0782,
      "step": 6640
    },
    {
      "epoch": 25.74031007751938,
      "grad_norm": 0.009246316738426685,
      "learning_rate": 2.4259689922480622e-05,
      "loss": 0.0003,
      "step": 6641
    },
    {
      "epoch": 25.74418604651163,
      "grad_norm": 1.0912102460861206,
      "learning_rate": 2.4255813953488375e-05,
      "loss": 0.0011,
      "step": 6642
    },
    {
      "epoch": 25.748062015503876,
      "grad_norm": 0.0032598592806607485,
      "learning_rate": 2.4251937984496127e-05,
      "loss": 0.0002,
      "step": 6643
    },
    {
      "epoch": 25.751937984496124,
      "grad_norm": 0.002107237232849002,
      "learning_rate": 2.424806201550388e-05,
      "loss": 0.0002,
      "step": 6644
    },
    {
      "epoch": 25.75581395348837,
      "grad_norm": 0.04062340036034584,
      "learning_rate": 2.424418604651163e-05,
      "loss": 0.0005,
      "step": 6645
    },
    {
      "epoch": 25.75968992248062,
      "grad_norm": 0.014990899711847305,
      "learning_rate": 2.424031007751938e-05,
      "loss": 0.0003,
      "step": 6646
    },
    {
      "epoch": 25.76356589147287,
      "grad_norm": 0.012445587664842606,
      "learning_rate": 2.4236434108527133e-05,
      "loss": 0.0006,
      "step": 6647
    },
    {
      "epoch": 25.767441860465116,
      "grad_norm": 0.01758296974003315,
      "learning_rate": 2.4232558139534886e-05,
      "loss": 0.0003,
      "step": 6648
    },
    {
      "epoch": 25.771317829457363,
      "grad_norm": 0.010012373328208923,
      "learning_rate": 2.4228682170542638e-05,
      "loss": 0.0004,
      "step": 6649
    },
    {
      "epoch": 25.775193798449614,
      "grad_norm": 0.0013598438818007708,
      "learning_rate": 2.4224806201550387e-05,
      "loss": 0.0001,
      "step": 6650
    },
    {
      "epoch": 25.77906976744186,
      "grad_norm": 0.0017415967304259539,
      "learning_rate": 2.422093023255814e-05,
      "loss": 0.0001,
      "step": 6651
    },
    {
      "epoch": 25.782945736434108,
      "grad_norm": 0.0012225137325003743,
      "learning_rate": 2.4217054263565892e-05,
      "loss": 0.0001,
      "step": 6652
    },
    {
      "epoch": 25.786821705426355,
      "grad_norm": 0.004541641101241112,
      "learning_rate": 2.4213178294573645e-05,
      "loss": 0.0003,
      "step": 6653
    },
    {
      "epoch": 25.790697674418606,
      "grad_norm": 0.0046469951048493385,
      "learning_rate": 2.4209302325581397e-05,
      "loss": 0.0002,
      "step": 6654
    },
    {
      "epoch": 25.794573643410853,
      "grad_norm": 2.223573923110962,
      "learning_rate": 2.4205426356589146e-05,
      "loss": 0.1579,
      "step": 6655
    },
    {
      "epoch": 25.7984496124031,
      "grad_norm": 0.001454586861655116,
      "learning_rate": 2.42015503875969e-05,
      "loss": 0.0001,
      "step": 6656
    },
    {
      "epoch": 25.802325581395348,
      "grad_norm": 0.0015584768261760473,
      "learning_rate": 2.419767441860465e-05,
      "loss": 0.0001,
      "step": 6657
    },
    {
      "epoch": 25.8062015503876,
      "grad_norm": 0.0018400902627035975,
      "learning_rate": 2.4193798449612403e-05,
      "loss": 0.0001,
      "step": 6658
    },
    {
      "epoch": 25.810077519379846,
      "grad_norm": 3.2375471591949463,
      "learning_rate": 2.4189922480620156e-05,
      "loss": 0.4741,
      "step": 6659
    },
    {
      "epoch": 25.813953488372093,
      "grad_norm": 1.3415563106536865,
      "learning_rate": 2.4186046511627908e-05,
      "loss": 0.1322,
      "step": 6660
    },
    {
      "epoch": 25.81782945736434,
      "grad_norm": 0.002604969311505556,
      "learning_rate": 2.418217054263566e-05,
      "loss": 0.0002,
      "step": 6661
    },
    {
      "epoch": 25.82170542635659,
      "grad_norm": 0.0016651672776788473,
      "learning_rate": 2.4178294573643413e-05,
      "loss": 0.0001,
      "step": 6662
    },
    {
      "epoch": 25.825581395348838,
      "grad_norm": 0.06506626307964325,
      "learning_rate": 2.4174418604651165e-05,
      "loss": 0.0007,
      "step": 6663
    },
    {
      "epoch": 25.829457364341085,
      "grad_norm": 0.3188815116882324,
      "learning_rate": 2.4170542635658914e-05,
      "loss": 0.0011,
      "step": 6664
    },
    {
      "epoch": 25.833333333333332,
      "grad_norm": 0.04648185148835182,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.001,
      "step": 6665
    },
    {
      "epoch": 25.837209302325583,
      "grad_norm": 0.004774760454893112,
      "learning_rate": 2.416279069767442e-05,
      "loss": 0.0003,
      "step": 6666
    },
    {
      "epoch": 25.84108527131783,
      "grad_norm": 0.010672726668417454,
      "learning_rate": 2.415891472868217e-05,
      "loss": 0.0003,
      "step": 6667
    },
    {
      "epoch": 25.844961240310077,
      "grad_norm": 0.21005208790302277,
      "learning_rate": 2.4155038759689924e-05,
      "loss": 0.0007,
      "step": 6668
    },
    {
      "epoch": 25.848837209302324,
      "grad_norm": 1.8167495727539062,
      "learning_rate": 2.4151162790697676e-05,
      "loss": 0.0573,
      "step": 6669
    },
    {
      "epoch": 25.852713178294575,
      "grad_norm": 0.03144571930170059,
      "learning_rate": 2.414728682170543e-05,
      "loss": 0.001,
      "step": 6670
    },
    {
      "epoch": 25.856589147286822,
      "grad_norm": 0.010831566527485847,
      "learning_rate": 2.414341085271318e-05,
      "loss": 0.0005,
      "step": 6671
    },
    {
      "epoch": 25.86046511627907,
      "grad_norm": 0.004858695436269045,
      "learning_rate": 2.4139534883720934e-05,
      "loss": 0.0002,
      "step": 6672
    },
    {
      "epoch": 25.864341085271317,
      "grad_norm": 0.006200076546519995,
      "learning_rate": 2.4135658914728683e-05,
      "loss": 0.0004,
      "step": 6673
    },
    {
      "epoch": 25.868217054263567,
      "grad_norm": 0.3644397556781769,
      "learning_rate": 2.4131782945736435e-05,
      "loss": 0.0126,
      "step": 6674
    },
    {
      "epoch": 25.872093023255815,
      "grad_norm": 0.006351351737976074,
      "learning_rate": 2.4127906976744188e-05,
      "loss": 0.0004,
      "step": 6675
    },
    {
      "epoch": 25.875968992248062,
      "grad_norm": 0.014397681690752506,
      "learning_rate": 2.412403100775194e-05,
      "loss": 0.0006,
      "step": 6676
    },
    {
      "epoch": 25.87984496124031,
      "grad_norm": 0.006397736258804798,
      "learning_rate": 2.412015503875969e-05,
      "loss": 0.0004,
      "step": 6677
    },
    {
      "epoch": 25.88372093023256,
      "grad_norm": 0.13040687143802643,
      "learning_rate": 2.411627906976744e-05,
      "loss": 0.0007,
      "step": 6678
    },
    {
      "epoch": 25.887596899224807,
      "grad_norm": 0.011909645982086658,
      "learning_rate": 2.4112403100775194e-05,
      "loss": 0.0005,
      "step": 6679
    },
    {
      "epoch": 25.891472868217054,
      "grad_norm": 0.9356027245521545,
      "learning_rate": 2.4108527131782946e-05,
      "loss": 0.0449,
      "step": 6680
    },
    {
      "epoch": 25.8953488372093,
      "grad_norm": 0.007398219313472509,
      "learning_rate": 2.41046511627907e-05,
      "loss": 0.0003,
      "step": 6681
    },
    {
      "epoch": 25.899224806201552,
      "grad_norm": 0.004863806534558535,
      "learning_rate": 2.410077519379845e-05,
      "loss": 0.0003,
      "step": 6682
    },
    {
      "epoch": 25.9031007751938,
      "grad_norm": 0.005177728366106749,
      "learning_rate": 2.4096899224806204e-05,
      "loss": 0.0003,
      "step": 6683
    },
    {
      "epoch": 25.906976744186046,
      "grad_norm": 4.385269641876221,
      "learning_rate": 2.4093023255813953e-05,
      "loss": 0.0536,
      "step": 6684
    },
    {
      "epoch": 25.910852713178294,
      "grad_norm": 0.5550347566604614,
      "learning_rate": 2.4089147286821705e-05,
      "loss": 0.027,
      "step": 6685
    },
    {
      "epoch": 25.914728682170544,
      "grad_norm": 0.006751790642738342,
      "learning_rate": 2.4085271317829457e-05,
      "loss": 0.0003,
      "step": 6686
    },
    {
      "epoch": 25.91860465116279,
      "grad_norm": 0.0024486996699124575,
      "learning_rate": 2.408139534883721e-05,
      "loss": 0.0002,
      "step": 6687
    },
    {
      "epoch": 25.92248062015504,
      "grad_norm": 0.004296696279197931,
      "learning_rate": 2.4077519379844962e-05,
      "loss": 0.0003,
      "step": 6688
    },
    {
      "epoch": 25.926356589147286,
      "grad_norm": 0.0033273480366915464,
      "learning_rate": 2.4073643410852715e-05,
      "loss": 0.0003,
      "step": 6689
    },
    {
      "epoch": 25.930232558139537,
      "grad_norm": 0.003308690618723631,
      "learning_rate": 2.4069767441860467e-05,
      "loss": 0.0002,
      "step": 6690
    },
    {
      "epoch": 25.934108527131784,
      "grad_norm": 0.015266217291355133,
      "learning_rate": 2.406589147286822e-05,
      "loss": 0.0006,
      "step": 6691
    },
    {
      "epoch": 25.93798449612403,
      "grad_norm": 0.011904548853635788,
      "learning_rate": 2.4062015503875972e-05,
      "loss": 0.0005,
      "step": 6692
    },
    {
      "epoch": 25.941860465116278,
      "grad_norm": 0.008098357357084751,
      "learning_rate": 2.405813953488372e-05,
      "loss": 0.0004,
      "step": 6693
    },
    {
      "epoch": 25.94573643410853,
      "grad_norm": 0.0018040408613160253,
      "learning_rate": 2.4054263565891473e-05,
      "loss": 0.0002,
      "step": 6694
    },
    {
      "epoch": 25.949612403100776,
      "grad_norm": 0.0036178533919155598,
      "learning_rate": 2.4050387596899226e-05,
      "loss": 0.0002,
      "step": 6695
    },
    {
      "epoch": 25.953488372093023,
      "grad_norm": 0.005008644890040159,
      "learning_rate": 2.404651162790698e-05,
      "loss": 0.0003,
      "step": 6696
    },
    {
      "epoch": 25.95736434108527,
      "grad_norm": 0.0029599941335618496,
      "learning_rate": 2.404263565891473e-05,
      "loss": 0.0002,
      "step": 6697
    },
    {
      "epoch": 25.96124031007752,
      "grad_norm": 0.016903551295399666,
      "learning_rate": 2.4038759689922483e-05,
      "loss": 0.0005,
      "step": 6698
    },
    {
      "epoch": 25.96511627906977,
      "grad_norm": 0.009520524181425571,
      "learning_rate": 2.4034883720930236e-05,
      "loss": 0.0004,
      "step": 6699
    },
    {
      "epoch": 25.968992248062015,
      "grad_norm": 0.2998456656932831,
      "learning_rate": 2.4031007751937988e-05,
      "loss": 0.0101,
      "step": 6700
    },
    {
      "epoch": 25.972868217054263,
      "grad_norm": 0.001745646819472313,
      "learning_rate": 2.402713178294574e-05,
      "loss": 0.0002,
      "step": 6701
    },
    {
      "epoch": 25.97674418604651,
      "grad_norm": 0.048755716532468796,
      "learning_rate": 2.402325581395349e-05,
      "loss": 0.0014,
      "step": 6702
    },
    {
      "epoch": 25.98062015503876,
      "grad_norm": 0.001770135946571827,
      "learning_rate": 2.4019379844961242e-05,
      "loss": 0.0002,
      "step": 6703
    },
    {
      "epoch": 25.984496124031008,
      "grad_norm": 0.007640592288225889,
      "learning_rate": 2.401550387596899e-05,
      "loss": 0.0003,
      "step": 6704
    },
    {
      "epoch": 25.988372093023255,
      "grad_norm": 1.7956701517105103,
      "learning_rate": 2.4011627906976743e-05,
      "loss": 0.0679,
      "step": 6705
    },
    {
      "epoch": 25.992248062015506,
      "grad_norm": 0.05489534139633179,
      "learning_rate": 2.4007751937984496e-05,
      "loss": 0.0018,
      "step": 6706
    },
    {
      "epoch": 25.996124031007753,
      "grad_norm": 0.0036831756588071585,
      "learning_rate": 2.4003875968992248e-05,
      "loss": 0.0003,
      "step": 6707
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.001355607993900776,
      "learning_rate": 2.4e-05,
      "loss": 0.0001,
      "step": 6708
    },
    {
      "epoch": 26.003875968992247,
      "grad_norm": 0.0034685786813497543,
      "learning_rate": 2.3996124031007753e-05,
      "loss": 0.0003,
      "step": 6709
    },
    {
      "epoch": 26.007751937984494,
      "grad_norm": 0.00822747778147459,
      "learning_rate": 2.3992248062015505e-05,
      "loss": 0.0004,
      "step": 6710
    },
    {
      "epoch": 26.011627906976745,
      "grad_norm": 0.001772901276126504,
      "learning_rate": 2.3988372093023258e-05,
      "loss": 0.0002,
      "step": 6711
    },
    {
      "epoch": 26.015503875968992,
      "grad_norm": 0.006775035057216883,
      "learning_rate": 2.3984496124031007e-05,
      "loss": 0.0003,
      "step": 6712
    },
    {
      "epoch": 26.01937984496124,
      "grad_norm": 1.102421760559082,
      "learning_rate": 2.398062015503876e-05,
      "loss": 0.0847,
      "step": 6713
    },
    {
      "epoch": 26.023255813953487,
      "grad_norm": 0.002367522567510605,
      "learning_rate": 2.3976744186046512e-05,
      "loss": 0.0002,
      "step": 6714
    },
    {
      "epoch": 26.027131782945737,
      "grad_norm": 0.0024395303335040808,
      "learning_rate": 2.3972868217054264e-05,
      "loss": 0.0002,
      "step": 6715
    },
    {
      "epoch": 26.031007751937985,
      "grad_norm": 0.008644762448966503,
      "learning_rate": 2.3968992248062017e-05,
      "loss": 0.0003,
      "step": 6716
    },
    {
      "epoch": 26.03488372093023,
      "grad_norm": 0.001750171184539795,
      "learning_rate": 2.396511627906977e-05,
      "loss": 0.0002,
      "step": 6717
    },
    {
      "epoch": 26.03875968992248,
      "grad_norm": 0.0014138389378786087,
      "learning_rate": 2.396124031007752e-05,
      "loss": 0.0001,
      "step": 6718
    },
    {
      "epoch": 26.04263565891473,
      "grad_norm": 0.0011731579434126616,
      "learning_rate": 2.3957364341085274e-05,
      "loss": 0.0001,
      "step": 6719
    },
    {
      "epoch": 26.046511627906977,
      "grad_norm": 1.1411272287368774,
      "learning_rate": 2.3953488372093026e-05,
      "loss": 0.0542,
      "step": 6720
    },
    {
      "epoch": 26.050387596899224,
      "grad_norm": 0.0021742272656410933,
      "learning_rate": 2.3949612403100775e-05,
      "loss": 0.0002,
      "step": 6721
    },
    {
      "epoch": 26.05426356589147,
      "grad_norm": 0.002422331366688013,
      "learning_rate": 2.3945736434108528e-05,
      "loss": 0.0002,
      "step": 6722
    },
    {
      "epoch": 26.058139534883722,
      "grad_norm": 0.0013797753490507603,
      "learning_rate": 2.394186046511628e-05,
      "loss": 0.0001,
      "step": 6723
    },
    {
      "epoch": 26.06201550387597,
      "grad_norm": 0.010149792768061161,
      "learning_rate": 2.3937984496124033e-05,
      "loss": 0.0005,
      "step": 6724
    },
    {
      "epoch": 26.065891472868216,
      "grad_norm": 0.0025118289049714804,
      "learning_rate": 2.3934108527131785e-05,
      "loss": 0.0002,
      "step": 6725
    },
    {
      "epoch": 26.069767441860463,
      "grad_norm": 0.006640775129199028,
      "learning_rate": 2.3930232558139537e-05,
      "loss": 0.0001,
      "step": 6726
    },
    {
      "epoch": 26.073643410852714,
      "grad_norm": 0.0012160303303971887,
      "learning_rate": 2.392635658914729e-05,
      "loss": 0.0001,
      "step": 6727
    },
    {
      "epoch": 26.07751937984496,
      "grad_norm": 0.0014940632972866297,
      "learning_rate": 2.3922480620155042e-05,
      "loss": 0.0002,
      "step": 6728
    },
    {
      "epoch": 26.08139534883721,
      "grad_norm": 0.0016700972337275743,
      "learning_rate": 2.3918604651162795e-05,
      "loss": 0.0002,
      "step": 6729
    },
    {
      "epoch": 26.085271317829456,
      "grad_norm": 0.008264129981398582,
      "learning_rate": 2.3914728682170544e-05,
      "loss": 0.0004,
      "step": 6730
    },
    {
      "epoch": 26.089147286821706,
      "grad_norm": 0.008558731526136398,
      "learning_rate": 2.3910852713178296e-05,
      "loss": 0.0004,
      "step": 6731
    },
    {
      "epoch": 26.093023255813954,
      "grad_norm": 0.008357200771570206,
      "learning_rate": 2.3906976744186045e-05,
      "loss": 0.0002,
      "step": 6732
    },
    {
      "epoch": 26.0968992248062,
      "grad_norm": 0.7141537070274353,
      "learning_rate": 2.3903100775193798e-05,
      "loss": 0.0326,
      "step": 6733
    },
    {
      "epoch": 26.100775193798448,
      "grad_norm": 0.0016688762698322535,
      "learning_rate": 2.389922480620155e-05,
      "loss": 0.0001,
      "step": 6734
    },
    {
      "epoch": 26.1046511627907,
      "grad_norm": 0.001966737676411867,
      "learning_rate": 2.3895348837209302e-05,
      "loss": 0.0002,
      "step": 6735
    },
    {
      "epoch": 26.108527131782946,
      "grad_norm": 0.001160852494649589,
      "learning_rate": 2.3891472868217055e-05,
      "loss": 0.0001,
      "step": 6736
    },
    {
      "epoch": 26.112403100775193,
      "grad_norm": 0.1845306009054184,
      "learning_rate": 2.3887596899224807e-05,
      "loss": 0.0017,
      "step": 6737
    },
    {
      "epoch": 26.11627906976744,
      "grad_norm": 0.0016861918848007917,
      "learning_rate": 2.388372093023256e-05,
      "loss": 0.0001,
      "step": 6738
    },
    {
      "epoch": 26.12015503875969,
      "grad_norm": 0.0019449949031695724,
      "learning_rate": 2.3879844961240312e-05,
      "loss": 0.0001,
      "step": 6739
    },
    {
      "epoch": 26.124031007751938,
      "grad_norm": 5.716644287109375,
      "learning_rate": 2.387596899224806e-05,
      "loss": 0.2728,
      "step": 6740
    },
    {
      "epoch": 26.127906976744185,
      "grad_norm": 0.01975039392709732,
      "learning_rate": 2.3872093023255814e-05,
      "loss": 0.0007,
      "step": 6741
    },
    {
      "epoch": 26.131782945736433,
      "grad_norm": 0.005415843799710274,
      "learning_rate": 2.3868217054263566e-05,
      "loss": 0.0003,
      "step": 6742
    },
    {
      "epoch": 26.135658914728683,
      "grad_norm": 0.00371313514187932,
      "learning_rate": 2.386434108527132e-05,
      "loss": 0.0003,
      "step": 6743
    },
    {
      "epoch": 26.13953488372093,
      "grad_norm": 4.722081184387207,
      "learning_rate": 2.386046511627907e-05,
      "loss": 0.1723,
      "step": 6744
    },
    {
      "epoch": 26.143410852713178,
      "grad_norm": 0.0038460094947367907,
      "learning_rate": 2.3856589147286823e-05,
      "loss": 0.0002,
      "step": 6745
    },
    {
      "epoch": 26.147286821705425,
      "grad_norm": 0.002093032468110323,
      "learning_rate": 2.3852713178294576e-05,
      "loss": 0.0002,
      "step": 6746
    },
    {
      "epoch": 26.151162790697676,
      "grad_norm": 0.001418267609551549,
      "learning_rate": 2.3848837209302328e-05,
      "loss": 0.0001,
      "step": 6747
    },
    {
      "epoch": 26.155038759689923,
      "grad_norm": 0.001141138607636094,
      "learning_rate": 2.384496124031008e-05,
      "loss": 0.0001,
      "step": 6748
    },
    {
      "epoch": 26.15891472868217,
      "grad_norm": 0.0012199121993035078,
      "learning_rate": 2.384108527131783e-05,
      "loss": 0.0001,
      "step": 6749
    },
    {
      "epoch": 26.162790697674417,
      "grad_norm": 0.0012580880429595709,
      "learning_rate": 2.3837209302325582e-05,
      "loss": 0.0001,
      "step": 6750
    },
    {
      "epoch": 26.166666666666668,
      "grad_norm": 0.0016618150984868407,
      "learning_rate": 2.3833333333333334e-05,
      "loss": 0.0001,
      "step": 6751
    },
    {
      "epoch": 26.170542635658915,
      "grad_norm": 0.0030620174948126078,
      "learning_rate": 2.3829457364341087e-05,
      "loss": 0.0002,
      "step": 6752
    },
    {
      "epoch": 26.174418604651162,
      "grad_norm": 0.0020956983789801598,
      "learning_rate": 2.382558139534884e-05,
      "loss": 0.0001,
      "step": 6753
    },
    {
      "epoch": 26.17829457364341,
      "grad_norm": 0.0013423399068415165,
      "learning_rate": 2.382170542635659e-05,
      "loss": 0.0001,
      "step": 6754
    },
    {
      "epoch": 26.18217054263566,
      "grad_norm": 0.0014495367649942636,
      "learning_rate": 2.3817829457364344e-05,
      "loss": 0.0001,
      "step": 6755
    },
    {
      "epoch": 26.186046511627907,
      "grad_norm": 0.0016105488175526261,
      "learning_rate": 2.3813953488372097e-05,
      "loss": 0.0001,
      "step": 6756
    },
    {
      "epoch": 26.189922480620154,
      "grad_norm": 0.0017086826264858246,
      "learning_rate": 2.3810077519379846e-05,
      "loss": 0.0002,
      "step": 6757
    },
    {
      "epoch": 26.1937984496124,
      "grad_norm": 0.8652013540267944,
      "learning_rate": 2.3806201550387598e-05,
      "loss": 0.0424,
      "step": 6758
    },
    {
      "epoch": 26.197674418604652,
      "grad_norm": 0.014175607822835445,
      "learning_rate": 2.380232558139535e-05,
      "loss": 0.0005,
      "step": 6759
    },
    {
      "epoch": 26.2015503875969,
      "grad_norm": 0.0014313223073258996,
      "learning_rate": 2.37984496124031e-05,
      "loss": 0.0002,
      "step": 6760
    },
    {
      "epoch": 26.205426356589147,
      "grad_norm": 0.001743385219015181,
      "learning_rate": 2.3794573643410852e-05,
      "loss": 0.0002,
      "step": 6761
    },
    {
      "epoch": 26.209302325581394,
      "grad_norm": 0.007535072974860668,
      "learning_rate": 2.3790697674418604e-05,
      "loss": 0.0002,
      "step": 6762
    },
    {
      "epoch": 26.213178294573645,
      "grad_norm": 0.001395363244228065,
      "learning_rate": 2.3786821705426357e-05,
      "loss": 0.0001,
      "step": 6763
    },
    {
      "epoch": 26.217054263565892,
      "grad_norm": 0.002796613145619631,
      "learning_rate": 2.378294573643411e-05,
      "loss": 0.0002,
      "step": 6764
    },
    {
      "epoch": 26.22093023255814,
      "grad_norm": 0.007396311964839697,
      "learning_rate": 2.377906976744186e-05,
      "loss": 0.0003,
      "step": 6765
    },
    {
      "epoch": 26.224806201550386,
      "grad_norm": 0.001307705999352038,
      "learning_rate": 2.3775193798449614e-05,
      "loss": 0.0001,
      "step": 6766
    },
    {
      "epoch": 26.228682170542637,
      "grad_norm": 0.002906532259657979,
      "learning_rate": 2.3771317829457366e-05,
      "loss": 0.0001,
      "step": 6767
    },
    {
      "epoch": 26.232558139534884,
      "grad_norm": 1.8583393096923828,
      "learning_rate": 2.376744186046512e-05,
      "loss": 0.1344,
      "step": 6768
    },
    {
      "epoch": 26.23643410852713,
      "grad_norm": 0.027891993522644043,
      "learning_rate": 2.3763565891472868e-05,
      "loss": 0.0002,
      "step": 6769
    },
    {
      "epoch": 26.24031007751938,
      "grad_norm": 0.0014189071953296661,
      "learning_rate": 2.375968992248062e-05,
      "loss": 0.0001,
      "step": 6770
    },
    {
      "epoch": 26.24418604651163,
      "grad_norm": 0.01852697879076004,
      "learning_rate": 2.3755813953488373e-05,
      "loss": 0.0003,
      "step": 6771
    },
    {
      "epoch": 26.248062015503876,
      "grad_norm": 0.001526464824564755,
      "learning_rate": 2.3751937984496125e-05,
      "loss": 0.0001,
      "step": 6772
    },
    {
      "epoch": 26.251937984496124,
      "grad_norm": 0.005184276960790157,
      "learning_rate": 2.3748062015503878e-05,
      "loss": 0.0002,
      "step": 6773
    },
    {
      "epoch": 26.25581395348837,
      "grad_norm": 6.226710319519043,
      "learning_rate": 2.374418604651163e-05,
      "loss": 0.5853,
      "step": 6774
    },
    {
      "epoch": 26.25968992248062,
      "grad_norm": 0.04340711236000061,
      "learning_rate": 2.3740310077519382e-05,
      "loss": 0.0009,
      "step": 6775
    },
    {
      "epoch": 26.26356589147287,
      "grad_norm": 1.0495209693908691,
      "learning_rate": 2.3736434108527135e-05,
      "loss": 0.0006,
      "step": 6776
    },
    {
      "epoch": 26.267441860465116,
      "grad_norm": 0.0034448327496647835,
      "learning_rate": 2.3732558139534887e-05,
      "loss": 0.0002,
      "step": 6777
    },
    {
      "epoch": 26.271317829457363,
      "grad_norm": 4.620696544647217,
      "learning_rate": 2.3728682170542636e-05,
      "loss": 0.4836,
      "step": 6778
    },
    {
      "epoch": 26.275193798449614,
      "grad_norm": 0.0013390687527135015,
      "learning_rate": 2.372480620155039e-05,
      "loss": 0.0001,
      "step": 6779
    },
    {
      "epoch": 26.27906976744186,
      "grad_norm": 0.006172617431730032,
      "learning_rate": 2.372093023255814e-05,
      "loss": 0.0003,
      "step": 6780
    },
    {
      "epoch": 26.282945736434108,
      "grad_norm": 0.01006267685443163,
      "learning_rate": 2.3717054263565894e-05,
      "loss": 0.0002,
      "step": 6781
    },
    {
      "epoch": 26.286821705426355,
      "grad_norm": 0.0026300575118511915,
      "learning_rate": 2.3713178294573646e-05,
      "loss": 0.0002,
      "step": 6782
    },
    {
      "epoch": 26.290697674418606,
      "grad_norm": 0.00402716314420104,
      "learning_rate": 2.37093023255814e-05,
      "loss": 0.0002,
      "step": 6783
    },
    {
      "epoch": 26.294573643410853,
      "grad_norm": 0.004486798774451017,
      "learning_rate": 2.3705426356589147e-05,
      "loss": 0.0003,
      "step": 6784
    },
    {
      "epoch": 26.2984496124031,
      "grad_norm": 0.039504650980234146,
      "learning_rate": 2.37015503875969e-05,
      "loss": 0.0003,
      "step": 6785
    },
    {
      "epoch": 26.302325581395348,
      "grad_norm": 0.002508229110389948,
      "learning_rate": 2.3697674418604652e-05,
      "loss": 0.0002,
      "step": 6786
    },
    {
      "epoch": 26.3062015503876,
      "grad_norm": 0.007678541354835033,
      "learning_rate": 2.3693798449612405e-05,
      "loss": 0.0004,
      "step": 6787
    },
    {
      "epoch": 26.310077519379846,
      "grad_norm": 0.0016829479718580842,
      "learning_rate": 2.3689922480620154e-05,
      "loss": 0.0001,
      "step": 6788
    },
    {
      "epoch": 26.313953488372093,
      "grad_norm": 0.004345783498138189,
      "learning_rate": 2.3686046511627906e-05,
      "loss": 0.0003,
      "step": 6789
    },
    {
      "epoch": 26.31782945736434,
      "grad_norm": 0.003132104640826583,
      "learning_rate": 2.368217054263566e-05,
      "loss": 0.0002,
      "step": 6790
    },
    {
      "epoch": 26.32170542635659,
      "grad_norm": 0.0021945079788565636,
      "learning_rate": 2.367829457364341e-05,
      "loss": 0.0002,
      "step": 6791
    },
    {
      "epoch": 26.325581395348838,
      "grad_norm": 0.010051751509308815,
      "learning_rate": 2.3674418604651163e-05,
      "loss": 0.0005,
      "step": 6792
    },
    {
      "epoch": 26.329457364341085,
      "grad_norm": 0.004608731251209974,
      "learning_rate": 2.3670542635658916e-05,
      "loss": 0.0003,
      "step": 6793
    },
    {
      "epoch": 26.333333333333332,
      "grad_norm": 0.5338265299797058,
      "learning_rate": 2.3666666666666668e-05,
      "loss": 0.0016,
      "step": 6794
    },
    {
      "epoch": 26.337209302325583,
      "grad_norm": 0.0015366252046078444,
      "learning_rate": 2.366279069767442e-05,
      "loss": 0.0001,
      "step": 6795
    },
    {
      "epoch": 26.34108527131783,
      "grad_norm": 0.0015303276013582945,
      "learning_rate": 2.3658914728682173e-05,
      "loss": 0.0002,
      "step": 6796
    },
    {
      "epoch": 26.344961240310077,
      "grad_norm": 0.01842918060719967,
      "learning_rate": 2.3655038759689922e-05,
      "loss": 0.0003,
      "step": 6797
    },
    {
      "epoch": 26.348837209302324,
      "grad_norm": 0.004126072861254215,
      "learning_rate": 2.3651162790697675e-05,
      "loss": 0.0003,
      "step": 6798
    },
    {
      "epoch": 26.352713178294575,
      "grad_norm": 0.012808926403522491,
      "learning_rate": 2.3647286821705427e-05,
      "loss": 0.0003,
      "step": 6799
    },
    {
      "epoch": 26.356589147286822,
      "grad_norm": 0.00540707353502512,
      "learning_rate": 2.364341085271318e-05,
      "loss": 0.0002,
      "step": 6800
    },
    {
      "epoch": 26.36046511627907,
      "grad_norm": 0.2951546311378479,
      "learning_rate": 2.3639534883720932e-05,
      "loss": 0.0018,
      "step": 6801
    },
    {
      "epoch": 26.364341085271317,
      "grad_norm": 16.11847496032715,
      "learning_rate": 2.3635658914728684e-05,
      "loss": 0.1687,
      "step": 6802
    },
    {
      "epoch": 26.368217054263567,
      "grad_norm": 0.0018898952985182405,
      "learning_rate": 2.3631782945736437e-05,
      "loss": 0.0002,
      "step": 6803
    },
    {
      "epoch": 26.372093023255815,
      "grad_norm": 2.5500471591949463,
      "learning_rate": 2.362790697674419e-05,
      "loss": 0.018,
      "step": 6804
    },
    {
      "epoch": 26.375968992248062,
      "grad_norm": 0.0085902726277709,
      "learning_rate": 2.362403100775194e-05,
      "loss": 0.0004,
      "step": 6805
    },
    {
      "epoch": 26.37984496124031,
      "grad_norm": 0.6519742608070374,
      "learning_rate": 2.362015503875969e-05,
      "loss": 0.0305,
      "step": 6806
    },
    {
      "epoch": 26.38372093023256,
      "grad_norm": 0.0029866406694054604,
      "learning_rate": 2.3616279069767443e-05,
      "loss": 0.0002,
      "step": 6807
    },
    {
      "epoch": 26.387596899224807,
      "grad_norm": 0.0011674717534333467,
      "learning_rate": 2.3612403100775195e-05,
      "loss": 0.0001,
      "step": 6808
    },
    {
      "epoch": 26.391472868217054,
      "grad_norm": 0.003520707366988063,
      "learning_rate": 2.3608527131782948e-05,
      "loss": 0.0002,
      "step": 6809
    },
    {
      "epoch": 26.3953488372093,
      "grad_norm": 0.0013025590451434255,
      "learning_rate": 2.3604651162790697e-05,
      "loss": 0.0001,
      "step": 6810
    },
    {
      "epoch": 26.399224806201552,
      "grad_norm": 0.0017134840600192547,
      "learning_rate": 2.360077519379845e-05,
      "loss": 0.0002,
      "step": 6811
    },
    {
      "epoch": 26.4031007751938,
      "grad_norm": 0.0013044815277680755,
      "learning_rate": 2.35968992248062e-05,
      "loss": 0.0001,
      "step": 6812
    },
    {
      "epoch": 26.406976744186046,
      "grad_norm": 0.001552354427985847,
      "learning_rate": 2.3593023255813954e-05,
      "loss": 0.0002,
      "step": 6813
    },
    {
      "epoch": 26.410852713178294,
      "grad_norm": 0.6295384764671326,
      "learning_rate": 2.3589147286821706e-05,
      "loss": 0.0285,
      "step": 6814
    },
    {
      "epoch": 26.414728682170544,
      "grad_norm": 0.003051786683499813,
      "learning_rate": 2.358527131782946e-05,
      "loss": 0.0003,
      "step": 6815
    },
    {
      "epoch": 26.41860465116279,
      "grad_norm": 0.0013338620774447918,
      "learning_rate": 2.358139534883721e-05,
      "loss": 0.0001,
      "step": 6816
    },
    {
      "epoch": 26.42248062015504,
      "grad_norm": 0.002931262133643031,
      "learning_rate": 2.357751937984496e-05,
      "loss": 0.0002,
      "step": 6817
    },
    {
      "epoch": 26.426356589147286,
      "grad_norm": 0.0013647516025230289,
      "learning_rate": 2.3573643410852713e-05,
      "loss": 0.0001,
      "step": 6818
    },
    {
      "epoch": 26.430232558139537,
      "grad_norm": 0.01370356883853674,
      "learning_rate": 2.3569767441860465e-05,
      "loss": 0.0007,
      "step": 6819
    },
    {
      "epoch": 26.434108527131784,
      "grad_norm": 0.002101355465129018,
      "learning_rate": 2.3565891472868218e-05,
      "loss": 0.0002,
      "step": 6820
    },
    {
      "epoch": 26.43798449612403,
      "grad_norm": 0.004978127311915159,
      "learning_rate": 2.356201550387597e-05,
      "loss": 0.0002,
      "step": 6821
    },
    {
      "epoch": 26.441860465116278,
      "grad_norm": 0.25910094380378723,
      "learning_rate": 2.3558139534883722e-05,
      "loss": 0.0033,
      "step": 6822
    },
    {
      "epoch": 26.44573643410853,
      "grad_norm": 0.0022476448211818933,
      "learning_rate": 2.3554263565891475e-05,
      "loss": 0.0002,
      "step": 6823
    },
    {
      "epoch": 26.449612403100776,
      "grad_norm": 0.002925193402916193,
      "learning_rate": 2.3550387596899227e-05,
      "loss": 0.0002,
      "step": 6824
    },
    {
      "epoch": 26.453488372093023,
      "grad_norm": 2.9406583309173584,
      "learning_rate": 2.354651162790698e-05,
      "loss": 0.285,
      "step": 6825
    },
    {
      "epoch": 26.45736434108527,
      "grad_norm": 0.0014683965127915144,
      "learning_rate": 2.354263565891473e-05,
      "loss": 0.0002,
      "step": 6826
    },
    {
      "epoch": 26.46124031007752,
      "grad_norm": 0.003186947200447321,
      "learning_rate": 2.353875968992248e-05,
      "loss": 0.0002,
      "step": 6827
    },
    {
      "epoch": 26.46511627906977,
      "grad_norm": 0.0015093986876308918,
      "learning_rate": 2.3534883720930234e-05,
      "loss": 0.0001,
      "step": 6828
    },
    {
      "epoch": 26.468992248062015,
      "grad_norm": 2.5539731979370117,
      "learning_rate": 2.3531007751937986e-05,
      "loss": 0.2671,
      "step": 6829
    },
    {
      "epoch": 26.472868217054263,
      "grad_norm": 0.0016345788026228547,
      "learning_rate": 2.352713178294574e-05,
      "loss": 0.0001,
      "step": 6830
    },
    {
      "epoch": 26.476744186046513,
      "grad_norm": 0.001506962813436985,
      "learning_rate": 2.352325581395349e-05,
      "loss": 0.0002,
      "step": 6831
    },
    {
      "epoch": 26.48062015503876,
      "grad_norm": 0.0016459794715046883,
      "learning_rate": 2.3519379844961243e-05,
      "loss": 0.0001,
      "step": 6832
    },
    {
      "epoch": 26.484496124031008,
      "grad_norm": 0.0015966389328241348,
      "learning_rate": 2.3515503875968996e-05,
      "loss": 0.0002,
      "step": 6833
    },
    {
      "epoch": 26.488372093023255,
      "grad_norm": 0.021688571199774742,
      "learning_rate": 2.3511627906976748e-05,
      "loss": 0.0002,
      "step": 6834
    },
    {
      "epoch": 26.492248062015506,
      "grad_norm": 0.0016388645162805915,
      "learning_rate": 2.3507751937984497e-05,
      "loss": 0.0001,
      "step": 6835
    },
    {
      "epoch": 26.496124031007753,
      "grad_norm": 1.3518143892288208,
      "learning_rate": 2.350387596899225e-05,
      "loss": 0.103,
      "step": 6836
    },
    {
      "epoch": 26.5,
      "grad_norm": 0.0019268145551905036,
      "learning_rate": 2.35e-05,
      "loss": 0.0001,
      "step": 6837
    },
    {
      "epoch": 26.503875968992247,
      "grad_norm": 0.007831964641809464,
      "learning_rate": 2.349612403100775e-05,
      "loss": 0.0003,
      "step": 6838
    },
    {
      "epoch": 26.507751937984494,
      "grad_norm": 0.005859968718141317,
      "learning_rate": 2.3492248062015503e-05,
      "loss": 0.0003,
      "step": 6839
    },
    {
      "epoch": 26.511627906976745,
      "grad_norm": 0.02112629823386669,
      "learning_rate": 2.3488372093023256e-05,
      "loss": 0.0006,
      "step": 6840
    },
    {
      "epoch": 26.515503875968992,
      "grad_norm": 0.009213948622345924,
      "learning_rate": 2.3484496124031008e-05,
      "loss": 0.0004,
      "step": 6841
    },
    {
      "epoch": 26.51937984496124,
      "grad_norm": 0.0033136140555143356,
      "learning_rate": 2.348062015503876e-05,
      "loss": 0.0002,
      "step": 6842
    },
    {
      "epoch": 26.52325581395349,
      "grad_norm": 0.003370595397427678,
      "learning_rate": 2.3476744186046513e-05,
      "loss": 0.0003,
      "step": 6843
    },
    {
      "epoch": 26.527131782945737,
      "grad_norm": 0.008063818328082561,
      "learning_rate": 2.3472868217054266e-05,
      "loss": 0.0003,
      "step": 6844
    },
    {
      "epoch": 26.531007751937985,
      "grad_norm": 0.004413553047925234,
      "learning_rate": 2.3468992248062015e-05,
      "loss": 0.0003,
      "step": 6845
    },
    {
      "epoch": 26.53488372093023,
      "grad_norm": 0.005284877959638834,
      "learning_rate": 2.3465116279069767e-05,
      "loss": 0.0002,
      "step": 6846
    },
    {
      "epoch": 26.53875968992248,
      "grad_norm": 0.0020245034247636795,
      "learning_rate": 2.346124031007752e-05,
      "loss": 0.0002,
      "step": 6847
    },
    {
      "epoch": 26.54263565891473,
      "grad_norm": 0.00275846547447145,
      "learning_rate": 2.3457364341085272e-05,
      "loss": 0.0002,
      "step": 6848
    },
    {
      "epoch": 26.546511627906977,
      "grad_norm": 1.0412999391555786,
      "learning_rate": 2.3453488372093024e-05,
      "loss": 0.09,
      "step": 6849
    },
    {
      "epoch": 26.550387596899224,
      "grad_norm": 0.0024377373047173023,
      "learning_rate": 2.3449612403100777e-05,
      "loss": 0.0002,
      "step": 6850
    },
    {
      "epoch": 26.55426356589147,
      "grad_norm": 0.0030221175402402878,
      "learning_rate": 2.344573643410853e-05,
      "loss": 0.0003,
      "step": 6851
    },
    {
      "epoch": 26.558139534883722,
      "grad_norm": 0.001420003012754023,
      "learning_rate": 2.344186046511628e-05,
      "loss": 0.0001,
      "step": 6852
    },
    {
      "epoch": 26.56201550387597,
      "grad_norm": 0.7707164287567139,
      "learning_rate": 2.3437984496124034e-05,
      "loss": 0.0322,
      "step": 6853
    },
    {
      "epoch": 26.565891472868216,
      "grad_norm": 0.10012222826480865,
      "learning_rate": 2.3434108527131783e-05,
      "loss": 0.0027,
      "step": 6854
    },
    {
      "epoch": 26.569767441860463,
      "grad_norm": 0.005682426504790783,
      "learning_rate": 2.3430232558139535e-05,
      "loss": 0.0003,
      "step": 6855
    },
    {
      "epoch": 26.573643410852714,
      "grad_norm": 0.0015889666974544525,
      "learning_rate": 2.3426356589147288e-05,
      "loss": 0.0002,
      "step": 6856
    },
    {
      "epoch": 26.57751937984496,
      "grad_norm": 0.005689283832907677,
      "learning_rate": 2.342248062015504e-05,
      "loss": 0.0002,
      "step": 6857
    },
    {
      "epoch": 26.58139534883721,
      "grad_norm": 7.348221302032471,
      "learning_rate": 2.3418604651162793e-05,
      "loss": 0.0882,
      "step": 6858
    },
    {
      "epoch": 26.585271317829456,
      "grad_norm": 0.0028458540327847004,
      "learning_rate": 2.3414728682170545e-05,
      "loss": 0.0002,
      "step": 6859
    },
    {
      "epoch": 26.589147286821706,
      "grad_norm": 4.099728107452393,
      "learning_rate": 2.3410852713178298e-05,
      "loss": 0.5027,
      "step": 6860
    },
    {
      "epoch": 26.593023255813954,
      "grad_norm": 0.12085352092981339,
      "learning_rate": 2.340697674418605e-05,
      "loss": 0.0031,
      "step": 6861
    },
    {
      "epoch": 26.5968992248062,
      "grad_norm": 0.3334425687789917,
      "learning_rate": 2.3403100775193802e-05,
      "loss": 0.0015,
      "step": 6862
    },
    {
      "epoch": 26.600775193798448,
      "grad_norm": 0.009151243604719639,
      "learning_rate": 2.339922480620155e-05,
      "loss": 0.0003,
      "step": 6863
    },
    {
      "epoch": 26.6046511627907,
      "grad_norm": 0.014795616269111633,
      "learning_rate": 2.3395348837209304e-05,
      "loss": 0.0002,
      "step": 6864
    },
    {
      "epoch": 26.608527131782946,
      "grad_norm": 0.42281848192214966,
      "learning_rate": 2.3391472868217053e-05,
      "loss": 0.0181,
      "step": 6865
    },
    {
      "epoch": 26.612403100775193,
      "grad_norm": 4.981770992279053,
      "learning_rate": 2.3387596899224805e-05,
      "loss": 0.4397,
      "step": 6866
    },
    {
      "epoch": 26.61627906976744,
      "grad_norm": 1.9825501441955566,
      "learning_rate": 2.3383720930232558e-05,
      "loss": 0.1776,
      "step": 6867
    },
    {
      "epoch": 26.62015503875969,
      "grad_norm": 7.509410381317139,
      "learning_rate": 2.337984496124031e-05,
      "loss": 0.1564,
      "step": 6868
    },
    {
      "epoch": 26.624031007751938,
      "grad_norm": 0.002548328135162592,
      "learning_rate": 2.3375968992248063e-05,
      "loss": 0.0002,
      "step": 6869
    },
    {
      "epoch": 26.627906976744185,
      "grad_norm": 0.0022587082348763943,
      "learning_rate": 2.3372093023255815e-05,
      "loss": 0.0002,
      "step": 6870
    },
    {
      "epoch": 26.631782945736433,
      "grad_norm": 0.05613350495696068,
      "learning_rate": 2.3368217054263567e-05,
      "loss": 0.001,
      "step": 6871
    },
    {
      "epoch": 26.635658914728683,
      "grad_norm": 0.0056218639947474,
      "learning_rate": 2.336434108527132e-05,
      "loss": 0.0002,
      "step": 6872
    },
    {
      "epoch": 26.63953488372093,
      "grad_norm": 0.001537314965389669,
      "learning_rate": 2.336046511627907e-05,
      "loss": 0.0002,
      "step": 6873
    },
    {
      "epoch": 26.643410852713178,
      "grad_norm": 0.0013438441092148423,
      "learning_rate": 2.335658914728682e-05,
      "loss": 0.0001,
      "step": 6874
    },
    {
      "epoch": 26.647286821705425,
      "grad_norm": 4.536577224731445,
      "learning_rate": 2.3352713178294574e-05,
      "loss": 0.2257,
      "step": 6875
    },
    {
      "epoch": 26.651162790697676,
      "grad_norm": 1.9383059740066528,
      "learning_rate": 2.3348837209302326e-05,
      "loss": 0.1009,
      "step": 6876
    },
    {
      "epoch": 26.655038759689923,
      "grad_norm": 0.2731967270374298,
      "learning_rate": 2.334496124031008e-05,
      "loss": 0.0118,
      "step": 6877
    },
    {
      "epoch": 26.65891472868217,
      "grad_norm": 0.01583758182823658,
      "learning_rate": 2.334108527131783e-05,
      "loss": 0.0004,
      "step": 6878
    },
    {
      "epoch": 26.662790697674417,
      "grad_norm": 0.0012993302661925554,
      "learning_rate": 2.3337209302325583e-05,
      "loss": 0.0001,
      "step": 6879
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 0.010882699862122536,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.0002,
      "step": 6880
    },
    {
      "epoch": 26.670542635658915,
      "grad_norm": 0.001859078067354858,
      "learning_rate": 2.3329457364341088e-05,
      "loss": 0.0002,
      "step": 6881
    },
    {
      "epoch": 26.674418604651162,
      "grad_norm": 0.004918388091027737,
      "learning_rate": 2.3325581395348837e-05,
      "loss": 0.0003,
      "step": 6882
    },
    {
      "epoch": 26.67829457364341,
      "grad_norm": 0.0015460526337847114,
      "learning_rate": 2.332170542635659e-05,
      "loss": 0.0001,
      "step": 6883
    },
    {
      "epoch": 26.68217054263566,
      "grad_norm": 0.038177505135536194,
      "learning_rate": 2.3317829457364342e-05,
      "loss": 0.0008,
      "step": 6884
    },
    {
      "epoch": 26.686046511627907,
      "grad_norm": 0.003828254295513034,
      "learning_rate": 2.3313953488372095e-05,
      "loss": 0.0002,
      "step": 6885
    },
    {
      "epoch": 26.689922480620154,
      "grad_norm": 0.09374041110277176,
      "learning_rate": 2.3310077519379847e-05,
      "loss": 0.0016,
      "step": 6886
    },
    {
      "epoch": 26.6937984496124,
      "grad_norm": 0.0016211374895647168,
      "learning_rate": 2.33062015503876e-05,
      "loss": 0.0002,
      "step": 6887
    },
    {
      "epoch": 26.697674418604652,
      "grad_norm": 6.2485246658325195,
      "learning_rate": 2.3302325581395352e-05,
      "loss": 0.0176,
      "step": 6888
    },
    {
      "epoch": 26.7015503875969,
      "grad_norm": 0.001332121784798801,
      "learning_rate": 2.3298449612403104e-05,
      "loss": 0.0001,
      "step": 6889
    },
    {
      "epoch": 26.705426356589147,
      "grad_norm": 0.001829844550229609,
      "learning_rate": 2.3294573643410853e-05,
      "loss": 0.0002,
      "step": 6890
    },
    {
      "epoch": 26.709302325581394,
      "grad_norm": 0.0015436360845342278,
      "learning_rate": 2.3290697674418606e-05,
      "loss": 0.0002,
      "step": 6891
    },
    {
      "epoch": 26.713178294573645,
      "grad_norm": 0.0014905391726642847,
      "learning_rate": 2.3286821705426358e-05,
      "loss": 0.0001,
      "step": 6892
    },
    {
      "epoch": 26.717054263565892,
      "grad_norm": 0.001499735750257969,
      "learning_rate": 2.3282945736434107e-05,
      "loss": 0.0001,
      "step": 6893
    },
    {
      "epoch": 26.72093023255814,
      "grad_norm": 0.5194434523582458,
      "learning_rate": 2.327906976744186e-05,
      "loss": 0.0245,
      "step": 6894
    },
    {
      "epoch": 26.724806201550386,
      "grad_norm": 0.001402019988745451,
      "learning_rate": 2.3275193798449612e-05,
      "loss": 0.0001,
      "step": 6895
    },
    {
      "epoch": 26.728682170542637,
      "grad_norm": 0.012718900106847286,
      "learning_rate": 2.3271317829457364e-05,
      "loss": 0.0005,
      "step": 6896
    },
    {
      "epoch": 26.732558139534884,
      "grad_norm": 0.4859546422958374,
      "learning_rate": 2.3267441860465117e-05,
      "loss": 0.0021,
      "step": 6897
    },
    {
      "epoch": 26.73643410852713,
      "grad_norm": 0.0030230937991291285,
      "learning_rate": 2.326356589147287e-05,
      "loss": 0.0002,
      "step": 6898
    },
    {
      "epoch": 26.74031007751938,
      "grad_norm": 0.001773530151695013,
      "learning_rate": 2.325968992248062e-05,
      "loss": 0.0002,
      "step": 6899
    },
    {
      "epoch": 26.74418604651163,
      "grad_norm": 0.049382660537958145,
      "learning_rate": 2.3255813953488374e-05,
      "loss": 0.0008,
      "step": 6900
    },
    {
      "epoch": 26.748062015503876,
      "grad_norm": 0.0034514148719608784,
      "learning_rate": 2.3251937984496126e-05,
      "loss": 0.0002,
      "step": 6901
    },
    {
      "epoch": 26.751937984496124,
      "grad_norm": 0.0034690320026129484,
      "learning_rate": 2.3248062015503876e-05,
      "loss": 0.0002,
      "step": 6902
    },
    {
      "epoch": 26.75581395348837,
      "grad_norm": 0.0034860980231314898,
      "learning_rate": 2.3244186046511628e-05,
      "loss": 0.0002,
      "step": 6903
    },
    {
      "epoch": 26.75968992248062,
      "grad_norm": 0.001719202264212072,
      "learning_rate": 2.324031007751938e-05,
      "loss": 0.0002,
      "step": 6904
    },
    {
      "epoch": 26.76356589147287,
      "grad_norm": 0.0023233965039253235,
      "learning_rate": 2.3236434108527133e-05,
      "loss": 0.0001,
      "step": 6905
    },
    {
      "epoch": 26.767441860465116,
      "grad_norm": 0.008128420449793339,
      "learning_rate": 2.3232558139534885e-05,
      "loss": 0.0003,
      "step": 6906
    },
    {
      "epoch": 26.771317829457363,
      "grad_norm": 0.00396227790042758,
      "learning_rate": 2.3228682170542638e-05,
      "loss": 0.0003,
      "step": 6907
    },
    {
      "epoch": 26.775193798449614,
      "grad_norm": 0.0014434859622269869,
      "learning_rate": 2.322480620155039e-05,
      "loss": 0.0002,
      "step": 6908
    },
    {
      "epoch": 26.77906976744186,
      "grad_norm": 0.0012689816066995263,
      "learning_rate": 2.3220930232558142e-05,
      "loss": 0.0001,
      "step": 6909
    },
    {
      "epoch": 26.782945736434108,
      "grad_norm": 0.009337985888123512,
      "learning_rate": 2.3217054263565895e-05,
      "loss": 0.0004,
      "step": 6910
    },
    {
      "epoch": 26.786821705426355,
      "grad_norm": 0.01235889457166195,
      "learning_rate": 2.3213178294573644e-05,
      "loss": 0.0002,
      "step": 6911
    },
    {
      "epoch": 26.790697674418606,
      "grad_norm": 0.004935338627547026,
      "learning_rate": 2.3209302325581396e-05,
      "loss": 0.0004,
      "step": 6912
    },
    {
      "epoch": 26.794573643410853,
      "grad_norm": 0.14053985476493835,
      "learning_rate": 2.320542635658915e-05,
      "loss": 0.0024,
      "step": 6913
    },
    {
      "epoch": 26.7984496124031,
      "grad_norm": 0.5324663519859314,
      "learning_rate": 2.32015503875969e-05,
      "loss": 0.0012,
      "step": 6914
    },
    {
      "epoch": 26.802325581395348,
      "grad_norm": 0.023389669135212898,
      "learning_rate": 2.3197674418604654e-05,
      "loss": 0.0002,
      "step": 6915
    },
    {
      "epoch": 26.8062015503876,
      "grad_norm": 0.002202258910983801,
      "learning_rate": 2.3193798449612406e-05,
      "loss": 0.0002,
      "step": 6916
    },
    {
      "epoch": 26.810077519379846,
      "grad_norm": 1.5379624366760254,
      "learning_rate": 2.3189922480620155e-05,
      "loss": 0.0983,
      "step": 6917
    },
    {
      "epoch": 26.813953488372093,
      "grad_norm": 0.15223035216331482,
      "learning_rate": 2.3186046511627907e-05,
      "loss": 0.0071,
      "step": 6918
    },
    {
      "epoch": 26.81782945736434,
      "grad_norm": 0.005812564864754677,
      "learning_rate": 2.318217054263566e-05,
      "loss": 0.0002,
      "step": 6919
    },
    {
      "epoch": 26.82170542635659,
      "grad_norm": 0.0047699338756501675,
      "learning_rate": 2.3178294573643412e-05,
      "loss": 0.0003,
      "step": 6920
    },
    {
      "epoch": 26.825581395348838,
      "grad_norm": 0.0023518691305071115,
      "learning_rate": 2.317441860465116e-05,
      "loss": 0.0002,
      "step": 6921
    },
    {
      "epoch": 26.829457364341085,
      "grad_norm": 0.04566054791212082,
      "learning_rate": 2.3170542635658914e-05,
      "loss": 0.0007,
      "step": 6922
    },
    {
      "epoch": 26.833333333333332,
      "grad_norm": 0.004365220200270414,
      "learning_rate": 2.3166666666666666e-05,
      "loss": 0.0003,
      "step": 6923
    },
    {
      "epoch": 26.837209302325583,
      "grad_norm": 0.0015177143504843116,
      "learning_rate": 2.316279069767442e-05,
      "loss": 0.0002,
      "step": 6924
    },
    {
      "epoch": 26.84108527131783,
      "grad_norm": 0.00980936549603939,
      "learning_rate": 2.315891472868217e-05,
      "loss": 0.0004,
      "step": 6925
    },
    {
      "epoch": 26.844961240310077,
      "grad_norm": 0.005158335901796818,
      "learning_rate": 2.3155038759689923e-05,
      "loss": 0.0002,
      "step": 6926
    },
    {
      "epoch": 26.848837209302324,
      "grad_norm": 0.0015361730474978685,
      "learning_rate": 2.3151162790697676e-05,
      "loss": 0.0001,
      "step": 6927
    },
    {
      "epoch": 26.852713178294575,
      "grad_norm": 0.011768810451030731,
      "learning_rate": 2.314728682170543e-05,
      "loss": 0.0004,
      "step": 6928
    },
    {
      "epoch": 26.856589147286822,
      "grad_norm": 0.001133583951741457,
      "learning_rate": 2.314341085271318e-05,
      "loss": 0.0001,
      "step": 6929
    },
    {
      "epoch": 26.86046511627907,
      "grad_norm": 0.0014877375215291977,
      "learning_rate": 2.313953488372093e-05,
      "loss": 0.0002,
      "step": 6930
    },
    {
      "epoch": 26.864341085271317,
      "grad_norm": 0.007524029351770878,
      "learning_rate": 2.3135658914728682e-05,
      "loss": 0.0003,
      "step": 6931
    },
    {
      "epoch": 26.868217054263567,
      "grad_norm": 0.0014764016959816217,
      "learning_rate": 2.3131782945736435e-05,
      "loss": 0.0001,
      "step": 6932
    },
    {
      "epoch": 26.872093023255815,
      "grad_norm": 0.0015575786819681525,
      "learning_rate": 2.3127906976744187e-05,
      "loss": 0.0001,
      "step": 6933
    },
    {
      "epoch": 26.875968992248062,
      "grad_norm": 0.0011126988101750612,
      "learning_rate": 2.312403100775194e-05,
      "loss": 0.0001,
      "step": 6934
    },
    {
      "epoch": 26.87984496124031,
      "grad_norm": 0.0012954468838870525,
      "learning_rate": 2.3120155038759692e-05,
      "loss": 0.0001,
      "step": 6935
    },
    {
      "epoch": 26.88372093023256,
      "grad_norm": 0.12985773384571075,
      "learning_rate": 2.3116279069767444e-05,
      "loss": 0.0018,
      "step": 6936
    },
    {
      "epoch": 26.887596899224807,
      "grad_norm": 0.0011603916063904762,
      "learning_rate": 2.3112403100775197e-05,
      "loss": 0.0001,
      "step": 6937
    },
    {
      "epoch": 26.891472868217054,
      "grad_norm": 0.014586394652724266,
      "learning_rate": 2.310852713178295e-05,
      "loss": 0.0002,
      "step": 6938
    },
    {
      "epoch": 26.8953488372093,
      "grad_norm": 0.002391647547483444,
      "learning_rate": 2.3104651162790698e-05,
      "loss": 0.0002,
      "step": 6939
    },
    {
      "epoch": 26.899224806201552,
      "grad_norm": 0.0014197161654010415,
      "learning_rate": 2.310077519379845e-05,
      "loss": 0.0001,
      "step": 6940
    },
    {
      "epoch": 26.9031007751938,
      "grad_norm": 0.0011242106556892395,
      "learning_rate": 2.3096899224806203e-05,
      "loss": 0.0001,
      "step": 6941
    },
    {
      "epoch": 26.906976744186046,
      "grad_norm": 0.0040701087564229965,
      "learning_rate": 2.3093023255813955e-05,
      "loss": 0.0003,
      "step": 6942
    },
    {
      "epoch": 26.910852713178294,
      "grad_norm": 0.001359525485895574,
      "learning_rate": 2.3089147286821708e-05,
      "loss": 0.0001,
      "step": 6943
    },
    {
      "epoch": 26.914728682170544,
      "grad_norm": 2.1003453731536865,
      "learning_rate": 2.3085271317829457e-05,
      "loss": 0.1446,
      "step": 6944
    },
    {
      "epoch": 26.91860465116279,
      "grad_norm": 0.0012724233092740178,
      "learning_rate": 2.308139534883721e-05,
      "loss": 0.0001,
      "step": 6945
    },
    {
      "epoch": 26.92248062015504,
      "grad_norm": 0.0013752327067777514,
      "learning_rate": 2.3077519379844962e-05,
      "loss": 0.0001,
      "step": 6946
    },
    {
      "epoch": 26.926356589147286,
      "grad_norm": 0.010898876935243607,
      "learning_rate": 2.3073643410852714e-05,
      "loss": 0.0003,
      "step": 6947
    },
    {
      "epoch": 26.930232558139537,
      "grad_norm": 0.0013639605604112148,
      "learning_rate": 2.3069767441860467e-05,
      "loss": 0.0001,
      "step": 6948
    },
    {
      "epoch": 26.934108527131784,
      "grad_norm": 0.002021639607846737,
      "learning_rate": 2.306589147286822e-05,
      "loss": 0.0002,
      "step": 6949
    },
    {
      "epoch": 26.93798449612403,
      "grad_norm": 233.18408203125,
      "learning_rate": 2.3062015503875968e-05,
      "loss": 0.1282,
      "step": 6950
    },
    {
      "epoch": 26.941860465116278,
      "grad_norm": 0.6168314814567566,
      "learning_rate": 2.305813953488372e-05,
      "loss": 0.0077,
      "step": 6951
    },
    {
      "epoch": 26.94573643410853,
      "grad_norm": 0.0011198458960279822,
      "learning_rate": 2.3054263565891473e-05,
      "loss": 0.0001,
      "step": 6952
    },
    {
      "epoch": 26.949612403100776,
      "grad_norm": 0.001415796228684485,
      "learning_rate": 2.3050387596899225e-05,
      "loss": 0.0001,
      "step": 6953
    },
    {
      "epoch": 26.953488372093023,
      "grad_norm": 0.001059990143403411,
      "learning_rate": 2.3046511627906978e-05,
      "loss": 0.0001,
      "step": 6954
    },
    {
      "epoch": 26.95736434108527,
      "grad_norm": 0.004380902275443077,
      "learning_rate": 2.304263565891473e-05,
      "loss": 0.0003,
      "step": 6955
    },
    {
      "epoch": 26.96124031007752,
      "grad_norm": 0.0013791435630992055,
      "learning_rate": 2.3038759689922483e-05,
      "loss": 0.0001,
      "step": 6956
    },
    {
      "epoch": 26.96511627906977,
      "grad_norm": 0.0012977664591744542,
      "learning_rate": 2.3034883720930235e-05,
      "loss": 0.0001,
      "step": 6957
    },
    {
      "epoch": 26.968992248062015,
      "grad_norm": 0.0012424510205164552,
      "learning_rate": 2.3031007751937987e-05,
      "loss": 0.0001,
      "step": 6958
    },
    {
      "epoch": 26.972868217054263,
      "grad_norm": 0.0027564282063394785,
      "learning_rate": 2.3027131782945736e-05,
      "loss": 0.0001,
      "step": 6959
    },
    {
      "epoch": 26.97674418604651,
      "grad_norm": 0.002493517939001322,
      "learning_rate": 2.302325581395349e-05,
      "loss": 0.0002,
      "step": 6960
    },
    {
      "epoch": 26.98062015503876,
      "grad_norm": 0.23731450736522675,
      "learning_rate": 2.301937984496124e-05,
      "loss": 0.0101,
      "step": 6961
    },
    {
      "epoch": 26.984496124031008,
      "grad_norm": 0.0012934469850733876,
      "learning_rate": 2.3015503875968994e-05,
      "loss": 0.0001,
      "step": 6962
    },
    {
      "epoch": 26.988372093023255,
      "grad_norm": 0.0010023933136835694,
      "learning_rate": 2.3011627906976746e-05,
      "loss": 0.0001,
      "step": 6963
    },
    {
      "epoch": 26.992248062015506,
      "grad_norm": 0.006586639676243067,
      "learning_rate": 2.30077519379845e-05,
      "loss": 0.0004,
      "step": 6964
    },
    {
      "epoch": 26.996124031007753,
      "grad_norm": 7.065201282501221,
      "learning_rate": 2.300387596899225e-05,
      "loss": 0.1121,
      "step": 6965
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.0015676065813750029,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.0001,
      "step": 6966
    },
    {
      "epoch": 27.003875968992247,
      "grad_norm": 0.001832993351854384,
      "learning_rate": 2.2996124031007756e-05,
      "loss": 0.0002,
      "step": 6967
    },
    {
      "epoch": 27.007751937984494,
      "grad_norm": 0.00335298222489655,
      "learning_rate": 2.2992248062015505e-05,
      "loss": 0.0002,
      "step": 6968
    },
    {
      "epoch": 27.011627906976745,
      "grad_norm": 0.0015401893761008978,
      "learning_rate": 2.2988372093023257e-05,
      "loss": 0.0001,
      "step": 6969
    },
    {
      "epoch": 27.015503875968992,
      "grad_norm": 0.001540914410725236,
      "learning_rate": 2.2984496124031006e-05,
      "loss": 0.0001,
      "step": 6970
    },
    {
      "epoch": 27.01937984496124,
      "grad_norm": 0.006215732078999281,
      "learning_rate": 2.298062015503876e-05,
      "loss": 0.0004,
      "step": 6971
    },
    {
      "epoch": 27.023255813953487,
      "grad_norm": 0.0011765685630962253,
      "learning_rate": 2.297674418604651e-05,
      "loss": 0.0001,
      "step": 6972
    },
    {
      "epoch": 27.027131782945737,
      "grad_norm": 0.0021941890008747578,
      "learning_rate": 2.2972868217054264e-05,
      "loss": 0.0002,
      "step": 6973
    },
    {
      "epoch": 27.031007751937985,
      "grad_norm": 0.0013337313430383801,
      "learning_rate": 2.2968992248062016e-05,
      "loss": 0.0001,
      "step": 6974
    },
    {
      "epoch": 27.03488372093023,
      "grad_norm": 0.001237028045579791,
      "learning_rate": 2.296511627906977e-05,
      "loss": 0.0001,
      "step": 6975
    },
    {
      "epoch": 27.03875968992248,
      "grad_norm": 0.0016375300474464893,
      "learning_rate": 2.296124031007752e-05,
      "loss": 0.0002,
      "step": 6976
    },
    {
      "epoch": 27.04263565891473,
      "grad_norm": 0.26931554079055786,
      "learning_rate": 2.2957364341085273e-05,
      "loss": 0.0002,
      "step": 6977
    },
    {
      "epoch": 27.046511627906977,
      "grad_norm": 0.0012011071667075157,
      "learning_rate": 2.2953488372093022e-05,
      "loss": 0.0001,
      "step": 6978
    },
    {
      "epoch": 27.050387596899224,
      "grad_norm": 0.20711934566497803,
      "learning_rate": 2.2949612403100775e-05,
      "loss": 0.0043,
      "step": 6979
    },
    {
      "epoch": 27.05426356589147,
      "grad_norm": 0.0013045009691268206,
      "learning_rate": 2.2945736434108527e-05,
      "loss": 0.0001,
      "step": 6980
    },
    {
      "epoch": 27.058139534883722,
      "grad_norm": 0.0019580963999032974,
      "learning_rate": 2.294186046511628e-05,
      "loss": 0.0002,
      "step": 6981
    },
    {
      "epoch": 27.06201550387597,
      "grad_norm": 0.001022891839966178,
      "learning_rate": 2.2937984496124032e-05,
      "loss": 0.0001,
      "step": 6982
    },
    {
      "epoch": 27.065891472868216,
      "grad_norm": 0.002978985197842121,
      "learning_rate": 2.2934108527131784e-05,
      "loss": 0.0002,
      "step": 6983
    },
    {
      "epoch": 27.069767441860463,
      "grad_norm": 1.033042550086975,
      "learning_rate": 2.2930232558139537e-05,
      "loss": 0.0474,
      "step": 6984
    },
    {
      "epoch": 27.073643410852714,
      "grad_norm": 0.0015471571823582053,
      "learning_rate": 2.292635658914729e-05,
      "loss": 0.0001,
      "step": 6985
    },
    {
      "epoch": 27.07751937984496,
      "grad_norm": 0.005040320567786694,
      "learning_rate": 2.292248062015504e-05,
      "loss": 0.0001,
      "step": 6986
    },
    {
      "epoch": 27.08139534883721,
      "grad_norm": 0.0036297140177339315,
      "learning_rate": 2.291860465116279e-05,
      "loss": 0.0003,
      "step": 6987
    },
    {
      "epoch": 27.085271317829456,
      "grad_norm": 0.6573474407196045,
      "learning_rate": 2.2914728682170543e-05,
      "loss": 0.0368,
      "step": 6988
    },
    {
      "epoch": 27.089147286821706,
      "grad_norm": 0.0012222831137478352,
      "learning_rate": 2.2910852713178296e-05,
      "loss": 0.0001,
      "step": 6989
    },
    {
      "epoch": 27.093023255813954,
      "grad_norm": 0.0010851019760593772,
      "learning_rate": 2.2906976744186048e-05,
      "loss": 0.0001,
      "step": 6990
    },
    {
      "epoch": 27.0968992248062,
      "grad_norm": 0.0016896123997867107,
      "learning_rate": 2.29031007751938e-05,
      "loss": 0.0001,
      "step": 6991
    },
    {
      "epoch": 27.100775193798448,
      "grad_norm": 0.0012023356975987554,
      "learning_rate": 2.2899224806201553e-05,
      "loss": 0.0001,
      "step": 6992
    },
    {
      "epoch": 27.1046511627907,
      "grad_norm": 0.004535519517958164,
      "learning_rate": 2.2895348837209305e-05,
      "loss": 0.0002,
      "step": 6993
    },
    {
      "epoch": 27.108527131782946,
      "grad_norm": 0.9857630133628845,
      "learning_rate": 2.2891472868217058e-05,
      "loss": 0.0236,
      "step": 6994
    },
    {
      "epoch": 27.112403100775193,
      "grad_norm": 0.0031997677870094776,
      "learning_rate": 2.288759689922481e-05,
      "loss": 0.0002,
      "step": 6995
    },
    {
      "epoch": 27.11627906976744,
      "grad_norm": 0.26944485306739807,
      "learning_rate": 2.288372093023256e-05,
      "loss": 0.0023,
      "step": 6996
    },
    {
      "epoch": 27.12015503875969,
      "grad_norm": 0.08878300338983536,
      "learning_rate": 2.287984496124031e-05,
      "loss": 0.0007,
      "step": 6997
    },
    {
      "epoch": 27.124031007751938,
      "grad_norm": 0.001603421987965703,
      "learning_rate": 2.287596899224806e-05,
      "loss": 0.0001,
      "step": 6998
    },
    {
      "epoch": 27.127906976744185,
      "grad_norm": 0.001970769604668021,
      "learning_rate": 2.2872093023255813e-05,
      "loss": 0.0002,
      "step": 6999
    },
    {
      "epoch": 27.131782945736433,
      "grad_norm": 0.000984855112619698,
      "learning_rate": 2.2868217054263565e-05,
      "loss": 0.0001,
      "step": 7000
    },
    {
      "epoch": 27.135658914728683,
      "grad_norm": 0.0013328283093869686,
      "learning_rate": 2.2864341085271318e-05,
      "loss": 0.0001,
      "step": 7001
    },
    {
      "epoch": 27.13953488372093,
      "grad_norm": 0.0011913010384887457,
      "learning_rate": 2.286046511627907e-05,
      "loss": 0.0001,
      "step": 7002
    },
    {
      "epoch": 27.143410852713178,
      "grad_norm": 0.006284316536039114,
      "learning_rate": 2.2856589147286823e-05,
      "loss": 0.0003,
      "step": 7003
    },
    {
      "epoch": 27.147286821705425,
      "grad_norm": 1.6545089483261108,
      "learning_rate": 2.2852713178294575e-05,
      "loss": 0.0116,
      "step": 7004
    },
    {
      "epoch": 27.151162790697676,
      "grad_norm": 0.001541833276860416,
      "learning_rate": 2.2848837209302328e-05,
      "loss": 0.0001,
      "step": 7005
    },
    {
      "epoch": 27.155038759689923,
      "grad_norm": 0.0013203861890360713,
      "learning_rate": 2.2844961240310077e-05,
      "loss": 0.0001,
      "step": 7006
    },
    {
      "epoch": 27.15891472868217,
      "grad_norm": 0.004200178198516369,
      "learning_rate": 2.284108527131783e-05,
      "loss": 0.0003,
      "step": 7007
    },
    {
      "epoch": 27.162790697674417,
      "grad_norm": 0.07549954950809479,
      "learning_rate": 2.283720930232558e-05,
      "loss": 0.0005,
      "step": 7008
    },
    {
      "epoch": 27.166666666666668,
      "grad_norm": 0.011707914061844349,
      "learning_rate": 2.2833333333333334e-05,
      "loss": 0.0005,
      "step": 7009
    },
    {
      "epoch": 27.170542635658915,
      "grad_norm": 8.88060474395752,
      "learning_rate": 2.2829457364341086e-05,
      "loss": 0.5113,
      "step": 7010
    },
    {
      "epoch": 27.174418604651162,
      "grad_norm": 4.215915203094482,
      "learning_rate": 2.282558139534884e-05,
      "loss": 0.1083,
      "step": 7011
    },
    {
      "epoch": 27.17829457364341,
      "grad_norm": 0.018541868776082993,
      "learning_rate": 2.282170542635659e-05,
      "loss": 0.0005,
      "step": 7012
    },
    {
      "epoch": 27.18217054263566,
      "grad_norm": 0.0015219604829326272,
      "learning_rate": 2.2817829457364344e-05,
      "loss": 0.0001,
      "step": 7013
    },
    {
      "epoch": 27.186046511627907,
      "grad_norm": 0.004737808369100094,
      "learning_rate": 2.2813953488372096e-05,
      "loss": 0.0001,
      "step": 7014
    },
    {
      "epoch": 27.189922480620154,
      "grad_norm": 0.0010451938724145293,
      "learning_rate": 2.2810077519379845e-05,
      "loss": 0.0001,
      "step": 7015
    },
    {
      "epoch": 27.1937984496124,
      "grad_norm": 0.0013439764734357595,
      "learning_rate": 2.2806201550387597e-05,
      "loss": 0.0001,
      "step": 7016
    },
    {
      "epoch": 27.197674418604652,
      "grad_norm": 0.0073821935802698135,
      "learning_rate": 2.280232558139535e-05,
      "loss": 0.0002,
      "step": 7017
    },
    {
      "epoch": 27.2015503875969,
      "grad_norm": 0.18018129467964172,
      "learning_rate": 2.2798449612403102e-05,
      "loss": 0.0076,
      "step": 7018
    },
    {
      "epoch": 27.205426356589147,
      "grad_norm": 1.3922711610794067,
      "learning_rate": 2.2794573643410855e-05,
      "loss": 0.0501,
      "step": 7019
    },
    {
      "epoch": 27.209302325581394,
      "grad_norm": 0.006027920171618462,
      "learning_rate": 2.2790697674418607e-05,
      "loss": 0.0002,
      "step": 7020
    },
    {
      "epoch": 27.213178294573645,
      "grad_norm": 0.0025409413501620293,
      "learning_rate": 2.278682170542636e-05,
      "loss": 0.0002,
      "step": 7021
    },
    {
      "epoch": 27.217054263565892,
      "grad_norm": 0.002747560618445277,
      "learning_rate": 2.2782945736434112e-05,
      "loss": 0.0002,
      "step": 7022
    },
    {
      "epoch": 27.22093023255814,
      "grad_norm": 0.001166805042885244,
      "learning_rate": 2.2779069767441864e-05,
      "loss": 0.0001,
      "step": 7023
    },
    {
      "epoch": 27.224806201550386,
      "grad_norm": 0.0016193744959309697,
      "learning_rate": 2.2775193798449613e-05,
      "loss": 0.0001,
      "step": 7024
    },
    {
      "epoch": 27.228682170542637,
      "grad_norm": 0.13885797560214996,
      "learning_rate": 2.2771317829457366e-05,
      "loss": 0.0018,
      "step": 7025
    },
    {
      "epoch": 27.232558139534884,
      "grad_norm": 0.0018271399894729257,
      "learning_rate": 2.2767441860465115e-05,
      "loss": 0.0002,
      "step": 7026
    },
    {
      "epoch": 27.23643410852713,
      "grad_norm": 0.0021154198329895735,
      "learning_rate": 2.2763565891472867e-05,
      "loss": 0.0002,
      "step": 7027
    },
    {
      "epoch": 27.24031007751938,
      "grad_norm": 0.001142810215242207,
      "learning_rate": 2.275968992248062e-05,
      "loss": 0.0001,
      "step": 7028
    },
    {
      "epoch": 27.24418604651163,
      "grad_norm": 0.0015526412753388286,
      "learning_rate": 2.2755813953488372e-05,
      "loss": 0.0002,
      "step": 7029
    },
    {
      "epoch": 27.248062015503876,
      "grad_norm": 0.002497415291145444,
      "learning_rate": 2.2751937984496125e-05,
      "loss": 0.0001,
      "step": 7030
    },
    {
      "epoch": 27.251937984496124,
      "grad_norm": 0.9471442103385925,
      "learning_rate": 2.2748062015503877e-05,
      "loss": 0.0059,
      "step": 7031
    },
    {
      "epoch": 27.25581395348837,
      "grad_norm": 0.0017031769966706634,
      "learning_rate": 2.274418604651163e-05,
      "loss": 0.0001,
      "step": 7032
    },
    {
      "epoch": 27.25968992248062,
      "grad_norm": 4.565257549285889,
      "learning_rate": 2.2740310077519382e-05,
      "loss": 0.5145,
      "step": 7033
    },
    {
      "epoch": 27.26356589147287,
      "grad_norm": 2.0577495098114014,
      "learning_rate": 2.2736434108527134e-05,
      "loss": 0.0524,
      "step": 7034
    },
    {
      "epoch": 27.267441860465116,
      "grad_norm": 0.1165723130106926,
      "learning_rate": 2.2732558139534883e-05,
      "loss": 0.0009,
      "step": 7035
    },
    {
      "epoch": 27.271317829457363,
      "grad_norm": 0.0028404744807630777,
      "learning_rate": 2.2728682170542636e-05,
      "loss": 0.0002,
      "step": 7036
    },
    {
      "epoch": 27.275193798449614,
      "grad_norm": 0.001583741744980216,
      "learning_rate": 2.2724806201550388e-05,
      "loss": 0.0001,
      "step": 7037
    },
    {
      "epoch": 27.27906976744186,
      "grad_norm": 0.002295226790010929,
      "learning_rate": 2.272093023255814e-05,
      "loss": 0.0001,
      "step": 7038
    },
    {
      "epoch": 27.282945736434108,
      "grad_norm": 0.002093889517709613,
      "learning_rate": 2.2717054263565893e-05,
      "loss": 0.0002,
      "step": 7039
    },
    {
      "epoch": 27.286821705426355,
      "grad_norm": 52.0787467956543,
      "learning_rate": 2.2713178294573645e-05,
      "loss": 0.1001,
      "step": 7040
    },
    {
      "epoch": 27.290697674418606,
      "grad_norm": 0.6876744627952576,
      "learning_rate": 2.2709302325581398e-05,
      "loss": 0.0114,
      "step": 7041
    },
    {
      "epoch": 27.294573643410853,
      "grad_norm": 0.12714120745658875,
      "learning_rate": 2.270542635658915e-05,
      "loss": 0.0003,
      "step": 7042
    },
    {
      "epoch": 27.2984496124031,
      "grad_norm": 0.0010522098746150732,
      "learning_rate": 2.2701550387596903e-05,
      "loss": 0.0001,
      "step": 7043
    },
    {
      "epoch": 27.302325581395348,
      "grad_norm": 0.016684846952557564,
      "learning_rate": 2.269767441860465e-05,
      "loss": 0.0004,
      "step": 7044
    },
    {
      "epoch": 27.3062015503876,
      "grad_norm": 0.0017600774299353361,
      "learning_rate": 2.2693798449612404e-05,
      "loss": 0.0001,
      "step": 7045
    },
    {
      "epoch": 27.310077519379846,
      "grad_norm": 0.0023734893184155226,
      "learning_rate": 2.2689922480620156e-05,
      "loss": 0.0002,
      "step": 7046
    },
    {
      "epoch": 27.313953488372093,
      "grad_norm": 0.0010033639846369624,
      "learning_rate": 2.268604651162791e-05,
      "loss": 0.0001,
      "step": 7047
    },
    {
      "epoch": 27.31782945736434,
      "grad_norm": 0.006727296859025955,
      "learning_rate": 2.268217054263566e-05,
      "loss": 0.0003,
      "step": 7048
    },
    {
      "epoch": 27.32170542635659,
      "grad_norm": 0.0035130467731505632,
      "learning_rate": 2.2678294573643414e-05,
      "loss": 0.0002,
      "step": 7049
    },
    {
      "epoch": 27.325581395348838,
      "grad_norm": 0.02741767093539238,
      "learning_rate": 2.2674418604651163e-05,
      "loss": 0.0006,
      "step": 7050
    },
    {
      "epoch": 27.329457364341085,
      "grad_norm": 0.008340387605130672,
      "learning_rate": 2.2670542635658915e-05,
      "loss": 0.0004,
      "step": 7051
    },
    {
      "epoch": 27.333333333333332,
      "grad_norm": 0.25078919529914856,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 0.004,
      "step": 7052
    },
    {
      "epoch": 27.337209302325583,
      "grad_norm": 0.006619357969611883,
      "learning_rate": 2.266279069767442e-05,
      "loss": 0.0001,
      "step": 7053
    },
    {
      "epoch": 27.34108527131783,
      "grad_norm": 0.00282535539008677,
      "learning_rate": 2.265891472868217e-05,
      "loss": 0.0002,
      "step": 7054
    },
    {
      "epoch": 27.344961240310077,
      "grad_norm": 0.0011828842107206583,
      "learning_rate": 2.265503875968992e-05,
      "loss": 0.0001,
      "step": 7055
    },
    {
      "epoch": 27.348837209302324,
      "grad_norm": 0.0015649576671421528,
      "learning_rate": 2.2651162790697674e-05,
      "loss": 0.0001,
      "step": 7056
    },
    {
      "epoch": 27.352713178294575,
      "grad_norm": 0.13590267300605774,
      "learning_rate": 2.2647286821705426e-05,
      "loss": 0.0056,
      "step": 7057
    },
    {
      "epoch": 27.356589147286822,
      "grad_norm": 0.0016439096070826054,
      "learning_rate": 2.264341085271318e-05,
      "loss": 0.0001,
      "step": 7058
    },
    {
      "epoch": 27.36046511627907,
      "grad_norm": 0.0013259202241897583,
      "learning_rate": 2.263953488372093e-05,
      "loss": 0.0001,
      "step": 7059
    },
    {
      "epoch": 27.364341085271317,
      "grad_norm": 13.254904747009277,
      "learning_rate": 2.2635658914728684e-05,
      "loss": 0.0189,
      "step": 7060
    },
    {
      "epoch": 27.368217054263567,
      "grad_norm": 0.001680349581874907,
      "learning_rate": 2.2631782945736436e-05,
      "loss": 0.0001,
      "step": 7061
    },
    {
      "epoch": 27.372093023255815,
      "grad_norm": 0.0013065560488030314,
      "learning_rate": 2.262790697674419e-05,
      "loss": 0.0001,
      "step": 7062
    },
    {
      "epoch": 27.375968992248062,
      "grad_norm": 0.001357377041131258,
      "learning_rate": 2.2624031007751937e-05,
      "loss": 0.0001,
      "step": 7063
    },
    {
      "epoch": 27.37984496124031,
      "grad_norm": 0.511536717414856,
      "learning_rate": 2.262015503875969e-05,
      "loss": 0.0178,
      "step": 7064
    },
    {
      "epoch": 27.38372093023256,
      "grad_norm": 0.0013722109142690897,
      "learning_rate": 2.2616279069767442e-05,
      "loss": 0.0001,
      "step": 7065
    },
    {
      "epoch": 27.387596899224807,
      "grad_norm": 0.0033164822962135077,
      "learning_rate": 2.2612403100775195e-05,
      "loss": 0.0002,
      "step": 7066
    },
    {
      "epoch": 27.391472868217054,
      "grad_norm": 0.001293156761676073,
      "learning_rate": 2.2608527131782947e-05,
      "loss": 0.0001,
      "step": 7067
    },
    {
      "epoch": 27.3953488372093,
      "grad_norm": 0.0221447441726923,
      "learning_rate": 2.26046511627907e-05,
      "loss": 0.0006,
      "step": 7068
    },
    {
      "epoch": 27.399224806201552,
      "grad_norm": 0.04649766534566879,
      "learning_rate": 2.2600775193798452e-05,
      "loss": 0.0005,
      "step": 7069
    },
    {
      "epoch": 27.4031007751938,
      "grad_norm": 0.0022605026606470346,
      "learning_rate": 2.2596899224806204e-05,
      "loss": 0.0002,
      "step": 7070
    },
    {
      "epoch": 27.406976744186046,
      "grad_norm": 0.0017743516946211457,
      "learning_rate": 2.2593023255813957e-05,
      "loss": 0.0002,
      "step": 7071
    },
    {
      "epoch": 27.410852713178294,
      "grad_norm": 0.0014650156954303384,
      "learning_rate": 2.2589147286821706e-05,
      "loss": 0.0001,
      "step": 7072
    },
    {
      "epoch": 27.414728682170544,
      "grad_norm": 0.0018753549084067345,
      "learning_rate": 2.258527131782946e-05,
      "loss": 0.0001,
      "step": 7073
    },
    {
      "epoch": 27.41860465116279,
      "grad_norm": 0.001276168623007834,
      "learning_rate": 2.258139534883721e-05,
      "loss": 0.0001,
      "step": 7074
    },
    {
      "epoch": 27.42248062015504,
      "grad_norm": 0.002983354264870286,
      "learning_rate": 2.2577519379844963e-05,
      "loss": 0.0002,
      "step": 7075
    },
    {
      "epoch": 27.426356589147286,
      "grad_norm": 0.0016301495488733053,
      "learning_rate": 2.2573643410852716e-05,
      "loss": 0.0001,
      "step": 7076
    },
    {
      "epoch": 27.430232558139537,
      "grad_norm": 0.002391149988397956,
      "learning_rate": 2.2569767441860465e-05,
      "loss": 0.0002,
      "step": 7077
    },
    {
      "epoch": 27.434108527131784,
      "grad_norm": 0.0022941811475902796,
      "learning_rate": 2.2565891472868217e-05,
      "loss": 0.0002,
      "step": 7078
    },
    {
      "epoch": 27.43798449612403,
      "grad_norm": 0.0015066202031448483,
      "learning_rate": 2.256201550387597e-05,
      "loss": 0.0002,
      "step": 7079
    },
    {
      "epoch": 27.441860465116278,
      "grad_norm": 0.007187528070062399,
      "learning_rate": 2.2558139534883722e-05,
      "loss": 0.0003,
      "step": 7080
    },
    {
      "epoch": 27.44573643410853,
      "grad_norm": 0.0012897903798148036,
      "learning_rate": 2.2554263565891474e-05,
      "loss": 0.0001,
      "step": 7081
    },
    {
      "epoch": 27.449612403100776,
      "grad_norm": 0.002669344190508127,
      "learning_rate": 2.2550387596899227e-05,
      "loss": 0.0002,
      "step": 7082
    },
    {
      "epoch": 27.453488372093023,
      "grad_norm": 0.0010329115903005004,
      "learning_rate": 2.2546511627906976e-05,
      "loss": 0.0001,
      "step": 7083
    },
    {
      "epoch": 27.45736434108527,
      "grad_norm": 0.001351737417280674,
      "learning_rate": 2.2542635658914728e-05,
      "loss": 0.0001,
      "step": 7084
    },
    {
      "epoch": 27.46124031007752,
      "grad_norm": 0.0019408244406804442,
      "learning_rate": 2.253875968992248e-05,
      "loss": 0.0001,
      "step": 7085
    },
    {
      "epoch": 27.46511627906977,
      "grad_norm": 0.0030706776306033134,
      "learning_rate": 2.2534883720930233e-05,
      "loss": 0.0002,
      "step": 7086
    },
    {
      "epoch": 27.468992248062015,
      "grad_norm": 10.078409194946289,
      "learning_rate": 2.2531007751937985e-05,
      "loss": 0.4461,
      "step": 7087
    },
    {
      "epoch": 27.472868217054263,
      "grad_norm": 0.0019499327754601836,
      "learning_rate": 2.2527131782945738e-05,
      "loss": 0.0001,
      "step": 7088
    },
    {
      "epoch": 27.476744186046513,
      "grad_norm": 0.0010373545810580254,
      "learning_rate": 2.252325581395349e-05,
      "loss": 0.0001,
      "step": 7089
    },
    {
      "epoch": 27.48062015503876,
      "grad_norm": 0.0010745024774223566,
      "learning_rate": 2.2519379844961243e-05,
      "loss": 0.0001,
      "step": 7090
    },
    {
      "epoch": 27.484496124031008,
      "grad_norm": 0.0013893634313717484,
      "learning_rate": 2.2515503875968995e-05,
      "loss": 0.0001,
      "step": 7091
    },
    {
      "epoch": 27.488372093023255,
      "grad_norm": 2.5487678050994873,
      "learning_rate": 2.2511627906976744e-05,
      "loss": 0.2072,
      "step": 7092
    },
    {
      "epoch": 27.492248062015506,
      "grad_norm": 0.001297804876230657,
      "learning_rate": 2.2507751937984497e-05,
      "loss": 0.0001,
      "step": 7093
    },
    {
      "epoch": 27.496124031007753,
      "grad_norm": 0.0011288655223324895,
      "learning_rate": 2.250387596899225e-05,
      "loss": 0.0001,
      "step": 7094
    },
    {
      "epoch": 27.5,
      "grad_norm": 0.01374622993171215,
      "learning_rate": 2.25e-05,
      "loss": 0.0004,
      "step": 7095
    },
    {
      "epoch": 27.503875968992247,
      "grad_norm": 6.566888809204102,
      "learning_rate": 2.2496124031007754e-05,
      "loss": 0.9643,
      "step": 7096
    },
    {
      "epoch": 27.507751937984494,
      "grad_norm": 0.0013703403528779745,
      "learning_rate": 2.2492248062015506e-05,
      "loss": 0.0001,
      "step": 7097
    },
    {
      "epoch": 27.511627906976745,
      "grad_norm": 0.012747623957693577,
      "learning_rate": 2.248837209302326e-05,
      "loss": 0.0005,
      "step": 7098
    },
    {
      "epoch": 27.515503875968992,
      "grad_norm": 0.0169429462403059,
      "learning_rate": 2.248449612403101e-05,
      "loss": 0.0004,
      "step": 7099
    },
    {
      "epoch": 27.51937984496124,
      "grad_norm": 0.0014025565469637513,
      "learning_rate": 2.2480620155038764e-05,
      "loss": 0.0002,
      "step": 7100
    },
    {
      "epoch": 27.52325581395349,
      "grad_norm": 0.15919174253940582,
      "learning_rate": 2.2476744186046513e-05,
      "loss": 0.0008,
      "step": 7101
    },
    {
      "epoch": 27.527131782945737,
      "grad_norm": 2.008218765258789,
      "learning_rate": 2.2472868217054265e-05,
      "loss": 0.1911,
      "step": 7102
    },
    {
      "epoch": 27.531007751937985,
      "grad_norm": 0.0012517336290329695,
      "learning_rate": 2.2468992248062014e-05,
      "loss": 0.0001,
      "step": 7103
    },
    {
      "epoch": 27.53488372093023,
      "grad_norm": 1.0178650617599487,
      "learning_rate": 2.2465116279069766e-05,
      "loss": 0.0027,
      "step": 7104
    },
    {
      "epoch": 27.53875968992248,
      "grad_norm": 1.5136785507202148,
      "learning_rate": 2.246124031007752e-05,
      "loss": 0.0767,
      "step": 7105
    },
    {
      "epoch": 27.54263565891473,
      "grad_norm": 0.0011597281554713845,
      "learning_rate": 2.245736434108527e-05,
      "loss": 0.0001,
      "step": 7106
    },
    {
      "epoch": 27.546511627906977,
      "grad_norm": 0.0017659803852438927,
      "learning_rate": 2.2453488372093024e-05,
      "loss": 0.0001,
      "step": 7107
    },
    {
      "epoch": 27.550387596899224,
      "grad_norm": 0.0033163398038595915,
      "learning_rate": 2.2449612403100776e-05,
      "loss": 0.0003,
      "step": 7108
    },
    {
      "epoch": 27.55426356589147,
      "grad_norm": 0.002753064502030611,
      "learning_rate": 2.244573643410853e-05,
      "loss": 0.0003,
      "step": 7109
    },
    {
      "epoch": 27.558139534883722,
      "grad_norm": 0.0011780660133808851,
      "learning_rate": 2.244186046511628e-05,
      "loss": 0.0001,
      "step": 7110
    },
    {
      "epoch": 27.56201550387597,
      "grad_norm": 2.351266622543335,
      "learning_rate": 2.243798449612403e-05,
      "loss": 0.1757,
      "step": 7111
    },
    {
      "epoch": 27.565891472868216,
      "grad_norm": 0.0014822763623669744,
      "learning_rate": 2.2434108527131782e-05,
      "loss": 0.0001,
      "step": 7112
    },
    {
      "epoch": 27.569767441860463,
      "grad_norm": 0.006074813660234213,
      "learning_rate": 2.2430232558139535e-05,
      "loss": 0.0002,
      "step": 7113
    },
    {
      "epoch": 27.573643410852714,
      "grad_norm": 0.002096605719998479,
      "learning_rate": 2.2426356589147287e-05,
      "loss": 0.0002,
      "step": 7114
    },
    {
      "epoch": 27.57751937984496,
      "grad_norm": 0.002002815715968609,
      "learning_rate": 2.242248062015504e-05,
      "loss": 0.0001,
      "step": 7115
    },
    {
      "epoch": 27.58139534883721,
      "grad_norm": 0.0016640741378068924,
      "learning_rate": 2.2418604651162792e-05,
      "loss": 0.0001,
      "step": 7116
    },
    {
      "epoch": 27.585271317829456,
      "grad_norm": 0.0017177126137539744,
      "learning_rate": 2.2414728682170545e-05,
      "loss": 0.0002,
      "step": 7117
    },
    {
      "epoch": 27.589147286821706,
      "grad_norm": 0.009573686867952347,
      "learning_rate": 2.2410852713178297e-05,
      "loss": 0.0005,
      "step": 7118
    },
    {
      "epoch": 27.593023255813954,
      "grad_norm": 4.116029739379883,
      "learning_rate": 2.240697674418605e-05,
      "loss": 0.0331,
      "step": 7119
    },
    {
      "epoch": 27.5968992248062,
      "grad_norm": 0.0014448254369199276,
      "learning_rate": 2.24031007751938e-05,
      "loss": 0.0001,
      "step": 7120
    },
    {
      "epoch": 27.600775193798448,
      "grad_norm": 0.0013633626513183117,
      "learning_rate": 2.239922480620155e-05,
      "loss": 0.0001,
      "step": 7121
    },
    {
      "epoch": 27.6046511627907,
      "grad_norm": 0.001467578811571002,
      "learning_rate": 2.2395348837209303e-05,
      "loss": 0.0001,
      "step": 7122
    },
    {
      "epoch": 27.608527131782946,
      "grad_norm": 0.008051685988903046,
      "learning_rate": 2.2391472868217056e-05,
      "loss": 0.0002,
      "step": 7123
    },
    {
      "epoch": 27.612403100775193,
      "grad_norm": 0.0014575663954019547,
      "learning_rate": 2.2387596899224808e-05,
      "loss": 0.0002,
      "step": 7124
    },
    {
      "epoch": 27.61627906976744,
      "grad_norm": 0.001328394515439868,
      "learning_rate": 2.238372093023256e-05,
      "loss": 0.0001,
      "step": 7125
    },
    {
      "epoch": 27.62015503875969,
      "grad_norm": 0.0018847951432690024,
      "learning_rate": 2.2379844961240313e-05,
      "loss": 0.0002,
      "step": 7126
    },
    {
      "epoch": 27.624031007751938,
      "grad_norm": 0.002068157307803631,
      "learning_rate": 2.2375968992248065e-05,
      "loss": 0.0002,
      "step": 7127
    },
    {
      "epoch": 27.627906976744185,
      "grad_norm": 0.0014842119999229908,
      "learning_rate": 2.2372093023255818e-05,
      "loss": 0.0001,
      "step": 7128
    },
    {
      "epoch": 27.631782945736433,
      "grad_norm": 2.2548532485961914,
      "learning_rate": 2.2368217054263567e-05,
      "loss": 0.1846,
      "step": 7129
    },
    {
      "epoch": 27.635658914728683,
      "grad_norm": 0.0010801504831761122,
      "learning_rate": 2.236434108527132e-05,
      "loss": 0.0001,
      "step": 7130
    },
    {
      "epoch": 27.63953488372093,
      "grad_norm": 0.0025228022132068872,
      "learning_rate": 2.2360465116279068e-05,
      "loss": 0.0002,
      "step": 7131
    },
    {
      "epoch": 27.643410852713178,
      "grad_norm": 0.001554410089738667,
      "learning_rate": 2.235658914728682e-05,
      "loss": 0.0001,
      "step": 7132
    },
    {
      "epoch": 27.647286821705425,
      "grad_norm": 1.3422746658325195,
      "learning_rate": 2.2352713178294573e-05,
      "loss": 0.0577,
      "step": 7133
    },
    {
      "epoch": 27.651162790697676,
      "grad_norm": 0.0015547514194622636,
      "learning_rate": 2.2348837209302326e-05,
      "loss": 0.0002,
      "step": 7134
    },
    {
      "epoch": 27.655038759689923,
      "grad_norm": 0.7271711826324463,
      "learning_rate": 2.2344961240310078e-05,
      "loss": 0.034,
      "step": 7135
    },
    {
      "epoch": 27.65891472868217,
      "grad_norm": 0.001140107517130673,
      "learning_rate": 2.234108527131783e-05,
      "loss": 0.0001,
      "step": 7136
    },
    {
      "epoch": 27.662790697674417,
      "grad_norm": 0.001592044485732913,
      "learning_rate": 2.2337209302325583e-05,
      "loss": 0.0001,
      "step": 7137
    },
    {
      "epoch": 27.666666666666668,
      "grad_norm": 0.0017847090493887663,
      "learning_rate": 2.2333333333333335e-05,
      "loss": 0.0001,
      "step": 7138
    },
    {
      "epoch": 27.670542635658915,
      "grad_norm": 0.0016186751890927553,
      "learning_rate": 2.2329457364341084e-05,
      "loss": 0.0002,
      "step": 7139
    },
    {
      "epoch": 27.674418604651162,
      "grad_norm": 0.0009023104212246835,
      "learning_rate": 2.2325581395348837e-05,
      "loss": 0.0001,
      "step": 7140
    },
    {
      "epoch": 27.67829457364341,
      "grad_norm": 0.0012906199553981423,
      "learning_rate": 2.232170542635659e-05,
      "loss": 0.0001,
      "step": 7141
    },
    {
      "epoch": 27.68217054263566,
      "grad_norm": 0.0014278379967436194,
      "learning_rate": 2.231782945736434e-05,
      "loss": 0.0001,
      "step": 7142
    },
    {
      "epoch": 27.686046511627907,
      "grad_norm": 0.009411272592842579,
      "learning_rate": 2.2313953488372094e-05,
      "loss": 0.0004,
      "step": 7143
    },
    {
      "epoch": 27.689922480620154,
      "grad_norm": 0.004091610666364431,
      "learning_rate": 2.2310077519379846e-05,
      "loss": 0.0003,
      "step": 7144
    },
    {
      "epoch": 27.6937984496124,
      "grad_norm": 0.0015698797069489956,
      "learning_rate": 2.23062015503876e-05,
      "loss": 0.0001,
      "step": 7145
    },
    {
      "epoch": 27.697674418604652,
      "grad_norm": 7.662999153137207,
      "learning_rate": 2.230232558139535e-05,
      "loss": 0.1217,
      "step": 7146
    },
    {
      "epoch": 27.7015503875969,
      "grad_norm": 0.0017931618494912982,
      "learning_rate": 2.2298449612403104e-05,
      "loss": 0.0001,
      "step": 7147
    },
    {
      "epoch": 27.705426356589147,
      "grad_norm": 0.001805369509384036,
      "learning_rate": 2.2294573643410853e-05,
      "loss": 0.0002,
      "step": 7148
    },
    {
      "epoch": 27.709302325581394,
      "grad_norm": 0.0012964158086106181,
      "learning_rate": 2.2290697674418605e-05,
      "loss": 0.0001,
      "step": 7149
    },
    {
      "epoch": 27.713178294573645,
      "grad_norm": 0.0013313660165295005,
      "learning_rate": 2.2286821705426357e-05,
      "loss": 0.0001,
      "step": 7150
    },
    {
      "epoch": 27.717054263565892,
      "grad_norm": 0.008341122418642044,
      "learning_rate": 2.228294573643411e-05,
      "loss": 0.0002,
      "step": 7151
    },
    {
      "epoch": 27.72093023255814,
      "grad_norm": 0.49919354915618896,
      "learning_rate": 2.2279069767441862e-05,
      "loss": 0.0023,
      "step": 7152
    },
    {
      "epoch": 27.724806201550386,
      "grad_norm": 0.0031665146816521883,
      "learning_rate": 2.2275193798449615e-05,
      "loss": 0.0002,
      "step": 7153
    },
    {
      "epoch": 27.728682170542637,
      "grad_norm": 148.9207305908203,
      "learning_rate": 2.2271317829457367e-05,
      "loss": 0.0768,
      "step": 7154
    },
    {
      "epoch": 27.732558139534884,
      "grad_norm": 0.002126789651811123,
      "learning_rate": 2.226744186046512e-05,
      "loss": 0.0002,
      "step": 7155
    },
    {
      "epoch": 27.73643410852713,
      "grad_norm": 0.0029287333600223064,
      "learning_rate": 2.2263565891472872e-05,
      "loss": 0.0002,
      "step": 7156
    },
    {
      "epoch": 27.74031007751938,
      "grad_norm": 0.006009829230606556,
      "learning_rate": 2.225968992248062e-05,
      "loss": 0.0003,
      "step": 7157
    },
    {
      "epoch": 27.74418604651163,
      "grad_norm": 0.0018958004657179117,
      "learning_rate": 2.2255813953488373e-05,
      "loss": 0.0002,
      "step": 7158
    },
    {
      "epoch": 27.748062015503876,
      "grad_norm": 0.0013649121392518282,
      "learning_rate": 2.2251937984496123e-05,
      "loss": 0.0002,
      "step": 7159
    },
    {
      "epoch": 27.751937984496124,
      "grad_norm": 0.005071267019957304,
      "learning_rate": 2.2248062015503875e-05,
      "loss": 0.0002,
      "step": 7160
    },
    {
      "epoch": 27.75581395348837,
      "grad_norm": 0.001302757067605853,
      "learning_rate": 2.2244186046511627e-05,
      "loss": 0.0001,
      "step": 7161
    },
    {
      "epoch": 27.75968992248062,
      "grad_norm": 1.3371546268463135,
      "learning_rate": 2.224031007751938e-05,
      "loss": 0.0078,
      "step": 7162
    },
    {
      "epoch": 27.76356589147287,
      "grad_norm": 0.0013645014259964228,
      "learning_rate": 2.2236434108527132e-05,
      "loss": 0.0001,
      "step": 7163
    },
    {
      "epoch": 27.767441860465116,
      "grad_norm": 0.0011308215325698256,
      "learning_rate": 2.2232558139534885e-05,
      "loss": 0.0001,
      "step": 7164
    },
    {
      "epoch": 27.771317829457363,
      "grad_norm": 0.002370375907048583,
      "learning_rate": 2.2228682170542637e-05,
      "loss": 0.0002,
      "step": 7165
    },
    {
      "epoch": 27.775193798449614,
      "grad_norm": 0.0010407925583422184,
      "learning_rate": 2.222480620155039e-05,
      "loss": 0.0001,
      "step": 7166
    },
    {
      "epoch": 27.77906976744186,
      "grad_norm": 0.0013210901524871588,
      "learning_rate": 2.2220930232558142e-05,
      "loss": 0.0001,
      "step": 7167
    },
    {
      "epoch": 27.782945736434108,
      "grad_norm": 0.0010667011374607682,
      "learning_rate": 2.221705426356589e-05,
      "loss": 0.0001,
      "step": 7168
    },
    {
      "epoch": 27.786821705426355,
      "grad_norm": 0.0018826790619641542,
      "learning_rate": 2.2213178294573643e-05,
      "loss": 0.0002,
      "step": 7169
    },
    {
      "epoch": 27.790697674418606,
      "grad_norm": 19.67103385925293,
      "learning_rate": 2.2209302325581396e-05,
      "loss": 0.3744,
      "step": 7170
    },
    {
      "epoch": 27.794573643410853,
      "grad_norm": 0.001306820660829544,
      "learning_rate": 2.2205426356589148e-05,
      "loss": 0.0001,
      "step": 7171
    },
    {
      "epoch": 27.7984496124031,
      "grad_norm": 0.0013122719246894121,
      "learning_rate": 2.22015503875969e-05,
      "loss": 0.0001,
      "step": 7172
    },
    {
      "epoch": 27.802325581395348,
      "grad_norm": 0.0012503989273682237,
      "learning_rate": 2.2197674418604653e-05,
      "loss": 0.0001,
      "step": 7173
    },
    {
      "epoch": 27.8062015503876,
      "grad_norm": 0.0013651287881657481,
      "learning_rate": 2.2193798449612405e-05,
      "loss": 0.0001,
      "step": 7174
    },
    {
      "epoch": 27.810077519379846,
      "grad_norm": 0.001560994191095233,
      "learning_rate": 2.2189922480620158e-05,
      "loss": 0.0001,
      "step": 7175
    },
    {
      "epoch": 27.813953488372093,
      "grad_norm": 0.001434024190530181,
      "learning_rate": 2.218604651162791e-05,
      "loss": 0.0001,
      "step": 7176
    },
    {
      "epoch": 27.81782945736434,
      "grad_norm": 0.0013832023832947016,
      "learning_rate": 2.218217054263566e-05,
      "loss": 0.0001,
      "step": 7177
    },
    {
      "epoch": 27.82170542635659,
      "grad_norm": 0.0014663934707641602,
      "learning_rate": 2.2178294573643412e-05,
      "loss": 0.0001,
      "step": 7178
    },
    {
      "epoch": 27.825581395348838,
      "grad_norm": 0.13189341127872467,
      "learning_rate": 2.2174418604651164e-05,
      "loss": 0.0041,
      "step": 7179
    },
    {
      "epoch": 27.829457364341085,
      "grad_norm": 0.0014018131187185645,
      "learning_rate": 2.2170542635658917e-05,
      "loss": 0.0001,
      "step": 7180
    },
    {
      "epoch": 27.833333333333332,
      "grad_norm": 0.49680590629577637,
      "learning_rate": 2.216666666666667e-05,
      "loss": 0.0016,
      "step": 7181
    },
    {
      "epoch": 27.837209302325583,
      "grad_norm": 0.0015654132002964616,
      "learning_rate": 2.216279069767442e-05,
      "loss": 0.0001,
      "step": 7182
    },
    {
      "epoch": 27.84108527131783,
      "grad_norm": 0.0018286225385963917,
      "learning_rate": 2.215891472868217e-05,
      "loss": 0.0002,
      "step": 7183
    },
    {
      "epoch": 27.844961240310077,
      "grad_norm": 0.001720940344966948,
      "learning_rate": 2.2155038759689923e-05,
      "loss": 0.0002,
      "step": 7184
    },
    {
      "epoch": 27.848837209302324,
      "grad_norm": 0.009468563832342625,
      "learning_rate": 2.2151162790697675e-05,
      "loss": 0.0002,
      "step": 7185
    },
    {
      "epoch": 27.852713178294575,
      "grad_norm": 1.0433266162872314,
      "learning_rate": 2.2147286821705428e-05,
      "loss": 0.1324,
      "step": 7186
    },
    {
      "epoch": 27.856589147286822,
      "grad_norm": 0.014313229359686375,
      "learning_rate": 2.2143410852713177e-05,
      "loss": 0.0001,
      "step": 7187
    },
    {
      "epoch": 27.86046511627907,
      "grad_norm": 0.0028107515536248684,
      "learning_rate": 2.213953488372093e-05,
      "loss": 0.0001,
      "step": 7188
    },
    {
      "epoch": 27.864341085271317,
      "grad_norm": 2.4359397888183594,
      "learning_rate": 2.213565891472868e-05,
      "loss": 0.2817,
      "step": 7189
    },
    {
      "epoch": 27.868217054263567,
      "grad_norm": 2.7113828659057617,
      "learning_rate": 2.2131782945736434e-05,
      "loss": 0.1797,
      "step": 7190
    },
    {
      "epoch": 27.872093023255815,
      "grad_norm": 0.001106796320527792,
      "learning_rate": 2.2127906976744186e-05,
      "loss": 0.0001,
      "step": 7191
    },
    {
      "epoch": 27.875968992248062,
      "grad_norm": 0.004489583428949118,
      "learning_rate": 2.212403100775194e-05,
      "loss": 0.0003,
      "step": 7192
    },
    {
      "epoch": 27.87984496124031,
      "grad_norm": 0.0031361503060907125,
      "learning_rate": 2.212015503875969e-05,
      "loss": 0.0002,
      "step": 7193
    },
    {
      "epoch": 27.88372093023256,
      "grad_norm": 0.0008737501339055598,
      "learning_rate": 2.2116279069767444e-05,
      "loss": 0.0001,
      "step": 7194
    },
    {
      "epoch": 27.887596899224807,
      "grad_norm": 0.005764685571193695,
      "learning_rate": 2.2112403100775196e-05,
      "loss": 0.0003,
      "step": 7195
    },
    {
      "epoch": 27.891472868217054,
      "grad_norm": 0.001611793995834887,
      "learning_rate": 2.2108527131782945e-05,
      "loss": 0.0001,
      "step": 7196
    },
    {
      "epoch": 27.8953488372093,
      "grad_norm": 0.007433740422129631,
      "learning_rate": 2.2104651162790698e-05,
      "loss": 0.0004,
      "step": 7197
    },
    {
      "epoch": 27.899224806201552,
      "grad_norm": 10.28911304473877,
      "learning_rate": 2.210077519379845e-05,
      "loss": 0.3271,
      "step": 7198
    },
    {
      "epoch": 27.9031007751938,
      "grad_norm": 0.001373749109916389,
      "learning_rate": 2.2096899224806202e-05,
      "loss": 0.0001,
      "step": 7199
    },
    {
      "epoch": 27.906976744186046,
      "grad_norm": 0.001469144714064896,
      "learning_rate": 2.2093023255813955e-05,
      "loss": 0.0001,
      "step": 7200
    },
    {
      "epoch": 27.910852713178294,
      "grad_norm": 0.799117922782898,
      "learning_rate": 2.2089147286821707e-05,
      "loss": 0.0339,
      "step": 7201
    },
    {
      "epoch": 27.914728682170544,
      "grad_norm": 0.001442444627173245,
      "learning_rate": 2.208527131782946e-05,
      "loss": 0.0001,
      "step": 7202
    },
    {
      "epoch": 27.91860465116279,
      "grad_norm": 0.0016293657245114446,
      "learning_rate": 2.2081395348837212e-05,
      "loss": 0.0001,
      "step": 7203
    },
    {
      "epoch": 27.92248062015504,
      "grad_norm": 0.0012486712075769901,
      "learning_rate": 2.2077519379844965e-05,
      "loss": 0.0001,
      "step": 7204
    },
    {
      "epoch": 27.926356589147286,
      "grad_norm": 0.00111009378451854,
      "learning_rate": 2.2073643410852714e-05,
      "loss": 0.0001,
      "step": 7205
    },
    {
      "epoch": 27.930232558139537,
      "grad_norm": 0.0009897199925035238,
      "learning_rate": 2.2069767441860466e-05,
      "loss": 0.0001,
      "step": 7206
    },
    {
      "epoch": 27.934108527131784,
      "grad_norm": 0.0016395780257880688,
      "learning_rate": 2.206589147286822e-05,
      "loss": 0.0001,
      "step": 7207
    },
    {
      "epoch": 27.93798449612403,
      "grad_norm": 0.011590543203055859,
      "learning_rate": 2.206201550387597e-05,
      "loss": 0.0006,
      "step": 7208
    },
    {
      "epoch": 27.941860465116278,
      "grad_norm": 0.0032692209351807833,
      "learning_rate": 2.2058139534883723e-05,
      "loss": 0.0002,
      "step": 7209
    },
    {
      "epoch": 27.94573643410853,
      "grad_norm": 0.0010102681117132306,
      "learning_rate": 2.2054263565891472e-05,
      "loss": 0.0001,
      "step": 7210
    },
    {
      "epoch": 27.949612403100776,
      "grad_norm": 0.0011974406661465764,
      "learning_rate": 2.2050387596899225e-05,
      "loss": 0.0001,
      "step": 7211
    },
    {
      "epoch": 27.953488372093023,
      "grad_norm": 0.006387087982147932,
      "learning_rate": 2.2046511627906977e-05,
      "loss": 0.0004,
      "step": 7212
    },
    {
      "epoch": 27.95736434108527,
      "grad_norm": 0.002482255222275853,
      "learning_rate": 2.204263565891473e-05,
      "loss": 0.0001,
      "step": 7213
    },
    {
      "epoch": 27.96124031007752,
      "grad_norm": 0.0012970244279131293,
      "learning_rate": 2.2038759689922482e-05,
      "loss": 0.0001,
      "step": 7214
    },
    {
      "epoch": 27.96511627906977,
      "grad_norm": 0.004321267828345299,
      "learning_rate": 2.2034883720930234e-05,
      "loss": 0.0003,
      "step": 7215
    },
    {
      "epoch": 27.968992248062015,
      "grad_norm": 0.0025895978324115276,
      "learning_rate": 2.2031007751937983e-05,
      "loss": 0.0002,
      "step": 7216
    },
    {
      "epoch": 27.972868217054263,
      "grad_norm": 0.001521781668998301,
      "learning_rate": 2.2027131782945736e-05,
      "loss": 0.0001,
      "step": 7217
    },
    {
      "epoch": 27.97674418604651,
      "grad_norm": 4.1554036140441895,
      "learning_rate": 2.2023255813953488e-05,
      "loss": 0.0641,
      "step": 7218
    },
    {
      "epoch": 27.98062015503876,
      "grad_norm": 0.001793664530850947,
      "learning_rate": 2.201937984496124e-05,
      "loss": 0.0002,
      "step": 7219
    },
    {
      "epoch": 27.984496124031008,
      "grad_norm": 0.0075240349397063255,
      "learning_rate": 2.2015503875968993e-05,
      "loss": 0.0005,
      "step": 7220
    },
    {
      "epoch": 27.988372093023255,
      "grad_norm": 0.001454562065191567,
      "learning_rate": 2.2011627906976746e-05,
      "loss": 0.0001,
      "step": 7221
    },
    {
      "epoch": 27.992248062015506,
      "grad_norm": 0.0023729130625724792,
      "learning_rate": 2.2007751937984498e-05,
      "loss": 0.0002,
      "step": 7222
    },
    {
      "epoch": 27.996124031007753,
      "grad_norm": 0.0011846362613141537,
      "learning_rate": 2.200387596899225e-05,
      "loss": 0.0001,
      "step": 7223
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.0011037449585273862,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0001,
      "step": 7224
    },
    {
      "epoch": 28.003875968992247,
      "grad_norm": 0.001533490139991045,
      "learning_rate": 2.1996124031007752e-05,
      "loss": 0.0001,
      "step": 7225
    },
    {
      "epoch": 28.007751937984494,
      "grad_norm": 0.001355598447844386,
      "learning_rate": 2.1992248062015504e-05,
      "loss": 0.0001,
      "step": 7226
    },
    {
      "epoch": 28.011627906976745,
      "grad_norm": 0.2503493130207062,
      "learning_rate": 2.1988372093023257e-05,
      "loss": 0.0108,
      "step": 7227
    },
    {
      "epoch": 28.015503875968992,
      "grad_norm": 3.2743453979492188,
      "learning_rate": 2.198449612403101e-05,
      "loss": 0.3492,
      "step": 7228
    },
    {
      "epoch": 28.01937984496124,
      "grad_norm": 0.001588443759828806,
      "learning_rate": 2.198062015503876e-05,
      "loss": 0.0001,
      "step": 7229
    },
    {
      "epoch": 28.023255813953487,
      "grad_norm": 2.6931331157684326,
      "learning_rate": 2.1976744186046514e-05,
      "loss": 0.1414,
      "step": 7230
    },
    {
      "epoch": 28.027131782945737,
      "grad_norm": 0.02925221063196659,
      "learning_rate": 2.1972868217054266e-05,
      "loss": 0.0002,
      "step": 7231
    },
    {
      "epoch": 28.031007751937985,
      "grad_norm": 0.0013793918769806623,
      "learning_rate": 2.196899224806202e-05,
      "loss": 0.0001,
      "step": 7232
    },
    {
      "epoch": 28.03488372093023,
      "grad_norm": 0.00277453800663352,
      "learning_rate": 2.196511627906977e-05,
      "loss": 0.0002,
      "step": 7233
    },
    {
      "epoch": 28.03875968992248,
      "grad_norm": 0.08283188939094543,
      "learning_rate": 2.196124031007752e-05,
      "loss": 0.002,
      "step": 7234
    },
    {
      "epoch": 28.04263565891473,
      "grad_norm": 0.003499022452160716,
      "learning_rate": 2.1957364341085273e-05,
      "loss": 0.0003,
      "step": 7235
    },
    {
      "epoch": 28.046511627906977,
      "grad_norm": 0.0010519711067900062,
      "learning_rate": 2.1953488372093025e-05,
      "loss": 0.0001,
      "step": 7236
    },
    {
      "epoch": 28.050387596899224,
      "grad_norm": 1.967934489250183,
      "learning_rate": 2.1949612403100774e-05,
      "loss": 0.2754,
      "step": 7237
    },
    {
      "epoch": 28.05426356589147,
      "grad_norm": 0.8839454650878906,
      "learning_rate": 2.1945736434108527e-05,
      "loss": 0.179,
      "step": 7238
    },
    {
      "epoch": 28.058139534883722,
      "grad_norm": 0.002117475960403681,
      "learning_rate": 2.194186046511628e-05,
      "loss": 0.0002,
      "step": 7239
    },
    {
      "epoch": 28.06201550387597,
      "grad_norm": 1.0965452194213867,
      "learning_rate": 2.193798449612403e-05,
      "loss": 0.0678,
      "step": 7240
    },
    {
      "epoch": 28.065891472868216,
      "grad_norm": 0.0010821751784533262,
      "learning_rate": 2.1934108527131784e-05,
      "loss": 0.0001,
      "step": 7241
    },
    {
      "epoch": 28.069767441860463,
      "grad_norm": 3.1957898139953613,
      "learning_rate": 2.1930232558139536e-05,
      "loss": 0.3728,
      "step": 7242
    },
    {
      "epoch": 28.073643410852714,
      "grad_norm": 0.0019254283979535103,
      "learning_rate": 2.192635658914729e-05,
      "loss": 0.0002,
      "step": 7243
    },
    {
      "epoch": 28.07751937984496,
      "grad_norm": 0.001093789003789425,
      "learning_rate": 2.1922480620155038e-05,
      "loss": 0.0001,
      "step": 7244
    },
    {
      "epoch": 28.08139534883721,
      "grad_norm": 0.009578910656273365,
      "learning_rate": 2.191860465116279e-05,
      "loss": 0.0003,
      "step": 7245
    },
    {
      "epoch": 28.085271317829456,
      "grad_norm": 0.35751959681510925,
      "learning_rate": 2.1914728682170543e-05,
      "loss": 0.0147,
      "step": 7246
    },
    {
      "epoch": 28.089147286821706,
      "grad_norm": 0.4578796625137329,
      "learning_rate": 2.1910852713178295e-05,
      "loss": 0.0169,
      "step": 7247
    },
    {
      "epoch": 28.093023255813954,
      "grad_norm": 0.0017259723972529173,
      "learning_rate": 2.1906976744186047e-05,
      "loss": 0.0001,
      "step": 7248
    },
    {
      "epoch": 28.0968992248062,
      "grad_norm": 0.0010249870829284191,
      "learning_rate": 2.19031007751938e-05,
      "loss": 0.0001,
      "step": 7249
    },
    {
      "epoch": 28.100775193798448,
      "grad_norm": 0.0023194265086203814,
      "learning_rate": 2.1899224806201552e-05,
      "loss": 0.0002,
      "step": 7250
    },
    {
      "epoch": 28.1046511627907,
      "grad_norm": 0.027882691472768784,
      "learning_rate": 2.1895348837209305e-05,
      "loss": 0.0011,
      "step": 7251
    },
    {
      "epoch": 28.108527131782946,
      "grad_norm": 0.6619148850440979,
      "learning_rate": 2.1891472868217057e-05,
      "loss": 0.0314,
      "step": 7252
    },
    {
      "epoch": 28.112403100775193,
      "grad_norm": 0.0012045385083183646,
      "learning_rate": 2.1887596899224806e-05,
      "loss": 0.0001,
      "step": 7253
    },
    {
      "epoch": 28.11627906976744,
      "grad_norm": 0.0013805722119286656,
      "learning_rate": 2.188372093023256e-05,
      "loss": 0.0001,
      "step": 7254
    },
    {
      "epoch": 28.12015503875969,
      "grad_norm": 2.6450843811035156,
      "learning_rate": 2.187984496124031e-05,
      "loss": 0.34,
      "step": 7255
    },
    {
      "epoch": 28.124031007751938,
      "grad_norm": 0.04786675423383713,
      "learning_rate": 2.1875968992248063e-05,
      "loss": 0.0019,
      "step": 7256
    },
    {
      "epoch": 28.127906976744185,
      "grad_norm": 0.03661518916487694,
      "learning_rate": 2.1872093023255816e-05,
      "loss": 0.0015,
      "step": 7257
    },
    {
      "epoch": 28.131782945736433,
      "grad_norm": 0.5666788816452026,
      "learning_rate": 2.1868217054263568e-05,
      "loss": 0.0183,
      "step": 7258
    },
    {
      "epoch": 28.135658914728683,
      "grad_norm": 8.09549331665039,
      "learning_rate": 2.186434108527132e-05,
      "loss": 0.11,
      "step": 7259
    },
    {
      "epoch": 28.13953488372093,
      "grad_norm": 0.001665135263465345,
      "learning_rate": 2.1860465116279073e-05,
      "loss": 0.0001,
      "step": 7260
    },
    {
      "epoch": 28.143410852713178,
      "grad_norm": 0.0013769265497103333,
      "learning_rate": 2.1856589147286825e-05,
      "loss": 0.0001,
      "step": 7261
    },
    {
      "epoch": 28.147286821705425,
      "grad_norm": 0.0016165798297151923,
      "learning_rate": 2.1852713178294575e-05,
      "loss": 0.0001,
      "step": 7262
    },
    {
      "epoch": 28.151162790697676,
      "grad_norm": 0.014924461022019386,
      "learning_rate": 2.1848837209302327e-05,
      "loss": 0.0005,
      "step": 7263
    },
    {
      "epoch": 28.155038759689923,
      "grad_norm": 0.04293819144368172,
      "learning_rate": 2.1844961240310076e-05,
      "loss": 0.0017,
      "step": 7264
    },
    {
      "epoch": 28.15891472868217,
      "grad_norm": 0.1605890393257141,
      "learning_rate": 2.184108527131783e-05,
      "loss": 0.0066,
      "step": 7265
    },
    {
      "epoch": 28.162790697674417,
      "grad_norm": 0.0011409063590690494,
      "learning_rate": 2.183720930232558e-05,
      "loss": 0.0001,
      "step": 7266
    },
    {
      "epoch": 28.166666666666668,
      "grad_norm": 0.0011570652713999152,
      "learning_rate": 2.1833333333333333e-05,
      "loss": 0.0001,
      "step": 7267
    },
    {
      "epoch": 28.170542635658915,
      "grad_norm": 0.0019019793253391981,
      "learning_rate": 2.1829457364341086e-05,
      "loss": 0.0001,
      "step": 7268
    },
    {
      "epoch": 28.174418604651162,
      "grad_norm": 0.01009543426334858,
      "learning_rate": 2.1825581395348838e-05,
      "loss": 0.0005,
      "step": 7269
    },
    {
      "epoch": 28.17829457364341,
      "grad_norm": 0.0017080309335142374,
      "learning_rate": 2.182170542635659e-05,
      "loss": 0.0001,
      "step": 7270
    },
    {
      "epoch": 28.18217054263566,
      "grad_norm": 0.00778629444539547,
      "learning_rate": 2.1817829457364343e-05,
      "loss": 0.0002,
      "step": 7271
    },
    {
      "epoch": 28.186046511627907,
      "grad_norm": 0.0278767142444849,
      "learning_rate": 2.1813953488372092e-05,
      "loss": 0.0012,
      "step": 7272
    },
    {
      "epoch": 28.189922480620154,
      "grad_norm": 0.0017875084886327386,
      "learning_rate": 2.1810077519379844e-05,
      "loss": 0.0001,
      "step": 7273
    },
    {
      "epoch": 28.1937984496124,
      "grad_norm": 0.0013812686083838344,
      "learning_rate": 2.1806201550387597e-05,
      "loss": 0.0001,
      "step": 7274
    },
    {
      "epoch": 28.197674418604652,
      "grad_norm": 0.011219766922295094,
      "learning_rate": 2.180232558139535e-05,
      "loss": 0.0007,
      "step": 7275
    },
    {
      "epoch": 28.2015503875969,
      "grad_norm": 0.01491549052298069,
      "learning_rate": 2.17984496124031e-05,
      "loss": 0.0007,
      "step": 7276
    },
    {
      "epoch": 28.205426356589147,
      "grad_norm": 0.001161996042355895,
      "learning_rate": 2.1794573643410854e-05,
      "loss": 0.0001,
      "step": 7277
    },
    {
      "epoch": 28.209302325581394,
      "grad_norm": 0.040456678718328476,
      "learning_rate": 2.1790697674418606e-05,
      "loss": 0.0017,
      "step": 7278
    },
    {
      "epoch": 28.213178294573645,
      "grad_norm": 0.0013915144372731447,
      "learning_rate": 2.178682170542636e-05,
      "loss": 0.0001,
      "step": 7279
    },
    {
      "epoch": 28.217054263565892,
      "grad_norm": 0.0009755864157341421,
      "learning_rate": 2.178294573643411e-05,
      "loss": 0.0001,
      "step": 7280
    },
    {
      "epoch": 28.22093023255814,
      "grad_norm": 0.0014102152781561017,
      "learning_rate": 2.177906976744186e-05,
      "loss": 0.0001,
      "step": 7281
    },
    {
      "epoch": 28.224806201550386,
      "grad_norm": 0.012994055636227131,
      "learning_rate": 2.1775193798449613e-05,
      "loss": 0.0002,
      "step": 7282
    },
    {
      "epoch": 28.228682170542637,
      "grad_norm": 0.0010903471847996116,
      "learning_rate": 2.1771317829457365e-05,
      "loss": 0.0001,
      "step": 7283
    },
    {
      "epoch": 28.232558139534884,
      "grad_norm": 0.09904515743255615,
      "learning_rate": 2.1767441860465118e-05,
      "loss": 0.0034,
      "step": 7284
    },
    {
      "epoch": 28.23643410852713,
      "grad_norm": 0.001530705252662301,
      "learning_rate": 2.176356589147287e-05,
      "loss": 0.0001,
      "step": 7285
    },
    {
      "epoch": 28.24031007751938,
      "grad_norm": 1.1310042142868042,
      "learning_rate": 2.1759689922480622e-05,
      "loss": 0.0622,
      "step": 7286
    },
    {
      "epoch": 28.24418604651163,
      "grad_norm": 0.01680113933980465,
      "learning_rate": 2.1755813953488375e-05,
      "loss": 0.0009,
      "step": 7287
    },
    {
      "epoch": 28.248062015503876,
      "grad_norm": 0.0014260309981182218,
      "learning_rate": 2.1751937984496127e-05,
      "loss": 0.0001,
      "step": 7288
    },
    {
      "epoch": 28.251937984496124,
      "grad_norm": 0.020125284790992737,
      "learning_rate": 2.174806201550388e-05,
      "loss": 0.001,
      "step": 7289
    },
    {
      "epoch": 28.25581395348837,
      "grad_norm": 0.002878709463402629,
      "learning_rate": 2.174418604651163e-05,
      "loss": 0.0002,
      "step": 7290
    },
    {
      "epoch": 28.25968992248062,
      "grad_norm": 0.0016462061321362853,
      "learning_rate": 2.174031007751938e-05,
      "loss": 0.0002,
      "step": 7291
    },
    {
      "epoch": 28.26356589147287,
      "grad_norm": 0.001436283579096198,
      "learning_rate": 2.173643410852713e-05,
      "loss": 0.0001,
      "step": 7292
    },
    {
      "epoch": 28.267441860465116,
      "grad_norm": 0.00876049418002367,
      "learning_rate": 2.1732558139534883e-05,
      "loss": 0.0004,
      "step": 7293
    },
    {
      "epoch": 28.271317829457363,
      "grad_norm": 0.22518764436244965,
      "learning_rate": 2.1728682170542635e-05,
      "loss": 0.0092,
      "step": 7294
    },
    {
      "epoch": 28.275193798449614,
      "grad_norm": 0.012997311539947987,
      "learning_rate": 2.1724806201550387e-05,
      "loss": 0.0007,
      "step": 7295
    },
    {
      "epoch": 28.27906976744186,
      "grad_norm": 0.0009951780084520578,
      "learning_rate": 2.172093023255814e-05,
      "loss": 0.0001,
      "step": 7296
    },
    {
      "epoch": 28.282945736434108,
      "grad_norm": 0.001128321629948914,
      "learning_rate": 2.1717054263565892e-05,
      "loss": 0.0001,
      "step": 7297
    },
    {
      "epoch": 28.286821705426355,
      "grad_norm": 0.03985126316547394,
      "learning_rate": 2.1713178294573645e-05,
      "loss": 0.0019,
      "step": 7298
    },
    {
      "epoch": 28.290697674418606,
      "grad_norm": 0.0024683622177690268,
      "learning_rate": 2.1709302325581397e-05,
      "loss": 0.0002,
      "step": 7299
    },
    {
      "epoch": 28.294573643410853,
      "grad_norm": 0.006129907444119453,
      "learning_rate": 2.170542635658915e-05,
      "loss": 0.0004,
      "step": 7300
    },
    {
      "epoch": 28.2984496124031,
      "grad_norm": 0.001161588472314179,
      "learning_rate": 2.17015503875969e-05,
      "loss": 0.0001,
      "step": 7301
    },
    {
      "epoch": 28.302325581395348,
      "grad_norm": 0.001705767004750669,
      "learning_rate": 2.169767441860465e-05,
      "loss": 0.0001,
      "step": 7302
    },
    {
      "epoch": 28.3062015503876,
      "grad_norm": 0.008777562528848648,
      "learning_rate": 2.1693798449612403e-05,
      "loss": 0.0005,
      "step": 7303
    },
    {
      "epoch": 28.310077519379846,
      "grad_norm": 0.0009409093181602657,
      "learning_rate": 2.1689922480620156e-05,
      "loss": 0.0001,
      "step": 7304
    },
    {
      "epoch": 28.313953488372093,
      "grad_norm": 0.0022875433787703514,
      "learning_rate": 2.168604651162791e-05,
      "loss": 0.0001,
      "step": 7305
    },
    {
      "epoch": 28.31782945736434,
      "grad_norm": 0.0015038925921544433,
      "learning_rate": 2.168217054263566e-05,
      "loss": 0.0001,
      "step": 7306
    },
    {
      "epoch": 28.32170542635659,
      "grad_norm": 9.371344566345215,
      "learning_rate": 2.1678294573643413e-05,
      "loss": 0.3835,
      "step": 7307
    },
    {
      "epoch": 28.325581395348838,
      "grad_norm": 0.0010112670715898275,
      "learning_rate": 2.1674418604651166e-05,
      "loss": 0.0001,
      "step": 7308
    },
    {
      "epoch": 28.329457364341085,
      "grad_norm": 0.005368036217987537,
      "learning_rate": 2.1670542635658918e-05,
      "loss": 0.0003,
      "step": 7309
    },
    {
      "epoch": 28.333333333333332,
      "grad_norm": 0.30343374609947205,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.0035,
      "step": 7310
    },
    {
      "epoch": 28.337209302325583,
      "grad_norm": 0.001113368198275566,
      "learning_rate": 2.166279069767442e-05,
      "loss": 0.0001,
      "step": 7311
    },
    {
      "epoch": 28.34108527131783,
      "grad_norm": 0.0013769585639238358,
      "learning_rate": 2.1658914728682172e-05,
      "loss": 0.0001,
      "step": 7312
    },
    {
      "epoch": 28.344961240310077,
      "grad_norm": 0.001044241595081985,
      "learning_rate": 2.1655038759689924e-05,
      "loss": 0.0001,
      "step": 7313
    },
    {
      "epoch": 28.348837209302324,
      "grad_norm": 0.008608589880168438,
      "learning_rate": 2.1651162790697677e-05,
      "loss": 0.0003,
      "step": 7314
    },
    {
      "epoch": 28.352713178294575,
      "grad_norm": 0.0012800107942894101,
      "learning_rate": 2.164728682170543e-05,
      "loss": 0.0001,
      "step": 7315
    },
    {
      "epoch": 28.356589147286822,
      "grad_norm": 0.0011185703333467245,
      "learning_rate": 2.164341085271318e-05,
      "loss": 0.0001,
      "step": 7316
    },
    {
      "epoch": 28.36046511627907,
      "grad_norm": 0.001150791416876018,
      "learning_rate": 2.163953488372093e-05,
      "loss": 0.0001,
      "step": 7317
    },
    {
      "epoch": 28.364341085271317,
      "grad_norm": 0.0035532349720597267,
      "learning_rate": 2.1635658914728683e-05,
      "loss": 0.0002,
      "step": 7318
    },
    {
      "epoch": 28.368217054263567,
      "grad_norm": 0.011819384060800076,
      "learning_rate": 2.1631782945736435e-05,
      "loss": 0.0004,
      "step": 7319
    },
    {
      "epoch": 28.372093023255815,
      "grad_norm": 0.00416850158944726,
      "learning_rate": 2.1627906976744184e-05,
      "loss": 0.0003,
      "step": 7320
    },
    {
      "epoch": 28.375968992248062,
      "grad_norm": 0.011682170443236828,
      "learning_rate": 2.1624031007751937e-05,
      "loss": 0.0006,
      "step": 7321
    },
    {
      "epoch": 28.37984496124031,
      "grad_norm": 219.8451385498047,
      "learning_rate": 2.162015503875969e-05,
      "loss": 0.0611,
      "step": 7322
    },
    {
      "epoch": 28.38372093023256,
      "grad_norm": 0.0014162049628794193,
      "learning_rate": 2.1616279069767442e-05,
      "loss": 0.0001,
      "step": 7323
    },
    {
      "epoch": 28.387596899224807,
      "grad_norm": 0.0012036488624289632,
      "learning_rate": 2.1612403100775194e-05,
      "loss": 0.0001,
      "step": 7324
    },
    {
      "epoch": 28.391472868217054,
      "grad_norm": 0.0035958283115178347,
      "learning_rate": 2.1608527131782947e-05,
      "loss": 0.0003,
      "step": 7325
    },
    {
      "epoch": 28.3953488372093,
      "grad_norm": 0.0057561988942325115,
      "learning_rate": 2.16046511627907e-05,
      "loss": 0.0003,
      "step": 7326
    },
    {
      "epoch": 28.399224806201552,
      "grad_norm": 0.0013378206640481949,
      "learning_rate": 2.160077519379845e-05,
      "loss": 0.0001,
      "step": 7327
    },
    {
      "epoch": 28.4031007751938,
      "grad_norm": 0.00260656769387424,
      "learning_rate": 2.1596899224806204e-05,
      "loss": 0.0002,
      "step": 7328
    },
    {
      "epoch": 28.406976744186046,
      "grad_norm": 0.020665308460593224,
      "learning_rate": 2.1593023255813953e-05,
      "loss": 0.0011,
      "step": 7329
    },
    {
      "epoch": 28.410852713178294,
      "grad_norm": 0.0012365918373689055,
      "learning_rate": 2.1589147286821705e-05,
      "loss": 0.0001,
      "step": 7330
    },
    {
      "epoch": 28.414728682170544,
      "grad_norm": 0.0027806502766907215,
      "learning_rate": 2.1585271317829458e-05,
      "loss": 0.0002,
      "step": 7331
    },
    {
      "epoch": 28.41860465116279,
      "grad_norm": 0.0013189297169446945,
      "learning_rate": 2.158139534883721e-05,
      "loss": 0.0001,
      "step": 7332
    },
    {
      "epoch": 28.42248062015504,
      "grad_norm": 0.0011591926449909806,
      "learning_rate": 2.1577519379844963e-05,
      "loss": 0.0001,
      "step": 7333
    },
    {
      "epoch": 28.426356589147286,
      "grad_norm": 0.06735403090715408,
      "learning_rate": 2.1573643410852715e-05,
      "loss": 0.0015,
      "step": 7334
    },
    {
      "epoch": 28.430232558139537,
      "grad_norm": 0.0011975339148193598,
      "learning_rate": 2.1569767441860467e-05,
      "loss": 0.0001,
      "step": 7335
    },
    {
      "epoch": 28.434108527131784,
      "grad_norm": 45.03791046142578,
      "learning_rate": 2.156589147286822e-05,
      "loss": 0.5,
      "step": 7336
    },
    {
      "epoch": 28.43798449612403,
      "grad_norm": 0.0012814529472962022,
      "learning_rate": 2.1562015503875972e-05,
      "loss": 0.0001,
      "step": 7337
    },
    {
      "epoch": 28.441860465116278,
      "grad_norm": 0.0014858519425615668,
      "learning_rate": 2.155813953488372e-05,
      "loss": 0.0001,
      "step": 7338
    },
    {
      "epoch": 28.44573643410853,
      "grad_norm": 0.02181917242705822,
      "learning_rate": 2.1554263565891474e-05,
      "loss": 0.001,
      "step": 7339
    },
    {
      "epoch": 28.449612403100776,
      "grad_norm": 0.09184801578521729,
      "learning_rate": 2.1550387596899226e-05,
      "loss": 0.002,
      "step": 7340
    },
    {
      "epoch": 28.453488372093023,
      "grad_norm": 0.0011046454310417175,
      "learning_rate": 2.154651162790698e-05,
      "loss": 0.0001,
      "step": 7341
    },
    {
      "epoch": 28.45736434108527,
      "grad_norm": 0.0057723200879991055,
      "learning_rate": 2.154263565891473e-05,
      "loss": 0.0004,
      "step": 7342
    },
    {
      "epoch": 28.46124031007752,
      "grad_norm": 0.0014093394856899977,
      "learning_rate": 2.153875968992248e-05,
      "loss": 0.0001,
      "step": 7343
    },
    {
      "epoch": 28.46511627906977,
      "grad_norm": 0.001136107835918665,
      "learning_rate": 2.1534883720930232e-05,
      "loss": 0.0001,
      "step": 7344
    },
    {
      "epoch": 28.468992248062015,
      "grad_norm": 0.0015611577546223998,
      "learning_rate": 2.1531007751937985e-05,
      "loss": 0.0002,
      "step": 7345
    },
    {
      "epoch": 28.472868217054263,
      "grad_norm": 0.0013833502307534218,
      "learning_rate": 2.1527131782945737e-05,
      "loss": 0.0001,
      "step": 7346
    },
    {
      "epoch": 28.476744186046513,
      "grad_norm": 0.0016197131481021643,
      "learning_rate": 2.152325581395349e-05,
      "loss": 0.0001,
      "step": 7347
    },
    {
      "epoch": 28.48062015503876,
      "grad_norm": 0.0012734668562188745,
      "learning_rate": 2.1519379844961242e-05,
      "loss": 0.0001,
      "step": 7348
    },
    {
      "epoch": 28.484496124031008,
      "grad_norm": 0.01749536022543907,
      "learning_rate": 2.151550387596899e-05,
      "loss": 0.0004,
      "step": 7349
    },
    {
      "epoch": 28.488372093023255,
      "grad_norm": 0.0011108849430456758,
      "learning_rate": 2.1511627906976744e-05,
      "loss": 0.0001,
      "step": 7350
    },
    {
      "epoch": 28.492248062015506,
      "grad_norm": 0.0011391995940357447,
      "learning_rate": 2.1507751937984496e-05,
      "loss": 0.0001,
      "step": 7351
    },
    {
      "epoch": 28.496124031007753,
      "grad_norm": 0.001082956325262785,
      "learning_rate": 2.150387596899225e-05,
      "loss": 0.0001,
      "step": 7352
    },
    {
      "epoch": 28.5,
      "grad_norm": 0.011201907880604267,
      "learning_rate": 2.15e-05,
      "loss": 0.0006,
      "step": 7353
    },
    {
      "epoch": 28.503875968992247,
      "grad_norm": 0.0011647894280031323,
      "learning_rate": 2.1496124031007753e-05,
      "loss": 0.0001,
      "step": 7354
    },
    {
      "epoch": 28.507751937984494,
      "grad_norm": 0.0009606819949112833,
      "learning_rate": 2.1492248062015506e-05,
      "loss": 0.0001,
      "step": 7355
    },
    {
      "epoch": 28.511627906976745,
      "grad_norm": 0.0017318053869530559,
      "learning_rate": 2.1488372093023258e-05,
      "loss": 0.0001,
      "step": 7356
    },
    {
      "epoch": 28.515503875968992,
      "grad_norm": 1.844174861907959,
      "learning_rate": 2.148449612403101e-05,
      "loss": 0.0706,
      "step": 7357
    },
    {
      "epoch": 28.51937984496124,
      "grad_norm": 0.0053953249007463455,
      "learning_rate": 2.148062015503876e-05,
      "loss": 0.0004,
      "step": 7358
    },
    {
      "epoch": 28.52325581395349,
      "grad_norm": 0.01025149691849947,
      "learning_rate": 2.1476744186046512e-05,
      "loss": 0.0001,
      "step": 7359
    },
    {
      "epoch": 28.527131782945737,
      "grad_norm": 0.0034037556033581495,
      "learning_rate": 2.1472868217054264e-05,
      "loss": 0.0002,
      "step": 7360
    },
    {
      "epoch": 28.531007751937985,
      "grad_norm": 1.1904934644699097,
      "learning_rate": 2.1468992248062017e-05,
      "loss": 0.0503,
      "step": 7361
    },
    {
      "epoch": 28.53488372093023,
      "grad_norm": 0.0009585903026163578,
      "learning_rate": 2.146511627906977e-05,
      "loss": 0.0001,
      "step": 7362
    },
    {
      "epoch": 28.53875968992248,
      "grad_norm": 0.12275470048189163,
      "learning_rate": 2.146124031007752e-05,
      "loss": 0.0008,
      "step": 7363
    },
    {
      "epoch": 28.54263565891473,
      "grad_norm": 0.07562069594860077,
      "learning_rate": 2.1457364341085274e-05,
      "loss": 0.0033,
      "step": 7364
    },
    {
      "epoch": 28.546511627906977,
      "grad_norm": 0.0013255017111077905,
      "learning_rate": 2.1453488372093026e-05,
      "loss": 0.0001,
      "step": 7365
    },
    {
      "epoch": 28.550387596899224,
      "grad_norm": 0.0011587610933929682,
      "learning_rate": 2.144961240310078e-05,
      "loss": 0.0001,
      "step": 7366
    },
    {
      "epoch": 28.55426356589147,
      "grad_norm": 0.0014851127052679658,
      "learning_rate": 2.1445736434108528e-05,
      "loss": 0.0001,
      "step": 7367
    },
    {
      "epoch": 28.558139534883722,
      "grad_norm": 0.000938290380872786,
      "learning_rate": 2.144186046511628e-05,
      "loss": 0.0001,
      "step": 7368
    },
    {
      "epoch": 28.56201550387597,
      "grad_norm": 0.001265234430320561,
      "learning_rate": 2.1437984496124033e-05,
      "loss": 0.0001,
      "step": 7369
    },
    {
      "epoch": 28.565891472868216,
      "grad_norm": 0.0011761084897443652,
      "learning_rate": 2.1434108527131782e-05,
      "loss": 0.0001,
      "step": 7370
    },
    {
      "epoch": 28.569767441860463,
      "grad_norm": 0.0015037928242236376,
      "learning_rate": 2.1430232558139534e-05,
      "loss": 0.0001,
      "step": 7371
    },
    {
      "epoch": 28.573643410852714,
      "grad_norm": 58.128273010253906,
      "learning_rate": 2.1426356589147287e-05,
      "loss": 0.2398,
      "step": 7372
    },
    {
      "epoch": 28.57751937984496,
      "grad_norm": 0.0012994481949135661,
      "learning_rate": 2.142248062015504e-05,
      "loss": 0.0001,
      "step": 7373
    },
    {
      "epoch": 28.58139534883721,
      "grad_norm": 0.003819262608885765,
      "learning_rate": 2.141860465116279e-05,
      "loss": 0.0003,
      "step": 7374
    },
    {
      "epoch": 28.585271317829456,
      "grad_norm": 0.006755292881280184,
      "learning_rate": 2.1414728682170544e-05,
      "loss": 0.0004,
      "step": 7375
    },
    {
      "epoch": 28.589147286821706,
      "grad_norm": 0.004134617745876312,
      "learning_rate": 2.1410852713178296e-05,
      "loss": 0.0003,
      "step": 7376
    },
    {
      "epoch": 28.593023255813954,
      "grad_norm": 0.0011067193700000644,
      "learning_rate": 2.1406976744186045e-05,
      "loss": 0.0001,
      "step": 7377
    },
    {
      "epoch": 28.5968992248062,
      "grad_norm": 0.0009651242289692163,
      "learning_rate": 2.1403100775193798e-05,
      "loss": 0.0001,
      "step": 7378
    },
    {
      "epoch": 28.600775193798448,
      "grad_norm": 0.0010473309084773064,
      "learning_rate": 2.139922480620155e-05,
      "loss": 0.0001,
      "step": 7379
    },
    {
      "epoch": 28.6046511627907,
      "grad_norm": 0.0013641532277688384,
      "learning_rate": 2.1395348837209303e-05,
      "loss": 0.0001,
      "step": 7380
    },
    {
      "epoch": 28.608527131782946,
      "grad_norm": 0.36034828424453735,
      "learning_rate": 2.1391472868217055e-05,
      "loss": 0.0003,
      "step": 7381
    },
    {
      "epoch": 28.612403100775193,
      "grad_norm": 0.0010597680229693651,
      "learning_rate": 2.1387596899224808e-05,
      "loss": 0.0001,
      "step": 7382
    },
    {
      "epoch": 28.61627906976744,
      "grad_norm": 1.3428541421890259,
      "learning_rate": 2.138372093023256e-05,
      "loss": 0.1002,
      "step": 7383
    },
    {
      "epoch": 28.62015503875969,
      "grad_norm": 0.0010987779824063182,
      "learning_rate": 2.1379844961240312e-05,
      "loss": 0.0001,
      "step": 7384
    },
    {
      "epoch": 28.624031007751938,
      "grad_norm": 0.0016061996575444937,
      "learning_rate": 2.1375968992248065e-05,
      "loss": 0.0001,
      "step": 7385
    },
    {
      "epoch": 28.627906976744185,
      "grad_norm": 0.001151959877461195,
      "learning_rate": 2.1372093023255814e-05,
      "loss": 0.0001,
      "step": 7386
    },
    {
      "epoch": 28.631782945736433,
      "grad_norm": 2.9857981204986572,
      "learning_rate": 2.1368217054263566e-05,
      "loss": 0.1896,
      "step": 7387
    },
    {
      "epoch": 28.635658914728683,
      "grad_norm": 0.0011700954055413604,
      "learning_rate": 2.136434108527132e-05,
      "loss": 0.0001,
      "step": 7388
    },
    {
      "epoch": 28.63953488372093,
      "grad_norm": 0.005911860149353743,
      "learning_rate": 2.136046511627907e-05,
      "loss": 0.0004,
      "step": 7389
    },
    {
      "epoch": 28.643410852713178,
      "grad_norm": 0.001695549115538597,
      "learning_rate": 2.1356589147286823e-05,
      "loss": 0.0002,
      "step": 7390
    },
    {
      "epoch": 28.647286821705425,
      "grad_norm": 1.9306851625442505,
      "learning_rate": 2.1352713178294576e-05,
      "loss": 0.16,
      "step": 7391
    },
    {
      "epoch": 28.651162790697676,
      "grad_norm": 0.00580824026837945,
      "learning_rate": 2.134883720930233e-05,
      "loss": 0.0002,
      "step": 7392
    },
    {
      "epoch": 28.655038759689923,
      "grad_norm": 0.006365490611642599,
      "learning_rate": 2.134496124031008e-05,
      "loss": 0.0004,
      "step": 7393
    },
    {
      "epoch": 28.65891472868217,
      "grad_norm": 0.006943110376596451,
      "learning_rate": 2.1341085271317833e-05,
      "loss": 0.0004,
      "step": 7394
    },
    {
      "epoch": 28.662790697674417,
      "grad_norm": 0.0023401116486638784,
      "learning_rate": 2.1337209302325582e-05,
      "loss": 0.0002,
      "step": 7395
    },
    {
      "epoch": 28.666666666666668,
      "grad_norm": 0.005069793667644262,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.0002,
      "step": 7396
    },
    {
      "epoch": 28.670542635658915,
      "grad_norm": 0.017088688910007477,
      "learning_rate": 2.1329457364341084e-05,
      "loss": 0.0009,
      "step": 7397
    },
    {
      "epoch": 28.674418604651162,
      "grad_norm": 0.002128247171640396,
      "learning_rate": 2.1325581395348836e-05,
      "loss": 0.0001,
      "step": 7398
    },
    {
      "epoch": 28.67829457364341,
      "grad_norm": 1.393052101135254,
      "learning_rate": 2.132170542635659e-05,
      "loss": 0.0018,
      "step": 7399
    },
    {
      "epoch": 28.68217054263566,
      "grad_norm": 0.001531516551040113,
      "learning_rate": 2.131782945736434e-05,
      "loss": 0.0001,
      "step": 7400
    },
    {
      "epoch": 28.686046511627907,
      "grad_norm": 0.0013374077389016747,
      "learning_rate": 2.1313953488372093e-05,
      "loss": 0.0001,
      "step": 7401
    },
    {
      "epoch": 28.689922480620154,
      "grad_norm": 0.0014444721164181828,
      "learning_rate": 2.1310077519379846e-05,
      "loss": 0.0001,
      "step": 7402
    },
    {
      "epoch": 28.6937984496124,
      "grad_norm": 0.0021183534990996122,
      "learning_rate": 2.1306201550387598e-05,
      "loss": 0.0002,
      "step": 7403
    },
    {
      "epoch": 28.697674418604652,
      "grad_norm": 3.3714895248413086,
      "learning_rate": 2.130232558139535e-05,
      "loss": 0.3532,
      "step": 7404
    },
    {
      "epoch": 28.7015503875969,
      "grad_norm": 0.003308420768007636,
      "learning_rate": 2.12984496124031e-05,
      "loss": 0.0002,
      "step": 7405
    },
    {
      "epoch": 28.705426356589147,
      "grad_norm": 0.00134695740416646,
      "learning_rate": 2.1294573643410852e-05,
      "loss": 0.0001,
      "step": 7406
    },
    {
      "epoch": 28.709302325581394,
      "grad_norm": 0.00842203851789236,
      "learning_rate": 2.1290697674418604e-05,
      "loss": 0.0005,
      "step": 7407
    },
    {
      "epoch": 28.713178294573645,
      "grad_norm": 21.343490600585938,
      "learning_rate": 2.1286821705426357e-05,
      "loss": 0.0828,
      "step": 7408
    },
    {
      "epoch": 28.717054263565892,
      "grad_norm": 0.2390817105770111,
      "learning_rate": 2.128294573643411e-05,
      "loss": 0.0014,
      "step": 7409
    },
    {
      "epoch": 28.72093023255814,
      "grad_norm": 0.006085890810936689,
      "learning_rate": 2.1279069767441862e-05,
      "loss": 0.0004,
      "step": 7410
    },
    {
      "epoch": 28.724806201550386,
      "grad_norm": 0.002478712471202016,
      "learning_rate": 2.1275193798449614e-05,
      "loss": 0.0002,
      "step": 7411
    },
    {
      "epoch": 28.728682170542637,
      "grad_norm": 0.0055922516621649265,
      "learning_rate": 2.1271317829457367e-05,
      "loss": 0.0002,
      "step": 7412
    },
    {
      "epoch": 28.732558139534884,
      "grad_norm": 0.003183741122484207,
      "learning_rate": 2.126744186046512e-05,
      "loss": 0.0002,
      "step": 7413
    },
    {
      "epoch": 28.73643410852713,
      "grad_norm": 0.010500201024115086,
      "learning_rate": 2.1263565891472868e-05,
      "loss": 0.0006,
      "step": 7414
    },
    {
      "epoch": 28.74031007751938,
      "grad_norm": 0.0018937446875497699,
      "learning_rate": 2.125968992248062e-05,
      "loss": 0.0002,
      "step": 7415
    },
    {
      "epoch": 28.74418604651163,
      "grad_norm": 0.002117651514708996,
      "learning_rate": 2.1255813953488373e-05,
      "loss": 0.0002,
      "step": 7416
    },
    {
      "epoch": 28.748062015503876,
      "grad_norm": 0.003069851314648986,
      "learning_rate": 2.1251937984496125e-05,
      "loss": 0.0002,
      "step": 7417
    },
    {
      "epoch": 28.751937984496124,
      "grad_norm": 0.0015668910928070545,
      "learning_rate": 2.1248062015503878e-05,
      "loss": 0.0002,
      "step": 7418
    },
    {
      "epoch": 28.75581395348837,
      "grad_norm": 0.17267051339149475,
      "learning_rate": 2.124418604651163e-05,
      "loss": 0.0018,
      "step": 7419
    },
    {
      "epoch": 28.75968992248062,
      "grad_norm": 0.0015878297854214907,
      "learning_rate": 2.1240310077519383e-05,
      "loss": 0.0001,
      "step": 7420
    },
    {
      "epoch": 28.76356589147287,
      "grad_norm": 0.04799167811870575,
      "learning_rate": 2.1236434108527135e-05,
      "loss": 0.0007,
      "step": 7421
    },
    {
      "epoch": 28.767441860465116,
      "grad_norm": 0.006671268958598375,
      "learning_rate": 2.1232558139534887e-05,
      "loss": 0.0004,
      "step": 7422
    },
    {
      "epoch": 28.771317829457363,
      "grad_norm": 1.627893090248108,
      "learning_rate": 2.1228682170542636e-05,
      "loss": 0.1086,
      "step": 7423
    },
    {
      "epoch": 28.775193798449614,
      "grad_norm": 0.01427024882286787,
      "learning_rate": 2.122480620155039e-05,
      "loss": 0.0002,
      "step": 7424
    },
    {
      "epoch": 28.77906976744186,
      "grad_norm": 0.0029747693333774805,
      "learning_rate": 2.1220930232558138e-05,
      "loss": 0.0002,
      "step": 7425
    },
    {
      "epoch": 28.782945736434108,
      "grad_norm": 0.0019915217999368906,
      "learning_rate": 2.121705426356589e-05,
      "loss": 0.0002,
      "step": 7426
    },
    {
      "epoch": 28.786821705426355,
      "grad_norm": 0.01154941413551569,
      "learning_rate": 2.1213178294573643e-05,
      "loss": 0.0006,
      "step": 7427
    },
    {
      "epoch": 28.790697674418606,
      "grad_norm": 0.003326117992401123,
      "learning_rate": 2.1209302325581395e-05,
      "loss": 0.0002,
      "step": 7428
    },
    {
      "epoch": 28.794573643410853,
      "grad_norm": 0.0019965250976383686,
      "learning_rate": 2.1205426356589148e-05,
      "loss": 0.0001,
      "step": 7429
    },
    {
      "epoch": 28.7984496124031,
      "grad_norm": 0.0036113064270466566,
      "learning_rate": 2.12015503875969e-05,
      "loss": 0.0002,
      "step": 7430
    },
    {
      "epoch": 28.802325581395348,
      "grad_norm": 0.19744479656219482,
      "learning_rate": 2.1197674418604652e-05,
      "loss": 0.0005,
      "step": 7431
    },
    {
      "epoch": 28.8062015503876,
      "grad_norm": 0.006049653049558401,
      "learning_rate": 2.1193798449612405e-05,
      "loss": 0.0003,
      "step": 7432
    },
    {
      "epoch": 28.810077519379846,
      "grad_norm": 4.8979716300964355,
      "learning_rate": 2.1189922480620157e-05,
      "loss": 0.244,
      "step": 7433
    },
    {
      "epoch": 28.813953488372093,
      "grad_norm": 0.030157333239912987,
      "learning_rate": 2.1186046511627906e-05,
      "loss": 0.0003,
      "step": 7434
    },
    {
      "epoch": 28.81782945736434,
      "grad_norm": 42.92253875732422,
      "learning_rate": 2.118217054263566e-05,
      "loss": 0.0222,
      "step": 7435
    },
    {
      "epoch": 28.82170542635659,
      "grad_norm": 0.0018661335343495011,
      "learning_rate": 2.117829457364341e-05,
      "loss": 0.0001,
      "step": 7436
    },
    {
      "epoch": 28.825581395348838,
      "grad_norm": 0.002796689048409462,
      "learning_rate": 2.1174418604651164e-05,
      "loss": 0.0002,
      "step": 7437
    },
    {
      "epoch": 28.829457364341085,
      "grad_norm": 0.0016247984021902084,
      "learning_rate": 2.1170542635658916e-05,
      "loss": 0.0001,
      "step": 7438
    },
    {
      "epoch": 28.833333333333332,
      "grad_norm": 0.002211310202255845,
      "learning_rate": 2.116666666666667e-05,
      "loss": 0.0002,
      "step": 7439
    },
    {
      "epoch": 28.837209302325583,
      "grad_norm": 0.005230278242379427,
      "learning_rate": 2.116279069767442e-05,
      "loss": 0.0004,
      "step": 7440
    },
    {
      "epoch": 28.84108527131783,
      "grad_norm": 0.001997410086914897,
      "learning_rate": 2.1158914728682173e-05,
      "loss": 0.0001,
      "step": 7441
    },
    {
      "epoch": 28.844961240310077,
      "grad_norm": 0.0019211568869650364,
      "learning_rate": 2.1155038759689926e-05,
      "loss": 0.0001,
      "step": 7442
    },
    {
      "epoch": 28.848837209302324,
      "grad_norm": 0.6916883587837219,
      "learning_rate": 2.1151162790697675e-05,
      "loss": 0.0163,
      "step": 7443
    },
    {
      "epoch": 28.852713178294575,
      "grad_norm": 0.01431562565267086,
      "learning_rate": 2.1147286821705427e-05,
      "loss": 0.0004,
      "step": 7444
    },
    {
      "epoch": 28.856589147286822,
      "grad_norm": 0.011894701048731804,
      "learning_rate": 2.114341085271318e-05,
      "loss": 0.0005,
      "step": 7445
    },
    {
      "epoch": 28.86046511627907,
      "grad_norm": 0.002503171795979142,
      "learning_rate": 2.1139534883720932e-05,
      "loss": 0.0002,
      "step": 7446
    },
    {
      "epoch": 28.864341085271317,
      "grad_norm": 0.0025297794491052628,
      "learning_rate": 2.1135658914728684e-05,
      "loss": 0.0002,
      "step": 7447
    },
    {
      "epoch": 28.868217054263567,
      "grad_norm": 0.003471552161499858,
      "learning_rate": 2.1131782945736437e-05,
      "loss": 0.0002,
      "step": 7448
    },
    {
      "epoch": 28.872093023255815,
      "grad_norm": 0.20118534564971924,
      "learning_rate": 2.112790697674419e-05,
      "loss": 0.0097,
      "step": 7449
    },
    {
      "epoch": 28.875968992248062,
      "grad_norm": 0.001878088223747909,
      "learning_rate": 2.1124031007751938e-05,
      "loss": 0.0002,
      "step": 7450
    },
    {
      "epoch": 28.87984496124031,
      "grad_norm": 0.001707828021608293,
      "learning_rate": 2.112015503875969e-05,
      "loss": 0.0002,
      "step": 7451
    },
    {
      "epoch": 28.88372093023256,
      "grad_norm": 0.29206088185310364,
      "learning_rate": 2.1116279069767443e-05,
      "loss": 0.0111,
      "step": 7452
    },
    {
      "epoch": 28.887596899224807,
      "grad_norm": 0.0013214417267590761,
      "learning_rate": 2.1112403100775192e-05,
      "loss": 0.0001,
      "step": 7453
    },
    {
      "epoch": 28.891472868217054,
      "grad_norm": 0.006092553026974201,
      "learning_rate": 2.1108527131782945e-05,
      "loss": 0.0002,
      "step": 7454
    },
    {
      "epoch": 28.8953488372093,
      "grad_norm": 3.4946084022521973,
      "learning_rate": 2.1104651162790697e-05,
      "loss": 0.1892,
      "step": 7455
    },
    {
      "epoch": 28.899224806201552,
      "grad_norm": 0.0015701219672337174,
      "learning_rate": 2.110077519379845e-05,
      "loss": 0.0001,
      "step": 7456
    },
    {
      "epoch": 28.9031007751938,
      "grad_norm": 0.0023325502406805754,
      "learning_rate": 2.1096899224806202e-05,
      "loss": 0.0002,
      "step": 7457
    },
    {
      "epoch": 28.906976744186046,
      "grad_norm": 0.0027821892872452736,
      "learning_rate": 2.1093023255813954e-05,
      "loss": 0.0002,
      "step": 7458
    },
    {
      "epoch": 28.910852713178294,
      "grad_norm": 0.0026020260993391275,
      "learning_rate": 2.1089147286821707e-05,
      "loss": 0.0002,
      "step": 7459
    },
    {
      "epoch": 28.914728682170544,
      "grad_norm": 0.0017831205623224378,
      "learning_rate": 2.108527131782946e-05,
      "loss": 0.0002,
      "step": 7460
    },
    {
      "epoch": 28.91860465116279,
      "grad_norm": 0.002753653796389699,
      "learning_rate": 2.108139534883721e-05,
      "loss": 0.0002,
      "step": 7461
    },
    {
      "epoch": 28.92248062015504,
      "grad_norm": 0.0016092201694846153,
      "learning_rate": 2.107751937984496e-05,
      "loss": 0.0001,
      "step": 7462
    },
    {
      "epoch": 28.926356589147286,
      "grad_norm": 0.01963198371231556,
      "learning_rate": 2.1073643410852713e-05,
      "loss": 0.0007,
      "step": 7463
    },
    {
      "epoch": 28.930232558139537,
      "grad_norm": 0.0025088568218052387,
      "learning_rate": 2.1069767441860465e-05,
      "loss": 0.0002,
      "step": 7464
    },
    {
      "epoch": 28.934108527131784,
      "grad_norm": 0.0018253683811053634,
      "learning_rate": 2.1065891472868218e-05,
      "loss": 0.0002,
      "step": 7465
    },
    {
      "epoch": 28.93798449612403,
      "grad_norm": 0.0015157022280618548,
      "learning_rate": 2.106201550387597e-05,
      "loss": 0.0001,
      "step": 7466
    },
    {
      "epoch": 28.941860465116278,
      "grad_norm": 0.0015045421896502376,
      "learning_rate": 2.1058139534883723e-05,
      "loss": 0.0001,
      "step": 7467
    },
    {
      "epoch": 28.94573643410853,
      "grad_norm": 0.005467581562697887,
      "learning_rate": 2.1054263565891475e-05,
      "loss": 0.0004,
      "step": 7468
    },
    {
      "epoch": 28.949612403100776,
      "grad_norm": 0.001658321125432849,
      "learning_rate": 2.1050387596899228e-05,
      "loss": 0.0001,
      "step": 7469
    },
    {
      "epoch": 28.953488372093023,
      "grad_norm": 0.0018541135359555483,
      "learning_rate": 2.104651162790698e-05,
      "loss": 0.0002,
      "step": 7470
    },
    {
      "epoch": 28.95736434108527,
      "grad_norm": 1.2709934711456299,
      "learning_rate": 2.104263565891473e-05,
      "loss": 0.0694,
      "step": 7471
    },
    {
      "epoch": 28.96124031007752,
      "grad_norm": 0.005779307335615158,
      "learning_rate": 2.103875968992248e-05,
      "loss": 0.0004,
      "step": 7472
    },
    {
      "epoch": 28.96511627906977,
      "grad_norm": 0.0017533968202769756,
      "learning_rate": 2.1034883720930234e-05,
      "loss": 0.0002,
      "step": 7473
    },
    {
      "epoch": 28.968992248062015,
      "grad_norm": 0.0018260101787745953,
      "learning_rate": 2.1031007751937986e-05,
      "loss": 0.0001,
      "step": 7474
    },
    {
      "epoch": 28.972868217054263,
      "grad_norm": 0.0023354722652584314,
      "learning_rate": 2.102713178294574e-05,
      "loss": 0.0002,
      "step": 7475
    },
    {
      "epoch": 28.97674418604651,
      "grad_norm": 0.08663486689329147,
      "learning_rate": 2.102325581395349e-05,
      "loss": 0.0014,
      "step": 7476
    },
    {
      "epoch": 28.98062015503876,
      "grad_norm": 0.0017012276221066713,
      "learning_rate": 2.101937984496124e-05,
      "loss": 0.0001,
      "step": 7477
    },
    {
      "epoch": 28.984496124031008,
      "grad_norm": 0.002875130157917738,
      "learning_rate": 2.1015503875968993e-05,
      "loss": 0.0002,
      "step": 7478
    },
    {
      "epoch": 28.988372093023255,
      "grad_norm": 6.600929260253906,
      "learning_rate": 2.1011627906976745e-05,
      "loss": 0.2324,
      "step": 7479
    },
    {
      "epoch": 28.992248062015506,
      "grad_norm": 0.0020980839617550373,
      "learning_rate": 2.1007751937984497e-05,
      "loss": 0.0002,
      "step": 7480
    },
    {
      "epoch": 28.996124031007753,
      "grad_norm": 0.0027036836836487055,
      "learning_rate": 2.100387596899225e-05,
      "loss": 0.0002,
      "step": 7481
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.001685862778685987,
      "learning_rate": 2.1e-05,
      "loss": 0.0001,
      "step": 7482
    },
    {
      "epoch": 29.003875968992247,
      "grad_norm": 0.0052610840648412704,
      "learning_rate": 2.099612403100775e-05,
      "loss": 0.0004,
      "step": 7483
    },
    {
      "epoch": 29.007751937984494,
      "grad_norm": 0.0022697781678289175,
      "learning_rate": 2.0992248062015504e-05,
      "loss": 0.0001,
      "step": 7484
    },
    {
      "epoch": 29.011627906976745,
      "grad_norm": 0.0018181484192609787,
      "learning_rate": 2.0988372093023256e-05,
      "loss": 0.0001,
      "step": 7485
    },
    {
      "epoch": 29.015503875968992,
      "grad_norm": 0.0056182811968028545,
      "learning_rate": 2.098449612403101e-05,
      "loss": 0.0004,
      "step": 7486
    },
    {
      "epoch": 29.01937984496124,
      "grad_norm": 69.81707000732422,
      "learning_rate": 2.098062015503876e-05,
      "loss": 0.1473,
      "step": 7487
    },
    {
      "epoch": 29.023255813953487,
      "grad_norm": 0.004973265342414379,
      "learning_rate": 2.0976744186046513e-05,
      "loss": 0.0004,
      "step": 7488
    },
    {
      "epoch": 29.027131782945737,
      "grad_norm": 4.88516092300415,
      "learning_rate": 2.0972868217054266e-05,
      "loss": 0.6053,
      "step": 7489
    },
    {
      "epoch": 29.031007751937985,
      "grad_norm": 0.0027612873818725348,
      "learning_rate": 2.0968992248062018e-05,
      "loss": 0.0002,
      "step": 7490
    },
    {
      "epoch": 29.03488372093023,
      "grad_norm": 0.535926342010498,
      "learning_rate": 2.0965116279069767e-05,
      "loss": 0.0471,
      "step": 7491
    },
    {
      "epoch": 29.03875968992248,
      "grad_norm": 0.33791354298591614,
      "learning_rate": 2.096124031007752e-05,
      "loss": 0.0144,
      "step": 7492
    },
    {
      "epoch": 29.04263565891473,
      "grad_norm": 0.0018620988121256232,
      "learning_rate": 2.0957364341085272e-05,
      "loss": 0.0002,
      "step": 7493
    },
    {
      "epoch": 29.046511627906977,
      "grad_norm": 0.0015033690724521875,
      "learning_rate": 2.0953488372093025e-05,
      "loss": 0.0001,
      "step": 7494
    },
    {
      "epoch": 29.050387596899224,
      "grad_norm": 0.019361548125743866,
      "learning_rate": 2.0949612403100777e-05,
      "loss": 0.0006,
      "step": 7495
    },
    {
      "epoch": 29.05426356589147,
      "grad_norm": 0.0010625525610521436,
      "learning_rate": 2.094573643410853e-05,
      "loss": 0.0001,
      "step": 7496
    },
    {
      "epoch": 29.058139534883722,
      "grad_norm": 1.4088739156723022,
      "learning_rate": 2.0941860465116282e-05,
      "loss": 0.0758,
      "step": 7497
    },
    {
      "epoch": 29.06201550387597,
      "grad_norm": 0.003346144687384367,
      "learning_rate": 2.0937984496124034e-05,
      "loss": 0.0002,
      "step": 7498
    },
    {
      "epoch": 29.065891472868216,
      "grad_norm": 0.0011454075574874878,
      "learning_rate": 2.0934108527131787e-05,
      "loss": 0.0001,
      "step": 7499
    },
    {
      "epoch": 29.069767441860463,
      "grad_norm": 0.0031325840391218662,
      "learning_rate": 2.0930232558139536e-05,
      "loss": 0.0003,
      "step": 7500
    },
    {
      "epoch": 29.073643410852714,
      "grad_norm": 0.0014943090500310063,
      "learning_rate": 2.0926356589147288e-05,
      "loss": 0.0001,
      "step": 7501
    },
    {
      "epoch": 29.07751937984496,
      "grad_norm": 0.0013999767834320664,
      "learning_rate": 2.092248062015504e-05,
      "loss": 0.0001,
      "step": 7502
    },
    {
      "epoch": 29.08139534883721,
      "grad_norm": 0.0016405453206971288,
      "learning_rate": 2.091860465116279e-05,
      "loss": 0.0001,
      "step": 7503
    },
    {
      "epoch": 29.085271317829456,
      "grad_norm": 0.0013382199686020613,
      "learning_rate": 2.0914728682170542e-05,
      "loss": 0.0001,
      "step": 7504
    },
    {
      "epoch": 29.089147286821706,
      "grad_norm": 5.54365348815918,
      "learning_rate": 2.0910852713178294e-05,
      "loss": 0.0562,
      "step": 7505
    },
    {
      "epoch": 29.093023255813954,
      "grad_norm": 0.313269704580307,
      "learning_rate": 2.0906976744186047e-05,
      "loss": 0.0043,
      "step": 7506
    },
    {
      "epoch": 29.0968992248062,
      "grad_norm": 0.0016170033486559987,
      "learning_rate": 2.09031007751938e-05,
      "loss": 0.0001,
      "step": 7507
    },
    {
      "epoch": 29.100775193798448,
      "grad_norm": 0.0033294372260570526,
      "learning_rate": 2.089922480620155e-05,
      "loss": 0.0003,
      "step": 7508
    },
    {
      "epoch": 29.1046511627907,
      "grad_norm": 0.008268515579402447,
      "learning_rate": 2.0895348837209304e-05,
      "loss": 0.0002,
      "step": 7509
    },
    {
      "epoch": 29.108527131782946,
      "grad_norm": 0.005429273471236229,
      "learning_rate": 2.0891472868217053e-05,
      "loss": 0.0003,
      "step": 7510
    },
    {
      "epoch": 29.112403100775193,
      "grad_norm": 0.025234419852495193,
      "learning_rate": 2.0887596899224806e-05,
      "loss": 0.0007,
      "step": 7511
    },
    {
      "epoch": 29.11627906976744,
      "grad_norm": 0.010029799304902554,
      "learning_rate": 2.0883720930232558e-05,
      "loss": 0.0005,
      "step": 7512
    },
    {
      "epoch": 29.12015503875969,
      "grad_norm": 0.0014458228833973408,
      "learning_rate": 2.087984496124031e-05,
      "loss": 0.0001,
      "step": 7513
    },
    {
      "epoch": 29.124031007751938,
      "grad_norm": 0.0014215705450624228,
      "learning_rate": 2.0875968992248063e-05,
      "loss": 0.0001,
      "step": 7514
    },
    {
      "epoch": 29.127906976744185,
      "grad_norm": 69.44599914550781,
      "learning_rate": 2.0872093023255815e-05,
      "loss": 0.2432,
      "step": 7515
    },
    {
      "epoch": 29.131782945736433,
      "grad_norm": 0.0018882565200328827,
      "learning_rate": 2.0868217054263568e-05,
      "loss": 0.0002,
      "step": 7516
    },
    {
      "epoch": 29.135658914728683,
      "grad_norm": 0.0018206383101642132,
      "learning_rate": 2.086434108527132e-05,
      "loss": 0.0001,
      "step": 7517
    },
    {
      "epoch": 29.13953488372093,
      "grad_norm": 0.0013857233570888638,
      "learning_rate": 2.0860465116279072e-05,
      "loss": 0.0001,
      "step": 7518
    },
    {
      "epoch": 29.143410852713178,
      "grad_norm": 0.0019050055416300893,
      "learning_rate": 2.085658914728682e-05,
      "loss": 0.0002,
      "step": 7519
    },
    {
      "epoch": 29.147286821705425,
      "grad_norm": 0.0014637019485235214,
      "learning_rate": 2.0852713178294574e-05,
      "loss": 0.0001,
      "step": 7520
    },
    {
      "epoch": 29.151162790697676,
      "grad_norm": 0.0021459688432514668,
      "learning_rate": 2.0848837209302326e-05,
      "loss": 0.0001,
      "step": 7521
    },
    {
      "epoch": 29.155038759689923,
      "grad_norm": 0.005240615922957659,
      "learning_rate": 2.084496124031008e-05,
      "loss": 0.0003,
      "step": 7522
    },
    {
      "epoch": 29.15891472868217,
      "grad_norm": 0.0065524997189641,
      "learning_rate": 2.084108527131783e-05,
      "loss": 0.0003,
      "step": 7523
    },
    {
      "epoch": 29.162790697674417,
      "grad_norm": 3.2977874279022217,
      "learning_rate": 2.0837209302325584e-05,
      "loss": 0.0151,
      "step": 7524
    },
    {
      "epoch": 29.166666666666668,
      "grad_norm": 16.69918441772461,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 0.07,
      "step": 7525
    },
    {
      "epoch": 29.170542635658915,
      "grad_norm": 0.0013504148228093982,
      "learning_rate": 2.082945736434109e-05,
      "loss": 0.0001,
      "step": 7526
    },
    {
      "epoch": 29.174418604651162,
      "grad_norm": 0.006861808709800243,
      "learning_rate": 2.082558139534884e-05,
      "loss": 0.0004,
      "step": 7527
    },
    {
      "epoch": 29.17829457364341,
      "grad_norm": 0.0012518538860604167,
      "learning_rate": 2.082170542635659e-05,
      "loss": 0.0001,
      "step": 7528
    },
    {
      "epoch": 29.18217054263566,
      "grad_norm": 0.0012927805073559284,
      "learning_rate": 2.0817829457364342e-05,
      "loss": 0.0001,
      "step": 7529
    },
    {
      "epoch": 29.186046511627907,
      "grad_norm": 0.0014232223620638251,
      "learning_rate": 2.081395348837209e-05,
      "loss": 0.0001,
      "step": 7530
    },
    {
      "epoch": 29.189922480620154,
      "grad_norm": 0.007388523314148188,
      "learning_rate": 2.0810077519379844e-05,
      "loss": 0.0001,
      "step": 7531
    },
    {
      "epoch": 29.1937984496124,
      "grad_norm": 0.0033881866838783026,
      "learning_rate": 2.0806201550387596e-05,
      "loss": 0.0003,
      "step": 7532
    },
    {
      "epoch": 29.197674418604652,
      "grad_norm": 3.1352334022521973,
      "learning_rate": 2.080232558139535e-05,
      "loss": 0.1854,
      "step": 7533
    },
    {
      "epoch": 29.2015503875969,
      "grad_norm": 0.0014245513593778014,
      "learning_rate": 2.07984496124031e-05,
      "loss": 0.0001,
      "step": 7534
    },
    {
      "epoch": 29.205426356589147,
      "grad_norm": 0.0016903176438063383,
      "learning_rate": 2.0794573643410853e-05,
      "loss": 0.0001,
      "step": 7535
    },
    {
      "epoch": 29.209302325581394,
      "grad_norm": 0.002202065195888281,
      "learning_rate": 2.0790697674418606e-05,
      "loss": 0.0002,
      "step": 7536
    },
    {
      "epoch": 29.213178294573645,
      "grad_norm": 0.0019509331323206425,
      "learning_rate": 2.078682170542636e-05,
      "loss": 0.0001,
      "step": 7537
    },
    {
      "epoch": 29.217054263565892,
      "grad_norm": 0.0017968170577660203,
      "learning_rate": 2.0782945736434107e-05,
      "loss": 0.0002,
      "step": 7538
    },
    {
      "epoch": 29.22093023255814,
      "grad_norm": 0.013938438147306442,
      "learning_rate": 2.077906976744186e-05,
      "loss": 0.0007,
      "step": 7539
    },
    {
      "epoch": 29.224806201550386,
      "grad_norm": 0.0072507974691689014,
      "learning_rate": 2.0775193798449612e-05,
      "loss": 0.0004,
      "step": 7540
    },
    {
      "epoch": 29.228682170542637,
      "grad_norm": 0.0013917797477915883,
      "learning_rate": 2.0771317829457365e-05,
      "loss": 0.0001,
      "step": 7541
    },
    {
      "epoch": 29.232558139534884,
      "grad_norm": 0.0017686000792309642,
      "learning_rate": 2.0767441860465117e-05,
      "loss": 0.0001,
      "step": 7542
    },
    {
      "epoch": 29.23643410852713,
      "grad_norm": 0.001341066905297339,
      "learning_rate": 2.076356589147287e-05,
      "loss": 0.0001,
      "step": 7543
    },
    {
      "epoch": 29.24031007751938,
      "grad_norm": 0.0017593661323189735,
      "learning_rate": 2.0759689922480622e-05,
      "loss": 0.0001,
      "step": 7544
    },
    {
      "epoch": 29.24418604651163,
      "grad_norm": 0.04404508322477341,
      "learning_rate": 2.0755813953488374e-05,
      "loss": 0.0008,
      "step": 7545
    },
    {
      "epoch": 29.248062015503876,
      "grad_norm": 0.001498703844845295,
      "learning_rate": 2.0751937984496127e-05,
      "loss": 0.0001,
      "step": 7546
    },
    {
      "epoch": 29.251937984496124,
      "grad_norm": 0.0018477332778275013,
      "learning_rate": 2.0748062015503876e-05,
      "loss": 0.0002,
      "step": 7547
    },
    {
      "epoch": 29.25581395348837,
      "grad_norm": 2.343567371368408,
      "learning_rate": 2.0744186046511628e-05,
      "loss": 0.1804,
      "step": 7548
    },
    {
      "epoch": 29.25968992248062,
      "grad_norm": 0.0014699568273499608,
      "learning_rate": 2.074031007751938e-05,
      "loss": 0.0001,
      "step": 7549
    },
    {
      "epoch": 29.26356589147287,
      "grad_norm": 0.0017455160850659013,
      "learning_rate": 2.0736434108527133e-05,
      "loss": 0.0002,
      "step": 7550
    },
    {
      "epoch": 29.267441860465116,
      "grad_norm": 1.822481632232666,
      "learning_rate": 2.0732558139534885e-05,
      "loss": 0.1561,
      "step": 7551
    },
    {
      "epoch": 29.271317829457363,
      "grad_norm": 0.0017987368628382683,
      "learning_rate": 2.0728682170542638e-05,
      "loss": 0.0001,
      "step": 7552
    },
    {
      "epoch": 29.275193798449614,
      "grad_norm": 0.0037906146608293056,
      "learning_rate": 2.072480620155039e-05,
      "loss": 0.0003,
      "step": 7553
    },
    {
      "epoch": 29.27906976744186,
      "grad_norm": 0.005089249927550554,
      "learning_rate": 2.0720930232558143e-05,
      "loss": 0.0003,
      "step": 7554
    },
    {
      "epoch": 29.282945736434108,
      "grad_norm": 0.0016646498115733266,
      "learning_rate": 2.0717054263565895e-05,
      "loss": 0.0001,
      "step": 7555
    },
    {
      "epoch": 29.286821705426355,
      "grad_norm": 0.2934008240699768,
      "learning_rate": 2.0713178294573644e-05,
      "loss": 0.001,
      "step": 7556
    },
    {
      "epoch": 29.290697674418606,
      "grad_norm": 0.0017144879093393683,
      "learning_rate": 2.0709302325581397e-05,
      "loss": 0.0001,
      "step": 7557
    },
    {
      "epoch": 29.294573643410853,
      "grad_norm": 0.4994131326675415,
      "learning_rate": 2.0705426356589146e-05,
      "loss": 0.021,
      "step": 7558
    },
    {
      "epoch": 29.2984496124031,
      "grad_norm": 0.001383650116622448,
      "learning_rate": 2.0701550387596898e-05,
      "loss": 0.0001,
      "step": 7559
    },
    {
      "epoch": 29.302325581395348,
      "grad_norm": 0.0012403407599776983,
      "learning_rate": 2.069767441860465e-05,
      "loss": 0.0001,
      "step": 7560
    },
    {
      "epoch": 29.3062015503876,
      "grad_norm": 0.002162868157029152,
      "learning_rate": 2.0693798449612403e-05,
      "loss": 0.0002,
      "step": 7561
    },
    {
      "epoch": 29.310077519379846,
      "grad_norm": 0.00198210496455431,
      "learning_rate": 2.0689922480620155e-05,
      "loss": 0.0002,
      "step": 7562
    },
    {
      "epoch": 29.313953488372093,
      "grad_norm": 0.06471824645996094,
      "learning_rate": 2.0686046511627908e-05,
      "loss": 0.0013,
      "step": 7563
    },
    {
      "epoch": 29.31782945736434,
      "grad_norm": 0.001191526185721159,
      "learning_rate": 2.068217054263566e-05,
      "loss": 0.0001,
      "step": 7564
    },
    {
      "epoch": 29.32170542635659,
      "grad_norm": 0.987068235874176,
      "learning_rate": 2.0678294573643413e-05,
      "loss": 0.0041,
      "step": 7565
    },
    {
      "epoch": 29.325581395348838,
      "grad_norm": 13.068801879882812,
      "learning_rate": 2.0674418604651165e-05,
      "loss": 0.3022,
      "step": 7566
    },
    {
      "epoch": 29.329457364341085,
      "grad_norm": 0.00723079452291131,
      "learning_rate": 2.0670542635658914e-05,
      "loss": 0.0004,
      "step": 7567
    },
    {
      "epoch": 29.333333333333332,
      "grad_norm": 0.003868405008688569,
      "learning_rate": 2.0666666666666666e-05,
      "loss": 0.0003,
      "step": 7568
    },
    {
      "epoch": 29.337209302325583,
      "grad_norm": 0.0033081346191465855,
      "learning_rate": 2.066279069767442e-05,
      "loss": 0.0002,
      "step": 7569
    },
    {
      "epoch": 29.34108527131783,
      "grad_norm": 0.0031597395427525043,
      "learning_rate": 2.065891472868217e-05,
      "loss": 0.0002,
      "step": 7570
    },
    {
      "epoch": 29.344961240310077,
      "grad_norm": 0.1680365949869156,
      "learning_rate": 2.0655038759689924e-05,
      "loss": 0.0069,
      "step": 7571
    },
    {
      "epoch": 29.348837209302324,
      "grad_norm": 6.736881732940674,
      "learning_rate": 2.0651162790697676e-05,
      "loss": 0.0606,
      "step": 7572
    },
    {
      "epoch": 29.352713178294575,
      "grad_norm": 0.0015280122170224786,
      "learning_rate": 2.064728682170543e-05,
      "loss": 0.0001,
      "step": 7573
    },
    {
      "epoch": 29.356589147286822,
      "grad_norm": 0.002505573211237788,
      "learning_rate": 2.064341085271318e-05,
      "loss": 0.0002,
      "step": 7574
    },
    {
      "epoch": 29.36046511627907,
      "grad_norm": 0.0014015581691637635,
      "learning_rate": 2.0639534883720933e-05,
      "loss": 0.0001,
      "step": 7575
    },
    {
      "epoch": 29.364341085271317,
      "grad_norm": 0.0027326561976224184,
      "learning_rate": 2.0635658914728682e-05,
      "loss": 0.0002,
      "step": 7576
    },
    {
      "epoch": 29.368217054263567,
      "grad_norm": 0.0018561817705631256,
      "learning_rate": 2.0631782945736435e-05,
      "loss": 0.0001,
      "step": 7577
    },
    {
      "epoch": 29.372093023255815,
      "grad_norm": 0.9266550540924072,
      "learning_rate": 2.0627906976744187e-05,
      "loss": 0.0012,
      "step": 7578
    },
    {
      "epoch": 29.375968992248062,
      "grad_norm": 0.009100636467337608,
      "learning_rate": 2.062403100775194e-05,
      "loss": 0.0005,
      "step": 7579
    },
    {
      "epoch": 29.37984496124031,
      "grad_norm": 0.0016669370234012604,
      "learning_rate": 2.0620155038759692e-05,
      "loss": 0.0001,
      "step": 7580
    },
    {
      "epoch": 29.38372093023256,
      "grad_norm": 0.00128262082580477,
      "learning_rate": 2.0616279069767445e-05,
      "loss": 0.0001,
      "step": 7581
    },
    {
      "epoch": 29.387596899224807,
      "grad_norm": 0.0019576442427933216,
      "learning_rate": 2.0612403100775197e-05,
      "loss": 0.0001,
      "step": 7582
    },
    {
      "epoch": 29.391472868217054,
      "grad_norm": 0.013048416934907436,
      "learning_rate": 2.0608527131782946e-05,
      "loss": 0.0006,
      "step": 7583
    },
    {
      "epoch": 29.3953488372093,
      "grad_norm": 0.012672115117311478,
      "learning_rate": 2.06046511627907e-05,
      "loss": 0.0007,
      "step": 7584
    },
    {
      "epoch": 29.399224806201552,
      "grad_norm": 0.011965200304985046,
      "learning_rate": 2.060077519379845e-05,
      "loss": 0.0003,
      "step": 7585
    },
    {
      "epoch": 29.4031007751938,
      "grad_norm": 0.044895824044942856,
      "learning_rate": 2.05968992248062e-05,
      "loss": 0.001,
      "step": 7586
    },
    {
      "epoch": 29.406976744186046,
      "grad_norm": 0.0020041312091052532,
      "learning_rate": 2.0593023255813952e-05,
      "loss": 0.0002,
      "step": 7587
    },
    {
      "epoch": 29.410852713178294,
      "grad_norm": 0.1615867167711258,
      "learning_rate": 2.0589147286821705e-05,
      "loss": 0.0068,
      "step": 7588
    },
    {
      "epoch": 29.414728682170544,
      "grad_norm": 0.012953953817486763,
      "learning_rate": 2.0585271317829457e-05,
      "loss": 0.0004,
      "step": 7589
    },
    {
      "epoch": 29.41860465116279,
      "grad_norm": 0.003987784963101149,
      "learning_rate": 2.058139534883721e-05,
      "loss": 0.0002,
      "step": 7590
    },
    {
      "epoch": 29.42248062015504,
      "grad_norm": 0.029768215492367744,
      "learning_rate": 2.0577519379844962e-05,
      "loss": 0.0003,
      "step": 7591
    },
    {
      "epoch": 29.426356589147286,
      "grad_norm": 0.0024786817375570536,
      "learning_rate": 2.0573643410852714e-05,
      "loss": 0.0002,
      "step": 7592
    },
    {
      "epoch": 29.430232558139537,
      "grad_norm": 0.008612556383013725,
      "learning_rate": 2.0569767441860467e-05,
      "loss": 0.0004,
      "step": 7593
    },
    {
      "epoch": 29.434108527131784,
      "grad_norm": 0.003954246174544096,
      "learning_rate": 2.056589147286822e-05,
      "loss": 0.0002,
      "step": 7594
    },
    {
      "epoch": 29.43798449612403,
      "grad_norm": 0.0021893209777772427,
      "learning_rate": 2.0562015503875968e-05,
      "loss": 0.0001,
      "step": 7595
    },
    {
      "epoch": 29.441860465116278,
      "grad_norm": 24.343931198120117,
      "learning_rate": 2.055813953488372e-05,
      "loss": 0.0066,
      "step": 7596
    },
    {
      "epoch": 29.44573643410853,
      "grad_norm": 0.001775677315890789,
      "learning_rate": 2.0554263565891473e-05,
      "loss": 0.0002,
      "step": 7597
    },
    {
      "epoch": 29.449612403100776,
      "grad_norm": 0.004527092911303043,
      "learning_rate": 2.0550387596899226e-05,
      "loss": 0.0003,
      "step": 7598
    },
    {
      "epoch": 29.453488372093023,
      "grad_norm": 0.0017208820208907127,
      "learning_rate": 2.0546511627906978e-05,
      "loss": 0.0001,
      "step": 7599
    },
    {
      "epoch": 29.45736434108527,
      "grad_norm": 0.005414571613073349,
      "learning_rate": 2.054263565891473e-05,
      "loss": 0.0003,
      "step": 7600
    },
    {
      "epoch": 29.46124031007752,
      "grad_norm": 2.3896219730377197,
      "learning_rate": 2.0538759689922483e-05,
      "loss": 0.0332,
      "step": 7601
    },
    {
      "epoch": 29.46511627906977,
      "grad_norm": 0.0017993185902014375,
      "learning_rate": 2.0534883720930235e-05,
      "loss": 0.0002,
      "step": 7602
    },
    {
      "epoch": 29.468992248062015,
      "grad_norm": 0.001369755482301116,
      "learning_rate": 2.0531007751937988e-05,
      "loss": 0.0001,
      "step": 7603
    },
    {
      "epoch": 29.472868217054263,
      "grad_norm": 0.0024148498196154833,
      "learning_rate": 2.0527131782945737e-05,
      "loss": 0.0002,
      "step": 7604
    },
    {
      "epoch": 29.476744186046513,
      "grad_norm": 0.004197813104838133,
      "learning_rate": 2.052325581395349e-05,
      "loss": 0.0003,
      "step": 7605
    },
    {
      "epoch": 29.48062015503876,
      "grad_norm": 0.038176827132701874,
      "learning_rate": 2.051937984496124e-05,
      "loss": 0.0009,
      "step": 7606
    },
    {
      "epoch": 29.484496124031008,
      "grad_norm": 0.009957589209079742,
      "learning_rate": 2.0515503875968994e-05,
      "loss": 0.0005,
      "step": 7607
    },
    {
      "epoch": 29.488372093023255,
      "grad_norm": 0.0014562231954187155,
      "learning_rate": 2.0511627906976746e-05,
      "loss": 0.0001,
      "step": 7608
    },
    {
      "epoch": 29.492248062015506,
      "grad_norm": 0.004756708163768053,
      "learning_rate": 2.05077519379845e-05,
      "loss": 0.0003,
      "step": 7609
    },
    {
      "epoch": 29.496124031007753,
      "grad_norm": 0.0011709131067618728,
      "learning_rate": 2.0503875968992248e-05,
      "loss": 0.0001,
      "step": 7610
    },
    {
      "epoch": 29.5,
      "grad_norm": 0.0012760870158672333,
      "learning_rate": 2.05e-05,
      "loss": 0.0001,
      "step": 7611
    },
    {
      "epoch": 29.503875968992247,
      "grad_norm": 0.20166026055812836,
      "learning_rate": 2.0496124031007753e-05,
      "loss": 0.0086,
      "step": 7612
    },
    {
      "epoch": 29.507751937984494,
      "grad_norm": 0.0014516945229843259,
      "learning_rate": 2.0492248062015505e-05,
      "loss": 0.0001,
      "step": 7613
    },
    {
      "epoch": 29.511627906976745,
      "grad_norm": 2.804378032684326,
      "learning_rate": 2.0488372093023258e-05,
      "loss": 0.2972,
      "step": 7614
    },
    {
      "epoch": 29.515503875968992,
      "grad_norm": 0.0017986537422984838,
      "learning_rate": 2.0484496124031007e-05,
      "loss": 0.0002,
      "step": 7615
    },
    {
      "epoch": 29.51937984496124,
      "grad_norm": 0.001252397894859314,
      "learning_rate": 2.048062015503876e-05,
      "loss": 0.0001,
      "step": 7616
    },
    {
      "epoch": 29.52325581395349,
      "grad_norm": 2.3600101470947266,
      "learning_rate": 2.047674418604651e-05,
      "loss": 0.178,
      "step": 7617
    },
    {
      "epoch": 29.527131782945737,
      "grad_norm": 0.001252455054782331,
      "learning_rate": 2.0472868217054264e-05,
      "loss": 0.0001,
      "step": 7618
    },
    {
      "epoch": 29.531007751937985,
      "grad_norm": 44.6743278503418,
      "learning_rate": 2.0468992248062016e-05,
      "loss": 0.0595,
      "step": 7619
    },
    {
      "epoch": 29.53488372093023,
      "grad_norm": 0.0013903352664783597,
      "learning_rate": 2.046511627906977e-05,
      "loss": 0.0001,
      "step": 7620
    },
    {
      "epoch": 29.53875968992248,
      "grad_norm": 0.002856734674423933,
      "learning_rate": 2.046124031007752e-05,
      "loss": 0.0002,
      "step": 7621
    },
    {
      "epoch": 29.54263565891473,
      "grad_norm": 0.002019488252699375,
      "learning_rate": 2.0457364341085273e-05,
      "loss": 0.0001,
      "step": 7622
    },
    {
      "epoch": 29.546511627906977,
      "grad_norm": 0.017373858019709587,
      "learning_rate": 2.0453488372093026e-05,
      "loss": 0.0004,
      "step": 7623
    },
    {
      "epoch": 29.550387596899224,
      "grad_norm": 0.044035475701093674,
      "learning_rate": 2.0449612403100775e-05,
      "loss": 0.001,
      "step": 7624
    },
    {
      "epoch": 29.55426356589147,
      "grad_norm": 0.001505002728663385,
      "learning_rate": 2.0445736434108527e-05,
      "loss": 0.0001,
      "step": 7625
    },
    {
      "epoch": 29.558139534883722,
      "grad_norm": 0.001300662406720221,
      "learning_rate": 2.044186046511628e-05,
      "loss": 0.0001,
      "step": 7626
    },
    {
      "epoch": 29.56201550387597,
      "grad_norm": 0.005575205665081739,
      "learning_rate": 2.0437984496124032e-05,
      "loss": 0.0004,
      "step": 7627
    },
    {
      "epoch": 29.565891472868216,
      "grad_norm": 0.001505239517427981,
      "learning_rate": 2.0434108527131785e-05,
      "loss": 0.0001,
      "step": 7628
    },
    {
      "epoch": 29.569767441860463,
      "grad_norm": 0.0034952701535075903,
      "learning_rate": 2.0430232558139537e-05,
      "loss": 0.0002,
      "step": 7629
    },
    {
      "epoch": 29.573643410852714,
      "grad_norm": 0.01621057465672493,
      "learning_rate": 2.042635658914729e-05,
      "loss": 0.0009,
      "step": 7630
    },
    {
      "epoch": 29.57751937984496,
      "grad_norm": 0.0014514579670503736,
      "learning_rate": 2.0422480620155042e-05,
      "loss": 0.0001,
      "step": 7631
    },
    {
      "epoch": 29.58139534883721,
      "grad_norm": 0.001562643563374877,
      "learning_rate": 2.0418604651162794e-05,
      "loss": 0.0001,
      "step": 7632
    },
    {
      "epoch": 29.585271317829456,
      "grad_norm": 0.001172407646663487,
      "learning_rate": 2.0414728682170543e-05,
      "loss": 0.0001,
      "step": 7633
    },
    {
      "epoch": 29.589147286821706,
      "grad_norm": 1.625353455543518,
      "learning_rate": 2.0410852713178296e-05,
      "loss": 0.1032,
      "step": 7634
    },
    {
      "epoch": 29.593023255813954,
      "grad_norm": 0.011212148703634739,
      "learning_rate": 2.0406976744186048e-05,
      "loss": 0.0004,
      "step": 7635
    },
    {
      "epoch": 29.5968992248062,
      "grad_norm": 0.0013278460828587413,
      "learning_rate": 2.04031007751938e-05,
      "loss": 0.0001,
      "step": 7636
    },
    {
      "epoch": 29.600775193798448,
      "grad_norm": 0.009553525596857071,
      "learning_rate": 2.039922480620155e-05,
      "loss": 0.0005,
      "step": 7637
    },
    {
      "epoch": 29.6046511627907,
      "grad_norm": 0.002034601289778948,
      "learning_rate": 2.0395348837209302e-05,
      "loss": 0.0001,
      "step": 7638
    },
    {
      "epoch": 29.608527131782946,
      "grad_norm": 0.0011894279159605503,
      "learning_rate": 2.0391472868217054e-05,
      "loss": 0.0001,
      "step": 7639
    },
    {
      "epoch": 29.612403100775193,
      "grad_norm": 0.002545391907915473,
      "learning_rate": 2.0387596899224807e-05,
      "loss": 0.0001,
      "step": 7640
    },
    {
      "epoch": 29.61627906976744,
      "grad_norm": 0.001144016277976334,
      "learning_rate": 2.038372093023256e-05,
      "loss": 0.0001,
      "step": 7641
    },
    {
      "epoch": 29.62015503875969,
      "grad_norm": 3.6898934841156006,
      "learning_rate": 2.0379844961240312e-05,
      "loss": 0.4242,
      "step": 7642
    },
    {
      "epoch": 29.624031007751938,
      "grad_norm": 0.030532563105225563,
      "learning_rate": 2.037596899224806e-05,
      "loss": 0.0002,
      "step": 7643
    },
    {
      "epoch": 29.627906976744185,
      "grad_norm": 0.0012401792919263244,
      "learning_rate": 2.0372093023255813e-05,
      "loss": 0.0001,
      "step": 7644
    },
    {
      "epoch": 29.631782945736433,
      "grad_norm": 0.003964516334235668,
      "learning_rate": 2.0368217054263566e-05,
      "loss": 0.0002,
      "step": 7645
    },
    {
      "epoch": 29.635658914728683,
      "grad_norm": 0.0015508257783949375,
      "learning_rate": 2.0364341085271318e-05,
      "loss": 0.0001,
      "step": 7646
    },
    {
      "epoch": 29.63953488372093,
      "grad_norm": 0.004622716922312975,
      "learning_rate": 2.036046511627907e-05,
      "loss": 0.0004,
      "step": 7647
    },
    {
      "epoch": 29.643410852713178,
      "grad_norm": 2.381938934326172,
      "learning_rate": 2.0356589147286823e-05,
      "loss": 0.0414,
      "step": 7648
    },
    {
      "epoch": 29.647286821705425,
      "grad_norm": 0.0012929396471008658,
      "learning_rate": 2.0352713178294575e-05,
      "loss": 0.0001,
      "step": 7649
    },
    {
      "epoch": 29.651162790697676,
      "grad_norm": 0.0011285787913948298,
      "learning_rate": 2.0348837209302328e-05,
      "loss": 0.0001,
      "step": 7650
    },
    {
      "epoch": 29.655038759689923,
      "grad_norm": 0.001688192947767675,
      "learning_rate": 2.034496124031008e-05,
      "loss": 0.0001,
      "step": 7651
    },
    {
      "epoch": 29.65891472868217,
      "grad_norm": 0.0015642475336790085,
      "learning_rate": 2.034108527131783e-05,
      "loss": 0.0001,
      "step": 7652
    },
    {
      "epoch": 29.662790697674417,
      "grad_norm": 0.0019329529022797942,
      "learning_rate": 2.033720930232558e-05,
      "loss": 0.0001,
      "step": 7653
    },
    {
      "epoch": 29.666666666666668,
      "grad_norm": 4.105041980743408,
      "learning_rate": 2.0333333333333334e-05,
      "loss": 0.0319,
      "step": 7654
    },
    {
      "epoch": 29.670542635658915,
      "grad_norm": 0.004437833558768034,
      "learning_rate": 2.0329457364341086e-05,
      "loss": 0.0002,
      "step": 7655
    },
    {
      "epoch": 29.674418604651162,
      "grad_norm": 9.581311225891113,
      "learning_rate": 2.032558139534884e-05,
      "loss": 0.1829,
      "step": 7656
    },
    {
      "epoch": 29.67829457364341,
      "grad_norm": 0.0014229699736461043,
      "learning_rate": 2.032170542635659e-05,
      "loss": 0.0001,
      "step": 7657
    },
    {
      "epoch": 29.68217054263566,
      "grad_norm": 0.001257080934010446,
      "learning_rate": 2.0317829457364344e-05,
      "loss": 0.0001,
      "step": 7658
    },
    {
      "epoch": 29.686046511627907,
      "grad_norm": 0.0013968147104606032,
      "learning_rate": 2.0313953488372096e-05,
      "loss": 0.0001,
      "step": 7659
    },
    {
      "epoch": 29.689922480620154,
      "grad_norm": 1.812629222869873,
      "learning_rate": 2.031007751937985e-05,
      "loss": 0.2171,
      "step": 7660
    },
    {
      "epoch": 29.6937984496124,
      "grad_norm": 0.0013942529913038015,
      "learning_rate": 2.0306201550387598e-05,
      "loss": 0.0001,
      "step": 7661
    },
    {
      "epoch": 29.697674418604652,
      "grad_norm": 0.006517632864415646,
      "learning_rate": 2.030232558139535e-05,
      "loss": 0.0004,
      "step": 7662
    },
    {
      "epoch": 29.7015503875969,
      "grad_norm": 0.0017974914517253637,
      "learning_rate": 2.02984496124031e-05,
      "loss": 0.0002,
      "step": 7663
    },
    {
      "epoch": 29.705426356589147,
      "grad_norm": 0.0019164677942171693,
      "learning_rate": 2.029457364341085e-05,
      "loss": 0.0001,
      "step": 7664
    },
    {
      "epoch": 29.709302325581394,
      "grad_norm": 0.0011883542174473405,
      "learning_rate": 2.0290697674418604e-05,
      "loss": 0.0001,
      "step": 7665
    },
    {
      "epoch": 29.713178294573645,
      "grad_norm": 0.0011768006952479482,
      "learning_rate": 2.0286821705426356e-05,
      "loss": 0.0001,
      "step": 7666
    },
    {
      "epoch": 29.717054263565892,
      "grad_norm": 0.0015195658197626472,
      "learning_rate": 2.028294573643411e-05,
      "loss": 0.0001,
      "step": 7667
    },
    {
      "epoch": 29.72093023255814,
      "grad_norm": 0.001617290312424302,
      "learning_rate": 2.027906976744186e-05,
      "loss": 0.0001,
      "step": 7668
    },
    {
      "epoch": 29.724806201550386,
      "grad_norm": 5.176992893218994,
      "learning_rate": 2.0275193798449614e-05,
      "loss": 0.0259,
      "step": 7669
    },
    {
      "epoch": 29.728682170542637,
      "grad_norm": 0.32079270482063293,
      "learning_rate": 2.0271317829457366e-05,
      "loss": 0.0132,
      "step": 7670
    },
    {
      "epoch": 29.732558139534884,
      "grad_norm": 0.006951741874217987,
      "learning_rate": 2.0267441860465115e-05,
      "loss": 0.0004,
      "step": 7671
    },
    {
      "epoch": 29.73643410852713,
      "grad_norm": 4.380694389343262,
      "learning_rate": 2.0263565891472867e-05,
      "loss": 0.0252,
      "step": 7672
    },
    {
      "epoch": 29.74031007751938,
      "grad_norm": 0.002971792593598366,
      "learning_rate": 2.025968992248062e-05,
      "loss": 0.0003,
      "step": 7673
    },
    {
      "epoch": 29.74418604651163,
      "grad_norm": 0.006207102909684181,
      "learning_rate": 2.0255813953488372e-05,
      "loss": 0.0001,
      "step": 7674
    },
    {
      "epoch": 29.748062015503876,
      "grad_norm": 0.0021236883476376534,
      "learning_rate": 2.0251937984496125e-05,
      "loss": 0.0001,
      "step": 7675
    },
    {
      "epoch": 29.751937984496124,
      "grad_norm": 99.63986206054688,
      "learning_rate": 2.0248062015503877e-05,
      "loss": 0.2205,
      "step": 7676
    },
    {
      "epoch": 29.75581395348837,
      "grad_norm": 0.0009985009673982859,
      "learning_rate": 2.024418604651163e-05,
      "loss": 0.0001,
      "step": 7677
    },
    {
      "epoch": 29.75968992248062,
      "grad_norm": 0.0027509655337780714,
      "learning_rate": 2.0240310077519382e-05,
      "loss": 0.0002,
      "step": 7678
    },
    {
      "epoch": 29.76356589147287,
      "grad_norm": 0.0025768200866878033,
      "learning_rate": 2.0236434108527134e-05,
      "loss": 0.0002,
      "step": 7679
    },
    {
      "epoch": 29.767441860465116,
      "grad_norm": 0.007041898090392351,
      "learning_rate": 2.0232558139534883e-05,
      "loss": 0.0005,
      "step": 7680
    },
    {
      "epoch": 29.771317829457363,
      "grad_norm": 0.27873656153678894,
      "learning_rate": 2.0228682170542636e-05,
      "loss": 0.0118,
      "step": 7681
    },
    {
      "epoch": 29.775193798449614,
      "grad_norm": 0.0016543989768251777,
      "learning_rate": 2.0224806201550388e-05,
      "loss": 0.0001,
      "step": 7682
    },
    {
      "epoch": 29.77906976744186,
      "grad_norm": 0.0011010367888957262,
      "learning_rate": 2.022093023255814e-05,
      "loss": 0.0001,
      "step": 7683
    },
    {
      "epoch": 29.782945736434108,
      "grad_norm": 23.175853729248047,
      "learning_rate": 2.0217054263565893e-05,
      "loss": 0.0941,
      "step": 7684
    },
    {
      "epoch": 29.786821705426355,
      "grad_norm": 0.0010280425194650888,
      "learning_rate": 2.0213178294573646e-05,
      "loss": 0.0001,
      "step": 7685
    },
    {
      "epoch": 29.790697674418606,
      "grad_norm": 0.0011280266335234046,
      "learning_rate": 2.0209302325581398e-05,
      "loss": 0.0001,
      "step": 7686
    },
    {
      "epoch": 29.794573643410853,
      "grad_norm": 0.0015953079564496875,
      "learning_rate": 2.020542635658915e-05,
      "loss": 0.0001,
      "step": 7687
    },
    {
      "epoch": 29.7984496124031,
      "grad_norm": 0.0016429488314315677,
      "learning_rate": 2.0201550387596903e-05,
      "loss": 0.0001,
      "step": 7688
    },
    {
      "epoch": 29.802325581395348,
      "grad_norm": 1.4587064981460571,
      "learning_rate": 2.0197674418604652e-05,
      "loss": 0.1017,
      "step": 7689
    },
    {
      "epoch": 29.8062015503876,
      "grad_norm": 0.004052449949085712,
      "learning_rate": 2.0193798449612404e-05,
      "loss": 0.0002,
      "step": 7690
    },
    {
      "epoch": 29.810077519379846,
      "grad_norm": 0.0017927431035786867,
      "learning_rate": 2.0189922480620153e-05,
      "loss": 0.0002,
      "step": 7691
    },
    {
      "epoch": 29.813953488372093,
      "grad_norm": 19.82179832458496,
      "learning_rate": 2.0186046511627906e-05,
      "loss": 0.3332,
      "step": 7692
    },
    {
      "epoch": 29.81782945736434,
      "grad_norm": 0.0013544884277507663,
      "learning_rate": 2.0182170542635658e-05,
      "loss": 0.0001,
      "step": 7693
    },
    {
      "epoch": 29.82170542635659,
      "grad_norm": 0.0020311076659709215,
      "learning_rate": 2.017829457364341e-05,
      "loss": 0.0002,
      "step": 7694
    },
    {
      "epoch": 29.825581395348838,
      "grad_norm": 0.003907294012606144,
      "learning_rate": 2.0174418604651163e-05,
      "loss": 0.0003,
      "step": 7695
    },
    {
      "epoch": 29.829457364341085,
      "grad_norm": 0.0018965300405398011,
      "learning_rate": 2.0170542635658915e-05,
      "loss": 0.0002,
      "step": 7696
    },
    {
      "epoch": 29.833333333333332,
      "grad_norm": 0.0016840207390487194,
      "learning_rate": 2.0166666666666668e-05,
      "loss": 0.0002,
      "step": 7697
    },
    {
      "epoch": 29.837209302325583,
      "grad_norm": 0.0017706899670884013,
      "learning_rate": 2.016279069767442e-05,
      "loss": 0.0001,
      "step": 7698
    },
    {
      "epoch": 29.84108527131783,
      "grad_norm": 0.005720856599509716,
      "learning_rate": 2.0158914728682173e-05,
      "loss": 0.0003,
      "step": 7699
    },
    {
      "epoch": 29.844961240310077,
      "grad_norm": 0.026814771816134453,
      "learning_rate": 2.0155038759689922e-05,
      "loss": 0.0002,
      "step": 7700
    },
    {
      "epoch": 29.848837209302324,
      "grad_norm": 0.0038223552983254194,
      "learning_rate": 2.0151162790697674e-05,
      "loss": 0.0002,
      "step": 7701
    },
    {
      "epoch": 29.852713178294575,
      "grad_norm": 0.030324336141347885,
      "learning_rate": 2.0147286821705427e-05,
      "loss": 0.0005,
      "step": 7702
    },
    {
      "epoch": 29.856589147286822,
      "grad_norm": 0.002298553241416812,
      "learning_rate": 2.014341085271318e-05,
      "loss": 0.0002,
      "step": 7703
    },
    {
      "epoch": 29.86046511627907,
      "grad_norm": 22.172815322875977,
      "learning_rate": 2.013953488372093e-05,
      "loss": 0.0458,
      "step": 7704
    },
    {
      "epoch": 29.864341085271317,
      "grad_norm": 2.139829635620117,
      "learning_rate": 2.0135658914728684e-05,
      "loss": 0.2339,
      "step": 7705
    },
    {
      "epoch": 29.868217054263567,
      "grad_norm": 0.002058614743873477,
      "learning_rate": 2.0131782945736436e-05,
      "loss": 0.0002,
      "step": 7706
    },
    {
      "epoch": 29.872093023255815,
      "grad_norm": 0.00794614665210247,
      "learning_rate": 2.012790697674419e-05,
      "loss": 0.0002,
      "step": 7707
    },
    {
      "epoch": 29.875968992248062,
      "grad_norm": 0.0012508033541962504,
      "learning_rate": 2.012403100775194e-05,
      "loss": 0.0001,
      "step": 7708
    },
    {
      "epoch": 29.87984496124031,
      "grad_norm": 0.002165472600609064,
      "learning_rate": 2.012015503875969e-05,
      "loss": 0.0001,
      "step": 7709
    },
    {
      "epoch": 29.88372093023256,
      "grad_norm": 0.0022818550933152437,
      "learning_rate": 2.0116279069767443e-05,
      "loss": 0.0001,
      "step": 7710
    },
    {
      "epoch": 29.887596899224807,
      "grad_norm": 7.971044063568115,
      "learning_rate": 2.0112403100775195e-05,
      "loss": 0.1198,
      "step": 7711
    },
    {
      "epoch": 29.891472868217054,
      "grad_norm": 0.14893434941768646,
      "learning_rate": 2.0108527131782947e-05,
      "loss": 0.0007,
      "step": 7712
    },
    {
      "epoch": 29.8953488372093,
      "grad_norm": 0.0025031149853020906,
      "learning_rate": 2.01046511627907e-05,
      "loss": 0.0002,
      "step": 7713
    },
    {
      "epoch": 29.899224806201552,
      "grad_norm": 0.002463008277118206,
      "learning_rate": 2.0100775193798452e-05,
      "loss": 0.0002,
      "step": 7714
    },
    {
      "epoch": 29.9031007751938,
      "grad_norm": 0.0022820362355560064,
      "learning_rate": 2.0096899224806205e-05,
      "loss": 0.0002,
      "step": 7715
    },
    {
      "epoch": 29.906976744186046,
      "grad_norm": 0.004301718436181545,
      "learning_rate": 2.0093023255813957e-05,
      "loss": 0.0002,
      "step": 7716
    },
    {
      "epoch": 29.910852713178294,
      "grad_norm": 0.0016741076251491904,
      "learning_rate": 2.0089147286821706e-05,
      "loss": 0.0002,
      "step": 7717
    },
    {
      "epoch": 29.914728682170544,
      "grad_norm": 0.0021319743245840073,
      "learning_rate": 2.008527131782946e-05,
      "loss": 0.0001,
      "step": 7718
    },
    {
      "epoch": 29.91860465116279,
      "grad_norm": 0.0011917426018044353,
      "learning_rate": 2.0081395348837208e-05,
      "loss": 0.0001,
      "step": 7719
    },
    {
      "epoch": 29.92248062015504,
      "grad_norm": 0.0013165029231458902,
      "learning_rate": 2.007751937984496e-05,
      "loss": 0.0001,
      "step": 7720
    },
    {
      "epoch": 29.926356589147286,
      "grad_norm": 0.0027361151296645403,
      "learning_rate": 2.0073643410852712e-05,
      "loss": 0.0002,
      "step": 7721
    },
    {
      "epoch": 29.930232558139537,
      "grad_norm": 0.006964194588363171,
      "learning_rate": 2.0069767441860465e-05,
      "loss": 0.0004,
      "step": 7722
    },
    {
      "epoch": 29.934108527131784,
      "grad_norm": 0.5987861156463623,
      "learning_rate": 2.0065891472868217e-05,
      "loss": 0.0283,
      "step": 7723
    },
    {
      "epoch": 29.93798449612403,
      "grad_norm": 0.003106749849393964,
      "learning_rate": 2.006201550387597e-05,
      "loss": 0.0002,
      "step": 7724
    },
    {
      "epoch": 29.941860465116278,
      "grad_norm": 12.40505599975586,
      "learning_rate": 2.0058139534883722e-05,
      "loss": 0.5271,
      "step": 7725
    },
    {
      "epoch": 29.94573643410853,
      "grad_norm": 0.003149650525301695,
      "learning_rate": 2.0054263565891475e-05,
      "loss": 0.0002,
      "step": 7726
    },
    {
      "epoch": 29.949612403100776,
      "grad_norm": 0.003115610918030143,
      "learning_rate": 2.0050387596899227e-05,
      "loss": 0.0002,
      "step": 7727
    },
    {
      "epoch": 29.953488372093023,
      "grad_norm": 0.003745917696505785,
      "learning_rate": 2.0046511627906976e-05,
      "loss": 0.0002,
      "step": 7728
    },
    {
      "epoch": 29.95736434108527,
      "grad_norm": 0.0018084394978359342,
      "learning_rate": 2.004263565891473e-05,
      "loss": 0.0001,
      "step": 7729
    },
    {
      "epoch": 29.96124031007752,
      "grad_norm": 0.0020230384543538094,
      "learning_rate": 2.003875968992248e-05,
      "loss": 0.0001,
      "step": 7730
    },
    {
      "epoch": 29.96511627906977,
      "grad_norm": 0.05298374220728874,
      "learning_rate": 2.0034883720930233e-05,
      "loss": 0.0002,
      "step": 7731
    },
    {
      "epoch": 29.968992248062015,
      "grad_norm": 0.0016062601935118437,
      "learning_rate": 2.0031007751937986e-05,
      "loss": 0.0001,
      "step": 7732
    },
    {
      "epoch": 29.972868217054263,
      "grad_norm": 3.0094399452209473,
      "learning_rate": 2.0027131782945738e-05,
      "loss": 0.2893,
      "step": 7733
    },
    {
      "epoch": 29.97674418604651,
      "grad_norm": 0.031001489609479904,
      "learning_rate": 2.002325581395349e-05,
      "loss": 0.0003,
      "step": 7734
    },
    {
      "epoch": 29.98062015503876,
      "grad_norm": 1.0387604236602783,
      "learning_rate": 2.0019379844961243e-05,
      "loss": 0.2334,
      "step": 7735
    },
    {
      "epoch": 29.984496124031008,
      "grad_norm": 0.1858580857515335,
      "learning_rate": 2.0015503875968995e-05,
      "loss": 0.0083,
      "step": 7736
    },
    {
      "epoch": 29.988372093023255,
      "grad_norm": 0.001337618799880147,
      "learning_rate": 2.0011627906976744e-05,
      "loss": 0.0001,
      "step": 7737
    },
    {
      "epoch": 29.992248062015506,
      "grad_norm": 0.9458032846450806,
      "learning_rate": 2.0007751937984497e-05,
      "loss": 0.0568,
      "step": 7738
    },
    {
      "epoch": 29.996124031007753,
      "grad_norm": 0.002156125847250223,
      "learning_rate": 2.000387596899225e-05,
      "loss": 0.0001,
      "step": 7739
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.0014103472931310534,
      "learning_rate": 2e-05,
      "loss": 0.0001,
      "step": 7740
    },
    {
      "epoch": 30.003875968992247,
      "grad_norm": 0.3067654073238373,
      "learning_rate": 1.9996124031007754e-05,
      "loss": 0.0006,
      "step": 7741
    },
    {
      "epoch": 30.007751937984494,
      "grad_norm": 0.0025855458807200193,
      "learning_rate": 1.9992248062015506e-05,
      "loss": 0.0001,
      "step": 7742
    },
    {
      "epoch": 30.011627906976745,
      "grad_norm": 6.8541669845581055,
      "learning_rate": 1.9988372093023256e-05,
      "loss": 0.1807,
      "step": 7743
    },
    {
      "epoch": 30.015503875968992,
      "grad_norm": 0.002243574010208249,
      "learning_rate": 1.9984496124031008e-05,
      "loss": 0.0002,
      "step": 7744
    },
    {
      "epoch": 30.01937984496124,
      "grad_norm": 0.0011957132956013083,
      "learning_rate": 1.998062015503876e-05,
      "loss": 0.0001,
      "step": 7745
    },
    {
      "epoch": 30.023255813953487,
      "grad_norm": 0.001508768880739808,
      "learning_rate": 1.9976744186046513e-05,
      "loss": 0.0001,
      "step": 7746
    },
    {
      "epoch": 30.027131782945737,
      "grad_norm": 0.006370248273015022,
      "learning_rate": 1.9972868217054265e-05,
      "loss": 0.0004,
      "step": 7747
    },
    {
      "epoch": 30.031007751937985,
      "grad_norm": 0.006816357374191284,
      "learning_rate": 1.9968992248062014e-05,
      "loss": 0.0002,
      "step": 7748
    },
    {
      "epoch": 30.03488372093023,
      "grad_norm": 0.016574513167142868,
      "learning_rate": 1.9965116279069767e-05,
      "loss": 0.0008,
      "step": 7749
    },
    {
      "epoch": 30.03875968992248,
      "grad_norm": 0.024256275966763496,
      "learning_rate": 1.996124031007752e-05,
      "loss": 0.0007,
      "step": 7750
    },
    {
      "epoch": 30.04263565891473,
      "grad_norm": 0.0028190382290631533,
      "learning_rate": 1.995736434108527e-05,
      "loss": 0.0002,
      "step": 7751
    },
    {
      "epoch": 30.046511627906977,
      "grad_norm": 0.002635232638567686,
      "learning_rate": 1.9953488372093024e-05,
      "loss": 0.0002,
      "step": 7752
    },
    {
      "epoch": 30.050387596899224,
      "grad_norm": 0.0023184814490377903,
      "learning_rate": 1.9949612403100776e-05,
      "loss": 0.0001,
      "step": 7753
    },
    {
      "epoch": 30.05426356589147,
      "grad_norm": 0.0054637533612549305,
      "learning_rate": 1.994573643410853e-05,
      "loss": 0.0003,
      "step": 7754
    },
    {
      "epoch": 30.058139534883722,
      "grad_norm": 0.001179852639324963,
      "learning_rate": 1.994186046511628e-05,
      "loss": 0.0001,
      "step": 7755
    },
    {
      "epoch": 30.06201550387597,
      "grad_norm": 1.6363180875778198,
      "learning_rate": 1.9937984496124034e-05,
      "loss": 0.212,
      "step": 7756
    },
    {
      "epoch": 30.065891472868216,
      "grad_norm": 0.002904279623180628,
      "learning_rate": 1.9934108527131783e-05,
      "loss": 0.0002,
      "step": 7757
    },
    {
      "epoch": 30.069767441860463,
      "grad_norm": 3.0260119438171387,
      "learning_rate": 1.9930232558139535e-05,
      "loss": 0.3103,
      "step": 7758
    },
    {
      "epoch": 30.073643410852714,
      "grad_norm": 0.5843589305877686,
      "learning_rate": 1.9926356589147287e-05,
      "loss": 0.027,
      "step": 7759
    },
    {
      "epoch": 30.07751937984496,
      "grad_norm": 0.002191706094890833,
      "learning_rate": 1.992248062015504e-05,
      "loss": 0.0002,
      "step": 7760
    },
    {
      "epoch": 30.08139534883721,
      "grad_norm": 0.0034855783451348543,
      "learning_rate": 1.9918604651162792e-05,
      "loss": 0.0003,
      "step": 7761
    },
    {
      "epoch": 30.085271317829456,
      "grad_norm": 1.5874991416931152,
      "learning_rate": 1.9914728682170545e-05,
      "loss": 0.114,
      "step": 7762
    },
    {
      "epoch": 30.089147286821706,
      "grad_norm": 0.005029937718063593,
      "learning_rate": 1.9910852713178297e-05,
      "loss": 0.0002,
      "step": 7763
    },
    {
      "epoch": 30.093023255813954,
      "grad_norm": 0.004749620798975229,
      "learning_rate": 1.990697674418605e-05,
      "loss": 0.0002,
      "step": 7764
    },
    {
      "epoch": 30.0968992248062,
      "grad_norm": 0.011317688971757889,
      "learning_rate": 1.9903100775193802e-05,
      "loss": 0.0004,
      "step": 7765
    },
    {
      "epoch": 30.100775193798448,
      "grad_norm": 0.008079157210886478,
      "learning_rate": 1.989922480620155e-05,
      "loss": 0.0003,
      "step": 7766
    },
    {
      "epoch": 30.1046511627907,
      "grad_norm": 0.005041220691055059,
      "learning_rate": 1.9895348837209303e-05,
      "loss": 0.0003,
      "step": 7767
    },
    {
      "epoch": 30.108527131782946,
      "grad_norm": 0.11802790313959122,
      "learning_rate": 1.9891472868217056e-05,
      "loss": 0.0006,
      "step": 7768
    },
    {
      "epoch": 30.112403100775193,
      "grad_norm": 0.3720408082008362,
      "learning_rate": 1.988759689922481e-05,
      "loss": 0.004,
      "step": 7769
    },
    {
      "epoch": 30.11627906976744,
      "grad_norm": 0.008859698660671711,
      "learning_rate": 1.9883720930232557e-05,
      "loss": 0.0005,
      "step": 7770
    },
    {
      "epoch": 30.12015503875969,
      "grad_norm": 0.013006605207920074,
      "learning_rate": 1.987984496124031e-05,
      "loss": 0.0004,
      "step": 7771
    },
    {
      "epoch": 30.124031007751938,
      "grad_norm": 0.02278001233935356,
      "learning_rate": 1.9875968992248062e-05,
      "loss": 0.0008,
      "step": 7772
    },
    {
      "epoch": 30.127906976744185,
      "grad_norm": 0.3917458951473236,
      "learning_rate": 1.9872093023255815e-05,
      "loss": 0.0006,
      "step": 7773
    },
    {
      "epoch": 30.131782945736433,
      "grad_norm": 0.006705945357680321,
      "learning_rate": 1.9868217054263567e-05,
      "loss": 0.0003,
      "step": 7774
    },
    {
      "epoch": 30.135658914728683,
      "grad_norm": 0.021369554102420807,
      "learning_rate": 1.986434108527132e-05,
      "loss": 0.0006,
      "step": 7775
    },
    {
      "epoch": 30.13953488372093,
      "grad_norm": 0.006773794535547495,
      "learning_rate": 1.986046511627907e-05,
      "loss": 0.0003,
      "step": 7776
    },
    {
      "epoch": 30.143410852713178,
      "grad_norm": 0.022269299253821373,
      "learning_rate": 1.985658914728682e-05,
      "loss": 0.0007,
      "step": 7777
    },
    {
      "epoch": 30.147286821705425,
      "grad_norm": 0.05918226018548012,
      "learning_rate": 1.9852713178294573e-05,
      "loss": 0.001,
      "step": 7778
    },
    {
      "epoch": 30.151162790697676,
      "grad_norm": 0.02366417646408081,
      "learning_rate": 1.9848837209302326e-05,
      "loss": 0.0008,
      "step": 7779
    },
    {
      "epoch": 30.155038759689923,
      "grad_norm": 0.044549133628606796,
      "learning_rate": 1.9844961240310078e-05,
      "loss": 0.0012,
      "step": 7780
    },
    {
      "epoch": 30.15891472868217,
      "grad_norm": 0.010715873911976814,
      "learning_rate": 1.984108527131783e-05,
      "loss": 0.0006,
      "step": 7781
    },
    {
      "epoch": 30.162790697674417,
      "grad_norm": 0.023789148777723312,
      "learning_rate": 1.9837209302325583e-05,
      "loss": 0.0007,
      "step": 7782
    },
    {
      "epoch": 30.166666666666668,
      "grad_norm": 0.006361617241054773,
      "learning_rate": 1.9833333333333335e-05,
      "loss": 0.0003,
      "step": 7783
    },
    {
      "epoch": 30.170542635658915,
      "grad_norm": 0.3106648325920105,
      "learning_rate": 1.9829457364341088e-05,
      "loss": 0.0147,
      "step": 7784
    },
    {
      "epoch": 30.174418604651162,
      "grad_norm": 0.008544390089809895,
      "learning_rate": 1.9825581395348837e-05,
      "loss": 0.0004,
      "step": 7785
    },
    {
      "epoch": 30.17829457364341,
      "grad_norm": 0.006538815330713987,
      "learning_rate": 1.982170542635659e-05,
      "loss": 0.0003,
      "step": 7786
    },
    {
      "epoch": 30.18217054263566,
      "grad_norm": 0.009615225717425346,
      "learning_rate": 1.9817829457364342e-05,
      "loss": 0.0004,
      "step": 7787
    },
    {
      "epoch": 30.186046511627907,
      "grad_norm": 0.005654977634549141,
      "learning_rate": 1.9813953488372094e-05,
      "loss": 0.0003,
      "step": 7788
    },
    {
      "epoch": 30.189922480620154,
      "grad_norm": 0.007755897473543882,
      "learning_rate": 1.9810077519379847e-05,
      "loss": 0.0003,
      "step": 7789
    },
    {
      "epoch": 30.1937984496124,
      "grad_norm": 2.882631778717041,
      "learning_rate": 1.98062015503876e-05,
      "loss": 0.0137,
      "step": 7790
    },
    {
      "epoch": 30.197674418604652,
      "grad_norm": 0.006001993082463741,
      "learning_rate": 1.980232558139535e-05,
      "loss": 0.0003,
      "step": 7791
    },
    {
      "epoch": 30.2015503875969,
      "grad_norm": 0.006785275414586067,
      "learning_rate": 1.9798449612403104e-05,
      "loss": 0.0005,
      "step": 7792
    },
    {
      "epoch": 30.205426356589147,
      "grad_norm": 0.006336820777505636,
      "learning_rate": 1.9794573643410856e-05,
      "loss": 0.0002,
      "step": 7793
    },
    {
      "epoch": 30.209302325581394,
      "grad_norm": 0.16473092138767242,
      "learning_rate": 1.9790697674418605e-05,
      "loss": 0.0073,
      "step": 7794
    },
    {
      "epoch": 30.213178294573645,
      "grad_norm": 0.008326075971126556,
      "learning_rate": 1.9786821705426358e-05,
      "loss": 0.0005,
      "step": 7795
    },
    {
      "epoch": 30.217054263565892,
      "grad_norm": 0.0039247493259608746,
      "learning_rate": 1.9782945736434107e-05,
      "loss": 0.0002,
      "step": 7796
    },
    {
      "epoch": 30.22093023255814,
      "grad_norm": 0.007018606644123793,
      "learning_rate": 1.977906976744186e-05,
      "loss": 0.0003,
      "step": 7797
    },
    {
      "epoch": 30.224806201550386,
      "grad_norm": 9.158604621887207,
      "learning_rate": 1.977519379844961e-05,
      "loss": 0.1331,
      "step": 7798
    },
    {
      "epoch": 30.228682170542637,
      "grad_norm": 0.0033120594453066587,
      "learning_rate": 1.9771317829457364e-05,
      "loss": 0.0002,
      "step": 7799
    },
    {
      "epoch": 30.232558139534884,
      "grad_norm": 0.027259206399321556,
      "learning_rate": 1.9767441860465116e-05,
      "loss": 0.0009,
      "step": 7800
    },
    {
      "epoch": 30.23643410852713,
      "grad_norm": 0.002649684902280569,
      "learning_rate": 1.976356589147287e-05,
      "loss": 0.0002,
      "step": 7801
    },
    {
      "epoch": 30.24031007751938,
      "grad_norm": 0.006104160100221634,
      "learning_rate": 1.975968992248062e-05,
      "loss": 0.0003,
      "step": 7802
    },
    {
      "epoch": 30.24418604651163,
      "grad_norm": 0.004539146553725004,
      "learning_rate": 1.9755813953488374e-05,
      "loss": 0.0003,
      "step": 7803
    },
    {
      "epoch": 30.248062015503876,
      "grad_norm": 6.039943218231201,
      "learning_rate": 1.9751937984496123e-05,
      "loss": 0.2628,
      "step": 7804
    },
    {
      "epoch": 30.251937984496124,
      "grad_norm": 0.0037166655529290438,
      "learning_rate": 1.9748062015503875e-05,
      "loss": 0.0002,
      "step": 7805
    },
    {
      "epoch": 30.25581395348837,
      "grad_norm": 0.0020299823954701424,
      "learning_rate": 1.9744186046511628e-05,
      "loss": 0.0002,
      "step": 7806
    },
    {
      "epoch": 30.25968992248062,
      "grad_norm": 0.0022181400563567877,
      "learning_rate": 1.974031007751938e-05,
      "loss": 0.0002,
      "step": 7807
    },
    {
      "epoch": 30.26356589147287,
      "grad_norm": 0.06019151955842972,
      "learning_rate": 1.9736434108527132e-05,
      "loss": 0.001,
      "step": 7808
    },
    {
      "epoch": 30.267441860465116,
      "grad_norm": 0.0065373750403523445,
      "learning_rate": 1.9732558139534885e-05,
      "loss": 0.0004,
      "step": 7809
    },
    {
      "epoch": 30.271317829457363,
      "grad_norm": 0.0023218090645968914,
      "learning_rate": 1.9728682170542637e-05,
      "loss": 0.0002,
      "step": 7810
    },
    {
      "epoch": 30.275193798449614,
      "grad_norm": 1.8139728307724,
      "learning_rate": 1.972480620155039e-05,
      "loss": 0.1559,
      "step": 7811
    },
    {
      "epoch": 30.27906976744186,
      "grad_norm": 0.012048211880028248,
      "learning_rate": 1.9720930232558142e-05,
      "loss": 0.0002,
      "step": 7812
    },
    {
      "epoch": 30.282945736434108,
      "grad_norm": 0.003818213241174817,
      "learning_rate": 1.971705426356589e-05,
      "loss": 0.0003,
      "step": 7813
    },
    {
      "epoch": 30.286821705426355,
      "grad_norm": 0.0029757823795080185,
      "learning_rate": 1.9713178294573644e-05,
      "loss": 0.0002,
      "step": 7814
    },
    {
      "epoch": 30.290697674418606,
      "grad_norm": 0.002669805660843849,
      "learning_rate": 1.9709302325581396e-05,
      "loss": 0.0002,
      "step": 7815
    },
    {
      "epoch": 30.294573643410853,
      "grad_norm": 0.0029689210932701826,
      "learning_rate": 1.970542635658915e-05,
      "loss": 0.0002,
      "step": 7816
    },
    {
      "epoch": 30.2984496124031,
      "grad_norm": 0.003984931390732527,
      "learning_rate": 1.97015503875969e-05,
      "loss": 0.0002,
      "step": 7817
    },
    {
      "epoch": 30.302325581395348,
      "grad_norm": 0.005416932515799999,
      "learning_rate": 1.9697674418604653e-05,
      "loss": 0.0003,
      "step": 7818
    },
    {
      "epoch": 30.3062015503876,
      "grad_norm": 0.004422474652528763,
      "learning_rate": 1.9693798449612406e-05,
      "loss": 0.0002,
      "step": 7819
    },
    {
      "epoch": 30.310077519379846,
      "grad_norm": 0.030189326032996178,
      "learning_rate": 1.9689922480620158e-05,
      "loss": 0.0003,
      "step": 7820
    },
    {
      "epoch": 30.313953488372093,
      "grad_norm": 0.002450710628181696,
      "learning_rate": 1.968604651162791e-05,
      "loss": 0.0002,
      "step": 7821
    },
    {
      "epoch": 30.31782945736434,
      "grad_norm": 0.7086969017982483,
      "learning_rate": 1.968217054263566e-05,
      "loss": 0.0348,
      "step": 7822
    },
    {
      "epoch": 30.32170542635659,
      "grad_norm": 0.008696422912180424,
      "learning_rate": 1.9678294573643412e-05,
      "loss": 0.0005,
      "step": 7823
    },
    {
      "epoch": 30.325581395348838,
      "grad_norm": 0.9488961696624756,
      "learning_rate": 1.967441860465116e-05,
      "loss": 0.0511,
      "step": 7824
    },
    {
      "epoch": 30.329457364341085,
      "grad_norm": 0.014350551180541515,
      "learning_rate": 1.9670542635658913e-05,
      "loss": 0.0005,
      "step": 7825
    },
    {
      "epoch": 30.333333333333332,
      "grad_norm": 0.003170949639752507,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 0.0003,
      "step": 7826
    },
    {
      "epoch": 30.337209302325583,
      "grad_norm": 0.0036373427137732506,
      "learning_rate": 1.9662790697674418e-05,
      "loss": 0.0002,
      "step": 7827
    },
    {
      "epoch": 30.34108527131783,
      "grad_norm": 0.0037474711425602436,
      "learning_rate": 1.965891472868217e-05,
      "loss": 0.0002,
      "step": 7828
    },
    {
      "epoch": 30.344961240310077,
      "grad_norm": 5.656306266784668,
      "learning_rate": 1.9655038759689923e-05,
      "loss": 0.0716,
      "step": 7829
    },
    {
      "epoch": 30.348837209302324,
      "grad_norm": 0.09152708947658539,
      "learning_rate": 1.9651162790697676e-05,
      "loss": 0.001,
      "step": 7830
    },
    {
      "epoch": 30.352713178294575,
      "grad_norm": 0.0024257677141577005,
      "learning_rate": 1.9647286821705428e-05,
      "loss": 0.0002,
      "step": 7831
    },
    {
      "epoch": 30.356589147286822,
      "grad_norm": 0.0029936805367469788,
      "learning_rate": 1.964341085271318e-05,
      "loss": 0.0002,
      "step": 7832
    },
    {
      "epoch": 30.36046511627907,
      "grad_norm": 0.0036853544879704714,
      "learning_rate": 1.963953488372093e-05,
      "loss": 0.0002,
      "step": 7833
    },
    {
      "epoch": 30.364341085271317,
      "grad_norm": 0.0026099805254489183,
      "learning_rate": 1.9635658914728682e-05,
      "loss": 0.0002,
      "step": 7834
    },
    {
      "epoch": 30.368217054263567,
      "grad_norm": 0.0028549605049192905,
      "learning_rate": 1.9631782945736434e-05,
      "loss": 0.0002,
      "step": 7835
    },
    {
      "epoch": 30.372093023255815,
      "grad_norm": 0.018798504024744034,
      "learning_rate": 1.9627906976744187e-05,
      "loss": 0.0004,
      "step": 7836
    },
    {
      "epoch": 30.375968992248062,
      "grad_norm": 0.0022553419694304466,
      "learning_rate": 1.962403100775194e-05,
      "loss": 0.0002,
      "step": 7837
    },
    {
      "epoch": 30.37984496124031,
      "grad_norm": 0.00691528245806694,
      "learning_rate": 1.962015503875969e-05,
      "loss": 0.0005,
      "step": 7838
    },
    {
      "epoch": 30.38372093023256,
      "grad_norm": 0.01125312503427267,
      "learning_rate": 1.9616279069767444e-05,
      "loss": 0.0005,
      "step": 7839
    },
    {
      "epoch": 30.387596899224807,
      "grad_norm": 0.009571556933224201,
      "learning_rate": 1.9612403100775196e-05,
      "loss": 0.0004,
      "step": 7840
    },
    {
      "epoch": 30.391472868217054,
      "grad_norm": 0.0024615139700472355,
      "learning_rate": 1.960852713178295e-05,
      "loss": 0.0002,
      "step": 7841
    },
    {
      "epoch": 30.3953488372093,
      "grad_norm": 0.0023254454135894775,
      "learning_rate": 1.9604651162790698e-05,
      "loss": 0.0002,
      "step": 7842
    },
    {
      "epoch": 30.399224806201552,
      "grad_norm": 0.003667077049612999,
      "learning_rate": 1.960077519379845e-05,
      "loss": 0.0002,
      "step": 7843
    },
    {
      "epoch": 30.4031007751938,
      "grad_norm": 0.7423053979873657,
      "learning_rate": 1.9596899224806203e-05,
      "loss": 0.0321,
      "step": 7844
    },
    {
      "epoch": 30.406976744186046,
      "grad_norm": 0.0014082016423344612,
      "learning_rate": 1.9593023255813955e-05,
      "loss": 0.0001,
      "step": 7845
    },
    {
      "epoch": 30.410852713178294,
      "grad_norm": 0.0022579682990908623,
      "learning_rate": 1.9589147286821708e-05,
      "loss": 0.0002,
      "step": 7846
    },
    {
      "epoch": 30.414728682170544,
      "grad_norm": 0.2761024832725525,
      "learning_rate": 1.958527131782946e-05,
      "loss": 0.0117,
      "step": 7847
    },
    {
      "epoch": 30.41860465116279,
      "grad_norm": 0.017626294866204262,
      "learning_rate": 1.9581395348837212e-05,
      "loss": 0.0006,
      "step": 7848
    },
    {
      "epoch": 30.42248062015504,
      "grad_norm": 0.006398187950253487,
      "learning_rate": 1.9577519379844965e-05,
      "loss": 0.0005,
      "step": 7849
    },
    {
      "epoch": 30.426356589147286,
      "grad_norm": 0.49113795161247253,
      "learning_rate": 1.9573643410852714e-05,
      "loss": 0.1008,
      "step": 7850
    },
    {
      "epoch": 30.430232558139537,
      "grad_norm": 0.002240673406049609,
      "learning_rate": 1.9569767441860466e-05,
      "loss": 0.0002,
      "step": 7851
    },
    {
      "epoch": 30.434108527131784,
      "grad_norm": 0.004058925900608301,
      "learning_rate": 1.9565891472868215e-05,
      "loss": 0.0003,
      "step": 7852
    },
    {
      "epoch": 30.43798449612403,
      "grad_norm": 1.1139235496520996,
      "learning_rate": 1.9562015503875968e-05,
      "loss": 0.066,
      "step": 7853
    },
    {
      "epoch": 30.441860465116278,
      "grad_norm": 0.005655332934111357,
      "learning_rate": 1.955813953488372e-05,
      "loss": 0.0004,
      "step": 7854
    },
    {
      "epoch": 30.44573643410853,
      "grad_norm": 2.4304039478302,
      "learning_rate": 1.9554263565891473e-05,
      "loss": 0.0668,
      "step": 7855
    },
    {
      "epoch": 30.449612403100776,
      "grad_norm": 0.004950258415192366,
      "learning_rate": 1.9550387596899225e-05,
      "loss": 0.0004,
      "step": 7856
    },
    {
      "epoch": 30.453488372093023,
      "grad_norm": 0.002770578721538186,
      "learning_rate": 1.9546511627906977e-05,
      "loss": 0.0002,
      "step": 7857
    },
    {
      "epoch": 30.45736434108527,
      "grad_norm": 4.928541660308838,
      "learning_rate": 1.954263565891473e-05,
      "loss": 0.0968,
      "step": 7858
    },
    {
      "epoch": 30.46124031007752,
      "grad_norm": 0.0015807311283424497,
      "learning_rate": 1.9538759689922482e-05,
      "loss": 0.0001,
      "step": 7859
    },
    {
      "epoch": 30.46511627906977,
      "grad_norm": 0.0020407314877957106,
      "learning_rate": 1.9534883720930235e-05,
      "loss": 0.0002,
      "step": 7860
    },
    {
      "epoch": 30.468992248062015,
      "grad_norm": 0.0031766940373927355,
      "learning_rate": 1.9531007751937984e-05,
      "loss": 0.0002,
      "step": 7861
    },
    {
      "epoch": 30.472868217054263,
      "grad_norm": 0.0025211439933627844,
      "learning_rate": 1.9527131782945736e-05,
      "loss": 0.0002,
      "step": 7862
    },
    {
      "epoch": 30.476744186046513,
      "grad_norm": 0.08214173465967178,
      "learning_rate": 1.952325581395349e-05,
      "loss": 0.0011,
      "step": 7863
    },
    {
      "epoch": 30.48062015503876,
      "grad_norm": 0.0018000188283622265,
      "learning_rate": 1.951937984496124e-05,
      "loss": 0.0001,
      "step": 7864
    },
    {
      "epoch": 30.484496124031008,
      "grad_norm": 0.007395321037620306,
      "learning_rate": 1.9515503875968993e-05,
      "loss": 0.0002,
      "step": 7865
    },
    {
      "epoch": 30.488372093023255,
      "grad_norm": 0.023686543107032776,
      "learning_rate": 1.9511627906976746e-05,
      "loss": 0.0002,
      "step": 7866
    },
    {
      "epoch": 30.492248062015506,
      "grad_norm": 0.0017005912959575653,
      "learning_rate": 1.9507751937984498e-05,
      "loss": 0.0002,
      "step": 7867
    },
    {
      "epoch": 30.496124031007753,
      "grad_norm": 0.0017721696058288217,
      "learning_rate": 1.950387596899225e-05,
      "loss": 0.0001,
      "step": 7868
    },
    {
      "epoch": 30.5,
      "grad_norm": 0.0020794752053916454,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 0.0001,
      "step": 7869
    },
    {
      "epoch": 30.503875968992247,
      "grad_norm": 0.0020268906373530626,
      "learning_rate": 1.9496124031007752e-05,
      "loss": 0.0002,
      "step": 7870
    },
    {
      "epoch": 30.507751937984494,
      "grad_norm": 0.008815020322799683,
      "learning_rate": 1.9492248062015504e-05,
      "loss": 0.0004,
      "step": 7871
    },
    {
      "epoch": 30.511627906976745,
      "grad_norm": 0.25653189420700073,
      "learning_rate": 1.9488372093023257e-05,
      "loss": 0.0073,
      "step": 7872
    },
    {
      "epoch": 30.515503875968992,
      "grad_norm": 2.0799992084503174,
      "learning_rate": 1.948449612403101e-05,
      "loss": 0.0278,
      "step": 7873
    },
    {
      "epoch": 30.51937984496124,
      "grad_norm": 0.01857933960855007,
      "learning_rate": 1.9480620155038762e-05,
      "loss": 0.0005,
      "step": 7874
    },
    {
      "epoch": 30.52325581395349,
      "grad_norm": 0.003634816501289606,
      "learning_rate": 1.9476744186046514e-05,
      "loss": 0.0002,
      "step": 7875
    },
    {
      "epoch": 30.527131782945737,
      "grad_norm": 1.0971561670303345,
      "learning_rate": 1.9472868217054263e-05,
      "loss": 0.0821,
      "step": 7876
    },
    {
      "epoch": 30.531007751937985,
      "grad_norm": 0.005260577891021967,
      "learning_rate": 1.9468992248062016e-05,
      "loss": 0.0002,
      "step": 7877
    },
    {
      "epoch": 30.53488372093023,
      "grad_norm": 0.018071046099066734,
      "learning_rate": 1.9465116279069768e-05,
      "loss": 0.0008,
      "step": 7878
    },
    {
      "epoch": 30.53875968992248,
      "grad_norm": 0.7663081288337708,
      "learning_rate": 1.946124031007752e-05,
      "loss": 0.0032,
      "step": 7879
    },
    {
      "epoch": 30.54263565891473,
      "grad_norm": 35.35093688964844,
      "learning_rate": 1.9457364341085273e-05,
      "loss": 0.1391,
      "step": 7880
    },
    {
      "epoch": 30.546511627906977,
      "grad_norm": 0.6202336549758911,
      "learning_rate": 1.9453488372093022e-05,
      "loss": 0.013,
      "step": 7881
    },
    {
      "epoch": 30.550387596899224,
      "grad_norm": 0.0018913154490292072,
      "learning_rate": 1.9449612403100774e-05,
      "loss": 0.0001,
      "step": 7882
    },
    {
      "epoch": 30.55426356589147,
      "grad_norm": 0.0018739205552265048,
      "learning_rate": 1.9445736434108527e-05,
      "loss": 0.0002,
      "step": 7883
    },
    {
      "epoch": 30.558139534883722,
      "grad_norm": 0.01714499667286873,
      "learning_rate": 1.944186046511628e-05,
      "loss": 0.0009,
      "step": 7884
    },
    {
      "epoch": 30.56201550387597,
      "grad_norm": 0.003473426215350628,
      "learning_rate": 1.943798449612403e-05,
      "loss": 0.0002,
      "step": 7885
    },
    {
      "epoch": 30.565891472868216,
      "grad_norm": 0.001498079509474337,
      "learning_rate": 1.9434108527131784e-05,
      "loss": 0.0001,
      "step": 7886
    },
    {
      "epoch": 30.569767441860463,
      "grad_norm": 0.0014818502822890878,
      "learning_rate": 1.9430232558139536e-05,
      "loss": 0.0001,
      "step": 7887
    },
    {
      "epoch": 30.573643410852714,
      "grad_norm": 0.0033064689487218857,
      "learning_rate": 1.942635658914729e-05,
      "loss": 0.0003,
      "step": 7888
    },
    {
      "epoch": 30.57751937984496,
      "grad_norm": 0.01387003157287836,
      "learning_rate": 1.942248062015504e-05,
      "loss": 0.0006,
      "step": 7889
    },
    {
      "epoch": 30.58139534883721,
      "grad_norm": 0.0013977029593661427,
      "learning_rate": 1.941860465116279e-05,
      "loss": 0.0001,
      "step": 7890
    },
    {
      "epoch": 30.585271317829456,
      "grad_norm": 1.4568334817886353,
      "learning_rate": 1.9414728682170543e-05,
      "loss": 0.1543,
      "step": 7891
    },
    {
      "epoch": 30.589147286821706,
      "grad_norm": 0.023386923596262932,
      "learning_rate": 1.9410852713178295e-05,
      "loss": 0.0002,
      "step": 7892
    },
    {
      "epoch": 30.593023255813954,
      "grad_norm": 4.881465435028076,
      "learning_rate": 1.9406976744186048e-05,
      "loss": 0.4892,
      "step": 7893
    },
    {
      "epoch": 30.5968992248062,
      "grad_norm": 0.015525802969932556,
      "learning_rate": 1.94031007751938e-05,
      "loss": 0.0007,
      "step": 7894
    },
    {
      "epoch": 30.600775193798448,
      "grad_norm": 0.0013756431872025132,
      "learning_rate": 1.9399224806201552e-05,
      "loss": 0.0001,
      "step": 7895
    },
    {
      "epoch": 30.6046511627907,
      "grad_norm": 0.3114970922470093,
      "learning_rate": 1.9395348837209305e-05,
      "loss": 0.0026,
      "step": 7896
    },
    {
      "epoch": 30.608527131782946,
      "grad_norm": 0.011122521013021469,
      "learning_rate": 1.9391472868217057e-05,
      "loss": 0.0004,
      "step": 7897
    },
    {
      "epoch": 30.612403100775193,
      "grad_norm": 0.8099973797798157,
      "learning_rate": 1.938759689922481e-05,
      "loss": 0.046,
      "step": 7898
    },
    {
      "epoch": 30.61627906976744,
      "grad_norm": 0.002205273136496544,
      "learning_rate": 1.938372093023256e-05,
      "loss": 0.0002,
      "step": 7899
    },
    {
      "epoch": 30.62015503875969,
      "grad_norm": 0.003769263392314315,
      "learning_rate": 1.937984496124031e-05,
      "loss": 0.0002,
      "step": 7900
    },
    {
      "epoch": 30.624031007751938,
      "grad_norm": 0.0011325912782922387,
      "learning_rate": 1.9375968992248064e-05,
      "loss": 0.0001,
      "step": 7901
    },
    {
      "epoch": 30.627906976744185,
      "grad_norm": 0.0013382222969084978,
      "learning_rate": 1.9372093023255816e-05,
      "loss": 0.0001,
      "step": 7902
    },
    {
      "epoch": 30.631782945736433,
      "grad_norm": 0.0022041259799152613,
      "learning_rate": 1.9368217054263565e-05,
      "loss": 0.0001,
      "step": 7903
    },
    {
      "epoch": 30.635658914728683,
      "grad_norm": 0.0013557963538914919,
      "learning_rate": 1.9364341085271317e-05,
      "loss": 0.0001,
      "step": 7904
    },
    {
      "epoch": 30.63953488372093,
      "grad_norm": 1.448828935623169,
      "learning_rate": 1.936046511627907e-05,
      "loss": 0.1201,
      "step": 7905
    },
    {
      "epoch": 30.643410852713178,
      "grad_norm": 0.6194562315940857,
      "learning_rate": 1.9356589147286822e-05,
      "loss": 0.0102,
      "step": 7906
    },
    {
      "epoch": 30.647286821705425,
      "grad_norm": 0.002191605046391487,
      "learning_rate": 1.9352713178294575e-05,
      "loss": 0.0002,
      "step": 7907
    },
    {
      "epoch": 30.651162790697676,
      "grad_norm": 0.0032575763761997223,
      "learning_rate": 1.9348837209302327e-05,
      "loss": 0.0002,
      "step": 7908
    },
    {
      "epoch": 30.655038759689923,
      "grad_norm": 0.002419747645035386,
      "learning_rate": 1.9344961240310076e-05,
      "loss": 0.0002,
      "step": 7909
    },
    {
      "epoch": 30.65891472868217,
      "grad_norm": 0.005352748092263937,
      "learning_rate": 1.934108527131783e-05,
      "loss": 0.0003,
      "step": 7910
    },
    {
      "epoch": 30.662790697674417,
      "grad_norm": 6.05281400680542,
      "learning_rate": 1.933720930232558e-05,
      "loss": 1.0213,
      "step": 7911
    },
    {
      "epoch": 30.666666666666668,
      "grad_norm": 0.001359649351797998,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.0001,
      "step": 7912
    },
    {
      "epoch": 30.670542635658915,
      "grad_norm": 0.0013738373527303338,
      "learning_rate": 1.9329457364341086e-05,
      "loss": 0.0001,
      "step": 7913
    },
    {
      "epoch": 30.674418604651162,
      "grad_norm": 2.5852742195129395,
      "learning_rate": 1.9325581395348838e-05,
      "loss": 0.1608,
      "step": 7914
    },
    {
      "epoch": 30.67829457364341,
      "grad_norm": 0.002620820887386799,
      "learning_rate": 1.932170542635659e-05,
      "loss": 0.0002,
      "step": 7915
    },
    {
      "epoch": 30.68217054263566,
      "grad_norm": 0.01896640844643116,
      "learning_rate": 1.9317829457364343e-05,
      "loss": 0.0005,
      "step": 7916
    },
    {
      "epoch": 30.686046511627907,
      "grad_norm": 0.001488449634052813,
      "learning_rate": 1.9313953488372096e-05,
      "loss": 0.0001,
      "step": 7917
    },
    {
      "epoch": 30.689922480620154,
      "grad_norm": 0.0016865882789716125,
      "learning_rate": 1.9310077519379845e-05,
      "loss": 0.0001,
      "step": 7918
    },
    {
      "epoch": 30.6937984496124,
      "grad_norm": 0.0039058749098330736,
      "learning_rate": 1.9306201550387597e-05,
      "loss": 0.0002,
      "step": 7919
    },
    {
      "epoch": 30.697674418604652,
      "grad_norm": 0.001891260500997305,
      "learning_rate": 1.930232558139535e-05,
      "loss": 0.0001,
      "step": 7920
    },
    {
      "epoch": 30.7015503875969,
      "grad_norm": 0.0024834666401147842,
      "learning_rate": 1.9298449612403102e-05,
      "loss": 0.0002,
      "step": 7921
    },
    {
      "epoch": 30.705426356589147,
      "grad_norm": 0.5959019660949707,
      "learning_rate": 1.9294573643410854e-05,
      "loss": 0.0114,
      "step": 7922
    },
    {
      "epoch": 30.709302325581394,
      "grad_norm": 0.0014986700844019651,
      "learning_rate": 1.9290697674418607e-05,
      "loss": 0.0001,
      "step": 7923
    },
    {
      "epoch": 30.713178294573645,
      "grad_norm": 0.0014548609033226967,
      "learning_rate": 1.928682170542636e-05,
      "loss": 0.0001,
      "step": 7924
    },
    {
      "epoch": 30.717054263565892,
      "grad_norm": 0.001224887790158391,
      "learning_rate": 1.928294573643411e-05,
      "loss": 0.0001,
      "step": 7925
    },
    {
      "epoch": 30.72093023255814,
      "grad_norm": 0.5887383222579956,
      "learning_rate": 1.9279069767441864e-05,
      "loss": 0.0291,
      "step": 7926
    },
    {
      "epoch": 30.724806201550386,
      "grad_norm": 1.7771457433700562,
      "learning_rate": 1.9275193798449613e-05,
      "loss": 0.0241,
      "step": 7927
    },
    {
      "epoch": 30.728682170542637,
      "grad_norm": 30.138626098632812,
      "learning_rate": 1.9271317829457365e-05,
      "loss": 0.0823,
      "step": 7928
    },
    {
      "epoch": 30.732558139534884,
      "grad_norm": 0.04691682755947113,
      "learning_rate": 1.9267441860465118e-05,
      "loss": 0.0002,
      "step": 7929
    },
    {
      "epoch": 30.73643410852713,
      "grad_norm": 0.07518894970417023,
      "learning_rate": 1.9263565891472867e-05,
      "loss": 0.0005,
      "step": 7930
    },
    {
      "epoch": 30.74031007751938,
      "grad_norm": 0.0026784080546349287,
      "learning_rate": 1.925968992248062e-05,
      "loss": 0.0002,
      "step": 7931
    },
    {
      "epoch": 30.74418604651163,
      "grad_norm": 0.008850425481796265,
      "learning_rate": 1.9255813953488372e-05,
      "loss": 0.0003,
      "step": 7932
    },
    {
      "epoch": 30.748062015503876,
      "grad_norm": 0.0014352977741509676,
      "learning_rate": 1.9251937984496124e-05,
      "loss": 0.0001,
      "step": 7933
    },
    {
      "epoch": 30.751937984496124,
      "grad_norm": 2.4436991214752197,
      "learning_rate": 1.9248062015503877e-05,
      "loss": 0.007,
      "step": 7934
    },
    {
      "epoch": 30.75581395348837,
      "grad_norm": 0.001478332793340087,
      "learning_rate": 1.924418604651163e-05,
      "loss": 0.0001,
      "step": 7935
    },
    {
      "epoch": 30.75968992248062,
      "grad_norm": 25.138437271118164,
      "learning_rate": 1.924031007751938e-05,
      "loss": 0.0063,
      "step": 7936
    },
    {
      "epoch": 30.76356589147287,
      "grad_norm": 0.001855662907473743,
      "learning_rate": 1.923643410852713e-05,
      "loss": 0.0002,
      "step": 7937
    },
    {
      "epoch": 30.767441860465116,
      "grad_norm": 0.0018821608973667026,
      "learning_rate": 1.9232558139534883e-05,
      "loss": 0.0002,
      "step": 7938
    },
    {
      "epoch": 30.771317829457363,
      "grad_norm": 0.00431806268170476,
      "learning_rate": 1.9228682170542635e-05,
      "loss": 0.0002,
      "step": 7939
    },
    {
      "epoch": 30.775193798449614,
      "grad_norm": 0.05689745768904686,
      "learning_rate": 1.9224806201550388e-05,
      "loss": 0.0011,
      "step": 7940
    },
    {
      "epoch": 30.77906976744186,
      "grad_norm": 0.001966377953067422,
      "learning_rate": 1.922093023255814e-05,
      "loss": 0.0002,
      "step": 7941
    },
    {
      "epoch": 30.782945736434108,
      "grad_norm": 9.689208030700684,
      "learning_rate": 1.9217054263565893e-05,
      "loss": 0.0081,
      "step": 7942
    },
    {
      "epoch": 30.786821705426355,
      "grad_norm": 0.0013423230266198516,
      "learning_rate": 1.9213178294573645e-05,
      "loss": 0.0001,
      "step": 7943
    },
    {
      "epoch": 30.790697674418606,
      "grad_norm": 0.03406604006886482,
      "learning_rate": 1.9209302325581397e-05,
      "loss": 0.001,
      "step": 7944
    },
    {
      "epoch": 30.794573643410853,
      "grad_norm": 1.0537676811218262,
      "learning_rate": 1.920542635658915e-05,
      "loss": 0.2964,
      "step": 7945
    },
    {
      "epoch": 30.7984496124031,
      "grad_norm": 0.008535148575901985,
      "learning_rate": 1.92015503875969e-05,
      "loss": 0.0005,
      "step": 7946
    },
    {
      "epoch": 30.802325581395348,
      "grad_norm": 0.0015384908765554428,
      "learning_rate": 1.919767441860465e-05,
      "loss": 0.0001,
      "step": 7947
    },
    {
      "epoch": 30.8062015503876,
      "grad_norm": 0.02737640030682087,
      "learning_rate": 1.9193798449612404e-05,
      "loss": 0.0004,
      "step": 7948
    },
    {
      "epoch": 30.810077519379846,
      "grad_norm": 0.0024776991922408342,
      "learning_rate": 1.9189922480620156e-05,
      "loss": 0.0002,
      "step": 7949
    },
    {
      "epoch": 30.813953488372093,
      "grad_norm": 0.016435589641332626,
      "learning_rate": 1.918604651162791e-05,
      "loss": 0.0006,
      "step": 7950
    },
    {
      "epoch": 30.81782945736434,
      "grad_norm": 0.001947923214174807,
      "learning_rate": 1.918217054263566e-05,
      "loss": 0.0002,
      "step": 7951
    },
    {
      "epoch": 30.82170542635659,
      "grad_norm": 0.006126215681433678,
      "learning_rate": 1.9178294573643413e-05,
      "loss": 0.0003,
      "step": 7952
    },
    {
      "epoch": 30.825581395348838,
      "grad_norm": 0.006288603879511356,
      "learning_rate": 1.9174418604651166e-05,
      "loss": 0.0003,
      "step": 7953
    },
    {
      "epoch": 30.829457364341085,
      "grad_norm": 0.0012893234379589558,
      "learning_rate": 1.9170542635658918e-05,
      "loss": 0.0001,
      "step": 7954
    },
    {
      "epoch": 30.833333333333332,
      "grad_norm": 0.013405244797468185,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 0.0004,
      "step": 7955
    },
    {
      "epoch": 30.837209302325583,
      "grad_norm": 0.01414752658456564,
      "learning_rate": 1.916279069767442e-05,
      "loss": 0.0005,
      "step": 7956
    },
    {
      "epoch": 30.84108527131783,
      "grad_norm": 0.008900419808924198,
      "learning_rate": 1.915891472868217e-05,
      "loss": 0.0004,
      "step": 7957
    },
    {
      "epoch": 30.844961240310077,
      "grad_norm": 0.0056123617105185986,
      "learning_rate": 1.915503875968992e-05,
      "loss": 0.0003,
      "step": 7958
    },
    {
      "epoch": 30.848837209302324,
      "grad_norm": 0.694624662399292,
      "learning_rate": 1.9151162790697674e-05,
      "loss": 0.0336,
      "step": 7959
    },
    {
      "epoch": 30.852713178294575,
      "grad_norm": 1.205161213874817,
      "learning_rate": 1.9147286821705426e-05,
      "loss": 0.0579,
      "step": 7960
    },
    {
      "epoch": 30.856589147286822,
      "grad_norm": 0.02698744647204876,
      "learning_rate": 1.914341085271318e-05,
      "loss": 0.001,
      "step": 7961
    },
    {
      "epoch": 30.86046511627907,
      "grad_norm": 0.8835328221321106,
      "learning_rate": 1.913953488372093e-05,
      "loss": 0.0391,
      "step": 7962
    },
    {
      "epoch": 30.864341085271317,
      "grad_norm": 0.0018934850813820958,
      "learning_rate": 1.9135658914728683e-05,
      "loss": 0.0001,
      "step": 7963
    },
    {
      "epoch": 30.868217054263567,
      "grad_norm": 0.02475077658891678,
      "learning_rate": 1.9131782945736436e-05,
      "loss": 0.0005,
      "step": 7964
    },
    {
      "epoch": 30.872093023255815,
      "grad_norm": 0.015441990457475185,
      "learning_rate": 1.9127906976744188e-05,
      "loss": 0.0006,
      "step": 7965
    },
    {
      "epoch": 30.875968992248062,
      "grad_norm": 0.01783791184425354,
      "learning_rate": 1.9124031007751937e-05,
      "loss": 0.0006,
      "step": 7966
    },
    {
      "epoch": 30.87984496124031,
      "grad_norm": 0.006871496792882681,
      "learning_rate": 1.912015503875969e-05,
      "loss": 0.0004,
      "step": 7967
    },
    {
      "epoch": 30.88372093023256,
      "grad_norm": 0.0015804050490260124,
      "learning_rate": 1.9116279069767442e-05,
      "loss": 0.0001,
      "step": 7968
    },
    {
      "epoch": 30.887596899224807,
      "grad_norm": 0.29657986760139465,
      "learning_rate": 1.9112403100775194e-05,
      "loss": 0.0019,
      "step": 7969
    },
    {
      "epoch": 30.891472868217054,
      "grad_norm": 0.014703421853482723,
      "learning_rate": 1.9108527131782947e-05,
      "loss": 0.0006,
      "step": 7970
    },
    {
      "epoch": 30.8953488372093,
      "grad_norm": 26.33574867248535,
      "learning_rate": 1.91046511627907e-05,
      "loss": 0.1301,
      "step": 7971
    },
    {
      "epoch": 30.899224806201552,
      "grad_norm": 0.004389024805277586,
      "learning_rate": 1.910077519379845e-05,
      "loss": 0.0003,
      "step": 7972
    },
    {
      "epoch": 30.9031007751938,
      "grad_norm": 0.002997392090037465,
      "learning_rate": 1.9096899224806204e-05,
      "loss": 0.0002,
      "step": 7973
    },
    {
      "epoch": 30.906976744186046,
      "grad_norm": 1.7023415565490723,
      "learning_rate": 1.9093023255813956e-05,
      "loss": 0.2182,
      "step": 7974
    },
    {
      "epoch": 30.910852713178294,
      "grad_norm": 2.0906548500061035,
      "learning_rate": 1.9089147286821706e-05,
      "loss": 0.2153,
      "step": 7975
    },
    {
      "epoch": 30.914728682170544,
      "grad_norm": 0.002141451695933938,
      "learning_rate": 1.9085271317829458e-05,
      "loss": 0.0002,
      "step": 7976
    },
    {
      "epoch": 30.91860465116279,
      "grad_norm": 0.0027545017655938864,
      "learning_rate": 1.908139534883721e-05,
      "loss": 0.0002,
      "step": 7977
    },
    {
      "epoch": 30.92248062015504,
      "grad_norm": 1.0041663646697998,
      "learning_rate": 1.9077519379844963e-05,
      "loss": 0.1064,
      "step": 7978
    },
    {
      "epoch": 30.926356589147286,
      "grad_norm": 0.015341063030064106,
      "learning_rate": 1.9073643410852715e-05,
      "loss": 0.0005,
      "step": 7979
    },
    {
      "epoch": 30.930232558139537,
      "grad_norm": 0.08443259447813034,
      "learning_rate": 1.9069767441860468e-05,
      "loss": 0.0027,
      "step": 7980
    },
    {
      "epoch": 30.934108527131784,
      "grad_norm": 1.252131462097168,
      "learning_rate": 1.906589147286822e-05,
      "loss": 0.0064,
      "step": 7981
    },
    {
      "epoch": 30.93798449612403,
      "grad_norm": 0.12023197114467621,
      "learning_rate": 1.9062015503875972e-05,
      "loss": 0.0023,
      "step": 7982
    },
    {
      "epoch": 30.941860465116278,
      "grad_norm": 0.06226944923400879,
      "learning_rate": 1.905813953488372e-05,
      "loss": 0.0012,
      "step": 7983
    },
    {
      "epoch": 30.94573643410853,
      "grad_norm": 0.23495569825172424,
      "learning_rate": 1.9054263565891474e-05,
      "loss": 0.006,
      "step": 7984
    },
    {
      "epoch": 30.949612403100776,
      "grad_norm": 0.04714662581682205,
      "learning_rate": 1.9050387596899223e-05,
      "loss": 0.0011,
      "step": 7985
    },
    {
      "epoch": 30.953488372093023,
      "grad_norm": 0.24270641803741455,
      "learning_rate": 1.9046511627906975e-05,
      "loss": 0.0037,
      "step": 7986
    },
    {
      "epoch": 30.95736434108527,
      "grad_norm": 0.16391755640506744,
      "learning_rate": 1.9042635658914728e-05,
      "loss": 0.005,
      "step": 7987
    },
    {
      "epoch": 30.96124031007752,
      "grad_norm": 0.047224342823028564,
      "learning_rate": 1.903875968992248e-05,
      "loss": 0.0013,
      "step": 7988
    },
    {
      "epoch": 30.96511627906977,
      "grad_norm": 0.1312841773033142,
      "learning_rate": 1.9034883720930233e-05,
      "loss": 0.0035,
      "step": 7989
    },
    {
      "epoch": 30.968992248062015,
      "grad_norm": 0.1226314827799797,
      "learning_rate": 1.9031007751937985e-05,
      "loss": 0.0036,
      "step": 7990
    },
    {
      "epoch": 30.972868217054263,
      "grad_norm": 0.10713181644678116,
      "learning_rate": 1.9027131782945737e-05,
      "loss": 0.0028,
      "step": 7991
    },
    {
      "epoch": 30.97674418604651,
      "grad_norm": 0.06739955395460129,
      "learning_rate": 1.902325581395349e-05,
      "loss": 0.002,
      "step": 7992
    },
    {
      "epoch": 30.98062015503876,
      "grad_norm": 0.003990051336586475,
      "learning_rate": 1.9019379844961242e-05,
      "loss": 0.0003,
      "step": 7993
    },
    {
      "epoch": 30.984496124031008,
      "grad_norm": 14.58830738067627,
      "learning_rate": 1.901550387596899e-05,
      "loss": 0.0186,
      "step": 7994
    },
    {
      "epoch": 30.988372093023255,
      "grad_norm": 0.008541872724890709,
      "learning_rate": 1.9011627906976744e-05,
      "loss": 0.0004,
      "step": 7995
    },
    {
      "epoch": 30.992248062015506,
      "grad_norm": 0.02301822043955326,
      "learning_rate": 1.9007751937984496e-05,
      "loss": 0.0008,
      "step": 7996
    },
    {
      "epoch": 30.996124031007753,
      "grad_norm": 0.0015981908654794097,
      "learning_rate": 1.900387596899225e-05,
      "loss": 0.0001,
      "step": 7997
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.0074098603799939156,
      "learning_rate": 1.9e-05,
      "loss": 0.0003,
      "step": 7998
    },
    {
      "epoch": 31.003875968992247,
      "grad_norm": 0.0016651097685098648,
      "learning_rate": 1.8996124031007753e-05,
      "loss": 0.0001,
      "step": 7999
    },
    {
      "epoch": 31.007751937984494,
      "grad_norm": 0.0058684092946350574,
      "learning_rate": 1.8992248062015506e-05,
      "loss": 0.0003,
      "step": 8000
    },
    {
      "epoch": 31.011627906976745,
      "grad_norm": 0.045683812350034714,
      "learning_rate": 1.898837209302326e-05,
      "loss": 0.0006,
      "step": 8001
    },
    {
      "epoch": 31.015503875968992,
      "grad_norm": 0.0019624645356088877,
      "learning_rate": 1.898449612403101e-05,
      "loss": 0.0001,
      "step": 8002
    },
    {
      "epoch": 31.01937984496124,
      "grad_norm": 0.00468798354268074,
      "learning_rate": 1.898062015503876e-05,
      "loss": 0.0003,
      "step": 8003
    },
    {
      "epoch": 31.023255813953487,
      "grad_norm": 0.0024082544259727,
      "learning_rate": 1.8976744186046512e-05,
      "loss": 0.0002,
      "step": 8004
    },
    {
      "epoch": 31.027131782945737,
      "grad_norm": 0.008627530187368393,
      "learning_rate": 1.8972868217054265e-05,
      "loss": 0.0003,
      "step": 8005
    },
    {
      "epoch": 31.031007751937985,
      "grad_norm": 0.004851139150559902,
      "learning_rate": 1.8968992248062017e-05,
      "loss": 0.0003,
      "step": 8006
    },
    {
      "epoch": 31.03488372093023,
      "grad_norm": 0.19380371272563934,
      "learning_rate": 1.896511627906977e-05,
      "loss": 0.0017,
      "step": 8007
    },
    {
      "epoch": 31.03875968992248,
      "grad_norm": 0.004046218004077673,
      "learning_rate": 1.8961240310077522e-05,
      "loss": 0.0003,
      "step": 8008
    },
    {
      "epoch": 31.04263565891473,
      "grad_norm": 0.0034120059572160244,
      "learning_rate": 1.8957364341085274e-05,
      "loss": 0.0002,
      "step": 8009
    },
    {
      "epoch": 31.046511627906977,
      "grad_norm": 0.005681537091732025,
      "learning_rate": 1.8953488372093023e-05,
      "loss": 0.0003,
      "step": 8010
    },
    {
      "epoch": 31.050387596899224,
      "grad_norm": 0.00845436193048954,
      "learning_rate": 1.8949612403100776e-05,
      "loss": 0.0004,
      "step": 8011
    },
    {
      "epoch": 31.05426356589147,
      "grad_norm": 0.026563817635178566,
      "learning_rate": 1.8945736434108528e-05,
      "loss": 0.0007,
      "step": 8012
    },
    {
      "epoch": 31.058139534883722,
      "grad_norm": 0.0017883273540064692,
      "learning_rate": 1.894186046511628e-05,
      "loss": 0.0001,
      "step": 8013
    },
    {
      "epoch": 31.06201550387597,
      "grad_norm": 0.008128458634018898,
      "learning_rate": 1.893798449612403e-05,
      "loss": 0.0004,
      "step": 8014
    },
    {
      "epoch": 31.065891472868216,
      "grad_norm": 0.0026028582360595465,
      "learning_rate": 1.8934108527131782e-05,
      "loss": 0.0002,
      "step": 8015
    },
    {
      "epoch": 31.069767441860463,
      "grad_norm": 0.23490798473358154,
      "learning_rate": 1.8930232558139534e-05,
      "loss": 0.0089,
      "step": 8016
    },
    {
      "epoch": 31.073643410852714,
      "grad_norm": 1.52165949344635,
      "learning_rate": 1.8926356589147287e-05,
      "loss": 0.0622,
      "step": 8017
    },
    {
      "epoch": 31.07751937984496,
      "grad_norm": 0.0025641112588346004,
      "learning_rate": 1.892248062015504e-05,
      "loss": 0.0002,
      "step": 8018
    },
    {
      "epoch": 31.08139534883721,
      "grad_norm": 0.004463465418666601,
      "learning_rate": 1.8918604651162792e-05,
      "loss": 0.0002,
      "step": 8019
    },
    {
      "epoch": 31.085271317829456,
      "grad_norm": 0.003945630043745041,
      "learning_rate": 1.8914728682170544e-05,
      "loss": 0.0002,
      "step": 8020
    },
    {
      "epoch": 31.089147286821706,
      "grad_norm": 0.0035979067906737328,
      "learning_rate": 1.8910852713178297e-05,
      "loss": 0.0002,
      "step": 8021
    },
    {
      "epoch": 31.093023255813954,
      "grad_norm": 0.9275248646736145,
      "learning_rate": 1.890697674418605e-05,
      "loss": 0.0148,
      "step": 8022
    },
    {
      "epoch": 31.0968992248062,
      "grad_norm": 0.0027933530509471893,
      "learning_rate": 1.8903100775193798e-05,
      "loss": 0.0002,
      "step": 8023
    },
    {
      "epoch": 31.100775193798448,
      "grad_norm": 0.00377170299179852,
      "learning_rate": 1.889922480620155e-05,
      "loss": 0.0003,
      "step": 8024
    },
    {
      "epoch": 31.1046511627907,
      "grad_norm": 0.002618871396407485,
      "learning_rate": 1.8895348837209303e-05,
      "loss": 0.0002,
      "step": 8025
    },
    {
      "epoch": 31.108527131782946,
      "grad_norm": 0.0018462181324139237,
      "learning_rate": 1.8891472868217055e-05,
      "loss": 0.0001,
      "step": 8026
    },
    {
      "epoch": 31.112403100775193,
      "grad_norm": 0.001297332113608718,
      "learning_rate": 1.8887596899224808e-05,
      "loss": 0.0001,
      "step": 8027
    },
    {
      "epoch": 31.11627906976744,
      "grad_norm": 0.005219331011176109,
      "learning_rate": 1.888372093023256e-05,
      "loss": 0.0003,
      "step": 8028
    },
    {
      "epoch": 31.12015503875969,
      "grad_norm": 0.0025394477415829897,
      "learning_rate": 1.8879844961240313e-05,
      "loss": 0.0002,
      "step": 8029
    },
    {
      "epoch": 31.124031007751938,
      "grad_norm": 0.002722597448155284,
      "learning_rate": 1.8875968992248065e-05,
      "loss": 0.0002,
      "step": 8030
    },
    {
      "epoch": 31.127906976744185,
      "grad_norm": 0.0028623640537261963,
      "learning_rate": 1.8872093023255817e-05,
      "loss": 0.0002,
      "step": 8031
    },
    {
      "epoch": 31.131782945736433,
      "grad_norm": 0.005896895192563534,
      "learning_rate": 1.8868217054263566e-05,
      "loss": 0.0004,
      "step": 8032
    },
    {
      "epoch": 31.135658914728683,
      "grad_norm": 0.0016725383466109633,
      "learning_rate": 1.886434108527132e-05,
      "loss": 0.0001,
      "step": 8033
    },
    {
      "epoch": 31.13953488372093,
      "grad_norm": 0.004861836321651936,
      "learning_rate": 1.886046511627907e-05,
      "loss": 0.0004,
      "step": 8034
    },
    {
      "epoch": 31.143410852713178,
      "grad_norm": 0.0033628270030021667,
      "learning_rate": 1.8856589147286824e-05,
      "loss": 0.0002,
      "step": 8035
    },
    {
      "epoch": 31.147286821705425,
      "grad_norm": 1.4745255708694458,
      "learning_rate": 1.8852713178294573e-05,
      "loss": 0.1566,
      "step": 8036
    },
    {
      "epoch": 31.151162790697676,
      "grad_norm": 0.003883958328515291,
      "learning_rate": 1.8848837209302325e-05,
      "loss": 0.0003,
      "step": 8037
    },
    {
      "epoch": 31.155038759689923,
      "grad_norm": 0.01089798379689455,
      "learning_rate": 1.8844961240310078e-05,
      "loss": 0.0005,
      "step": 8038
    },
    {
      "epoch": 31.15891472868217,
      "grad_norm": 0.006482149474322796,
      "learning_rate": 1.884108527131783e-05,
      "loss": 0.0003,
      "step": 8039
    },
    {
      "epoch": 31.162790697674417,
      "grad_norm": 0.0014049141900613904,
      "learning_rate": 1.8837209302325582e-05,
      "loss": 0.0001,
      "step": 8040
    },
    {
      "epoch": 31.166666666666668,
      "grad_norm": 0.005466509610414505,
      "learning_rate": 1.8833333333333335e-05,
      "loss": 0.0002,
      "step": 8041
    },
    {
      "epoch": 31.170542635658915,
      "grad_norm": 0.0025480161421000957,
      "learning_rate": 1.8829457364341084e-05,
      "loss": 0.0001,
      "step": 8042
    },
    {
      "epoch": 31.174418604651162,
      "grad_norm": 14.313009262084961,
      "learning_rate": 1.8825581395348836e-05,
      "loss": 0.0928,
      "step": 8043
    },
    {
      "epoch": 31.17829457364341,
      "grad_norm": 0.001572314533405006,
      "learning_rate": 1.882170542635659e-05,
      "loss": 0.0001,
      "step": 8044
    },
    {
      "epoch": 31.18217054263566,
      "grad_norm": 0.012609722092747688,
      "learning_rate": 1.881782945736434e-05,
      "loss": 0.0004,
      "step": 8045
    },
    {
      "epoch": 31.186046511627907,
      "grad_norm": 0.0019204170675948262,
      "learning_rate": 1.8813953488372094e-05,
      "loss": 0.0002,
      "step": 8046
    },
    {
      "epoch": 31.189922480620154,
      "grad_norm": 0.0012835300294682384,
      "learning_rate": 1.8810077519379846e-05,
      "loss": 0.0001,
      "step": 8047
    },
    {
      "epoch": 31.1937984496124,
      "grad_norm": 0.0018517345888540149,
      "learning_rate": 1.88062015503876e-05,
      "loss": 0.0001,
      "step": 8048
    },
    {
      "epoch": 31.197674418604652,
      "grad_norm": 0.01295199804008007,
      "learning_rate": 1.880232558139535e-05,
      "loss": 0.0005,
      "step": 8049
    },
    {
      "epoch": 31.2015503875969,
      "grad_norm": 3.1073808670043945,
      "learning_rate": 1.8798449612403103e-05,
      "loss": 0.0039,
      "step": 8050
    },
    {
      "epoch": 31.205426356589147,
      "grad_norm": 10.965299606323242,
      "learning_rate": 1.8794573643410852e-05,
      "loss": 0.3552,
      "step": 8051
    },
    {
      "epoch": 31.209302325581394,
      "grad_norm": 0.12843389809131622,
      "learning_rate": 1.8790697674418605e-05,
      "loss": 0.0018,
      "step": 8052
    },
    {
      "epoch": 31.213178294573645,
      "grad_norm": 0.001977610867470503,
      "learning_rate": 1.8786821705426357e-05,
      "loss": 0.0002,
      "step": 8053
    },
    {
      "epoch": 31.217054263565892,
      "grad_norm": 0.02606174908578396,
      "learning_rate": 1.878294573643411e-05,
      "loss": 0.0008,
      "step": 8054
    },
    {
      "epoch": 31.22093023255814,
      "grad_norm": 0.01503734104335308,
      "learning_rate": 1.8779069767441862e-05,
      "loss": 0.0006,
      "step": 8055
    },
    {
      "epoch": 31.224806201550386,
      "grad_norm": 0.01966286450624466,
      "learning_rate": 1.8775193798449614e-05,
      "loss": 0.0007,
      "step": 8056
    },
    {
      "epoch": 31.228682170542637,
      "grad_norm": 0.0014910281170159578,
      "learning_rate": 1.8771317829457367e-05,
      "loss": 0.0001,
      "step": 8057
    },
    {
      "epoch": 31.232558139534884,
      "grad_norm": 0.0012880564900115132,
      "learning_rate": 1.876744186046512e-05,
      "loss": 0.0001,
      "step": 8058
    },
    {
      "epoch": 31.23643410852713,
      "grad_norm": 0.001575682545080781,
      "learning_rate": 1.876356589147287e-05,
      "loss": 0.0001,
      "step": 8059
    },
    {
      "epoch": 31.24031007751938,
      "grad_norm": 6.161662578582764,
      "learning_rate": 1.875968992248062e-05,
      "loss": 0.4391,
      "step": 8060
    },
    {
      "epoch": 31.24418604651163,
      "grad_norm": 1.2863945960998535,
      "learning_rate": 1.8755813953488373e-05,
      "loss": 0.0957,
      "step": 8061
    },
    {
      "epoch": 31.248062015503876,
      "grad_norm": 22.362337112426758,
      "learning_rate": 1.8751937984496126e-05,
      "loss": 0.4397,
      "step": 8062
    },
    {
      "epoch": 31.251937984496124,
      "grad_norm": 0.01010836660861969,
      "learning_rate": 1.8748062015503875e-05,
      "loss": 0.0004,
      "step": 8063
    },
    {
      "epoch": 31.25581395348837,
      "grad_norm": 1.0822722911834717,
      "learning_rate": 1.8744186046511627e-05,
      "loss": 0.0683,
      "step": 8064
    },
    {
      "epoch": 31.25968992248062,
      "grad_norm": 0.01985793374478817,
      "learning_rate": 1.874031007751938e-05,
      "loss": 0.0007,
      "step": 8065
    },
    {
      "epoch": 31.26356589147287,
      "grad_norm": 0.0012536500580608845,
      "learning_rate": 1.8736434108527132e-05,
      "loss": 0.0001,
      "step": 8066
    },
    {
      "epoch": 31.267441860465116,
      "grad_norm": 0.02273288369178772,
      "learning_rate": 1.8732558139534884e-05,
      "loss": 0.0009,
      "step": 8067
    },
    {
      "epoch": 31.271317829457363,
      "grad_norm": 0.003927923273295164,
      "learning_rate": 1.8728682170542637e-05,
      "loss": 0.0003,
      "step": 8068
    },
    {
      "epoch": 31.275193798449614,
      "grad_norm": 0.01736404187977314,
      "learning_rate": 1.872480620155039e-05,
      "loss": 0.0006,
      "step": 8069
    },
    {
      "epoch": 31.27906976744186,
      "grad_norm": 0.014890202321112156,
      "learning_rate": 1.8720930232558138e-05,
      "loss": 0.0005,
      "step": 8070
    },
    {
      "epoch": 31.282945736434108,
      "grad_norm": 0.15422296524047852,
      "learning_rate": 1.871705426356589e-05,
      "loss": 0.0059,
      "step": 8071
    },
    {
      "epoch": 31.286821705426355,
      "grad_norm": 0.011967129074037075,
      "learning_rate": 1.8713178294573643e-05,
      "loss": 0.0005,
      "step": 8072
    },
    {
      "epoch": 31.290697674418606,
      "grad_norm": 0.008543028496205807,
      "learning_rate": 1.8709302325581395e-05,
      "loss": 0.0004,
      "step": 8073
    },
    {
      "epoch": 31.294573643410853,
      "grad_norm": 0.01900467835366726,
      "learning_rate": 1.8705426356589148e-05,
      "loss": 0.0009,
      "step": 8074
    },
    {
      "epoch": 31.2984496124031,
      "grad_norm": 0.0076684667728841305,
      "learning_rate": 1.87015503875969e-05,
      "loss": 0.0004,
      "step": 8075
    },
    {
      "epoch": 31.302325581395348,
      "grad_norm": 0.012968329712748528,
      "learning_rate": 1.8697674418604653e-05,
      "loss": 0.0006,
      "step": 8076
    },
    {
      "epoch": 31.3062015503876,
      "grad_norm": 0.01348154153674841,
      "learning_rate": 1.8693798449612405e-05,
      "loss": 0.0005,
      "step": 8077
    },
    {
      "epoch": 31.310077519379846,
      "grad_norm": 0.013060355558991432,
      "learning_rate": 1.8689922480620158e-05,
      "loss": 0.0005,
      "step": 8078
    },
    {
      "epoch": 31.313953488372093,
      "grad_norm": 0.010473532602190971,
      "learning_rate": 1.8686046511627907e-05,
      "loss": 0.0004,
      "step": 8079
    },
    {
      "epoch": 31.31782945736434,
      "grad_norm": 0.0031869818922132254,
      "learning_rate": 1.868217054263566e-05,
      "loss": 0.0002,
      "step": 8080
    },
    {
      "epoch": 31.32170542635659,
      "grad_norm": 0.00860903225839138,
      "learning_rate": 1.867829457364341e-05,
      "loss": 0.0004,
      "step": 8081
    },
    {
      "epoch": 31.325581395348838,
      "grad_norm": 0.006491354200989008,
      "learning_rate": 1.8674418604651164e-05,
      "loss": 0.0003,
      "step": 8082
    },
    {
      "epoch": 31.329457364341085,
      "grad_norm": 0.009964109398424625,
      "learning_rate": 1.8670542635658916e-05,
      "loss": 0.0005,
      "step": 8083
    },
    {
      "epoch": 31.333333333333332,
      "grad_norm": 0.001852883375249803,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.0002,
      "step": 8084
    },
    {
      "epoch": 31.337209302325583,
      "grad_norm": 1.6528077125549316,
      "learning_rate": 1.866279069767442e-05,
      "loss": 0.0072,
      "step": 8085
    },
    {
      "epoch": 31.34108527131783,
      "grad_norm": 5.361225128173828,
      "learning_rate": 1.8658914728682173e-05,
      "loss": 0.7154,
      "step": 8086
    },
    {
      "epoch": 31.344961240310077,
      "grad_norm": 0.9974234104156494,
      "learning_rate": 1.8655038759689926e-05,
      "loss": 0.091,
      "step": 8087
    },
    {
      "epoch": 31.348837209302324,
      "grad_norm": 0.21602776646614075,
      "learning_rate": 1.8651162790697675e-05,
      "loss": 0.0092,
      "step": 8088
    },
    {
      "epoch": 31.352713178294575,
      "grad_norm": 1.0957214832305908,
      "learning_rate": 1.8647286821705427e-05,
      "loss": 0.0039,
      "step": 8089
    },
    {
      "epoch": 31.356589147286822,
      "grad_norm": 0.006935499142855406,
      "learning_rate": 1.8643410852713176e-05,
      "loss": 0.0003,
      "step": 8090
    },
    {
      "epoch": 31.36046511627907,
      "grad_norm": 1.2570685148239136,
      "learning_rate": 1.863953488372093e-05,
      "loss": 0.0803,
      "step": 8091
    },
    {
      "epoch": 31.364341085271317,
      "grad_norm": 0.021707706153392792,
      "learning_rate": 1.863565891472868e-05,
      "loss": 0.0005,
      "step": 8092
    },
    {
      "epoch": 31.368217054263567,
      "grad_norm": 0.0037211787421256304,
      "learning_rate": 1.8631782945736434e-05,
      "loss": 0.0002,
      "step": 8093
    },
    {
      "epoch": 31.372093023255815,
      "grad_norm": 0.004560688976198435,
      "learning_rate": 1.8627906976744186e-05,
      "loss": 0.0003,
      "step": 8094
    },
    {
      "epoch": 31.375968992248062,
      "grad_norm": 0.005222752224653959,
      "learning_rate": 1.862403100775194e-05,
      "loss": 0.0003,
      "step": 8095
    },
    {
      "epoch": 31.37984496124031,
      "grad_norm": 0.004074763506650925,
      "learning_rate": 1.862015503875969e-05,
      "loss": 0.0002,
      "step": 8096
    },
    {
      "epoch": 31.38372093023256,
      "grad_norm": 0.0036216811276972294,
      "learning_rate": 1.8616279069767443e-05,
      "loss": 0.0002,
      "step": 8097
    },
    {
      "epoch": 31.387596899224807,
      "grad_norm": 0.00443347729742527,
      "learning_rate": 1.8612403100775196e-05,
      "loss": 0.0003,
      "step": 8098
    },
    {
      "epoch": 31.391472868217054,
      "grad_norm": 0.0016111131990328431,
      "learning_rate": 1.8608527131782945e-05,
      "loss": 0.0001,
      "step": 8099
    },
    {
      "epoch": 31.3953488372093,
      "grad_norm": 0.01458791084587574,
      "learning_rate": 1.8604651162790697e-05,
      "loss": 0.0005,
      "step": 8100
    },
    {
      "epoch": 31.399224806201552,
      "grad_norm": 0.003780969185754657,
      "learning_rate": 1.860077519379845e-05,
      "loss": 0.0002,
      "step": 8101
    },
    {
      "epoch": 31.4031007751938,
      "grad_norm": 0.006977942306548357,
      "learning_rate": 1.8596899224806202e-05,
      "loss": 0.0004,
      "step": 8102
    },
    {
      "epoch": 31.406976744186046,
      "grad_norm": 0.007587546948343515,
      "learning_rate": 1.8593023255813954e-05,
      "loss": 0.0005,
      "step": 8103
    },
    {
      "epoch": 31.410852713178294,
      "grad_norm": 0.6911977529525757,
      "learning_rate": 1.8589147286821707e-05,
      "loss": 0.0256,
      "step": 8104
    },
    {
      "epoch": 31.414728682170544,
      "grad_norm": 0.010931011289358139,
      "learning_rate": 1.858527131782946e-05,
      "loss": 0.0006,
      "step": 8105
    },
    {
      "epoch": 31.41860465116279,
      "grad_norm": 0.03446590527892113,
      "learning_rate": 1.8581395348837212e-05,
      "loss": 0.0007,
      "step": 8106
    },
    {
      "epoch": 31.42248062015504,
      "grad_norm": 0.002387630520388484,
      "learning_rate": 1.8577519379844964e-05,
      "loss": 0.0002,
      "step": 8107
    },
    {
      "epoch": 31.426356589147286,
      "grad_norm": 0.0013756813714280725,
      "learning_rate": 1.8573643410852713e-05,
      "loss": 0.0001,
      "step": 8108
    },
    {
      "epoch": 31.430232558139537,
      "grad_norm": 7.200122356414795,
      "learning_rate": 1.8569767441860466e-05,
      "loss": 0.0896,
      "step": 8109
    },
    {
      "epoch": 31.434108527131784,
      "grad_norm": 0.003573537105694413,
      "learning_rate": 1.8565891472868218e-05,
      "loss": 0.0002,
      "step": 8110
    },
    {
      "epoch": 31.43798449612403,
      "grad_norm": 11.54825496673584,
      "learning_rate": 1.856201550387597e-05,
      "loss": 0.1076,
      "step": 8111
    },
    {
      "epoch": 31.441860465116278,
      "grad_norm": 0.0021864555310457945,
      "learning_rate": 1.8558139534883723e-05,
      "loss": 0.0002,
      "step": 8112
    },
    {
      "epoch": 31.44573643410853,
      "grad_norm": 0.006028174422681332,
      "learning_rate": 1.8554263565891475e-05,
      "loss": 0.0004,
      "step": 8113
    },
    {
      "epoch": 31.449612403100776,
      "grad_norm": 0.00315113109536469,
      "learning_rate": 1.8550387596899228e-05,
      "loss": 0.0002,
      "step": 8114
    },
    {
      "epoch": 31.453488372093023,
      "grad_norm": 21.599870681762695,
      "learning_rate": 1.854651162790698e-05,
      "loss": 0.093,
      "step": 8115
    },
    {
      "epoch": 31.45736434108527,
      "grad_norm": 0.003428658237680793,
      "learning_rate": 1.854263565891473e-05,
      "loss": 0.0002,
      "step": 8116
    },
    {
      "epoch": 31.46124031007752,
      "grad_norm": 0.0024930646177381277,
      "learning_rate": 1.853875968992248e-05,
      "loss": 0.0002,
      "step": 8117
    },
    {
      "epoch": 31.46511627906977,
      "grad_norm": 0.002504154806956649,
      "learning_rate": 1.853488372093023e-05,
      "loss": 0.0002,
      "step": 8118
    },
    {
      "epoch": 31.468992248062015,
      "grad_norm": 0.0015734699554741383,
      "learning_rate": 1.8531007751937983e-05,
      "loss": 0.0001,
      "step": 8119
    },
    {
      "epoch": 31.472868217054263,
      "grad_norm": 0.0036763534881174564,
      "learning_rate": 1.8527131782945735e-05,
      "loss": 0.0003,
      "step": 8120
    },
    {
      "epoch": 31.476744186046513,
      "grad_norm": 0.002425611251965165,
      "learning_rate": 1.8523255813953488e-05,
      "loss": 0.0002,
      "step": 8121
    },
    {
      "epoch": 31.48062015503876,
      "grad_norm": 0.0011959689436480403,
      "learning_rate": 1.851937984496124e-05,
      "loss": 0.0001,
      "step": 8122
    },
    {
      "epoch": 31.484496124031008,
      "grad_norm": 0.0018904332537204027,
      "learning_rate": 1.8515503875968993e-05,
      "loss": 0.0002,
      "step": 8123
    },
    {
      "epoch": 31.488372093023255,
      "grad_norm": 0.0027208682149648666,
      "learning_rate": 1.8511627906976745e-05,
      "loss": 0.0002,
      "step": 8124
    },
    {
      "epoch": 31.492248062015506,
      "grad_norm": 26.410907745361328,
      "learning_rate": 1.8507751937984498e-05,
      "loss": 0.7591,
      "step": 8125
    },
    {
      "epoch": 31.496124031007753,
      "grad_norm": 0.00331667042337358,
      "learning_rate": 1.850387596899225e-05,
      "loss": 0.0002,
      "step": 8126
    },
    {
      "epoch": 31.5,
      "grad_norm": 0.012493791058659554,
      "learning_rate": 1.85e-05,
      "loss": 0.0006,
      "step": 8127
    },
    {
      "epoch": 31.503875968992247,
      "grad_norm": 0.0023263704497367144,
      "learning_rate": 1.849612403100775e-05,
      "loss": 0.0002,
      "step": 8128
    },
    {
      "epoch": 31.507751937984494,
      "grad_norm": 2.627230405807495,
      "learning_rate": 1.8492248062015504e-05,
      "loss": 0.13,
      "step": 8129
    },
    {
      "epoch": 31.511627906976745,
      "grad_norm": 0.0023836807813495398,
      "learning_rate": 1.8488372093023256e-05,
      "loss": 0.0002,
      "step": 8130
    },
    {
      "epoch": 31.515503875968992,
      "grad_norm": 0.06614603102207184,
      "learning_rate": 1.848449612403101e-05,
      "loss": 0.0006,
      "step": 8131
    },
    {
      "epoch": 31.51937984496124,
      "grad_norm": 0.0012071258388459682,
      "learning_rate": 1.848062015503876e-05,
      "loss": 0.0001,
      "step": 8132
    },
    {
      "epoch": 31.52325581395349,
      "grad_norm": 0.003641620511189103,
      "learning_rate": 1.8476744186046514e-05,
      "loss": 0.0003,
      "step": 8133
    },
    {
      "epoch": 31.527131782945737,
      "grad_norm": 0.0065766796469688416,
      "learning_rate": 1.8472868217054266e-05,
      "loss": 0.0002,
      "step": 8134
    },
    {
      "epoch": 31.531007751937985,
      "grad_norm": 0.0016661620466038585,
      "learning_rate": 1.846899224806202e-05,
      "loss": 0.0002,
      "step": 8135
    },
    {
      "epoch": 31.53488372093023,
      "grad_norm": 0.13292399048805237,
      "learning_rate": 1.8465116279069767e-05,
      "loss": 0.0009,
      "step": 8136
    },
    {
      "epoch": 31.53875968992248,
      "grad_norm": 0.028886688873171806,
      "learning_rate": 1.846124031007752e-05,
      "loss": 0.0006,
      "step": 8137
    },
    {
      "epoch": 31.54263565891473,
      "grad_norm": 0.002466629259288311,
      "learning_rate": 1.8457364341085272e-05,
      "loss": 0.0002,
      "step": 8138
    },
    {
      "epoch": 31.546511627906977,
      "grad_norm": 0.016833757981657982,
      "learning_rate": 1.8453488372093025e-05,
      "loss": 0.0006,
      "step": 8139
    },
    {
      "epoch": 31.550387596899224,
      "grad_norm": 0.033076345920562744,
      "learning_rate": 1.8449612403100777e-05,
      "loss": 0.0004,
      "step": 8140
    },
    {
      "epoch": 31.55426356589147,
      "grad_norm": 0.006479383446276188,
      "learning_rate": 1.844573643410853e-05,
      "loss": 0.0004,
      "step": 8141
    },
    {
      "epoch": 31.558139534883722,
      "grad_norm": 0.004304301925003529,
      "learning_rate": 1.8441860465116282e-05,
      "loss": 0.0002,
      "step": 8142
    },
    {
      "epoch": 31.56201550387597,
      "grad_norm": 0.0017506086733192205,
      "learning_rate": 1.843798449612403e-05,
      "loss": 0.0001,
      "step": 8143
    },
    {
      "epoch": 31.565891472868216,
      "grad_norm": 9.902485847473145,
      "learning_rate": 1.8434108527131783e-05,
      "loss": 0.1688,
      "step": 8144
    },
    {
      "epoch": 31.569767441860463,
      "grad_norm": 0.002681964309886098,
      "learning_rate": 1.8430232558139536e-05,
      "loss": 0.0002,
      "step": 8145
    },
    {
      "epoch": 31.573643410852714,
      "grad_norm": 0.0038189594633877277,
      "learning_rate": 1.8426356589147288e-05,
      "loss": 0.0003,
      "step": 8146
    },
    {
      "epoch": 31.57751937984496,
      "grad_norm": 0.005130615551024675,
      "learning_rate": 1.8422480620155037e-05,
      "loss": 0.0002,
      "step": 8147
    },
    {
      "epoch": 31.58139534883721,
      "grad_norm": 0.005303959362208843,
      "learning_rate": 1.841860465116279e-05,
      "loss": 0.0003,
      "step": 8148
    },
    {
      "epoch": 31.585271317829456,
      "grad_norm": 0.0026066345162689686,
      "learning_rate": 1.8414728682170542e-05,
      "loss": 0.0002,
      "step": 8149
    },
    {
      "epoch": 31.589147286821706,
      "grad_norm": 0.017264975234866142,
      "learning_rate": 1.8410852713178295e-05,
      "loss": 0.0005,
      "step": 8150
    },
    {
      "epoch": 31.593023255813954,
      "grad_norm": 0.003284125356003642,
      "learning_rate": 1.8406976744186047e-05,
      "loss": 0.0002,
      "step": 8151
    },
    {
      "epoch": 31.5968992248062,
      "grad_norm": 0.0032743504270911217,
      "learning_rate": 1.84031007751938e-05,
      "loss": 0.0002,
      "step": 8152
    },
    {
      "epoch": 31.600775193798448,
      "grad_norm": 0.0018038906855508685,
      "learning_rate": 1.8399224806201552e-05,
      "loss": 0.0002,
      "step": 8153
    },
    {
      "epoch": 31.6046511627907,
      "grad_norm": 0.013296743854880333,
      "learning_rate": 1.8395348837209304e-05,
      "loss": 0.0002,
      "step": 8154
    },
    {
      "epoch": 31.608527131782946,
      "grad_norm": 0.00723343575373292,
      "learning_rate": 1.8391472868217057e-05,
      "loss": 0.0004,
      "step": 8155
    },
    {
      "epoch": 31.612403100775193,
      "grad_norm": 0.009581322781741619,
      "learning_rate": 1.8387596899224806e-05,
      "loss": 0.0005,
      "step": 8156
    },
    {
      "epoch": 31.61627906976744,
      "grad_norm": 3.103726387023926,
      "learning_rate": 1.8383720930232558e-05,
      "loss": 0.4624,
      "step": 8157
    },
    {
      "epoch": 31.62015503875969,
      "grad_norm": 0.5333755612373352,
      "learning_rate": 1.837984496124031e-05,
      "loss": 0.003,
      "step": 8158
    },
    {
      "epoch": 31.624031007751938,
      "grad_norm": 0.0026892104651778936,
      "learning_rate": 1.8375968992248063e-05,
      "loss": 0.0002,
      "step": 8159
    },
    {
      "epoch": 31.627906976744185,
      "grad_norm": 0.0017034586053341627,
      "learning_rate": 1.8372093023255815e-05,
      "loss": 0.0002,
      "step": 8160
    },
    {
      "epoch": 31.631782945736433,
      "grad_norm": 0.010990150272846222,
      "learning_rate": 1.8368217054263568e-05,
      "loss": 0.0003,
      "step": 8161
    },
    {
      "epoch": 31.635658914728683,
      "grad_norm": 0.0020872619934380054,
      "learning_rate": 1.836434108527132e-05,
      "loss": 0.0002,
      "step": 8162
    },
    {
      "epoch": 31.63953488372093,
      "grad_norm": 0.024091893807053566,
      "learning_rate": 1.8360465116279073e-05,
      "loss": 0.0007,
      "step": 8163
    },
    {
      "epoch": 31.643410852713178,
      "grad_norm": 0.003274275455623865,
      "learning_rate": 1.8356589147286825e-05,
      "loss": 0.0003,
      "step": 8164
    },
    {
      "epoch": 31.647286821705425,
      "grad_norm": 2.691028118133545,
      "learning_rate": 1.8352713178294574e-05,
      "loss": 0.2747,
      "step": 8165
    },
    {
      "epoch": 31.651162790697676,
      "grad_norm": 0.0028991010040044785,
      "learning_rate": 1.8348837209302327e-05,
      "loss": 0.0002,
      "step": 8166
    },
    {
      "epoch": 31.655038759689923,
      "grad_norm": 0.0022818862926214933,
      "learning_rate": 1.834496124031008e-05,
      "loss": 0.0002,
      "step": 8167
    },
    {
      "epoch": 31.65891472868217,
      "grad_norm": 0.00182343868073076,
      "learning_rate": 1.834108527131783e-05,
      "loss": 0.0002,
      "step": 8168
    },
    {
      "epoch": 31.662790697674417,
      "grad_norm": 0.00275996676646173,
      "learning_rate": 1.8337209302325584e-05,
      "loss": 0.0002,
      "step": 8169
    },
    {
      "epoch": 31.666666666666668,
      "grad_norm": 0.0014683144399896264,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.0001,
      "step": 8170
    },
    {
      "epoch": 31.670542635658915,
      "grad_norm": 0.0021661079954355955,
      "learning_rate": 1.8329457364341085e-05,
      "loss": 0.0002,
      "step": 8171
    },
    {
      "epoch": 31.674418604651162,
      "grad_norm": 0.0023324363864958286,
      "learning_rate": 1.8325581395348838e-05,
      "loss": 0.0002,
      "step": 8172
    },
    {
      "epoch": 31.67829457364341,
      "grad_norm": 0.0016042492352426052,
      "learning_rate": 1.832170542635659e-05,
      "loss": 0.0001,
      "step": 8173
    },
    {
      "epoch": 31.68217054263566,
      "grad_norm": 0.027089400216937065,
      "learning_rate": 1.8317829457364343e-05,
      "loss": 0.0008,
      "step": 8174
    },
    {
      "epoch": 31.686046511627907,
      "grad_norm": 0.0017257491126656532,
      "learning_rate": 1.831395348837209e-05,
      "loss": 0.0001,
      "step": 8175
    },
    {
      "epoch": 31.689922480620154,
      "grad_norm": 0.5209235548973083,
      "learning_rate": 1.8310077519379844e-05,
      "loss": 0.0173,
      "step": 8176
    },
    {
      "epoch": 31.6937984496124,
      "grad_norm": 0.001690532430075109,
      "learning_rate": 1.8306201550387596e-05,
      "loss": 0.0001,
      "step": 8177
    },
    {
      "epoch": 31.697674418604652,
      "grad_norm": 0.41981634497642517,
      "learning_rate": 1.830232558139535e-05,
      "loss": 0.0058,
      "step": 8178
    },
    {
      "epoch": 31.7015503875969,
      "grad_norm": 0.0013221404515206814,
      "learning_rate": 1.82984496124031e-05,
      "loss": 0.0001,
      "step": 8179
    },
    {
      "epoch": 31.705426356589147,
      "grad_norm": 0.002535630017518997,
      "learning_rate": 1.8294573643410854e-05,
      "loss": 0.0002,
      "step": 8180
    },
    {
      "epoch": 31.709302325581394,
      "grad_norm": 0.009432154707610607,
      "learning_rate": 1.8290697674418606e-05,
      "loss": 0.0005,
      "step": 8181
    },
    {
      "epoch": 31.713178294573645,
      "grad_norm": 0.003823499660938978,
      "learning_rate": 1.828682170542636e-05,
      "loss": 0.0003,
      "step": 8182
    },
    {
      "epoch": 31.717054263565892,
      "grad_norm": 0.0024305451661348343,
      "learning_rate": 1.828294573643411e-05,
      "loss": 0.0002,
      "step": 8183
    },
    {
      "epoch": 31.72093023255814,
      "grad_norm": 0.001482921070419252,
      "learning_rate": 1.827906976744186e-05,
      "loss": 0.0001,
      "step": 8184
    },
    {
      "epoch": 31.724806201550386,
      "grad_norm": 0.0018316346686333418,
      "learning_rate": 1.8275193798449612e-05,
      "loss": 0.0002,
      "step": 8185
    },
    {
      "epoch": 31.728682170542637,
      "grad_norm": 0.0026461624074727297,
      "learning_rate": 1.8271317829457365e-05,
      "loss": 0.0002,
      "step": 8186
    },
    {
      "epoch": 31.732558139534884,
      "grad_norm": 0.00252950144931674,
      "learning_rate": 1.8267441860465117e-05,
      "loss": 0.0002,
      "step": 8187
    },
    {
      "epoch": 31.73643410852713,
      "grad_norm": 0.0017908213194459677,
      "learning_rate": 1.826356589147287e-05,
      "loss": 0.0002,
      "step": 8188
    },
    {
      "epoch": 31.74031007751938,
      "grad_norm": 0.0022426496725529432,
      "learning_rate": 1.8259689922480622e-05,
      "loss": 0.0002,
      "step": 8189
    },
    {
      "epoch": 31.74418604651163,
      "grad_norm": 0.002647977089509368,
      "learning_rate": 1.8255813953488375e-05,
      "loss": 0.0002,
      "step": 8190
    },
    {
      "epoch": 31.748062015503876,
      "grad_norm": 1.0820914506912231,
      "learning_rate": 1.8251937984496127e-05,
      "loss": 0.0099,
      "step": 8191
    },
    {
      "epoch": 31.751937984496124,
      "grad_norm": 0.5724855065345764,
      "learning_rate": 1.824806201550388e-05,
      "loss": 0.0261,
      "step": 8192
    },
    {
      "epoch": 31.75581395348837,
      "grad_norm": 13.944608688354492,
      "learning_rate": 1.824418604651163e-05,
      "loss": 0.0792,
      "step": 8193
    },
    {
      "epoch": 31.75968992248062,
      "grad_norm": 0.0016558661591261625,
      "learning_rate": 1.824031007751938e-05,
      "loss": 0.0002,
      "step": 8194
    },
    {
      "epoch": 31.76356589147287,
      "grad_norm": 0.0011737345485016704,
      "learning_rate": 1.8236434108527133e-05,
      "loss": 0.0001,
      "step": 8195
    },
    {
      "epoch": 31.767441860465116,
      "grad_norm": 0.010006234981119633,
      "learning_rate": 1.8232558139534882e-05,
      "loss": 0.0002,
      "step": 8196
    },
    {
      "epoch": 31.771317829457363,
      "grad_norm": 0.0020541013218462467,
      "learning_rate": 1.8228682170542635e-05,
      "loss": 0.0001,
      "step": 8197
    },
    {
      "epoch": 31.775193798449614,
      "grad_norm": 0.0028050558175891638,
      "learning_rate": 1.8224806201550387e-05,
      "loss": 0.0002,
      "step": 8198
    },
    {
      "epoch": 31.77906976744186,
      "grad_norm": 0.0018008733168244362,
      "learning_rate": 1.822093023255814e-05,
      "loss": 0.0002,
      "step": 8199
    },
    {
      "epoch": 31.782945736434108,
      "grad_norm": 32.06679916381836,
      "learning_rate": 1.8217054263565892e-05,
      "loss": 0.0475,
      "step": 8200
    },
    {
      "epoch": 31.786821705426355,
      "grad_norm": 0.0019665348809212446,
      "learning_rate": 1.8213178294573644e-05,
      "loss": 0.0002,
      "step": 8201
    },
    {
      "epoch": 31.790697674418606,
      "grad_norm": 0.0019732126966118813,
      "learning_rate": 1.8209302325581397e-05,
      "loss": 0.0002,
      "step": 8202
    },
    {
      "epoch": 31.794573643410853,
      "grad_norm": 2.376431465148926,
      "learning_rate": 1.820542635658915e-05,
      "loss": 0.0213,
      "step": 8203
    },
    {
      "epoch": 31.7984496124031,
      "grad_norm": 0.002658483339473605,
      "learning_rate": 1.8201550387596898e-05,
      "loss": 0.0002,
      "step": 8204
    },
    {
      "epoch": 31.802325581395348,
      "grad_norm": 0.005050347186625004,
      "learning_rate": 1.819767441860465e-05,
      "loss": 0.0002,
      "step": 8205
    },
    {
      "epoch": 31.8062015503876,
      "grad_norm": 0.0016959072090685368,
      "learning_rate": 1.8193798449612403e-05,
      "loss": 0.0002,
      "step": 8206
    },
    {
      "epoch": 31.810077519379846,
      "grad_norm": 0.001475167809985578,
      "learning_rate": 1.8189922480620156e-05,
      "loss": 0.0001,
      "step": 8207
    },
    {
      "epoch": 31.813953488372093,
      "grad_norm": 0.006409471854567528,
      "learning_rate": 1.8186046511627908e-05,
      "loss": 0.0002,
      "step": 8208
    },
    {
      "epoch": 31.81782945736434,
      "grad_norm": 0.0015198559267446399,
      "learning_rate": 1.818217054263566e-05,
      "loss": 0.0001,
      "step": 8209
    },
    {
      "epoch": 31.82170542635659,
      "grad_norm": 0.012485364452004433,
      "learning_rate": 1.8178294573643413e-05,
      "loss": 0.0003,
      "step": 8210
    },
    {
      "epoch": 31.825581395348838,
      "grad_norm": 0.002996423514559865,
      "learning_rate": 1.8174418604651165e-05,
      "loss": 0.0002,
      "step": 8211
    },
    {
      "epoch": 31.829457364341085,
      "grad_norm": 0.001897689769975841,
      "learning_rate": 1.8170542635658914e-05,
      "loss": 0.0002,
      "step": 8212
    },
    {
      "epoch": 31.833333333333332,
      "grad_norm": 0.011073168367147446,
      "learning_rate": 1.8166666666666667e-05,
      "loss": 0.0005,
      "step": 8213
    },
    {
      "epoch": 31.837209302325583,
      "grad_norm": 0.003920127637684345,
      "learning_rate": 1.816279069767442e-05,
      "loss": 0.0002,
      "step": 8214
    },
    {
      "epoch": 31.84108527131783,
      "grad_norm": 0.01711045764386654,
      "learning_rate": 1.815891472868217e-05,
      "loss": 0.0006,
      "step": 8215
    },
    {
      "epoch": 31.844961240310077,
      "grad_norm": 0.0029241014271974564,
      "learning_rate": 1.8155038759689924e-05,
      "loss": 0.0002,
      "step": 8216
    },
    {
      "epoch": 31.848837209302324,
      "grad_norm": 0.0014199529541656375,
      "learning_rate": 1.8151162790697676e-05,
      "loss": 0.0001,
      "step": 8217
    },
    {
      "epoch": 31.852713178294575,
      "grad_norm": 0.0026843082159757614,
      "learning_rate": 1.814728682170543e-05,
      "loss": 0.0002,
      "step": 8218
    },
    {
      "epoch": 31.856589147286822,
      "grad_norm": 0.004039849154651165,
      "learning_rate": 1.814341085271318e-05,
      "loss": 0.0002,
      "step": 8219
    },
    {
      "epoch": 31.86046511627907,
      "grad_norm": 0.0026523226406425238,
      "learning_rate": 1.8139534883720934e-05,
      "loss": 0.0002,
      "step": 8220
    },
    {
      "epoch": 31.864341085271317,
      "grad_norm": 0.0015353180933743715,
      "learning_rate": 1.8135658914728683e-05,
      "loss": 0.0001,
      "step": 8221
    },
    {
      "epoch": 31.868217054263567,
      "grad_norm": 0.0014062834670767188,
      "learning_rate": 1.8131782945736435e-05,
      "loss": 0.0001,
      "step": 8222
    },
    {
      "epoch": 31.872093023255815,
      "grad_norm": 0.0017655212432146072,
      "learning_rate": 1.8127906976744184e-05,
      "loss": 0.0002,
      "step": 8223
    },
    {
      "epoch": 31.875968992248062,
      "grad_norm": 0.003373215440660715,
      "learning_rate": 1.8124031007751937e-05,
      "loss": 0.0002,
      "step": 8224
    },
    {
      "epoch": 31.87984496124031,
      "grad_norm": 0.05235227942466736,
      "learning_rate": 1.812015503875969e-05,
      "loss": 0.001,
      "step": 8225
    },
    {
      "epoch": 31.88372093023256,
      "grad_norm": 0.001524140709079802,
      "learning_rate": 1.811627906976744e-05,
      "loss": 0.0001,
      "step": 8226
    },
    {
      "epoch": 31.887596899224807,
      "grad_norm": 0.0023057402577251196,
      "learning_rate": 1.8112403100775194e-05,
      "loss": 0.0002,
      "step": 8227
    },
    {
      "epoch": 31.891472868217054,
      "grad_norm": 0.13749292492866516,
      "learning_rate": 1.8108527131782946e-05,
      "loss": 0.0037,
      "step": 8228
    },
    {
      "epoch": 31.8953488372093,
      "grad_norm": 6.757864952087402,
      "learning_rate": 1.81046511627907e-05,
      "loss": 0.5765,
      "step": 8229
    },
    {
      "epoch": 31.899224806201552,
      "grad_norm": 0.004698866046965122,
      "learning_rate": 1.810077519379845e-05,
      "loss": 0.0003,
      "step": 8230
    },
    {
      "epoch": 31.9031007751938,
      "grad_norm": 0.8196260929107666,
      "learning_rate": 1.8096899224806203e-05,
      "loss": 0.054,
      "step": 8231
    },
    {
      "epoch": 31.906976744186046,
      "grad_norm": 0.0023692063987255096,
      "learning_rate": 1.8093023255813953e-05,
      "loss": 0.0002,
      "step": 8232
    },
    {
      "epoch": 31.910852713178294,
      "grad_norm": 4.699591636657715,
      "learning_rate": 1.8089147286821705e-05,
      "loss": 0.336,
      "step": 8233
    },
    {
      "epoch": 31.914728682170544,
      "grad_norm": 0.005065092816948891,
      "learning_rate": 1.8085271317829457e-05,
      "loss": 0.0003,
      "step": 8234
    },
    {
      "epoch": 31.91860465116279,
      "grad_norm": 0.057774052023887634,
      "learning_rate": 1.808139534883721e-05,
      "loss": 0.0009,
      "step": 8235
    },
    {
      "epoch": 31.92248062015504,
      "grad_norm": 0.0027933965902775526,
      "learning_rate": 1.8077519379844962e-05,
      "loss": 0.0002,
      "step": 8236
    },
    {
      "epoch": 31.926356589147286,
      "grad_norm": 0.002772145438939333,
      "learning_rate": 1.8073643410852715e-05,
      "loss": 0.0002,
      "step": 8237
    },
    {
      "epoch": 31.930232558139537,
      "grad_norm": 0.003391050733625889,
      "learning_rate": 1.8069767441860467e-05,
      "loss": 0.0003,
      "step": 8238
    },
    {
      "epoch": 31.934108527131784,
      "grad_norm": 0.0016406950308009982,
      "learning_rate": 1.806589147286822e-05,
      "loss": 0.0002,
      "step": 8239
    },
    {
      "epoch": 31.93798449612403,
      "grad_norm": 0.0013834721175953746,
      "learning_rate": 1.8062015503875972e-05,
      "loss": 0.0001,
      "step": 8240
    },
    {
      "epoch": 31.941860465116278,
      "grad_norm": 0.0022371262311935425,
      "learning_rate": 1.805813953488372e-05,
      "loss": 0.0002,
      "step": 8241
    },
    {
      "epoch": 31.94573643410853,
      "grad_norm": 0.002188631799072027,
      "learning_rate": 1.8054263565891473e-05,
      "loss": 0.0002,
      "step": 8242
    },
    {
      "epoch": 31.949612403100776,
      "grad_norm": 0.004644606728106737,
      "learning_rate": 1.8050387596899226e-05,
      "loss": 0.0002,
      "step": 8243
    },
    {
      "epoch": 31.953488372093023,
      "grad_norm": 0.05168110504746437,
      "learning_rate": 1.8046511627906978e-05,
      "loss": 0.0005,
      "step": 8244
    },
    {
      "epoch": 31.95736434108527,
      "grad_norm": 1.4362648725509644,
      "learning_rate": 1.804263565891473e-05,
      "loss": 0.0911,
      "step": 8245
    },
    {
      "epoch": 31.96124031007752,
      "grad_norm": 0.7877706289291382,
      "learning_rate": 1.8038759689922483e-05,
      "loss": 0.0545,
      "step": 8246
    },
    {
      "epoch": 31.96511627906977,
      "grad_norm": 0.001891575870104134,
      "learning_rate": 1.8034883720930235e-05,
      "loss": 0.0002,
      "step": 8247
    },
    {
      "epoch": 31.968992248062015,
      "grad_norm": 1.1692464351654053,
      "learning_rate": 1.8031007751937988e-05,
      "loss": 0.0211,
      "step": 8248
    },
    {
      "epoch": 31.972868217054263,
      "grad_norm": 0.0028490854892879725,
      "learning_rate": 1.802713178294574e-05,
      "loss": 0.0002,
      "step": 8249
    },
    {
      "epoch": 31.97674418604651,
      "grad_norm": 0.018169190734624863,
      "learning_rate": 1.802325581395349e-05,
      "loss": 0.0003,
      "step": 8250
    },
    {
      "epoch": 31.98062015503876,
      "grad_norm": 14.41031551361084,
      "learning_rate": 1.801937984496124e-05,
      "loss": 0.0576,
      "step": 8251
    },
    {
      "epoch": 31.984496124031008,
      "grad_norm": 0.006671193987131119,
      "learning_rate": 1.801550387596899e-05,
      "loss": 0.0003,
      "step": 8252
    },
    {
      "epoch": 31.988372093023255,
      "grad_norm": 0.0024240727070719004,
      "learning_rate": 1.8011627906976743e-05,
      "loss": 0.0002,
      "step": 8253
    },
    {
      "epoch": 31.992248062015506,
      "grad_norm": 0.0022322055883705616,
      "learning_rate": 1.8007751937984496e-05,
      "loss": 0.0002,
      "step": 8254
    },
    {
      "epoch": 31.996124031007753,
      "grad_norm": 0.0054716928862035275,
      "learning_rate": 1.8003875968992248e-05,
      "loss": 0.0002,
      "step": 8255
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.0018961109453812242,
      "learning_rate": 1.8e-05,
      "loss": 0.0001,
      "step": 8256
    },
    {
      "epoch": 32.00387596899225,
      "grad_norm": 0.002179136499762535,
      "learning_rate": 1.7996124031007753e-05,
      "loss": 0.0002,
      "step": 8257
    },
    {
      "epoch": 32.007751937984494,
      "grad_norm": 0.0035548422019928694,
      "learning_rate": 1.7992248062015505e-05,
      "loss": 0.0002,
      "step": 8258
    },
    {
      "epoch": 32.01162790697674,
      "grad_norm": 0.001643544645048678,
      "learning_rate": 1.7988372093023258e-05,
      "loss": 0.0002,
      "step": 8259
    },
    {
      "epoch": 32.01550387596899,
      "grad_norm": 0.0013371186796575785,
      "learning_rate": 1.7984496124031007e-05,
      "loss": 0.0001,
      "step": 8260
    },
    {
      "epoch": 32.01937984496124,
      "grad_norm": 0.0020630022045224905,
      "learning_rate": 1.798062015503876e-05,
      "loss": 0.0002,
      "step": 8261
    },
    {
      "epoch": 32.02325581395349,
      "grad_norm": 0.003421109402552247,
      "learning_rate": 1.797674418604651e-05,
      "loss": 0.0003,
      "step": 8262
    },
    {
      "epoch": 32.02713178294574,
      "grad_norm": 0.0034908298403024673,
      "learning_rate": 1.7972868217054264e-05,
      "loss": 0.0002,
      "step": 8263
    },
    {
      "epoch": 32.031007751937985,
      "grad_norm": 0.013714633882045746,
      "learning_rate": 1.7968992248062016e-05,
      "loss": 0.0003,
      "step": 8264
    },
    {
      "epoch": 32.03488372093023,
      "grad_norm": 0.06652132421731949,
      "learning_rate": 1.796511627906977e-05,
      "loss": 0.0007,
      "step": 8265
    },
    {
      "epoch": 32.03875968992248,
      "grad_norm": 1.9273051023483276,
      "learning_rate": 1.796124031007752e-05,
      "loss": 0.1187,
      "step": 8266
    },
    {
      "epoch": 32.042635658914726,
      "grad_norm": 0.6186224222183228,
      "learning_rate": 1.7957364341085274e-05,
      "loss": 0.0383,
      "step": 8267
    },
    {
      "epoch": 32.04651162790697,
      "grad_norm": 0.05440068617463112,
      "learning_rate": 1.7953488372093026e-05,
      "loss": 0.0004,
      "step": 8268
    },
    {
      "epoch": 32.05038759689923,
      "grad_norm": 0.002798724453896284,
      "learning_rate": 1.7949612403100775e-05,
      "loss": 0.0002,
      "step": 8269
    },
    {
      "epoch": 32.054263565891475,
      "grad_norm": 0.00167795829474926,
      "learning_rate": 1.7945736434108528e-05,
      "loss": 0.0002,
      "step": 8270
    },
    {
      "epoch": 32.05813953488372,
      "grad_norm": 0.004890888929367065,
      "learning_rate": 1.794186046511628e-05,
      "loss": 0.0003,
      "step": 8271
    },
    {
      "epoch": 32.06201550387597,
      "grad_norm": 0.0021674251183867455,
      "learning_rate": 1.7937984496124032e-05,
      "loss": 0.0002,
      "step": 8272
    },
    {
      "epoch": 32.065891472868216,
      "grad_norm": 4.872121810913086,
      "learning_rate": 1.7934108527131785e-05,
      "loss": 0.1065,
      "step": 8273
    },
    {
      "epoch": 32.06976744186046,
      "grad_norm": 0.0018332392210140824,
      "learning_rate": 1.7930232558139537e-05,
      "loss": 0.0002,
      "step": 8274
    },
    {
      "epoch": 32.07364341085271,
      "grad_norm": 0.003954472951591015,
      "learning_rate": 1.792635658914729e-05,
      "loss": 0.0002,
      "step": 8275
    },
    {
      "epoch": 32.07751937984496,
      "grad_norm": 0.0014514644863083959,
      "learning_rate": 1.792248062015504e-05,
      "loss": 0.0001,
      "step": 8276
    },
    {
      "epoch": 32.08139534883721,
      "grad_norm": 0.001881456933915615,
      "learning_rate": 1.791860465116279e-05,
      "loss": 0.0002,
      "step": 8277
    },
    {
      "epoch": 32.08527131782946,
      "grad_norm": 0.0016635474748909473,
      "learning_rate": 1.7914728682170544e-05,
      "loss": 0.0002,
      "step": 8278
    },
    {
      "epoch": 32.08914728682171,
      "grad_norm": 0.6254758238792419,
      "learning_rate": 1.7910852713178296e-05,
      "loss": 0.0023,
      "step": 8279
    },
    {
      "epoch": 32.093023255813954,
      "grad_norm": 0.0016027651727199554,
      "learning_rate": 1.7906976744186045e-05,
      "loss": 0.0001,
      "step": 8280
    },
    {
      "epoch": 32.0968992248062,
      "grad_norm": 0.0036882911808788776,
      "learning_rate": 1.7903100775193797e-05,
      "loss": 0.0002,
      "step": 8281
    },
    {
      "epoch": 32.10077519379845,
      "grad_norm": 0.0015923080500215292,
      "learning_rate": 1.789922480620155e-05,
      "loss": 0.0002,
      "step": 8282
    },
    {
      "epoch": 32.104651162790695,
      "grad_norm": 0.0016621648101136088,
      "learning_rate": 1.7895348837209302e-05,
      "loss": 0.0002,
      "step": 8283
    },
    {
      "epoch": 32.10852713178294,
      "grad_norm": 0.0014477018266916275,
      "learning_rate": 1.7891472868217055e-05,
      "loss": 0.0001,
      "step": 8284
    },
    {
      "epoch": 32.1124031007752,
      "grad_norm": 0.0021630777046084404,
      "learning_rate": 1.7887596899224807e-05,
      "loss": 0.0002,
      "step": 8285
    },
    {
      "epoch": 32.116279069767444,
      "grad_norm": 0.0016880587209016085,
      "learning_rate": 1.788372093023256e-05,
      "loss": 0.0002,
      "step": 8286
    },
    {
      "epoch": 32.12015503875969,
      "grad_norm": 0.0018573671113699675,
      "learning_rate": 1.7879844961240312e-05,
      "loss": 0.0002,
      "step": 8287
    },
    {
      "epoch": 32.12403100775194,
      "grad_norm": 0.0022886598017066717,
      "learning_rate": 1.7875968992248064e-05,
      "loss": 0.0002,
      "step": 8288
    },
    {
      "epoch": 32.127906976744185,
      "grad_norm": 0.0019589450675994158,
      "learning_rate": 1.7872093023255813e-05,
      "loss": 0.0002,
      "step": 8289
    },
    {
      "epoch": 32.13178294573643,
      "grad_norm": 0.05230003222823143,
      "learning_rate": 1.7868217054263566e-05,
      "loss": 0.0006,
      "step": 8290
    },
    {
      "epoch": 32.13565891472868,
      "grad_norm": 0.9673067331314087,
      "learning_rate": 1.7864341085271318e-05,
      "loss": 0.0087,
      "step": 8291
    },
    {
      "epoch": 32.13953488372093,
      "grad_norm": 0.0029084375128149986,
      "learning_rate": 1.786046511627907e-05,
      "loss": 0.0002,
      "step": 8292
    },
    {
      "epoch": 32.14341085271318,
      "grad_norm": 1.3895485401153564,
      "learning_rate": 1.7856589147286823e-05,
      "loss": 0.0512,
      "step": 8293
    },
    {
      "epoch": 32.14728682170543,
      "grad_norm": 0.0032963489647954702,
      "learning_rate": 1.7852713178294576e-05,
      "loss": 0.0002,
      "step": 8294
    },
    {
      "epoch": 32.151162790697676,
      "grad_norm": 0.3243931531906128,
      "learning_rate": 1.7848837209302328e-05,
      "loss": 0.0034,
      "step": 8295
    },
    {
      "epoch": 32.15503875968992,
      "grad_norm": 0.045189447700977325,
      "learning_rate": 1.784496124031008e-05,
      "loss": 0.0007,
      "step": 8296
    },
    {
      "epoch": 32.15891472868217,
      "grad_norm": 0.001502206432633102,
      "learning_rate": 1.7841085271317833e-05,
      "loss": 0.0002,
      "step": 8297
    },
    {
      "epoch": 32.16279069767442,
      "grad_norm": 1.2661864757537842,
      "learning_rate": 1.7837209302325582e-05,
      "loss": 0.0865,
      "step": 8298
    },
    {
      "epoch": 32.166666666666664,
      "grad_norm": 0.0455554835498333,
      "learning_rate": 1.7833333333333334e-05,
      "loss": 0.0003,
      "step": 8299
    },
    {
      "epoch": 32.17054263565891,
      "grad_norm": 0.001383033231832087,
      "learning_rate": 1.7829457364341087e-05,
      "loss": 0.0001,
      "step": 8300
    },
    {
      "epoch": 32.174418604651166,
      "grad_norm": 1.2313134670257568,
      "learning_rate": 1.782558139534884e-05,
      "loss": 0.1773,
      "step": 8301
    },
    {
      "epoch": 32.17829457364341,
      "grad_norm": 0.0017134383087977767,
      "learning_rate": 1.782170542635659e-05,
      "loss": 0.0001,
      "step": 8302
    },
    {
      "epoch": 32.18217054263566,
      "grad_norm": 0.0012049246579408646,
      "learning_rate": 1.781782945736434e-05,
      "loss": 0.0001,
      "step": 8303
    },
    {
      "epoch": 32.18604651162791,
      "grad_norm": 0.005199871491640806,
      "learning_rate": 1.7813953488372093e-05,
      "loss": 0.0003,
      "step": 8304
    },
    {
      "epoch": 32.189922480620154,
      "grad_norm": 0.006916784681379795,
      "learning_rate": 1.7810077519379845e-05,
      "loss": 0.0002,
      "step": 8305
    },
    {
      "epoch": 32.1937984496124,
      "grad_norm": 0.0013844984350726008,
      "learning_rate": 1.7806201550387598e-05,
      "loss": 0.0001,
      "step": 8306
    },
    {
      "epoch": 32.19767441860465,
      "grad_norm": 0.002152174711227417,
      "learning_rate": 1.780232558139535e-05,
      "loss": 0.0002,
      "step": 8307
    },
    {
      "epoch": 32.201550387596896,
      "grad_norm": 0.0016827811487019062,
      "learning_rate": 1.77984496124031e-05,
      "loss": 0.0001,
      "step": 8308
    },
    {
      "epoch": 32.20542635658915,
      "grad_norm": 0.001336603076197207,
      "learning_rate": 1.7794573643410852e-05,
      "loss": 0.0001,
      "step": 8309
    },
    {
      "epoch": 32.2093023255814,
      "grad_norm": 1.543383002281189,
      "learning_rate": 1.7790697674418604e-05,
      "loss": 0.1143,
      "step": 8310
    },
    {
      "epoch": 32.213178294573645,
      "grad_norm": 0.16986766457557678,
      "learning_rate": 1.7786821705426357e-05,
      "loss": 0.0023,
      "step": 8311
    },
    {
      "epoch": 32.21705426356589,
      "grad_norm": 0.001687542418949306,
      "learning_rate": 1.778294573643411e-05,
      "loss": 0.0001,
      "step": 8312
    },
    {
      "epoch": 32.22093023255814,
      "grad_norm": 0.0020317179150879383,
      "learning_rate": 1.777906976744186e-05,
      "loss": 0.0002,
      "step": 8313
    },
    {
      "epoch": 32.224806201550386,
      "grad_norm": 0.0012991430703550577,
      "learning_rate": 1.7775193798449614e-05,
      "loss": 0.0001,
      "step": 8314
    },
    {
      "epoch": 32.22868217054263,
      "grad_norm": 0.03666166588664055,
      "learning_rate": 1.7771317829457366e-05,
      "loss": 0.0011,
      "step": 8315
    },
    {
      "epoch": 32.23255813953488,
      "grad_norm": 1.13652765750885,
      "learning_rate": 1.776744186046512e-05,
      "loss": 0.057,
      "step": 8316
    },
    {
      "epoch": 32.236434108527135,
      "grad_norm": 0.7615848183631897,
      "learning_rate": 1.7763565891472868e-05,
      "loss": 0.001,
      "step": 8317
    },
    {
      "epoch": 32.24031007751938,
      "grad_norm": 0.0024026697501540184,
      "learning_rate": 1.775968992248062e-05,
      "loss": 0.0001,
      "step": 8318
    },
    {
      "epoch": 32.24418604651163,
      "grad_norm": 0.014561367221176624,
      "learning_rate": 1.7755813953488373e-05,
      "loss": 0.0006,
      "step": 8319
    },
    {
      "epoch": 32.248062015503876,
      "grad_norm": 0.0016171891475096345,
      "learning_rate": 1.7751937984496125e-05,
      "loss": 0.0001,
      "step": 8320
    },
    {
      "epoch": 32.251937984496124,
      "grad_norm": 0.018040066584944725,
      "learning_rate": 1.7748062015503877e-05,
      "loss": 0.0006,
      "step": 8321
    },
    {
      "epoch": 32.25581395348837,
      "grad_norm": 0.0020201720762997866,
      "learning_rate": 1.774418604651163e-05,
      "loss": 0.0002,
      "step": 8322
    },
    {
      "epoch": 32.25968992248062,
      "grad_norm": 0.0018366328440606594,
      "learning_rate": 1.7740310077519382e-05,
      "loss": 0.0002,
      "step": 8323
    },
    {
      "epoch": 32.263565891472865,
      "grad_norm": 0.001604975201189518,
      "learning_rate": 1.7736434108527135e-05,
      "loss": 0.0001,
      "step": 8324
    },
    {
      "epoch": 32.26744186046512,
      "grad_norm": 0.8109445571899414,
      "learning_rate": 1.7732558139534887e-05,
      "loss": 0.0408,
      "step": 8325
    },
    {
      "epoch": 32.27131782945737,
      "grad_norm": 0.3450801372528076,
      "learning_rate": 1.7728682170542636e-05,
      "loss": 0.0147,
      "step": 8326
    },
    {
      "epoch": 32.275193798449614,
      "grad_norm": 0.9050700068473816,
      "learning_rate": 1.772480620155039e-05,
      "loss": 0.0387,
      "step": 8327
    },
    {
      "epoch": 32.27906976744186,
      "grad_norm": 0.001313644228503108,
      "learning_rate": 1.772093023255814e-05,
      "loss": 0.0001,
      "step": 8328
    },
    {
      "epoch": 32.28294573643411,
      "grad_norm": 0.0013798228465020657,
      "learning_rate": 1.7717054263565893e-05,
      "loss": 0.0001,
      "step": 8329
    },
    {
      "epoch": 32.286821705426355,
      "grad_norm": 0.00134683633223176,
      "learning_rate": 1.7713178294573642e-05,
      "loss": 0.0001,
      "step": 8330
    },
    {
      "epoch": 32.2906976744186,
      "grad_norm": 0.0021799798123538494,
      "learning_rate": 1.7709302325581395e-05,
      "loss": 0.0002,
      "step": 8331
    },
    {
      "epoch": 32.29457364341085,
      "grad_norm": 2.673341989517212,
      "learning_rate": 1.7705426356589147e-05,
      "loss": 0.0108,
      "step": 8332
    },
    {
      "epoch": 32.298449612403104,
      "grad_norm": 0.054682858288288116,
      "learning_rate": 1.77015503875969e-05,
      "loss": 0.0006,
      "step": 8333
    },
    {
      "epoch": 32.30232558139535,
      "grad_norm": 0.001502710161730647,
      "learning_rate": 1.7697674418604652e-05,
      "loss": 0.0001,
      "step": 8334
    },
    {
      "epoch": 32.3062015503876,
      "grad_norm": 0.0017308205133304,
      "learning_rate": 1.7693798449612404e-05,
      "loss": 0.0001,
      "step": 8335
    },
    {
      "epoch": 32.310077519379846,
      "grad_norm": 0.0014860755763947964,
      "learning_rate": 1.7689922480620157e-05,
      "loss": 0.0001,
      "step": 8336
    },
    {
      "epoch": 32.31395348837209,
      "grad_norm": 0.01429002359509468,
      "learning_rate": 1.7686046511627906e-05,
      "loss": 0.0005,
      "step": 8337
    },
    {
      "epoch": 32.31782945736434,
      "grad_norm": 0.006596340797841549,
      "learning_rate": 1.768217054263566e-05,
      "loss": 0.0003,
      "step": 8338
    },
    {
      "epoch": 32.32170542635659,
      "grad_norm": 0.019872913137078285,
      "learning_rate": 1.767829457364341e-05,
      "loss": 0.0008,
      "step": 8339
    },
    {
      "epoch": 32.325581395348834,
      "grad_norm": 0.0016351835802197456,
      "learning_rate": 1.7674418604651163e-05,
      "loss": 0.0001,
      "step": 8340
    },
    {
      "epoch": 32.32945736434109,
      "grad_norm": 1.8357748985290527,
      "learning_rate": 1.7670542635658916e-05,
      "loss": 0.2145,
      "step": 8341
    },
    {
      "epoch": 32.333333333333336,
      "grad_norm": 0.01061254646629095,
      "learning_rate": 1.7666666666666668e-05,
      "loss": 0.0001,
      "step": 8342
    },
    {
      "epoch": 32.33720930232558,
      "grad_norm": 0.0019416343420743942,
      "learning_rate": 1.766279069767442e-05,
      "loss": 0.0001,
      "step": 8343
    },
    {
      "epoch": 32.34108527131783,
      "grad_norm": 0.007748996373265982,
      "learning_rate": 1.7658914728682173e-05,
      "loss": 0.0003,
      "step": 8344
    },
    {
      "epoch": 32.34496124031008,
      "grad_norm": 0.0014274130808189511,
      "learning_rate": 1.7655038759689922e-05,
      "loss": 0.0001,
      "step": 8345
    },
    {
      "epoch": 32.348837209302324,
      "grad_norm": 0.001334917382337153,
      "learning_rate": 1.7651162790697674e-05,
      "loss": 0.0001,
      "step": 8346
    },
    {
      "epoch": 32.35271317829457,
      "grad_norm": 0.0014650309458374977,
      "learning_rate": 1.7647286821705427e-05,
      "loss": 0.0001,
      "step": 8347
    },
    {
      "epoch": 32.35658914728682,
      "grad_norm": 0.08553916215896606,
      "learning_rate": 1.764341085271318e-05,
      "loss": 0.0025,
      "step": 8348
    },
    {
      "epoch": 32.36046511627907,
      "grad_norm": 0.0011317908065393567,
      "learning_rate": 1.763953488372093e-05,
      "loss": 0.0001,
      "step": 8349
    },
    {
      "epoch": 32.36434108527132,
      "grad_norm": 0.12013044208288193,
      "learning_rate": 1.7635658914728684e-05,
      "loss": 0.001,
      "step": 8350
    },
    {
      "epoch": 32.36821705426357,
      "grad_norm": 19.758060455322266,
      "learning_rate": 1.7631782945736436e-05,
      "loss": 0.4523,
      "step": 8351
    },
    {
      "epoch": 32.372093023255815,
      "grad_norm": 0.17975762486457825,
      "learning_rate": 1.762790697674419e-05,
      "loss": 0.0064,
      "step": 8352
    },
    {
      "epoch": 32.37596899224806,
      "grad_norm": 0.0018666823161765933,
      "learning_rate": 1.762403100775194e-05,
      "loss": 0.0002,
      "step": 8353
    },
    {
      "epoch": 32.37984496124031,
      "grad_norm": 0.00167147780302912,
      "learning_rate": 1.762015503875969e-05,
      "loss": 0.0001,
      "step": 8354
    },
    {
      "epoch": 32.383720930232556,
      "grad_norm": 0.0010714654345065355,
      "learning_rate": 1.7616279069767443e-05,
      "loss": 0.0001,
      "step": 8355
    },
    {
      "epoch": 32.3875968992248,
      "grad_norm": 0.008618640713393688,
      "learning_rate": 1.7612403100775192e-05,
      "loss": 0.0005,
      "step": 8356
    },
    {
      "epoch": 32.39147286821706,
      "grad_norm": 0.005606849677860737,
      "learning_rate": 1.7608527131782944e-05,
      "loss": 0.0003,
      "step": 8357
    },
    {
      "epoch": 32.395348837209305,
      "grad_norm": 0.001726937131024897,
      "learning_rate": 1.7604651162790697e-05,
      "loss": 0.0002,
      "step": 8358
    },
    {
      "epoch": 32.39922480620155,
      "grad_norm": 0.0013305975589901209,
      "learning_rate": 1.760077519379845e-05,
      "loss": 0.0001,
      "step": 8359
    },
    {
      "epoch": 32.4031007751938,
      "grad_norm": 0.011434334330260754,
      "learning_rate": 1.75968992248062e-05,
      "loss": 0.0006,
      "step": 8360
    },
    {
      "epoch": 32.406976744186046,
      "grad_norm": 0.0016223149141296744,
      "learning_rate": 1.7593023255813954e-05,
      "loss": 0.0001,
      "step": 8361
    },
    {
      "epoch": 32.41085271317829,
      "grad_norm": 0.001949071534909308,
      "learning_rate": 1.7589147286821706e-05,
      "loss": 0.0002,
      "step": 8362
    },
    {
      "epoch": 32.41472868217054,
      "grad_norm": 0.0014650792581960559,
      "learning_rate": 1.758527131782946e-05,
      "loss": 0.0001,
      "step": 8363
    },
    {
      "epoch": 32.41860465116279,
      "grad_norm": 0.012410826981067657,
      "learning_rate": 1.758139534883721e-05,
      "loss": 0.0006,
      "step": 8364
    },
    {
      "epoch": 32.42248062015504,
      "grad_norm": 9.537467956542969,
      "learning_rate": 1.757751937984496e-05,
      "loss": 0.2962,
      "step": 8365
    },
    {
      "epoch": 32.42635658914729,
      "grad_norm": 24.464353561401367,
      "learning_rate": 1.7573643410852713e-05,
      "loss": 0.232,
      "step": 8366
    },
    {
      "epoch": 32.43023255813954,
      "grad_norm": 0.005716896615922451,
      "learning_rate": 1.7569767441860465e-05,
      "loss": 0.0002,
      "step": 8367
    },
    {
      "epoch": 32.434108527131784,
      "grad_norm": 0.006699646357446909,
      "learning_rate": 1.7565891472868217e-05,
      "loss": 0.0004,
      "step": 8368
    },
    {
      "epoch": 32.43798449612403,
      "grad_norm": 0.002763260155916214,
      "learning_rate": 1.756201550387597e-05,
      "loss": 0.0002,
      "step": 8369
    },
    {
      "epoch": 32.44186046511628,
      "grad_norm": 0.001493374933488667,
      "learning_rate": 1.7558139534883722e-05,
      "loss": 0.0001,
      "step": 8370
    },
    {
      "epoch": 32.445736434108525,
      "grad_norm": 0.001587016275152564,
      "learning_rate": 1.7554263565891475e-05,
      "loss": 0.0002,
      "step": 8371
    },
    {
      "epoch": 32.44961240310077,
      "grad_norm": 0.0016183436382561922,
      "learning_rate": 1.7550387596899227e-05,
      "loss": 0.0001,
      "step": 8372
    },
    {
      "epoch": 32.45348837209303,
      "grad_norm": 0.0015655076131224632,
      "learning_rate": 1.754651162790698e-05,
      "loss": 0.0002,
      "step": 8373
    },
    {
      "epoch": 32.457364341085274,
      "grad_norm": 0.005941683426499367,
      "learning_rate": 1.754263565891473e-05,
      "loss": 0.0003,
      "step": 8374
    },
    {
      "epoch": 32.46124031007752,
      "grad_norm": 0.0018296357011422515,
      "learning_rate": 1.753875968992248e-05,
      "loss": 0.0001,
      "step": 8375
    },
    {
      "epoch": 32.46511627906977,
      "grad_norm": 0.0025446589570492506,
      "learning_rate": 1.7534883720930233e-05,
      "loss": 0.0002,
      "step": 8376
    },
    {
      "epoch": 32.468992248062015,
      "grad_norm": 1.8334745168685913,
      "learning_rate": 1.7531007751937986e-05,
      "loss": 0.2067,
      "step": 8377
    },
    {
      "epoch": 32.47286821705426,
      "grad_norm": 0.001689635100774467,
      "learning_rate": 1.7527131782945738e-05,
      "loss": 0.0001,
      "step": 8378
    },
    {
      "epoch": 32.47674418604651,
      "grad_norm": 0.0013799192383885384,
      "learning_rate": 1.752325581395349e-05,
      "loss": 0.0001,
      "step": 8379
    },
    {
      "epoch": 32.48062015503876,
      "grad_norm": 0.001445580506697297,
      "learning_rate": 1.7519379844961243e-05,
      "loss": 0.0001,
      "step": 8380
    },
    {
      "epoch": 32.48449612403101,
      "grad_norm": 0.007910972461104393,
      "learning_rate": 1.7515503875968996e-05,
      "loss": 0.0004,
      "step": 8381
    },
    {
      "epoch": 32.48837209302326,
      "grad_norm": 0.0014775785384699702,
      "learning_rate": 1.7511627906976748e-05,
      "loss": 0.0001,
      "step": 8382
    },
    {
      "epoch": 32.492248062015506,
      "grad_norm": 0.001149047864601016,
      "learning_rate": 1.7507751937984497e-05,
      "loss": 0.0001,
      "step": 8383
    },
    {
      "epoch": 32.49612403100775,
      "grad_norm": 0.0014503519050776958,
      "learning_rate": 1.7503875968992246e-05,
      "loss": 0.0001,
      "step": 8384
    },
    {
      "epoch": 32.5,
      "grad_norm": 0.001488594338297844,
      "learning_rate": 1.75e-05,
      "loss": 0.0001,
      "step": 8385
    },
    {
      "epoch": 32.50387596899225,
      "grad_norm": 0.0013338382123038173,
      "learning_rate": 1.749612403100775e-05,
      "loss": 0.0001,
      "step": 8386
    },
    {
      "epoch": 32.507751937984494,
      "grad_norm": 0.0020899369847029448,
      "learning_rate": 1.7492248062015503e-05,
      "loss": 0.0002,
      "step": 8387
    },
    {
      "epoch": 32.51162790697674,
      "grad_norm": 2.453608751296997,
      "learning_rate": 1.7488372093023256e-05,
      "loss": 0.1565,
      "step": 8388
    },
    {
      "epoch": 32.51550387596899,
      "grad_norm": 11.288040161132812,
      "learning_rate": 1.7484496124031008e-05,
      "loss": 0.3853,
      "step": 8389
    },
    {
      "epoch": 32.51937984496124,
      "grad_norm": 0.18062573671340942,
      "learning_rate": 1.748062015503876e-05,
      "loss": 0.0011,
      "step": 8390
    },
    {
      "epoch": 32.52325581395349,
      "grad_norm": 0.001484830747358501,
      "learning_rate": 1.7476744186046513e-05,
      "loss": 0.0001,
      "step": 8391
    },
    {
      "epoch": 32.52713178294574,
      "grad_norm": 0.0015590391121804714,
      "learning_rate": 1.7472868217054265e-05,
      "loss": 0.0002,
      "step": 8392
    },
    {
      "epoch": 32.531007751937985,
      "grad_norm": 0.0016141056548804045,
      "learning_rate": 1.7468992248062014e-05,
      "loss": 0.0001,
      "step": 8393
    },
    {
      "epoch": 32.53488372093023,
      "grad_norm": 0.0011937943054363132,
      "learning_rate": 1.7465116279069767e-05,
      "loss": 0.0001,
      "step": 8394
    },
    {
      "epoch": 32.53875968992248,
      "grad_norm": 0.003936219494789839,
      "learning_rate": 1.746124031007752e-05,
      "loss": 0.0002,
      "step": 8395
    },
    {
      "epoch": 32.542635658914726,
      "grad_norm": 0.23814791440963745,
      "learning_rate": 1.7457364341085272e-05,
      "loss": 0.0102,
      "step": 8396
    },
    {
      "epoch": 32.54651162790697,
      "grad_norm": 0.0018473343225196004,
      "learning_rate": 1.7453488372093024e-05,
      "loss": 0.0001,
      "step": 8397
    },
    {
      "epoch": 32.55038759689923,
      "grad_norm": 1.0648363828659058,
      "learning_rate": 1.7449612403100777e-05,
      "loss": 0.0611,
      "step": 8398
    },
    {
      "epoch": 32.554263565891475,
      "grad_norm": 0.002154381014406681,
      "learning_rate": 1.744573643410853e-05,
      "loss": 0.0001,
      "step": 8399
    },
    {
      "epoch": 32.55813953488372,
      "grad_norm": 0.10389069467782974,
      "learning_rate": 1.744186046511628e-05,
      "loss": 0.0031,
      "step": 8400
    },
    {
      "epoch": 32.56201550387597,
      "grad_norm": 0.00183967687189579,
      "learning_rate": 1.7437984496124034e-05,
      "loss": 0.0001,
      "step": 8401
    },
    {
      "epoch": 32.565891472868216,
      "grad_norm": 1.4682440757751465,
      "learning_rate": 1.7434108527131783e-05,
      "loss": 0.0698,
      "step": 8402
    },
    {
      "epoch": 32.56976744186046,
      "grad_norm": 0.38092371821403503,
      "learning_rate": 1.7430232558139535e-05,
      "loss": 0.0011,
      "step": 8403
    },
    {
      "epoch": 32.57364341085271,
      "grad_norm": 0.0010219183750450611,
      "learning_rate": 1.7426356589147288e-05,
      "loss": 0.0001,
      "step": 8404
    },
    {
      "epoch": 32.57751937984496,
      "grad_norm": 0.0015633279690518975,
      "learning_rate": 1.742248062015504e-05,
      "loss": 0.0001,
      "step": 8405
    },
    {
      "epoch": 32.58139534883721,
      "grad_norm": 0.010702436789870262,
      "learning_rate": 1.7418604651162793e-05,
      "loss": 0.0005,
      "step": 8406
    },
    {
      "epoch": 32.58527131782946,
      "grad_norm": 0.0020851558074355125,
      "learning_rate": 1.7414728682170545e-05,
      "loss": 0.0001,
      "step": 8407
    },
    {
      "epoch": 32.58914728682171,
      "grad_norm": 0.0025702891871333122,
      "learning_rate": 1.7410852713178297e-05,
      "loss": 0.0002,
      "step": 8408
    },
    {
      "epoch": 32.593023255813954,
      "grad_norm": 1.8607261180877686,
      "learning_rate": 1.7406976744186046e-05,
      "loss": 0.003,
      "step": 8409
    },
    {
      "epoch": 32.5968992248062,
      "grad_norm": 0.0136940972879529,
      "learning_rate": 1.74031007751938e-05,
      "loss": 0.0006,
      "step": 8410
    },
    {
      "epoch": 32.60077519379845,
      "grad_norm": 0.001252690446563065,
      "learning_rate": 1.739922480620155e-05,
      "loss": 0.0001,
      "step": 8411
    },
    {
      "epoch": 32.604651162790695,
      "grad_norm": 0.014249804429709911,
      "learning_rate": 1.7395348837209304e-05,
      "loss": 0.0007,
      "step": 8412
    },
    {
      "epoch": 32.60852713178294,
      "grad_norm": 0.005116473417729139,
      "learning_rate": 1.7391472868217053e-05,
      "loss": 0.0003,
      "step": 8413
    },
    {
      "epoch": 32.6124031007752,
      "grad_norm": 0.0011731722624972463,
      "learning_rate": 1.7387596899224805e-05,
      "loss": 0.0001,
      "step": 8414
    },
    {
      "epoch": 32.616279069767444,
      "grad_norm": 0.001154080149717629,
      "learning_rate": 1.7383720930232558e-05,
      "loss": 0.0001,
      "step": 8415
    },
    {
      "epoch": 32.62015503875969,
      "grad_norm": 0.5343310832977295,
      "learning_rate": 1.737984496124031e-05,
      "loss": 0.0211,
      "step": 8416
    },
    {
      "epoch": 32.62403100775194,
      "grad_norm": 0.0026996470987796783,
      "learning_rate": 1.7375968992248062e-05,
      "loss": 0.0002,
      "step": 8417
    },
    {
      "epoch": 32.627906976744185,
      "grad_norm": 0.0012873582309111953,
      "learning_rate": 1.7372093023255815e-05,
      "loss": 0.0001,
      "step": 8418
    },
    {
      "epoch": 32.63178294573643,
      "grad_norm": 0.0012340124230831861,
      "learning_rate": 1.7368217054263567e-05,
      "loss": 0.0001,
      "step": 8419
    },
    {
      "epoch": 32.63565891472868,
      "grad_norm": 0.0013989688595756888,
      "learning_rate": 1.736434108527132e-05,
      "loss": 0.0001,
      "step": 8420
    },
    {
      "epoch": 32.63953488372093,
      "grad_norm": 2.419100761413574,
      "learning_rate": 1.7360465116279072e-05,
      "loss": 0.082,
      "step": 8421
    },
    {
      "epoch": 32.64341085271318,
      "grad_norm": 0.0012378290994092822,
      "learning_rate": 1.735658914728682e-05,
      "loss": 0.0001,
      "step": 8422
    },
    {
      "epoch": 32.64728682170543,
      "grad_norm": 0.002199126174673438,
      "learning_rate": 1.7352713178294574e-05,
      "loss": 0.0001,
      "step": 8423
    },
    {
      "epoch": 32.651162790697676,
      "grad_norm": 0.0163864865899086,
      "learning_rate": 1.7348837209302326e-05,
      "loss": 0.0003,
      "step": 8424
    },
    {
      "epoch": 32.65503875968992,
      "grad_norm": 0.0018851440399885178,
      "learning_rate": 1.734496124031008e-05,
      "loss": 0.0002,
      "step": 8425
    },
    {
      "epoch": 32.65891472868217,
      "grad_norm": 0.012087400071322918,
      "learning_rate": 1.734108527131783e-05,
      "loss": 0.0005,
      "step": 8426
    },
    {
      "epoch": 32.66279069767442,
      "grad_norm": 0.00631156237795949,
      "learning_rate": 1.7337209302325583e-05,
      "loss": 0.0004,
      "step": 8427
    },
    {
      "epoch": 32.666666666666664,
      "grad_norm": 0.008543767035007477,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.0005,
      "step": 8428
    },
    {
      "epoch": 32.67054263565891,
      "grad_norm": 0.005142750684171915,
      "learning_rate": 1.7329457364341088e-05,
      "loss": 0.0004,
      "step": 8429
    },
    {
      "epoch": 32.674418604651166,
      "grad_norm": 0.0012226628605276346,
      "learning_rate": 1.732558139534884e-05,
      "loss": 0.0001,
      "step": 8430
    },
    {
      "epoch": 32.67829457364341,
      "grad_norm": 0.0017619023565202951,
      "learning_rate": 1.732170542635659e-05,
      "loss": 0.0001,
      "step": 8431
    },
    {
      "epoch": 32.68217054263566,
      "grad_norm": 0.0029335878789424896,
      "learning_rate": 1.7317829457364342e-05,
      "loss": 0.0002,
      "step": 8432
    },
    {
      "epoch": 32.68604651162791,
      "grad_norm": 0.0011042186524719,
      "learning_rate": 1.7313953488372094e-05,
      "loss": 0.0001,
      "step": 8433
    },
    {
      "epoch": 32.689922480620154,
      "grad_norm": 0.001991682220250368,
      "learning_rate": 1.7310077519379847e-05,
      "loss": 0.0002,
      "step": 8434
    },
    {
      "epoch": 32.6937984496124,
      "grad_norm": 0.0012687168782576919,
      "learning_rate": 1.73062015503876e-05,
      "loss": 0.0001,
      "step": 8435
    },
    {
      "epoch": 32.69767441860465,
      "grad_norm": 0.001507260138168931,
      "learning_rate": 1.7302325581395348e-05,
      "loss": 0.0001,
      "step": 8436
    },
    {
      "epoch": 32.701550387596896,
      "grad_norm": 0.0018087534699589014,
      "learning_rate": 1.72984496124031e-05,
      "loss": 0.0002,
      "step": 8437
    },
    {
      "epoch": 32.70542635658915,
      "grad_norm": 0.0042510381899774075,
      "learning_rate": 1.7294573643410853e-05,
      "loss": 0.0003,
      "step": 8438
    },
    {
      "epoch": 32.7093023255814,
      "grad_norm": 0.005533952731639147,
      "learning_rate": 1.7290697674418606e-05,
      "loss": 0.0002,
      "step": 8439
    },
    {
      "epoch": 32.713178294573645,
      "grad_norm": 0.06555560976266861,
      "learning_rate": 1.7286821705426358e-05,
      "loss": 0.0002,
      "step": 8440
    },
    {
      "epoch": 32.71705426356589,
      "grad_norm": 0.0014110178453847766,
      "learning_rate": 1.7282945736434107e-05,
      "loss": 0.0001,
      "step": 8441
    },
    {
      "epoch": 32.72093023255814,
      "grad_norm": 7.630557060241699,
      "learning_rate": 1.727906976744186e-05,
      "loss": 0.0162,
      "step": 8442
    },
    {
      "epoch": 32.724806201550386,
      "grad_norm": 0.005222443025559187,
      "learning_rate": 1.7275193798449612e-05,
      "loss": 0.0003,
      "step": 8443
    },
    {
      "epoch": 32.72868217054263,
      "grad_norm": 0.0019332118099555373,
      "learning_rate": 1.7271317829457364e-05,
      "loss": 0.0002,
      "step": 8444
    },
    {
      "epoch": 32.73255813953488,
      "grad_norm": 0.0012126927031204104,
      "learning_rate": 1.7267441860465117e-05,
      "loss": 0.0001,
      "step": 8445
    },
    {
      "epoch": 32.736434108527135,
      "grad_norm": 0.00293902144767344,
      "learning_rate": 1.726356589147287e-05,
      "loss": 0.0002,
      "step": 8446
    },
    {
      "epoch": 32.74031007751938,
      "grad_norm": 0.0017934654606506228,
      "learning_rate": 1.725968992248062e-05,
      "loss": 0.0001,
      "step": 8447
    },
    {
      "epoch": 32.74418604651163,
      "grad_norm": 0.01031423732638359,
      "learning_rate": 1.7255813953488374e-05,
      "loss": 0.0005,
      "step": 8448
    },
    {
      "epoch": 32.748062015503876,
      "grad_norm": 0.0011323114158585668,
      "learning_rate": 1.7251937984496126e-05,
      "loss": 0.0001,
      "step": 8449
    },
    {
      "epoch": 32.751937984496124,
      "grad_norm": 0.0010571936145424843,
      "learning_rate": 1.7248062015503875e-05,
      "loss": 0.0001,
      "step": 8450
    },
    {
      "epoch": 32.75581395348837,
      "grad_norm": 0.0010452084243297577,
      "learning_rate": 1.7244186046511628e-05,
      "loss": 0.0001,
      "step": 8451
    },
    {
      "epoch": 32.75968992248062,
      "grad_norm": 0.3668363094329834,
      "learning_rate": 1.724031007751938e-05,
      "loss": 0.0155,
      "step": 8452
    },
    {
      "epoch": 32.763565891472865,
      "grad_norm": 15.56076431274414,
      "learning_rate": 1.7236434108527133e-05,
      "loss": 0.022,
      "step": 8453
    },
    {
      "epoch": 32.76744186046512,
      "grad_norm": 0.002021626802161336,
      "learning_rate": 1.7232558139534885e-05,
      "loss": 0.0002,
      "step": 8454
    },
    {
      "epoch": 32.77131782945737,
      "grad_norm": 0.0013443129137158394,
      "learning_rate": 1.7228682170542637e-05,
      "loss": 0.0001,
      "step": 8455
    },
    {
      "epoch": 32.775193798449614,
      "grad_norm": 0.004047320690006018,
      "learning_rate": 1.722480620155039e-05,
      "loss": 0.0002,
      "step": 8456
    },
    {
      "epoch": 32.77906976744186,
      "grad_norm": 0.0012903028400614858,
      "learning_rate": 1.7220930232558142e-05,
      "loss": 0.0001,
      "step": 8457
    },
    {
      "epoch": 32.78294573643411,
      "grad_norm": 0.0009635355672799051,
      "learning_rate": 1.7217054263565895e-05,
      "loss": 0.0001,
      "step": 8458
    },
    {
      "epoch": 32.786821705426355,
      "grad_norm": 0.004162187222391367,
      "learning_rate": 1.7213178294573644e-05,
      "loss": 0.0004,
      "step": 8459
    },
    {
      "epoch": 32.7906976744186,
      "grad_norm": 0.002014563884586096,
      "learning_rate": 1.7209302325581396e-05,
      "loss": 0.0002,
      "step": 8460
    },
    {
      "epoch": 32.79457364341085,
      "grad_norm": 0.0020039230585098267,
      "learning_rate": 1.720542635658915e-05,
      "loss": 0.0001,
      "step": 8461
    },
    {
      "epoch": 32.798449612403104,
      "grad_norm": 0.001559186028316617,
      "learning_rate": 1.72015503875969e-05,
      "loss": 0.0002,
      "step": 8462
    },
    {
      "epoch": 32.80232558139535,
      "grad_norm": 0.00106902199331671,
      "learning_rate": 1.719767441860465e-05,
      "loss": 0.0001,
      "step": 8463
    },
    {
      "epoch": 32.8062015503876,
      "grad_norm": 0.06352848559617996,
      "learning_rate": 1.7193798449612403e-05,
      "loss": 0.0005,
      "step": 8464
    },
    {
      "epoch": 32.810077519379846,
      "grad_norm": 0.0025551533326506615,
      "learning_rate": 1.7189922480620155e-05,
      "loss": 0.0001,
      "step": 8465
    },
    {
      "epoch": 32.81395348837209,
      "grad_norm": 0.0011770116398110986,
      "learning_rate": 1.7186046511627907e-05,
      "loss": 0.0001,
      "step": 8466
    },
    {
      "epoch": 32.81782945736434,
      "grad_norm": 0.001567058963701129,
      "learning_rate": 1.718217054263566e-05,
      "loss": 0.0002,
      "step": 8467
    },
    {
      "epoch": 32.82170542635659,
      "grad_norm": 0.0010489750420674682,
      "learning_rate": 1.7178294573643412e-05,
      "loss": 0.0001,
      "step": 8468
    },
    {
      "epoch": 32.825581395348834,
      "grad_norm": 0.0012692718300968409,
      "learning_rate": 1.7174418604651165e-05,
      "loss": 0.0001,
      "step": 8469
    },
    {
      "epoch": 32.82945736434109,
      "grad_norm": 1.6902315616607666,
      "learning_rate": 1.7170542635658914e-05,
      "loss": 0.1591,
      "step": 8470
    },
    {
      "epoch": 32.833333333333336,
      "grad_norm": 0.25726592540740967,
      "learning_rate": 1.7166666666666666e-05,
      "loss": 0.0113,
      "step": 8471
    },
    {
      "epoch": 32.83720930232558,
      "grad_norm": 0.0027218847535550594,
      "learning_rate": 1.716279069767442e-05,
      "loss": 0.0002,
      "step": 8472
    },
    {
      "epoch": 32.84108527131783,
      "grad_norm": 0.0021393790375441313,
      "learning_rate": 1.715891472868217e-05,
      "loss": 0.0002,
      "step": 8473
    },
    {
      "epoch": 32.84496124031008,
      "grad_norm": 1.5364516973495483,
      "learning_rate": 1.7155038759689923e-05,
      "loss": 0.1048,
      "step": 8474
    },
    {
      "epoch": 32.848837209302324,
      "grad_norm": 0.002298545790836215,
      "learning_rate": 1.7151162790697676e-05,
      "loss": 0.0002,
      "step": 8475
    },
    {
      "epoch": 32.85271317829457,
      "grad_norm": 0.002734740497544408,
      "learning_rate": 1.7147286821705428e-05,
      "loss": 0.0002,
      "step": 8476
    },
    {
      "epoch": 32.85658914728682,
      "grad_norm": 0.007817120291292667,
      "learning_rate": 1.714341085271318e-05,
      "loss": 0.0003,
      "step": 8477
    },
    {
      "epoch": 32.86046511627907,
      "grad_norm": 0.18910078704357147,
      "learning_rate": 1.713953488372093e-05,
      "loss": 0.001,
      "step": 8478
    },
    {
      "epoch": 32.86434108527132,
      "grad_norm": 0.00905308686196804,
      "learning_rate": 1.7135658914728682e-05,
      "loss": 0.0004,
      "step": 8479
    },
    {
      "epoch": 32.86821705426357,
      "grad_norm": 0.006462900433689356,
      "learning_rate": 1.7131782945736434e-05,
      "loss": 0.0003,
      "step": 8480
    },
    {
      "epoch": 32.872093023255815,
      "grad_norm": 0.00819726474583149,
      "learning_rate": 1.7127906976744187e-05,
      "loss": 0.0003,
      "step": 8481
    },
    {
      "epoch": 32.87596899224806,
      "grad_norm": 0.020033368840813637,
      "learning_rate": 1.712403100775194e-05,
      "loss": 0.0007,
      "step": 8482
    },
    {
      "epoch": 32.87984496124031,
      "grad_norm": 0.006654944270849228,
      "learning_rate": 1.7120155038759692e-05,
      "loss": 0.0003,
      "step": 8483
    },
    {
      "epoch": 32.883720930232556,
      "grad_norm": 0.01862608827650547,
      "learning_rate": 1.7116279069767444e-05,
      "loss": 0.0006,
      "step": 8484
    },
    {
      "epoch": 32.8875968992248,
      "grad_norm": 0.02488098107278347,
      "learning_rate": 1.7112403100775197e-05,
      "loss": 0.0007,
      "step": 8485
    },
    {
      "epoch": 32.89147286821706,
      "grad_norm": 0.010902684181928635,
      "learning_rate": 1.710852713178295e-05,
      "loss": 0.0004,
      "step": 8486
    },
    {
      "epoch": 32.895348837209305,
      "grad_norm": 0.018884051591157913,
      "learning_rate": 1.7104651162790698e-05,
      "loss": 0.0006,
      "step": 8487
    },
    {
      "epoch": 32.89922480620155,
      "grad_norm": 4.505776405334473,
      "learning_rate": 1.710077519379845e-05,
      "loss": 0.326,
      "step": 8488
    },
    {
      "epoch": 32.9031007751938,
      "grad_norm": 0.01315843965858221,
      "learning_rate": 1.70968992248062e-05,
      "loss": 0.0005,
      "step": 8489
    },
    {
      "epoch": 32.906976744186046,
      "grad_norm": 0.037925709038972855,
      "learning_rate": 1.7093023255813952e-05,
      "loss": 0.0011,
      "step": 8490
    },
    {
      "epoch": 32.91085271317829,
      "grad_norm": 0.004803638439625502,
      "learning_rate": 1.7089147286821704e-05,
      "loss": 0.0002,
      "step": 8491
    },
    {
      "epoch": 32.91472868217054,
      "grad_norm": 0.010287373326718807,
      "learning_rate": 1.7085271317829457e-05,
      "loss": 0.0004,
      "step": 8492
    },
    {
      "epoch": 32.91860465116279,
      "grad_norm": 0.019319912418723106,
      "learning_rate": 1.708139534883721e-05,
      "loss": 0.0007,
      "step": 8493
    },
    {
      "epoch": 32.92248062015504,
      "grad_norm": 0.010061313398182392,
      "learning_rate": 1.707751937984496e-05,
      "loss": 0.0004,
      "step": 8494
    },
    {
      "epoch": 32.92635658914729,
      "grad_norm": 0.00802496075630188,
      "learning_rate": 1.7073643410852714e-05,
      "loss": 0.0003,
      "step": 8495
    },
    {
      "epoch": 32.93023255813954,
      "grad_norm": 0.011380432173609734,
      "learning_rate": 1.7069767441860466e-05,
      "loss": 0.0004,
      "step": 8496
    },
    {
      "epoch": 32.934108527131784,
      "grad_norm": 0.01720382645726204,
      "learning_rate": 1.706589147286822e-05,
      "loss": 0.0005,
      "step": 8497
    },
    {
      "epoch": 32.93798449612403,
      "grad_norm": 4.484615325927734,
      "learning_rate": 1.7062015503875968e-05,
      "loss": 0.6184,
      "step": 8498
    },
    {
      "epoch": 32.94186046511628,
      "grad_norm": 0.04203605279326439,
      "learning_rate": 1.705813953488372e-05,
      "loss": 0.0012,
      "step": 8499
    },
    {
      "epoch": 32.945736434108525,
      "grad_norm": 0.0019380535231903195,
      "learning_rate": 1.7054263565891473e-05,
      "loss": 0.0002,
      "step": 8500
    },
    {
      "epoch": 32.94961240310077,
      "grad_norm": 0.21684832870960236,
      "learning_rate": 1.7050387596899225e-05,
      "loss": 0.0097,
      "step": 8501
    },
    {
      "epoch": 32.95348837209303,
      "grad_norm": 0.00925274845212698,
      "learning_rate": 1.7046511627906978e-05,
      "loss": 0.0003,
      "step": 8502
    },
    {
      "epoch": 32.957364341085274,
      "grad_norm": 0.0053349509835243225,
      "learning_rate": 1.704263565891473e-05,
      "loss": 0.0003,
      "step": 8503
    },
    {
      "epoch": 32.96124031007752,
      "grad_norm": 0.0043420251458883286,
      "learning_rate": 1.7038759689922482e-05,
      "loss": 0.0002,
      "step": 8504
    },
    {
      "epoch": 32.96511627906977,
      "grad_norm": 3.637871026992798,
      "learning_rate": 1.7034883720930235e-05,
      "loss": 0.3866,
      "step": 8505
    },
    {
      "epoch": 32.968992248062015,
      "grad_norm": 0.01036826241761446,
      "learning_rate": 1.7031007751937987e-05,
      "loss": 0.0004,
      "step": 8506
    },
    {
      "epoch": 32.97286821705426,
      "grad_norm": 0.0035910713486373425,
      "learning_rate": 1.7027131782945736e-05,
      "loss": 0.0002,
      "step": 8507
    },
    {
      "epoch": 32.97674418604651,
      "grad_norm": 0.004137961193919182,
      "learning_rate": 1.702325581395349e-05,
      "loss": 0.0002,
      "step": 8508
    },
    {
      "epoch": 32.98062015503876,
      "grad_norm": 0.0037192408926784992,
      "learning_rate": 1.701937984496124e-05,
      "loss": 0.0002,
      "step": 8509
    },
    {
      "epoch": 32.98449612403101,
      "grad_norm": 0.00168701633810997,
      "learning_rate": 1.7015503875968994e-05,
      "loss": 0.0002,
      "step": 8510
    },
    {
      "epoch": 32.98837209302326,
      "grad_norm": 0.003191567026078701,
      "learning_rate": 1.7011627906976746e-05,
      "loss": 0.0002,
      "step": 8511
    },
    {
      "epoch": 32.992248062015506,
      "grad_norm": 0.003232897026464343,
      "learning_rate": 1.70077519379845e-05,
      "loss": 0.0002,
      "step": 8512
    },
    {
      "epoch": 32.99612403100775,
      "grad_norm": 0.0029272912070155144,
      "learning_rate": 1.700387596899225e-05,
      "loss": 0.0002,
      "step": 8513
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.00200800527818501,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.0002,
      "step": 8514
    },
    {
      "epoch": 33.00387596899225,
      "grad_norm": 0.0035608727484941483,
      "learning_rate": 1.6996124031007756e-05,
      "loss": 0.0002,
      "step": 8515
    },
    {
      "epoch": 33.007751937984494,
      "grad_norm": 0.002940228907391429,
      "learning_rate": 1.6992248062015505e-05,
      "loss": 0.0002,
      "step": 8516
    },
    {
      "epoch": 33.01162790697674,
      "grad_norm": 0.0033059134148061275,
      "learning_rate": 1.6988372093023254e-05,
      "loss": 0.0002,
      "step": 8517
    },
    {
      "epoch": 33.01550387596899,
      "grad_norm": 0.004741266835480928,
      "learning_rate": 1.6984496124031006e-05,
      "loss": 0.0003,
      "step": 8518
    },
    {
      "epoch": 33.01937984496124,
      "grad_norm": 0.00790331605821848,
      "learning_rate": 1.698062015503876e-05,
      "loss": 0.0005,
      "step": 8519
    },
    {
      "epoch": 33.02325581395349,
      "grad_norm": 0.00313405878841877,
      "learning_rate": 1.697674418604651e-05,
      "loss": 0.0002,
      "step": 8520
    },
    {
      "epoch": 33.02713178294574,
      "grad_norm": 0.0025453821290284395,
      "learning_rate": 1.6972868217054263e-05,
      "loss": 0.0002,
      "step": 8521
    },
    {
      "epoch": 33.031007751937985,
      "grad_norm": 0.0019586305133998394,
      "learning_rate": 1.6968992248062016e-05,
      "loss": 0.0002,
      "step": 8522
    },
    {
      "epoch": 33.03488372093023,
      "grad_norm": 0.004291796125471592,
      "learning_rate": 1.6965116279069768e-05,
      "loss": 0.0003,
      "step": 8523
    },
    {
      "epoch": 33.03875968992248,
      "grad_norm": 0.010224545374512672,
      "learning_rate": 1.696124031007752e-05,
      "loss": 0.0004,
      "step": 8524
    },
    {
      "epoch": 33.042635658914726,
      "grad_norm": 0.0017596137477084994,
      "learning_rate": 1.6957364341085273e-05,
      "loss": 0.0001,
      "step": 8525
    },
    {
      "epoch": 33.04651162790697,
      "grad_norm": 0.0020033130422234535,
      "learning_rate": 1.6953488372093022e-05,
      "loss": 0.0002,
      "step": 8526
    },
    {
      "epoch": 33.05038759689923,
      "grad_norm": 0.00514678331092,
      "learning_rate": 1.6949612403100775e-05,
      "loss": 0.0004,
      "step": 8527
    },
    {
      "epoch": 33.054263565891475,
      "grad_norm": 0.0055550094693899155,
      "learning_rate": 1.6945736434108527e-05,
      "loss": 0.0002,
      "step": 8528
    },
    {
      "epoch": 33.05813953488372,
      "grad_norm": 2.7396674156188965,
      "learning_rate": 1.694186046511628e-05,
      "loss": 0.1677,
      "step": 8529
    },
    {
      "epoch": 33.06201550387597,
      "grad_norm": 0.0022174955811351538,
      "learning_rate": 1.6937984496124032e-05,
      "loss": 0.0002,
      "step": 8530
    },
    {
      "epoch": 33.065891472868216,
      "grad_norm": 0.0029829773120582104,
      "learning_rate": 1.6934108527131784e-05,
      "loss": 0.0002,
      "step": 8531
    },
    {
      "epoch": 33.06976744186046,
      "grad_norm": 0.0016813799738883972,
      "learning_rate": 1.6930232558139537e-05,
      "loss": 0.0002,
      "step": 8532
    },
    {
      "epoch": 33.07364341085271,
      "grad_norm": 0.0036609580274671316,
      "learning_rate": 1.692635658914729e-05,
      "loss": 0.0003,
      "step": 8533
    },
    {
      "epoch": 33.07751937984496,
      "grad_norm": 0.41551896929740906,
      "learning_rate": 1.692248062015504e-05,
      "loss": 0.0179,
      "step": 8534
    },
    {
      "epoch": 33.08139534883721,
      "grad_norm": 0.0018724924884736538,
      "learning_rate": 1.691860465116279e-05,
      "loss": 0.0002,
      "step": 8535
    },
    {
      "epoch": 33.08527131782946,
      "grad_norm": 0.0016062599606812,
      "learning_rate": 1.6914728682170543e-05,
      "loss": 0.0002,
      "step": 8536
    },
    {
      "epoch": 33.08914728682171,
      "grad_norm": 0.002465092111378908,
      "learning_rate": 1.6910852713178295e-05,
      "loss": 0.0002,
      "step": 8537
    },
    {
      "epoch": 33.093023255813954,
      "grad_norm": 0.00411904277279973,
      "learning_rate": 1.6906976744186048e-05,
      "loss": 0.0003,
      "step": 8538
    },
    {
      "epoch": 33.0968992248062,
      "grad_norm": 0.00251757656224072,
      "learning_rate": 1.69031007751938e-05,
      "loss": 0.0002,
      "step": 8539
    },
    {
      "epoch": 33.10077519379845,
      "grad_norm": 1.068717122077942,
      "learning_rate": 1.6899224806201553e-05,
      "loss": 0.0662,
      "step": 8540
    },
    {
      "epoch": 33.104651162790695,
      "grad_norm": 0.0024695899337530136,
      "learning_rate": 1.6895348837209305e-05,
      "loss": 0.0002,
      "step": 8541
    },
    {
      "epoch": 33.10852713178294,
      "grad_norm": 0.0035063819959759712,
      "learning_rate": 1.6891472868217058e-05,
      "loss": 0.0002,
      "step": 8542
    },
    {
      "epoch": 33.1124031007752,
      "grad_norm": 0.003052561776712537,
      "learning_rate": 1.6887596899224807e-05,
      "loss": 0.0003,
      "step": 8543
    },
    {
      "epoch": 33.116279069767444,
      "grad_norm": 0.005131198558956385,
      "learning_rate": 1.688372093023256e-05,
      "loss": 0.0003,
      "step": 8544
    },
    {
      "epoch": 33.12015503875969,
      "grad_norm": 0.011451478116214275,
      "learning_rate": 1.687984496124031e-05,
      "loss": 0.0004,
      "step": 8545
    },
    {
      "epoch": 33.12403100775194,
      "grad_norm": 0.002781414892524481,
      "learning_rate": 1.687596899224806e-05,
      "loss": 0.0003,
      "step": 8546
    },
    {
      "epoch": 33.127906976744185,
      "grad_norm": 0.19230976700782776,
      "learning_rate": 1.6872093023255813e-05,
      "loss": 0.0025,
      "step": 8547
    },
    {
      "epoch": 33.13178294573643,
      "grad_norm": 0.00161777064204216,
      "learning_rate": 1.6868217054263565e-05,
      "loss": 0.0001,
      "step": 8548
    },
    {
      "epoch": 33.13565891472868,
      "grad_norm": 0.002359757898375392,
      "learning_rate": 1.6864341085271318e-05,
      "loss": 0.0002,
      "step": 8549
    },
    {
      "epoch": 33.13953488372093,
      "grad_norm": 0.002767071593552828,
      "learning_rate": 1.686046511627907e-05,
      "loss": 0.0002,
      "step": 8550
    },
    {
      "epoch": 33.14341085271318,
      "grad_norm": 0.002849827753379941,
      "learning_rate": 1.6856589147286823e-05,
      "loss": 0.0002,
      "step": 8551
    },
    {
      "epoch": 33.14728682170543,
      "grad_norm": 6.763577461242676,
      "learning_rate": 1.6852713178294575e-05,
      "loss": 0.0088,
      "step": 8552
    },
    {
      "epoch": 33.151162790697676,
      "grad_norm": 0.0017017582431435585,
      "learning_rate": 1.6848837209302327e-05,
      "loss": 0.0002,
      "step": 8553
    },
    {
      "epoch": 33.15503875968992,
      "grad_norm": 0.0023868251591920853,
      "learning_rate": 1.684496124031008e-05,
      "loss": 0.0002,
      "step": 8554
    },
    {
      "epoch": 33.15891472868217,
      "grad_norm": 0.0012717104982584715,
      "learning_rate": 1.684108527131783e-05,
      "loss": 0.0001,
      "step": 8555
    },
    {
      "epoch": 33.16279069767442,
      "grad_norm": 0.002078090561553836,
      "learning_rate": 1.683720930232558e-05,
      "loss": 0.0002,
      "step": 8556
    },
    {
      "epoch": 33.166666666666664,
      "grad_norm": 0.008669203147292137,
      "learning_rate": 1.6833333333333334e-05,
      "loss": 0.0006,
      "step": 8557
    },
    {
      "epoch": 33.17054263565891,
      "grad_norm": 2.4743666648864746,
      "learning_rate": 1.6829457364341086e-05,
      "loss": 0.1796,
      "step": 8558
    },
    {
      "epoch": 33.174418604651166,
      "grad_norm": 0.0018832358764484525,
      "learning_rate": 1.682558139534884e-05,
      "loss": 0.0002,
      "step": 8559
    },
    {
      "epoch": 33.17829457364341,
      "grad_norm": 0.0015102699398994446,
      "learning_rate": 1.682170542635659e-05,
      "loss": 0.0001,
      "step": 8560
    },
    {
      "epoch": 33.18217054263566,
      "grad_norm": 0.8937247395515442,
      "learning_rate": 1.6817829457364343e-05,
      "loss": 0.0376,
      "step": 8561
    },
    {
      "epoch": 33.18604651162791,
      "grad_norm": 0.0015564810018986464,
      "learning_rate": 1.6813953488372096e-05,
      "loss": 0.0001,
      "step": 8562
    },
    {
      "epoch": 33.189922480620154,
      "grad_norm": 0.31647422909736633,
      "learning_rate": 1.6810077519379848e-05,
      "loss": 0.014,
      "step": 8563
    },
    {
      "epoch": 33.1937984496124,
      "grad_norm": 0.002535517094656825,
      "learning_rate": 1.6806201550387597e-05,
      "loss": 0.0002,
      "step": 8564
    },
    {
      "epoch": 33.19767441860465,
      "grad_norm": 0.0020401026122272015,
      "learning_rate": 1.680232558139535e-05,
      "loss": 0.0002,
      "step": 8565
    },
    {
      "epoch": 33.201550387596896,
      "grad_norm": 0.0029330928809940815,
      "learning_rate": 1.6798449612403102e-05,
      "loss": 0.0002,
      "step": 8566
    },
    {
      "epoch": 33.20542635658915,
      "grad_norm": 0.00819032359868288,
      "learning_rate": 1.6794573643410854e-05,
      "loss": 0.0004,
      "step": 8567
    },
    {
      "epoch": 33.2093023255814,
      "grad_norm": 0.3421846330165863,
      "learning_rate": 1.6790697674418607e-05,
      "loss": 0.0147,
      "step": 8568
    },
    {
      "epoch": 33.213178294573645,
      "grad_norm": 0.0016022620256990194,
      "learning_rate": 1.6786821705426356e-05,
      "loss": 0.0001,
      "step": 8569
    },
    {
      "epoch": 33.21705426356589,
      "grad_norm": 0.002174850320443511,
      "learning_rate": 1.678294573643411e-05,
      "loss": 0.0002,
      "step": 8570
    },
    {
      "epoch": 33.22093023255814,
      "grad_norm": 0.0020739343017339706,
      "learning_rate": 1.677906976744186e-05,
      "loss": 0.0002,
      "step": 8571
    },
    {
      "epoch": 33.224806201550386,
      "grad_norm": 0.002690450754016638,
      "learning_rate": 1.6775193798449613e-05,
      "loss": 0.0002,
      "step": 8572
    },
    {
      "epoch": 33.22868217054263,
      "grad_norm": 8.473798751831055,
      "learning_rate": 1.6771317829457366e-05,
      "loss": 0.0854,
      "step": 8573
    },
    {
      "epoch": 33.23255813953488,
      "grad_norm": 0.0025449912063777447,
      "learning_rate": 1.6767441860465115e-05,
      "loss": 0.0002,
      "step": 8574
    },
    {
      "epoch": 33.236434108527135,
      "grad_norm": 0.007035174872726202,
      "learning_rate": 1.6763565891472867e-05,
      "loss": 0.0002,
      "step": 8575
    },
    {
      "epoch": 33.24031007751938,
      "grad_norm": 0.0014471253380179405,
      "learning_rate": 1.675968992248062e-05,
      "loss": 0.0001,
      "step": 8576
    },
    {
      "epoch": 33.24418604651163,
      "grad_norm": 0.0017974985530599952,
      "learning_rate": 1.6755813953488372e-05,
      "loss": 0.0002,
      "step": 8577
    },
    {
      "epoch": 33.248062015503876,
      "grad_norm": 0.0028864226769655943,
      "learning_rate": 1.6751937984496124e-05,
      "loss": 0.0002,
      "step": 8578
    },
    {
      "epoch": 33.251937984496124,
      "grad_norm": 0.01554172858595848,
      "learning_rate": 1.6748062015503877e-05,
      "loss": 0.0004,
      "step": 8579
    },
    {
      "epoch": 33.25581395348837,
      "grad_norm": 3.7357711791992188,
      "learning_rate": 1.674418604651163e-05,
      "loss": 0.3069,
      "step": 8580
    },
    {
      "epoch": 33.25968992248062,
      "grad_norm": 0.0051893629133701324,
      "learning_rate": 1.674031007751938e-05,
      "loss": 0.0002,
      "step": 8581
    },
    {
      "epoch": 33.263565891472865,
      "grad_norm": 0.0023701204918324947,
      "learning_rate": 1.6736434108527134e-05,
      "loss": 0.0002,
      "step": 8582
    },
    {
      "epoch": 33.26744186046512,
      "grad_norm": 0.0018741898238658905,
      "learning_rate": 1.6732558139534883e-05,
      "loss": 0.0002,
      "step": 8583
    },
    {
      "epoch": 33.27131782945737,
      "grad_norm": 0.0023609939962625504,
      "learning_rate": 1.6728682170542635e-05,
      "loss": 0.0002,
      "step": 8584
    },
    {
      "epoch": 33.275193798449614,
      "grad_norm": 0.0020775804296135902,
      "learning_rate": 1.6724806201550388e-05,
      "loss": 0.0002,
      "step": 8585
    },
    {
      "epoch": 33.27906976744186,
      "grad_norm": 0.0019022272899746895,
      "learning_rate": 1.672093023255814e-05,
      "loss": 0.0002,
      "step": 8586
    },
    {
      "epoch": 33.28294573643411,
      "grad_norm": 0.010726941749453545,
      "learning_rate": 1.6717054263565893e-05,
      "loss": 0.0006,
      "step": 8587
    },
    {
      "epoch": 33.286821705426355,
      "grad_norm": 0.005137421190738678,
      "learning_rate": 1.6713178294573645e-05,
      "loss": 0.0002,
      "step": 8588
    },
    {
      "epoch": 33.2906976744186,
      "grad_norm": 0.003215571865439415,
      "learning_rate": 1.6709302325581398e-05,
      "loss": 0.0002,
      "step": 8589
    },
    {
      "epoch": 33.29457364341085,
      "grad_norm": 0.0022556164767593145,
      "learning_rate": 1.670542635658915e-05,
      "loss": 0.0002,
      "step": 8590
    },
    {
      "epoch": 33.298449612403104,
      "grad_norm": 0.0031879006419330835,
      "learning_rate": 1.6701550387596902e-05,
      "loss": 0.0002,
      "step": 8591
    },
    {
      "epoch": 33.30232558139535,
      "grad_norm": 1.9649386405944824,
      "learning_rate": 1.669767441860465e-05,
      "loss": 0.1677,
      "step": 8592
    },
    {
      "epoch": 33.3062015503876,
      "grad_norm": 0.002207779325544834,
      "learning_rate": 1.6693798449612404e-05,
      "loss": 0.0002,
      "step": 8593
    },
    {
      "epoch": 33.310077519379846,
      "grad_norm": 0.004153565503656864,
      "learning_rate": 1.6689922480620156e-05,
      "loss": 0.0002,
      "step": 8594
    },
    {
      "epoch": 33.31395348837209,
      "grad_norm": 2.510355234146118,
      "learning_rate": 1.668604651162791e-05,
      "loss": 0.1071,
      "step": 8595
    },
    {
      "epoch": 33.31782945736434,
      "grad_norm": 0.005927647929638624,
      "learning_rate": 1.6682170542635658e-05,
      "loss": 0.0002,
      "step": 8596
    },
    {
      "epoch": 33.32170542635659,
      "grad_norm": 0.002163916826248169,
      "learning_rate": 1.667829457364341e-05,
      "loss": 0.0002,
      "step": 8597
    },
    {
      "epoch": 33.325581395348834,
      "grad_norm": 0.0020536906085908413,
      "learning_rate": 1.6674418604651163e-05,
      "loss": 0.0002,
      "step": 8598
    },
    {
      "epoch": 33.32945736434109,
      "grad_norm": 0.44480958580970764,
      "learning_rate": 1.6670542635658915e-05,
      "loss": 0.0093,
      "step": 8599
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 0.6219586133956909,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0017,
      "step": 8600
    },
    {
      "epoch": 33.33720930232558,
      "grad_norm": 0.001593614462763071,
      "learning_rate": 1.666279069767442e-05,
      "loss": 0.0001,
      "step": 8601
    },
    {
      "epoch": 33.34108527131783,
      "grad_norm": 1.5804401636123657,
      "learning_rate": 1.6658914728682172e-05,
      "loss": 0.071,
      "step": 8602
    },
    {
      "epoch": 33.34496124031008,
      "grad_norm": 0.0013233592035248876,
      "learning_rate": 1.665503875968992e-05,
      "loss": 0.0001,
      "step": 8603
    },
    {
      "epoch": 33.348837209302324,
      "grad_norm": 0.0015837829560041428,
      "learning_rate": 1.6651162790697674e-05,
      "loss": 0.0001,
      "step": 8604
    },
    {
      "epoch": 33.35271317829457,
      "grad_norm": 0.0019799419678747654,
      "learning_rate": 1.6647286821705426e-05,
      "loss": 0.0001,
      "step": 8605
    },
    {
      "epoch": 33.35658914728682,
      "grad_norm": 0.0019691346678882837,
      "learning_rate": 1.664341085271318e-05,
      "loss": 0.0002,
      "step": 8606
    },
    {
      "epoch": 33.36046511627907,
      "grad_norm": 0.0019767810590565205,
      "learning_rate": 1.663953488372093e-05,
      "loss": 0.0001,
      "step": 8607
    },
    {
      "epoch": 33.36434108527132,
      "grad_norm": 0.00454852357506752,
      "learning_rate": 1.6635658914728683e-05,
      "loss": 0.0003,
      "step": 8608
    },
    {
      "epoch": 33.36821705426357,
      "grad_norm": 0.0016625829739496112,
      "learning_rate": 1.6631782945736436e-05,
      "loss": 0.0001,
      "step": 8609
    },
    {
      "epoch": 33.372093023255815,
      "grad_norm": 0.0061315507628023624,
      "learning_rate": 1.6627906976744188e-05,
      "loss": 0.0004,
      "step": 8610
    },
    {
      "epoch": 33.37596899224806,
      "grad_norm": 0.0014830027939751744,
      "learning_rate": 1.6624031007751937e-05,
      "loss": 0.0001,
      "step": 8611
    },
    {
      "epoch": 33.37984496124031,
      "grad_norm": 0.0014306969242170453,
      "learning_rate": 1.662015503875969e-05,
      "loss": 0.0001,
      "step": 8612
    },
    {
      "epoch": 33.383720930232556,
      "grad_norm": 0.0021411592606455088,
      "learning_rate": 1.6616279069767442e-05,
      "loss": 0.0002,
      "step": 8613
    },
    {
      "epoch": 33.3875968992248,
      "grad_norm": 0.0019382224418222904,
      "learning_rate": 1.6612403100775195e-05,
      "loss": 0.0002,
      "step": 8614
    },
    {
      "epoch": 33.39147286821706,
      "grad_norm": 0.07895299792289734,
      "learning_rate": 1.6608527131782947e-05,
      "loss": 0.0012,
      "step": 8615
    },
    {
      "epoch": 33.395348837209305,
      "grad_norm": 4.4872565269470215,
      "learning_rate": 1.66046511627907e-05,
      "loss": 0.4832,
      "step": 8616
    },
    {
      "epoch": 33.39922480620155,
      "grad_norm": 0.0027121715247631073,
      "learning_rate": 1.6600775193798452e-05,
      "loss": 0.0002,
      "step": 8617
    },
    {
      "epoch": 33.4031007751938,
      "grad_norm": 0.002480320166796446,
      "learning_rate": 1.6596899224806204e-05,
      "loss": 0.0002,
      "step": 8618
    },
    {
      "epoch": 33.406976744186046,
      "grad_norm": 0.0014944402500987053,
      "learning_rate": 1.6593023255813957e-05,
      "loss": 0.0001,
      "step": 8619
    },
    {
      "epoch": 33.41085271317829,
      "grad_norm": 0.0026241878513246775,
      "learning_rate": 1.6589147286821706e-05,
      "loss": 0.0002,
      "step": 8620
    },
    {
      "epoch": 33.41472868217054,
      "grad_norm": 0.001749377348460257,
      "learning_rate": 1.6585271317829458e-05,
      "loss": 0.0001,
      "step": 8621
    },
    {
      "epoch": 33.41860465116279,
      "grad_norm": 0.0026563655119389296,
      "learning_rate": 1.658139534883721e-05,
      "loss": 0.0002,
      "step": 8622
    },
    {
      "epoch": 33.42248062015504,
      "grad_norm": 0.002136355033144355,
      "learning_rate": 1.657751937984496e-05,
      "loss": 0.0002,
      "step": 8623
    },
    {
      "epoch": 33.42635658914729,
      "grad_norm": 0.0022324733436107635,
      "learning_rate": 1.6573643410852712e-05,
      "loss": 0.0002,
      "step": 8624
    },
    {
      "epoch": 33.43023255813954,
      "grad_norm": 0.004629224073141813,
      "learning_rate": 1.6569767441860464e-05,
      "loss": 0.0003,
      "step": 8625
    },
    {
      "epoch": 33.434108527131784,
      "grad_norm": 0.0029552297201007605,
      "learning_rate": 1.6565891472868217e-05,
      "loss": 0.0002,
      "step": 8626
    },
    {
      "epoch": 33.43798449612403,
      "grad_norm": 0.0016941680805757642,
      "learning_rate": 1.656201550387597e-05,
      "loss": 0.0001,
      "step": 8627
    },
    {
      "epoch": 33.44186046511628,
      "grad_norm": 0.0028304217848926783,
      "learning_rate": 1.6558139534883722e-05,
      "loss": 0.0002,
      "step": 8628
    },
    {
      "epoch": 33.445736434108525,
      "grad_norm": 0.004275011830031872,
      "learning_rate": 1.6554263565891474e-05,
      "loss": 0.0002,
      "step": 8629
    },
    {
      "epoch": 33.44961240310077,
      "grad_norm": 0.0024035824462771416,
      "learning_rate": 1.6550387596899227e-05,
      "loss": 0.0002,
      "step": 8630
    },
    {
      "epoch": 33.45348837209303,
      "grad_norm": 0.006091741379350424,
      "learning_rate": 1.6546511627906976e-05,
      "loss": 0.0004,
      "step": 8631
    },
    {
      "epoch": 33.457364341085274,
      "grad_norm": 0.0018764075357466936,
      "learning_rate": 1.6542635658914728e-05,
      "loss": 0.0001,
      "step": 8632
    },
    {
      "epoch": 33.46124031007752,
      "grad_norm": 25.464147567749023,
      "learning_rate": 1.653875968992248e-05,
      "loss": 0.1583,
      "step": 8633
    },
    {
      "epoch": 33.46511627906977,
      "grad_norm": 0.0013863724889233708,
      "learning_rate": 1.6534883720930233e-05,
      "loss": 0.0001,
      "step": 8634
    },
    {
      "epoch": 33.468992248062015,
      "grad_norm": 0.0034753684885799885,
      "learning_rate": 1.6531007751937985e-05,
      "loss": 0.0002,
      "step": 8635
    },
    {
      "epoch": 33.47286821705426,
      "grad_norm": 0.003446998307481408,
      "learning_rate": 1.6527131782945738e-05,
      "loss": 0.0003,
      "step": 8636
    },
    {
      "epoch": 33.47674418604651,
      "grad_norm": 0.0021232261788100004,
      "learning_rate": 1.652325581395349e-05,
      "loss": 0.0002,
      "step": 8637
    },
    {
      "epoch": 33.48062015503876,
      "grad_norm": 0.001467993832193315,
      "learning_rate": 1.6519379844961243e-05,
      "loss": 0.0001,
      "step": 8638
    },
    {
      "epoch": 33.48449612403101,
      "grad_norm": 0.0035847164690494537,
      "learning_rate": 1.6515503875968995e-05,
      "loss": 0.0002,
      "step": 8639
    },
    {
      "epoch": 33.48837209302326,
      "grad_norm": 0.015590852126479149,
      "learning_rate": 1.6511627906976744e-05,
      "loss": 0.0004,
      "step": 8640
    },
    {
      "epoch": 33.492248062015506,
      "grad_norm": 0.0018540978198871017,
      "learning_rate": 1.6507751937984496e-05,
      "loss": 0.0002,
      "step": 8641
    },
    {
      "epoch": 33.49612403100775,
      "grad_norm": 0.0019935593008995056,
      "learning_rate": 1.650387596899225e-05,
      "loss": 0.0001,
      "step": 8642
    },
    {
      "epoch": 33.5,
      "grad_norm": 0.0017019833903759718,
      "learning_rate": 1.65e-05,
      "loss": 0.0001,
      "step": 8643
    },
    {
      "epoch": 33.50387596899225,
      "grad_norm": 0.0016852603293955326,
      "learning_rate": 1.6496124031007754e-05,
      "loss": 0.0001,
      "step": 8644
    },
    {
      "epoch": 33.507751937984494,
      "grad_norm": 0.0014001867966726422,
      "learning_rate": 1.6492248062015506e-05,
      "loss": 0.0001,
      "step": 8645
    },
    {
      "epoch": 33.51162790697674,
      "grad_norm": 0.005605944897979498,
      "learning_rate": 1.648837209302326e-05,
      "loss": 0.0003,
      "step": 8646
    },
    {
      "epoch": 33.51550387596899,
      "grad_norm": 0.001488140202127397,
      "learning_rate": 1.648449612403101e-05,
      "loss": 0.0001,
      "step": 8647
    },
    {
      "epoch": 33.51937984496124,
      "grad_norm": 0.003028236562386155,
      "learning_rate": 1.6480620155038763e-05,
      "loss": 0.0002,
      "step": 8648
    },
    {
      "epoch": 33.52325581395349,
      "grad_norm": 0.004878081846982241,
      "learning_rate": 1.6476744186046512e-05,
      "loss": 0.0003,
      "step": 8649
    },
    {
      "epoch": 33.52713178294574,
      "grad_norm": 1.3391395807266235,
      "learning_rate": 1.647286821705426e-05,
      "loss": 0.0974,
      "step": 8650
    },
    {
      "epoch": 33.531007751937985,
      "grad_norm": 1.9560827016830444,
      "learning_rate": 1.6468992248062014e-05,
      "loss": 0.1118,
      "step": 8651
    },
    {
      "epoch": 33.53488372093023,
      "grad_norm": 0.00197234726510942,
      "learning_rate": 1.6465116279069766e-05,
      "loss": 0.0001,
      "step": 8652
    },
    {
      "epoch": 33.53875968992248,
      "grad_norm": 0.004489559680223465,
      "learning_rate": 1.646124031007752e-05,
      "loss": 0.0003,
      "step": 8653
    },
    {
      "epoch": 33.542635658914726,
      "grad_norm": 0.002226007403805852,
      "learning_rate": 1.645736434108527e-05,
      "loss": 0.0001,
      "step": 8654
    },
    {
      "epoch": 33.54651162790697,
      "grad_norm": 0.0021732922177761793,
      "learning_rate": 1.6453488372093024e-05,
      "loss": 0.0002,
      "step": 8655
    },
    {
      "epoch": 33.55038759689923,
      "grad_norm": 3.3671786785125732,
      "learning_rate": 1.6449612403100776e-05,
      "loss": 0.1045,
      "step": 8656
    },
    {
      "epoch": 33.554263565891475,
      "grad_norm": 0.0015565967187285423,
      "learning_rate": 1.644573643410853e-05,
      "loss": 0.0001,
      "step": 8657
    },
    {
      "epoch": 33.55813953488372,
      "grad_norm": 0.015534783713519573,
      "learning_rate": 1.644186046511628e-05,
      "loss": 0.0002,
      "step": 8658
    },
    {
      "epoch": 33.56201550387597,
      "grad_norm": 0.0015529911033809185,
      "learning_rate": 1.643798449612403e-05,
      "loss": 0.0001,
      "step": 8659
    },
    {
      "epoch": 33.565891472868216,
      "grad_norm": 0.001905497396364808,
      "learning_rate": 1.6434108527131782e-05,
      "loss": 0.0002,
      "step": 8660
    },
    {
      "epoch": 33.56976744186046,
      "grad_norm": 0.012814197689294815,
      "learning_rate": 1.6430232558139535e-05,
      "loss": 0.0004,
      "step": 8661
    },
    {
      "epoch": 33.57364341085271,
      "grad_norm": 0.8682953715324402,
      "learning_rate": 1.6426356589147287e-05,
      "loss": 0.0447,
      "step": 8662
    },
    {
      "epoch": 33.57751937984496,
      "grad_norm": 0.0015645710518583655,
      "learning_rate": 1.642248062015504e-05,
      "loss": 0.0001,
      "step": 8663
    },
    {
      "epoch": 33.58139534883721,
      "grad_norm": 0.0024670178536325693,
      "learning_rate": 1.6418604651162792e-05,
      "loss": 0.0002,
      "step": 8664
    },
    {
      "epoch": 33.58527131782946,
      "grad_norm": 0.0017892637988552451,
      "learning_rate": 1.6414728682170544e-05,
      "loss": 0.0002,
      "step": 8665
    },
    {
      "epoch": 33.58914728682171,
      "grad_norm": 0.001308778882957995,
      "learning_rate": 1.6410852713178297e-05,
      "loss": 0.0001,
      "step": 8666
    },
    {
      "epoch": 33.593023255813954,
      "grad_norm": 0.6003249883651733,
      "learning_rate": 1.640697674418605e-05,
      "loss": 0.0217,
      "step": 8667
    },
    {
      "epoch": 33.5968992248062,
      "grad_norm": 0.2784528434276581,
      "learning_rate": 1.6403100775193798e-05,
      "loss": 0.0117,
      "step": 8668
    },
    {
      "epoch": 33.60077519379845,
      "grad_norm": 0.0014193466631695628,
      "learning_rate": 1.639922480620155e-05,
      "loss": 0.0001,
      "step": 8669
    },
    {
      "epoch": 33.604651162790695,
      "grad_norm": 0.001197761856019497,
      "learning_rate": 1.6395348837209303e-05,
      "loss": 0.0001,
      "step": 8670
    },
    {
      "epoch": 33.60852713178294,
      "grad_norm": 0.0011489909375086427,
      "learning_rate": 1.6391472868217056e-05,
      "loss": 0.0001,
      "step": 8671
    },
    {
      "epoch": 33.6124031007752,
      "grad_norm": 1.1326974630355835,
      "learning_rate": 1.6387596899224808e-05,
      "loss": 0.0608,
      "step": 8672
    },
    {
      "epoch": 33.616279069767444,
      "grad_norm": 0.0014999228296801448,
      "learning_rate": 1.638372093023256e-05,
      "loss": 0.0001,
      "step": 8673
    },
    {
      "epoch": 33.62015503875969,
      "grad_norm": 0.001059757312759757,
      "learning_rate": 1.6379844961240313e-05,
      "loss": 0.0001,
      "step": 8674
    },
    {
      "epoch": 33.62403100775194,
      "grad_norm": 0.0011546640889719129,
      "learning_rate": 1.6375968992248065e-05,
      "loss": 0.0001,
      "step": 8675
    },
    {
      "epoch": 33.627906976744185,
      "grad_norm": 0.16431912779808044,
      "learning_rate": 1.6372093023255814e-05,
      "loss": 0.0027,
      "step": 8676
    },
    {
      "epoch": 33.63178294573643,
      "grad_norm": 0.0028496638406068087,
      "learning_rate": 1.6368217054263567e-05,
      "loss": 0.0002,
      "step": 8677
    },
    {
      "epoch": 33.63565891472868,
      "grad_norm": 0.0011058325180783868,
      "learning_rate": 1.636434108527132e-05,
      "loss": 0.0001,
      "step": 8678
    },
    {
      "epoch": 33.63953488372093,
      "grad_norm": 0.0012164651416242123,
      "learning_rate": 1.6360465116279068e-05,
      "loss": 0.0001,
      "step": 8679
    },
    {
      "epoch": 33.64341085271318,
      "grad_norm": 0.0011183208553120494,
      "learning_rate": 1.635658914728682e-05,
      "loss": 0.0001,
      "step": 8680
    },
    {
      "epoch": 33.64728682170543,
      "grad_norm": 0.0018472096417099237,
      "learning_rate": 1.6352713178294573e-05,
      "loss": 0.0002,
      "step": 8681
    },
    {
      "epoch": 33.651162790697676,
      "grad_norm": 0.0024391794577240944,
      "learning_rate": 1.6348837209302325e-05,
      "loss": 0.0002,
      "step": 8682
    },
    {
      "epoch": 33.65503875968992,
      "grad_norm": 0.0011073763016611338,
      "learning_rate": 1.6344961240310078e-05,
      "loss": 0.0001,
      "step": 8683
    },
    {
      "epoch": 33.65891472868217,
      "grad_norm": 0.0011419394286349416,
      "learning_rate": 1.634108527131783e-05,
      "loss": 0.0001,
      "step": 8684
    },
    {
      "epoch": 33.66279069767442,
      "grad_norm": 0.0012656707549467683,
      "learning_rate": 1.6337209302325583e-05,
      "loss": 0.0001,
      "step": 8685
    },
    {
      "epoch": 33.666666666666664,
      "grad_norm": 0.12546062469482422,
      "learning_rate": 1.6333333333333335e-05,
      "loss": 0.0056,
      "step": 8686
    },
    {
      "epoch": 33.67054263565891,
      "grad_norm": 0.0038495827466249466,
      "learning_rate": 1.6329457364341087e-05,
      "loss": 0.0003,
      "step": 8687
    },
    {
      "epoch": 33.674418604651166,
      "grad_norm": 0.0010578455403447151,
      "learning_rate": 1.6325581395348837e-05,
      "loss": 0.0001,
      "step": 8688
    },
    {
      "epoch": 33.67829457364341,
      "grad_norm": 0.0008832306484691799,
      "learning_rate": 1.632170542635659e-05,
      "loss": 0.0001,
      "step": 8689
    },
    {
      "epoch": 33.68217054263566,
      "grad_norm": 0.0010350655065849423,
      "learning_rate": 1.631782945736434e-05,
      "loss": 0.0001,
      "step": 8690
    },
    {
      "epoch": 33.68604651162791,
      "grad_norm": 0.0011612740345299244,
      "learning_rate": 1.6313953488372094e-05,
      "loss": 0.0001,
      "step": 8691
    },
    {
      "epoch": 33.689922480620154,
      "grad_norm": 0.0015919150318950415,
      "learning_rate": 1.6310077519379846e-05,
      "loss": 0.0001,
      "step": 8692
    },
    {
      "epoch": 33.6937984496124,
      "grad_norm": 0.003440410830080509,
      "learning_rate": 1.63062015503876e-05,
      "loss": 0.0003,
      "step": 8693
    },
    {
      "epoch": 33.69767441860465,
      "grad_norm": 0.0011697335867211223,
      "learning_rate": 1.630232558139535e-05,
      "loss": 0.0001,
      "step": 8694
    },
    {
      "epoch": 33.701550387596896,
      "grad_norm": 0.007183911744505167,
      "learning_rate": 1.6298449612403103e-05,
      "loss": 0.0003,
      "step": 8695
    },
    {
      "epoch": 33.70542635658915,
      "grad_norm": 0.0011318938340991735,
      "learning_rate": 1.6294573643410856e-05,
      "loss": 0.0001,
      "step": 8696
    },
    {
      "epoch": 33.7093023255814,
      "grad_norm": 0.0033478825353085995,
      "learning_rate": 1.6290697674418605e-05,
      "loss": 0.0002,
      "step": 8697
    },
    {
      "epoch": 33.713178294573645,
      "grad_norm": 0.0012744618579745293,
      "learning_rate": 1.6286821705426357e-05,
      "loss": 0.0001,
      "step": 8698
    },
    {
      "epoch": 33.71705426356589,
      "grad_norm": 0.0016486005624756217,
      "learning_rate": 1.628294573643411e-05,
      "loss": 0.0002,
      "step": 8699
    },
    {
      "epoch": 33.72093023255814,
      "grad_norm": 0.002087177475914359,
      "learning_rate": 1.6279069767441862e-05,
      "loss": 0.0001,
      "step": 8700
    },
    {
      "epoch": 33.724806201550386,
      "grad_norm": 0.0020717617589980364,
      "learning_rate": 1.6275193798449615e-05,
      "loss": 0.0002,
      "step": 8701
    },
    {
      "epoch": 33.72868217054263,
      "grad_norm": 0.0012738064397126436,
      "learning_rate": 1.6271317829457367e-05,
      "loss": 0.0001,
      "step": 8702
    },
    {
      "epoch": 33.73255813953488,
      "grad_norm": 0.001221545273438096,
      "learning_rate": 1.6267441860465116e-05,
      "loss": 0.0001,
      "step": 8703
    },
    {
      "epoch": 33.736434108527135,
      "grad_norm": 6.7962164878845215,
      "learning_rate": 1.626356589147287e-05,
      "loss": 0.0648,
      "step": 8704
    },
    {
      "epoch": 33.74031007751938,
      "grad_norm": 0.01505498867481947,
      "learning_rate": 1.625968992248062e-05,
      "loss": 0.0005,
      "step": 8705
    },
    {
      "epoch": 33.74418604651163,
      "grad_norm": 0.0012287276331335306,
      "learning_rate": 1.6255813953488373e-05,
      "loss": 0.0001,
      "step": 8706
    },
    {
      "epoch": 33.748062015503876,
      "grad_norm": 0.0012648790143430233,
      "learning_rate": 1.6251937984496122e-05,
      "loss": 0.0001,
      "step": 8707
    },
    {
      "epoch": 33.751937984496124,
      "grad_norm": 0.9512380361557007,
      "learning_rate": 1.6248062015503875e-05,
      "loss": 0.0563,
      "step": 8708
    },
    {
      "epoch": 33.75581395348837,
      "grad_norm": 0.001239111297763884,
      "learning_rate": 1.6244186046511627e-05,
      "loss": 0.0001,
      "step": 8709
    },
    {
      "epoch": 33.75968992248062,
      "grad_norm": 0.0011831915471702814,
      "learning_rate": 1.624031007751938e-05,
      "loss": 0.0001,
      "step": 8710
    },
    {
      "epoch": 33.763565891472865,
      "grad_norm": 0.0019143223762512207,
      "learning_rate": 1.6236434108527132e-05,
      "loss": 0.0001,
      "step": 8711
    },
    {
      "epoch": 33.76744186046512,
      "grad_norm": 0.002004564506933093,
      "learning_rate": 1.6232558139534884e-05,
      "loss": 0.0001,
      "step": 8712
    },
    {
      "epoch": 33.77131782945737,
      "grad_norm": 0.002636253135278821,
      "learning_rate": 1.6228682170542637e-05,
      "loss": 0.0002,
      "step": 8713
    },
    {
      "epoch": 33.775193798449614,
      "grad_norm": 0.002323034917935729,
      "learning_rate": 1.622480620155039e-05,
      "loss": 0.0001,
      "step": 8714
    },
    {
      "epoch": 33.77906976744186,
      "grad_norm": 0.0012186290696263313,
      "learning_rate": 1.6220930232558142e-05,
      "loss": 0.0001,
      "step": 8715
    },
    {
      "epoch": 33.78294573643411,
      "grad_norm": 0.0021061792504042387,
      "learning_rate": 1.621705426356589e-05,
      "loss": 0.0001,
      "step": 8716
    },
    {
      "epoch": 33.786821705426355,
      "grad_norm": 0.002690895926207304,
      "learning_rate": 1.6213178294573643e-05,
      "loss": 0.0002,
      "step": 8717
    },
    {
      "epoch": 33.7906976744186,
      "grad_norm": 0.0012130766408517957,
      "learning_rate": 1.6209302325581396e-05,
      "loss": 0.0001,
      "step": 8718
    },
    {
      "epoch": 33.79457364341085,
      "grad_norm": 0.0012439347337931395,
      "learning_rate": 1.6205426356589148e-05,
      "loss": 0.0001,
      "step": 8719
    },
    {
      "epoch": 33.798449612403104,
      "grad_norm": 2.444925308227539,
      "learning_rate": 1.62015503875969e-05,
      "loss": 0.2459,
      "step": 8720
    },
    {
      "epoch": 33.80232558139535,
      "grad_norm": 0.001063635339960456,
      "learning_rate": 1.6197674418604653e-05,
      "loss": 0.0001,
      "step": 8721
    },
    {
      "epoch": 33.8062015503876,
      "grad_norm": 0.007264129817485809,
      "learning_rate": 1.6193798449612405e-05,
      "loss": 0.0003,
      "step": 8722
    },
    {
      "epoch": 33.810077519379846,
      "grad_norm": 0.010080072097480297,
      "learning_rate": 1.6189922480620158e-05,
      "loss": 0.0006,
      "step": 8723
    },
    {
      "epoch": 33.81395348837209,
      "grad_norm": 0.0009647377883084118,
      "learning_rate": 1.618604651162791e-05,
      "loss": 0.0001,
      "step": 8724
    },
    {
      "epoch": 33.81782945736434,
      "grad_norm": 0.0012329919263720512,
      "learning_rate": 1.618217054263566e-05,
      "loss": 0.0001,
      "step": 8725
    },
    {
      "epoch": 33.82170542635659,
      "grad_norm": 0.0027467384934425354,
      "learning_rate": 1.617829457364341e-05,
      "loss": 0.0002,
      "step": 8726
    },
    {
      "epoch": 33.825581395348834,
      "grad_norm": 0.4353875517845154,
      "learning_rate": 1.6174418604651164e-05,
      "loss": 0.0187,
      "step": 8727
    },
    {
      "epoch": 33.82945736434109,
      "grad_norm": 4.622990608215332,
      "learning_rate": 1.6170542635658916e-05,
      "loss": 0.4925,
      "step": 8728
    },
    {
      "epoch": 33.833333333333336,
      "grad_norm": 0.002479690359905362,
      "learning_rate": 1.6166666666666665e-05,
      "loss": 0.0001,
      "step": 8729
    },
    {
      "epoch": 33.83720930232558,
      "grad_norm": 0.005968660581856966,
      "learning_rate": 1.6162790697674418e-05,
      "loss": 0.0003,
      "step": 8730
    },
    {
      "epoch": 33.84108527131783,
      "grad_norm": 0.0026391176506876945,
      "learning_rate": 1.615891472868217e-05,
      "loss": 0.0002,
      "step": 8731
    },
    {
      "epoch": 33.84496124031008,
      "grad_norm": 2.8146169185638428,
      "learning_rate": 1.6155038759689923e-05,
      "loss": 0.2916,
      "step": 8732
    },
    {
      "epoch": 33.848837209302324,
      "grad_norm": 0.0011400518706068397,
      "learning_rate": 1.6151162790697675e-05,
      "loss": 0.0001,
      "step": 8733
    },
    {
      "epoch": 33.85271317829457,
      "grad_norm": 1.7286276817321777,
      "learning_rate": 1.6147286821705428e-05,
      "loss": 0.1104,
      "step": 8734
    },
    {
      "epoch": 33.85658914728682,
      "grad_norm": 0.019420864060521126,
      "learning_rate": 1.614341085271318e-05,
      "loss": 0.0002,
      "step": 8735
    },
    {
      "epoch": 33.86046511627907,
      "grad_norm": 0.001696542021818459,
      "learning_rate": 1.613953488372093e-05,
      "loss": 0.0002,
      "step": 8736
    },
    {
      "epoch": 33.86434108527132,
      "grad_norm": 0.0013011450646445155,
      "learning_rate": 1.613565891472868e-05,
      "loss": 0.0001,
      "step": 8737
    },
    {
      "epoch": 33.86821705426357,
      "grad_norm": 0.016475634649395943,
      "learning_rate": 1.6131782945736434e-05,
      "loss": 0.0004,
      "step": 8738
    },
    {
      "epoch": 33.872093023255815,
      "grad_norm": 1.1088517904281616,
      "learning_rate": 1.6127906976744186e-05,
      "loss": 0.0281,
      "step": 8739
    },
    {
      "epoch": 33.87596899224806,
      "grad_norm": 0.0011890792520716786,
      "learning_rate": 1.612403100775194e-05,
      "loss": 0.0001,
      "step": 8740
    },
    {
      "epoch": 33.87984496124031,
      "grad_norm": 0.0013818534789606929,
      "learning_rate": 1.612015503875969e-05,
      "loss": 0.0001,
      "step": 8741
    },
    {
      "epoch": 33.883720930232556,
      "grad_norm": 0.004100962076336145,
      "learning_rate": 1.6116279069767444e-05,
      "loss": 0.0003,
      "step": 8742
    },
    {
      "epoch": 33.8875968992248,
      "grad_norm": 0.0023950114846229553,
      "learning_rate": 1.6112403100775196e-05,
      "loss": 0.0001,
      "step": 8743
    },
    {
      "epoch": 33.89147286821706,
      "grad_norm": 0.0015494797844439745,
      "learning_rate": 1.6108527131782945e-05,
      "loss": 0.0001,
      "step": 8744
    },
    {
      "epoch": 33.895348837209305,
      "grad_norm": 0.0009787677554413676,
      "learning_rate": 1.6104651162790697e-05,
      "loss": 0.0001,
      "step": 8745
    },
    {
      "epoch": 33.89922480620155,
      "grad_norm": 1.5307600498199463,
      "learning_rate": 1.610077519379845e-05,
      "loss": 0.0674,
      "step": 8746
    },
    {
      "epoch": 33.9031007751938,
      "grad_norm": 0.0009870058856904507,
      "learning_rate": 1.6096899224806202e-05,
      "loss": 0.0001,
      "step": 8747
    },
    {
      "epoch": 33.906976744186046,
      "grad_norm": 0.0016845883801579475,
      "learning_rate": 1.6093023255813955e-05,
      "loss": 0.0002,
      "step": 8748
    },
    {
      "epoch": 33.91085271317829,
      "grad_norm": 0.033109746873378754,
      "learning_rate": 1.6089147286821707e-05,
      "loss": 0.0005,
      "step": 8749
    },
    {
      "epoch": 33.91472868217054,
      "grad_norm": 0.0009892163798213005,
      "learning_rate": 1.608527131782946e-05,
      "loss": 0.0001,
      "step": 8750
    },
    {
      "epoch": 33.91860465116279,
      "grad_norm": 0.001148058450780809,
      "learning_rate": 1.6081395348837212e-05,
      "loss": 0.0001,
      "step": 8751
    },
    {
      "epoch": 33.92248062015504,
      "grad_norm": 0.0011770447017624974,
      "learning_rate": 1.6077519379844964e-05,
      "loss": 0.0001,
      "step": 8752
    },
    {
      "epoch": 33.92635658914729,
      "grad_norm": 0.0025201705284416676,
      "learning_rate": 1.6073643410852713e-05,
      "loss": 0.0002,
      "step": 8753
    },
    {
      "epoch": 33.93023255813954,
      "grad_norm": 0.0017488088924437761,
      "learning_rate": 1.6069767441860466e-05,
      "loss": 0.0001,
      "step": 8754
    },
    {
      "epoch": 33.934108527131784,
      "grad_norm": 0.000995764508843422,
      "learning_rate": 1.6065891472868218e-05,
      "loss": 0.0001,
      "step": 8755
    },
    {
      "epoch": 33.93798449612403,
      "grad_norm": 0.0010474646696820855,
      "learning_rate": 1.6062015503875967e-05,
      "loss": 0.0001,
      "step": 8756
    },
    {
      "epoch": 33.94186046511628,
      "grad_norm": 0.002539758337661624,
      "learning_rate": 1.605813953488372e-05,
      "loss": 0.0002,
      "step": 8757
    },
    {
      "epoch": 33.945736434108525,
      "grad_norm": 0.004252927377820015,
      "learning_rate": 1.6054263565891472e-05,
      "loss": 0.0002,
      "step": 8758
    },
    {
      "epoch": 33.94961240310077,
      "grad_norm": 0.05361726135015488,
      "learning_rate": 1.6050387596899225e-05,
      "loss": 0.0005,
      "step": 8759
    },
    {
      "epoch": 33.95348837209303,
      "grad_norm": 0.0011960179544985294,
      "learning_rate": 1.6046511627906977e-05,
      "loss": 0.0001,
      "step": 8760
    },
    {
      "epoch": 33.957364341085274,
      "grad_norm": 0.0012716824421659112,
      "learning_rate": 1.604263565891473e-05,
      "loss": 0.0001,
      "step": 8761
    },
    {
      "epoch": 33.96124031007752,
      "grad_norm": 0.12189289182424545,
      "learning_rate": 1.6038759689922482e-05,
      "loss": 0.0002,
      "step": 8762
    },
    {
      "epoch": 33.96511627906977,
      "grad_norm": 0.0012111379764974117,
      "learning_rate": 1.6034883720930234e-05,
      "loss": 0.0001,
      "step": 8763
    },
    {
      "epoch": 33.968992248062015,
      "grad_norm": 0.007286053150892258,
      "learning_rate": 1.6031007751937983e-05,
      "loss": 0.0003,
      "step": 8764
    },
    {
      "epoch": 33.97286821705426,
      "grad_norm": 0.0009396631503477693,
      "learning_rate": 1.6027131782945736e-05,
      "loss": 0.0001,
      "step": 8765
    },
    {
      "epoch": 33.97674418604651,
      "grad_norm": 0.006331787910312414,
      "learning_rate": 1.6023255813953488e-05,
      "loss": 0.0004,
      "step": 8766
    },
    {
      "epoch": 33.98062015503876,
      "grad_norm": 0.0012128178495913744,
      "learning_rate": 1.601937984496124e-05,
      "loss": 0.0001,
      "step": 8767
    },
    {
      "epoch": 33.98449612403101,
      "grad_norm": 0.09692530333995819,
      "learning_rate": 1.6015503875968993e-05,
      "loss": 0.003,
      "step": 8768
    },
    {
      "epoch": 33.98837209302326,
      "grad_norm": 0.0012320493115112185,
      "learning_rate": 1.6011627906976745e-05,
      "loss": 0.0001,
      "step": 8769
    },
    {
      "epoch": 33.992248062015506,
      "grad_norm": 0.0013655010843649507,
      "learning_rate": 1.6007751937984498e-05,
      "loss": 0.0001,
      "step": 8770
    },
    {
      "epoch": 33.99612403100775,
      "grad_norm": 0.09894665330648422,
      "learning_rate": 1.600387596899225e-05,
      "loss": 0.0007,
      "step": 8771
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.001977132400497794,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0001,
      "step": 8772
    },
    {
      "epoch": 34.00387596899225,
      "grad_norm": 0.0012251191074028611,
      "learning_rate": 1.5996124031007752e-05,
      "loss": 0.0001,
      "step": 8773
    },
    {
      "epoch": 34.007751937984494,
      "grad_norm": 0.0011447545839473605,
      "learning_rate": 1.5992248062015504e-05,
      "loss": 0.0001,
      "step": 8774
    },
    {
      "epoch": 34.01162790697674,
      "grad_norm": 0.0019422870827838778,
      "learning_rate": 1.5988372093023257e-05,
      "loss": 0.0001,
      "step": 8775
    },
    {
      "epoch": 34.01550387596899,
      "grad_norm": 1.583986759185791,
      "learning_rate": 1.598449612403101e-05,
      "loss": 0.1343,
      "step": 8776
    },
    {
      "epoch": 34.01937984496124,
      "grad_norm": 0.0011483031557872891,
      "learning_rate": 1.598062015503876e-05,
      "loss": 0.0001,
      "step": 8777
    },
    {
      "epoch": 34.02325581395349,
      "grad_norm": 0.001783429877832532,
      "learning_rate": 1.5976744186046514e-05,
      "loss": 0.0001,
      "step": 8778
    },
    {
      "epoch": 34.02713178294574,
      "grad_norm": 0.001159094157628715,
      "learning_rate": 1.5972868217054266e-05,
      "loss": 0.0001,
      "step": 8779
    },
    {
      "epoch": 34.031007751937985,
      "grad_norm": 0.0011250299867242575,
      "learning_rate": 1.596899224806202e-05,
      "loss": 0.0001,
      "step": 8780
    },
    {
      "epoch": 34.03488372093023,
      "grad_norm": 0.001326502300798893,
      "learning_rate": 1.596511627906977e-05,
      "loss": 0.0001,
      "step": 8781
    },
    {
      "epoch": 34.03875968992248,
      "grad_norm": 0.0011782367946580052,
      "learning_rate": 1.596124031007752e-05,
      "loss": 0.0001,
      "step": 8782
    },
    {
      "epoch": 34.042635658914726,
      "grad_norm": 0.0036896695382893085,
      "learning_rate": 1.595736434108527e-05,
      "loss": 0.0002,
      "step": 8783
    },
    {
      "epoch": 34.04651162790697,
      "grad_norm": 0.001733634970150888,
      "learning_rate": 1.595348837209302e-05,
      "loss": 0.0001,
      "step": 8784
    },
    {
      "epoch": 34.05038759689923,
      "grad_norm": 0.0013953252928331494,
      "learning_rate": 1.5949612403100774e-05,
      "loss": 0.0002,
      "step": 8785
    },
    {
      "epoch": 34.054263565891475,
      "grad_norm": 0.13768483698368073,
      "learning_rate": 1.5945736434108526e-05,
      "loss": 0.003,
      "step": 8786
    },
    {
      "epoch": 34.05813953488372,
      "grad_norm": 0.0011908547021448612,
      "learning_rate": 1.594186046511628e-05,
      "loss": 0.0001,
      "step": 8787
    },
    {
      "epoch": 34.06201550387597,
      "grad_norm": 0.001152646727859974,
      "learning_rate": 1.593798449612403e-05,
      "loss": 0.0001,
      "step": 8788
    },
    {
      "epoch": 34.065891472868216,
      "grad_norm": 0.2259780764579773,
      "learning_rate": 1.5934108527131784e-05,
      "loss": 0.0005,
      "step": 8789
    },
    {
      "epoch": 34.06976744186046,
      "grad_norm": 0.003329367144033313,
      "learning_rate": 1.5930232558139536e-05,
      "loss": 0.0003,
      "step": 8790
    },
    {
      "epoch": 34.07364341085271,
      "grad_norm": 0.0024198838509619236,
      "learning_rate": 1.592635658914729e-05,
      "loss": 0.0002,
      "step": 8791
    },
    {
      "epoch": 34.07751937984496,
      "grad_norm": 0.001149518764577806,
      "learning_rate": 1.5922480620155038e-05,
      "loss": 0.0001,
      "step": 8792
    },
    {
      "epoch": 34.08139534883721,
      "grad_norm": 0.0009982859482988715,
      "learning_rate": 1.591860465116279e-05,
      "loss": 0.0001,
      "step": 8793
    },
    {
      "epoch": 34.08527131782946,
      "grad_norm": 0.0012108602095395327,
      "learning_rate": 1.5914728682170542e-05,
      "loss": 0.0001,
      "step": 8794
    },
    {
      "epoch": 34.08914728682171,
      "grad_norm": 2.714724540710449,
      "learning_rate": 1.5910852713178295e-05,
      "loss": 0.2438,
      "step": 8795
    },
    {
      "epoch": 34.093023255813954,
      "grad_norm": 0.010706220753490925,
      "learning_rate": 1.5906976744186047e-05,
      "loss": 0.0004,
      "step": 8796
    },
    {
      "epoch": 34.0968992248062,
      "grad_norm": 6.753617763519287,
      "learning_rate": 1.59031007751938e-05,
      "loss": 0.0085,
      "step": 8797
    },
    {
      "epoch": 34.10077519379845,
      "grad_norm": 0.0012195539893582463,
      "learning_rate": 1.5899224806201552e-05,
      "loss": 0.0001,
      "step": 8798
    },
    {
      "epoch": 34.104651162790695,
      "grad_norm": 0.0013063420774415135,
      "learning_rate": 1.5895348837209304e-05,
      "loss": 0.0001,
      "step": 8799
    },
    {
      "epoch": 34.10852713178294,
      "grad_norm": 0.0016179642407223582,
      "learning_rate": 1.5891472868217057e-05,
      "loss": 0.0001,
      "step": 8800
    },
    {
      "epoch": 34.1124031007752,
      "grad_norm": 0.0011315615847706795,
      "learning_rate": 1.5887596899224806e-05,
      "loss": 0.0001,
      "step": 8801
    },
    {
      "epoch": 34.116279069767444,
      "grad_norm": 0.0016590898158028722,
      "learning_rate": 1.588372093023256e-05,
      "loss": 0.0001,
      "step": 8802
    },
    {
      "epoch": 34.12015503875969,
      "grad_norm": 0.0009956859285011888,
      "learning_rate": 1.587984496124031e-05,
      "loss": 0.0001,
      "step": 8803
    },
    {
      "epoch": 34.12403100775194,
      "grad_norm": 0.0012959346640855074,
      "learning_rate": 1.5875968992248063e-05,
      "loss": 0.0001,
      "step": 8804
    },
    {
      "epoch": 34.127906976744185,
      "grad_norm": 0.001034286804497242,
      "learning_rate": 1.5872093023255816e-05,
      "loss": 0.0001,
      "step": 8805
    },
    {
      "epoch": 34.13178294573643,
      "grad_norm": 0.0011527802562341094,
      "learning_rate": 1.5868217054263568e-05,
      "loss": 0.0001,
      "step": 8806
    },
    {
      "epoch": 34.13565891472868,
      "grad_norm": 0.0010200904216617346,
      "learning_rate": 1.586434108527132e-05,
      "loss": 0.0001,
      "step": 8807
    },
    {
      "epoch": 34.13953488372093,
      "grad_norm": 0.0009620464988984168,
      "learning_rate": 1.5860465116279073e-05,
      "loss": 0.0001,
      "step": 8808
    },
    {
      "epoch": 34.14341085271318,
      "grad_norm": 0.003100404981523752,
      "learning_rate": 1.5856589147286822e-05,
      "loss": 0.0002,
      "step": 8809
    },
    {
      "epoch": 34.14728682170543,
      "grad_norm": 0.0012971929972991347,
      "learning_rate": 1.5852713178294574e-05,
      "loss": 0.0001,
      "step": 8810
    },
    {
      "epoch": 34.151162790697676,
      "grad_norm": 0.002968753455206752,
      "learning_rate": 1.5848837209302327e-05,
      "loss": 0.0003,
      "step": 8811
    },
    {
      "epoch": 34.15503875968992,
      "grad_norm": 1.8729615211486816,
      "learning_rate": 1.5844961240310076e-05,
      "loss": 0.0858,
      "step": 8812
    },
    {
      "epoch": 34.15891472868217,
      "grad_norm": 0.0009783088462427258,
      "learning_rate": 1.5841085271317828e-05,
      "loss": 0.0001,
      "step": 8813
    },
    {
      "epoch": 34.16279069767442,
      "grad_norm": 0.001165610272437334,
      "learning_rate": 1.583720930232558e-05,
      "loss": 0.0001,
      "step": 8814
    },
    {
      "epoch": 34.166666666666664,
      "grad_norm": 0.0014246528735384345,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 0.0001,
      "step": 8815
    },
    {
      "epoch": 34.17054263565891,
      "grad_norm": 0.0050262692384421825,
      "learning_rate": 1.5829457364341085e-05,
      "loss": 0.0003,
      "step": 8816
    },
    {
      "epoch": 34.174418604651166,
      "grad_norm": 0.0010053891455754638,
      "learning_rate": 1.5825581395348838e-05,
      "loss": 0.0001,
      "step": 8817
    },
    {
      "epoch": 34.17829457364341,
      "grad_norm": 0.0010105848778039217,
      "learning_rate": 1.582170542635659e-05,
      "loss": 0.0001,
      "step": 8818
    },
    {
      "epoch": 34.18217054263566,
      "grad_norm": 0.0010329859796911478,
      "learning_rate": 1.5817829457364343e-05,
      "loss": 0.0001,
      "step": 8819
    },
    {
      "epoch": 34.18604651162791,
      "grad_norm": 0.0013245879672467709,
      "learning_rate": 1.5813953488372095e-05,
      "loss": 0.0001,
      "step": 8820
    },
    {
      "epoch": 34.189922480620154,
      "grad_norm": 0.0010231871856376529,
      "learning_rate": 1.5810077519379844e-05,
      "loss": 0.0001,
      "step": 8821
    },
    {
      "epoch": 34.1937984496124,
      "grad_norm": 0.001284147030673921,
      "learning_rate": 1.5806201550387597e-05,
      "loss": 0.0001,
      "step": 8822
    },
    {
      "epoch": 34.19767441860465,
      "grad_norm": 0.001722305896691978,
      "learning_rate": 1.580232558139535e-05,
      "loss": 0.0002,
      "step": 8823
    },
    {
      "epoch": 34.201550387596896,
      "grad_norm": 0.1125938892364502,
      "learning_rate": 1.57984496124031e-05,
      "loss": 0.0011,
      "step": 8824
    },
    {
      "epoch": 34.20542635658915,
      "grad_norm": 0.015675902366638184,
      "learning_rate": 1.5794573643410854e-05,
      "loss": 0.0003,
      "step": 8825
    },
    {
      "epoch": 34.2093023255814,
      "grad_norm": 0.0023530053440481424,
      "learning_rate": 1.5790697674418606e-05,
      "loss": 0.0002,
      "step": 8826
    },
    {
      "epoch": 34.213178294573645,
      "grad_norm": 0.0010235847439616919,
      "learning_rate": 1.578682170542636e-05,
      "loss": 0.0001,
      "step": 8827
    },
    {
      "epoch": 34.21705426356589,
      "grad_norm": 0.001145381829701364,
      "learning_rate": 1.578294573643411e-05,
      "loss": 0.0001,
      "step": 8828
    },
    {
      "epoch": 34.22093023255814,
      "grad_norm": 0.9668787717819214,
      "learning_rate": 1.5779069767441864e-05,
      "loss": 0.0605,
      "step": 8829
    },
    {
      "epoch": 34.224806201550386,
      "grad_norm": 0.0014637128915637732,
      "learning_rate": 1.5775193798449613e-05,
      "loss": 0.0001,
      "step": 8830
    },
    {
      "epoch": 34.22868217054263,
      "grad_norm": 0.005208821501582861,
      "learning_rate": 1.5771317829457365e-05,
      "loss": 0.0003,
      "step": 8831
    },
    {
      "epoch": 34.23255813953488,
      "grad_norm": 0.00255414261482656,
      "learning_rate": 1.5767441860465117e-05,
      "loss": 0.0002,
      "step": 8832
    },
    {
      "epoch": 34.236434108527135,
      "grad_norm": 0.0014491648180410266,
      "learning_rate": 1.576356589147287e-05,
      "loss": 0.0001,
      "step": 8833
    },
    {
      "epoch": 34.24031007751938,
      "grad_norm": 0.0023852030280977488,
      "learning_rate": 1.5759689922480622e-05,
      "loss": 0.0001,
      "step": 8834
    },
    {
      "epoch": 34.24418604651163,
      "grad_norm": 0.001120261731557548,
      "learning_rate": 1.5755813953488375e-05,
      "loss": 0.0001,
      "step": 8835
    },
    {
      "epoch": 34.248062015503876,
      "grad_norm": 0.0018358881352469325,
      "learning_rate": 1.5751937984496124e-05,
      "loss": 0.0001,
      "step": 8836
    },
    {
      "epoch": 34.251937984496124,
      "grad_norm": 0.0014859003713354468,
      "learning_rate": 1.5748062015503876e-05,
      "loss": 0.0002,
      "step": 8837
    },
    {
      "epoch": 34.25581395348837,
      "grad_norm": 0.0010397207224741578,
      "learning_rate": 1.574418604651163e-05,
      "loss": 0.0001,
      "step": 8838
    },
    {
      "epoch": 34.25968992248062,
      "grad_norm": 0.0010317725827917457,
      "learning_rate": 1.574031007751938e-05,
      "loss": 0.0001,
      "step": 8839
    },
    {
      "epoch": 34.263565891472865,
      "grad_norm": 0.0013825705973431468,
      "learning_rate": 1.573643410852713e-05,
      "loss": 0.0001,
      "step": 8840
    },
    {
      "epoch": 34.26744186046512,
      "grad_norm": 0.00889001414179802,
      "learning_rate": 1.5732558139534882e-05,
      "loss": 0.0003,
      "step": 8841
    },
    {
      "epoch": 34.27131782945737,
      "grad_norm": 0.0010879443725571036,
      "learning_rate": 1.5728682170542635e-05,
      "loss": 0.0001,
      "step": 8842
    },
    {
      "epoch": 34.275193798449614,
      "grad_norm": 0.001380076864734292,
      "learning_rate": 1.5724806201550387e-05,
      "loss": 0.0001,
      "step": 8843
    },
    {
      "epoch": 34.27906976744186,
      "grad_norm": 0.0014302004128694534,
      "learning_rate": 1.572093023255814e-05,
      "loss": 0.0002,
      "step": 8844
    },
    {
      "epoch": 34.28294573643411,
      "grad_norm": 0.0016339238500222564,
      "learning_rate": 1.5717054263565892e-05,
      "loss": 0.0001,
      "step": 8845
    },
    {
      "epoch": 34.286821705426355,
      "grad_norm": 14.727581977844238,
      "learning_rate": 1.5713178294573645e-05,
      "loss": 0.4384,
      "step": 8846
    },
    {
      "epoch": 34.2906976744186,
      "grad_norm": 0.001781993662007153,
      "learning_rate": 1.5709302325581397e-05,
      "loss": 0.0001,
      "step": 8847
    },
    {
      "epoch": 34.29457364341085,
      "grad_norm": 0.0009606803650967777,
      "learning_rate": 1.570542635658915e-05,
      "loss": 0.0001,
      "step": 8848
    },
    {
      "epoch": 34.298449612403104,
      "grad_norm": 0.0015005078166723251,
      "learning_rate": 1.57015503875969e-05,
      "loss": 0.0001,
      "step": 8849
    },
    {
      "epoch": 34.30232558139535,
      "grad_norm": 0.0016033330466598272,
      "learning_rate": 1.569767441860465e-05,
      "loss": 0.0001,
      "step": 8850
    },
    {
      "epoch": 34.3062015503876,
      "grad_norm": 0.002059770282357931,
      "learning_rate": 1.5693798449612403e-05,
      "loss": 0.0001,
      "step": 8851
    },
    {
      "epoch": 34.310077519379846,
      "grad_norm": 0.0029374747537076473,
      "learning_rate": 1.5689922480620156e-05,
      "loss": 0.0002,
      "step": 8852
    },
    {
      "epoch": 34.31395348837209,
      "grad_norm": 0.0010865742806345224,
      "learning_rate": 1.5686046511627908e-05,
      "loss": 0.0001,
      "step": 8853
    },
    {
      "epoch": 34.31782945736434,
      "grad_norm": 0.0012572547420859337,
      "learning_rate": 1.568217054263566e-05,
      "loss": 0.0001,
      "step": 8854
    },
    {
      "epoch": 34.32170542635659,
      "grad_norm": 1.8286179304122925,
      "learning_rate": 1.5678294573643413e-05,
      "loss": 0.1805,
      "step": 8855
    },
    {
      "epoch": 34.325581395348834,
      "grad_norm": 0.005278109572827816,
      "learning_rate": 1.5674418604651165e-05,
      "loss": 0.0003,
      "step": 8856
    },
    {
      "epoch": 34.32945736434109,
      "grad_norm": 0.00127607851754874,
      "learning_rate": 1.5670542635658918e-05,
      "loss": 0.0001,
      "step": 8857
    },
    {
      "epoch": 34.333333333333336,
      "grad_norm": 1.15407395362854,
      "learning_rate": 1.5666666666666667e-05,
      "loss": 0.0209,
      "step": 8858
    },
    {
      "epoch": 34.33720930232558,
      "grad_norm": 3.7621514797210693,
      "learning_rate": 1.566279069767442e-05,
      "loss": 0.2841,
      "step": 8859
    },
    {
      "epoch": 34.34108527131783,
      "grad_norm": 0.0020354166626930237,
      "learning_rate": 1.5658914728682172e-05,
      "loss": 0.0002,
      "step": 8860
    },
    {
      "epoch": 34.34496124031008,
      "grad_norm": 0.001040716073475778,
      "learning_rate": 1.5655038759689924e-05,
      "loss": 0.0001,
      "step": 8861
    },
    {
      "epoch": 34.348837209302324,
      "grad_norm": 1.6530568599700928,
      "learning_rate": 1.5651162790697677e-05,
      "loss": 0.0024,
      "step": 8862
    },
    {
      "epoch": 34.35271317829457,
      "grad_norm": 0.00347513472661376,
      "learning_rate": 1.5647286821705426e-05,
      "loss": 0.0002,
      "step": 8863
    },
    {
      "epoch": 34.35658914728682,
      "grad_norm": 0.003273647977039218,
      "learning_rate": 1.5643410852713178e-05,
      "loss": 0.0003,
      "step": 8864
    },
    {
      "epoch": 34.36046511627907,
      "grad_norm": 0.0009618530748412013,
      "learning_rate": 1.563953488372093e-05,
      "loss": 0.0001,
      "step": 8865
    },
    {
      "epoch": 34.36434108527132,
      "grad_norm": 0.0010840788017958403,
      "learning_rate": 1.5635658914728683e-05,
      "loss": 0.0001,
      "step": 8866
    },
    {
      "epoch": 34.36821705426357,
      "grad_norm": 0.000988730345852673,
      "learning_rate": 1.5631782945736435e-05,
      "loss": 0.0001,
      "step": 8867
    },
    {
      "epoch": 34.372093023255815,
      "grad_norm": 1.4454097747802734,
      "learning_rate": 1.5627906976744188e-05,
      "loss": 0.0763,
      "step": 8868
    },
    {
      "epoch": 34.37596899224806,
      "grad_norm": 0.0015191673301160336,
      "learning_rate": 1.5624031007751937e-05,
      "loss": 0.0001,
      "step": 8869
    },
    {
      "epoch": 34.37984496124031,
      "grad_norm": 0.0012226509861648083,
      "learning_rate": 1.562015503875969e-05,
      "loss": 0.0001,
      "step": 8870
    },
    {
      "epoch": 34.383720930232556,
      "grad_norm": 0.0037642233073711395,
      "learning_rate": 1.561627906976744e-05,
      "loss": 0.0003,
      "step": 8871
    },
    {
      "epoch": 34.3875968992248,
      "grad_norm": 0.002628224203363061,
      "learning_rate": 1.5612403100775194e-05,
      "loss": 0.0002,
      "step": 8872
    },
    {
      "epoch": 34.39147286821706,
      "grad_norm": 0.0021434910595417023,
      "learning_rate": 1.5608527131782946e-05,
      "loss": 0.0002,
      "step": 8873
    },
    {
      "epoch": 34.395348837209305,
      "grad_norm": 0.000993700115941465,
      "learning_rate": 1.56046511627907e-05,
      "loss": 0.0001,
      "step": 8874
    },
    {
      "epoch": 34.39922480620155,
      "grad_norm": 1.8642076253890991,
      "learning_rate": 1.560077519379845e-05,
      "loss": 0.0748,
      "step": 8875
    },
    {
      "epoch": 34.4031007751938,
      "grad_norm": 0.0021335456985980272,
      "learning_rate": 1.5596899224806204e-05,
      "loss": 0.0002,
      "step": 8876
    },
    {
      "epoch": 34.406976744186046,
      "grad_norm": 0.003352025058120489,
      "learning_rate": 1.5593023255813953e-05,
      "loss": 0.0001,
      "step": 8877
    },
    {
      "epoch": 34.41085271317829,
      "grad_norm": 0.0010535955661907792,
      "learning_rate": 1.5589147286821705e-05,
      "loss": 0.0001,
      "step": 8878
    },
    {
      "epoch": 34.41472868217054,
      "grad_norm": 0.0011942917481064796,
      "learning_rate": 1.5585271317829458e-05,
      "loss": 0.0001,
      "step": 8879
    },
    {
      "epoch": 34.41860465116279,
      "grad_norm": 20.110551834106445,
      "learning_rate": 1.558139534883721e-05,
      "loss": 0.2463,
      "step": 8880
    },
    {
      "epoch": 34.42248062015504,
      "grad_norm": 0.3808366358280182,
      "learning_rate": 1.5577519379844962e-05,
      "loss": 0.0024,
      "step": 8881
    },
    {
      "epoch": 34.42635658914729,
      "grad_norm": 0.0011110010091215372,
      "learning_rate": 1.5573643410852715e-05,
      "loss": 0.0001,
      "step": 8882
    },
    {
      "epoch": 34.43023255813954,
      "grad_norm": 0.001280235475860536,
      "learning_rate": 1.5569767441860467e-05,
      "loss": 0.0001,
      "step": 8883
    },
    {
      "epoch": 34.434108527131784,
      "grad_norm": 0.001228968147188425,
      "learning_rate": 1.556589147286822e-05,
      "loss": 0.0001,
      "step": 8884
    },
    {
      "epoch": 34.43798449612403,
      "grad_norm": 0.0010314288083463907,
      "learning_rate": 1.5562015503875972e-05,
      "loss": 0.0001,
      "step": 8885
    },
    {
      "epoch": 34.44186046511628,
      "grad_norm": 0.007766027469187975,
      "learning_rate": 1.555813953488372e-05,
      "loss": 0.0003,
      "step": 8886
    },
    {
      "epoch": 34.445736434108525,
      "grad_norm": 0.0013341889716684818,
      "learning_rate": 1.5554263565891474e-05,
      "loss": 0.0001,
      "step": 8887
    },
    {
      "epoch": 34.44961240310077,
      "grad_norm": 0.005134354345500469,
      "learning_rate": 1.5550387596899226e-05,
      "loss": 0.0003,
      "step": 8888
    },
    {
      "epoch": 34.45348837209303,
      "grad_norm": 0.0012064523762091994,
      "learning_rate": 1.5546511627906975e-05,
      "loss": 0.0001,
      "step": 8889
    },
    {
      "epoch": 34.457364341085274,
      "grad_norm": 0.0015930058434605598,
      "learning_rate": 1.5542635658914727e-05,
      "loss": 0.0001,
      "step": 8890
    },
    {
      "epoch": 34.46124031007752,
      "grad_norm": 0.001294970978051424,
      "learning_rate": 1.553875968992248e-05,
      "loss": 0.0001,
      "step": 8891
    },
    {
      "epoch": 34.46511627906977,
      "grad_norm": 0.0011059907265007496,
      "learning_rate": 1.5534883720930232e-05,
      "loss": 0.0001,
      "step": 8892
    },
    {
      "epoch": 34.468992248062015,
      "grad_norm": 0.0017481212271377444,
      "learning_rate": 1.5531007751937985e-05,
      "loss": 0.0001,
      "step": 8893
    },
    {
      "epoch": 34.47286821705426,
      "grad_norm": 0.004362665582448244,
      "learning_rate": 1.5527131782945737e-05,
      "loss": 0.0003,
      "step": 8894
    },
    {
      "epoch": 34.47674418604651,
      "grad_norm": 0.001925618969835341,
      "learning_rate": 1.552325581395349e-05,
      "loss": 0.0002,
      "step": 8895
    },
    {
      "epoch": 34.48062015503876,
      "grad_norm": 0.0018934996332973242,
      "learning_rate": 1.5519379844961242e-05,
      "loss": 0.0002,
      "step": 8896
    },
    {
      "epoch": 34.48449612403101,
      "grad_norm": 0.0011814221506938338,
      "learning_rate": 1.551550387596899e-05,
      "loss": 0.0001,
      "step": 8897
    },
    {
      "epoch": 34.48837209302326,
      "grad_norm": 0.0012056035920977592,
      "learning_rate": 1.5511627906976743e-05,
      "loss": 0.0001,
      "step": 8898
    },
    {
      "epoch": 34.492248062015506,
      "grad_norm": 0.005586056504398584,
      "learning_rate": 1.5507751937984496e-05,
      "loss": 0.0003,
      "step": 8899
    },
    {
      "epoch": 34.49612403100775,
      "grad_norm": 0.001032192725688219,
      "learning_rate": 1.5503875968992248e-05,
      "loss": 0.0001,
      "step": 8900
    },
    {
      "epoch": 34.5,
      "grad_norm": 0.021975740790367126,
      "learning_rate": 1.55e-05,
      "loss": 0.0003,
      "step": 8901
    },
    {
      "epoch": 34.50387596899225,
      "grad_norm": 0.01750900223851204,
      "learning_rate": 1.5496124031007753e-05,
      "loss": 0.0007,
      "step": 8902
    },
    {
      "epoch": 34.507751937984494,
      "grad_norm": 0.0020569406915456057,
      "learning_rate": 1.5492248062015506e-05,
      "loss": 0.0001,
      "step": 8903
    },
    {
      "epoch": 34.51162790697674,
      "grad_norm": 0.0017148511251434684,
      "learning_rate": 1.5488372093023258e-05,
      "loss": 0.0001,
      "step": 8904
    },
    {
      "epoch": 34.51550387596899,
      "grad_norm": 0.0012782284757122397,
      "learning_rate": 1.548449612403101e-05,
      "loss": 0.0001,
      "step": 8905
    },
    {
      "epoch": 34.51937984496124,
      "grad_norm": 0.0013380012242123485,
      "learning_rate": 1.548062015503876e-05,
      "loss": 0.0001,
      "step": 8906
    },
    {
      "epoch": 34.52325581395349,
      "grad_norm": 0.0011011577444151044,
      "learning_rate": 1.5476744186046512e-05,
      "loss": 0.0001,
      "step": 8907
    },
    {
      "epoch": 34.52713178294574,
      "grad_norm": 0.0010556044289842248,
      "learning_rate": 1.5472868217054264e-05,
      "loss": 0.0001,
      "step": 8908
    },
    {
      "epoch": 34.531007751937985,
      "grad_norm": 2.751063346862793,
      "learning_rate": 1.5468992248062017e-05,
      "loss": 0.0017,
      "step": 8909
    },
    {
      "epoch": 34.53488372093023,
      "grad_norm": 0.0011124031152576208,
      "learning_rate": 1.546511627906977e-05,
      "loss": 0.0001,
      "step": 8910
    },
    {
      "epoch": 34.53875968992248,
      "grad_norm": 0.0011908538872376084,
      "learning_rate": 1.546124031007752e-05,
      "loss": 0.0001,
      "step": 8911
    },
    {
      "epoch": 34.542635658914726,
      "grad_norm": 0.0019366602646186948,
      "learning_rate": 1.5457364341085274e-05,
      "loss": 0.0001,
      "step": 8912
    },
    {
      "epoch": 34.54651162790697,
      "grad_norm": 6.923402309417725,
      "learning_rate": 1.5453488372093026e-05,
      "loss": 1.0172,
      "step": 8913
    },
    {
      "epoch": 34.55038759689923,
      "grad_norm": 0.0011493482161313295,
      "learning_rate": 1.544961240310078e-05,
      "loss": 0.0001,
      "step": 8914
    },
    {
      "epoch": 34.554263565891475,
      "grad_norm": 0.0012382172280922532,
      "learning_rate": 1.5445736434108528e-05,
      "loss": 0.0001,
      "step": 8915
    },
    {
      "epoch": 34.55813953488372,
      "grad_norm": 0.006970210000872612,
      "learning_rate": 1.5441860465116277e-05,
      "loss": 0.0001,
      "step": 8916
    },
    {
      "epoch": 34.56201550387597,
      "grad_norm": 0.001668723882175982,
      "learning_rate": 1.543798449612403e-05,
      "loss": 0.0001,
      "step": 8917
    },
    {
      "epoch": 34.565891472868216,
      "grad_norm": 0.0009784777648746967,
      "learning_rate": 1.543410852713178e-05,
      "loss": 0.0001,
      "step": 8918
    },
    {
      "epoch": 34.56976744186046,
      "grad_norm": 1.323191523551941,
      "learning_rate": 1.5430232558139534e-05,
      "loss": 0.2183,
      "step": 8919
    },
    {
      "epoch": 34.57364341085271,
      "grad_norm": 3.7857823371887207,
      "learning_rate": 1.5426356589147287e-05,
      "loss": 0.1922,
      "step": 8920
    },
    {
      "epoch": 34.57751937984496,
      "grad_norm": 0.009713863022625446,
      "learning_rate": 1.542248062015504e-05,
      "loss": 0.0002,
      "step": 8921
    },
    {
      "epoch": 34.58139534883721,
      "grad_norm": 0.021232709288597107,
      "learning_rate": 1.541860465116279e-05,
      "loss": 0.0007,
      "step": 8922
    },
    {
      "epoch": 34.58527131782946,
      "grad_norm": 3.4145166873931885,
      "learning_rate": 1.5414728682170544e-05,
      "loss": 0.0138,
      "step": 8923
    },
    {
      "epoch": 34.58914728682171,
      "grad_norm": 0.002250725869089365,
      "learning_rate": 1.5410852713178296e-05,
      "loss": 0.0002,
      "step": 8924
    },
    {
      "epoch": 34.593023255813954,
      "grad_norm": 0.001074407366104424,
      "learning_rate": 1.5406976744186045e-05,
      "loss": 0.0001,
      "step": 8925
    },
    {
      "epoch": 34.5968992248062,
      "grad_norm": 0.005306213162839413,
      "learning_rate": 1.5403100775193798e-05,
      "loss": 0.0003,
      "step": 8926
    },
    {
      "epoch": 34.60077519379845,
      "grad_norm": 0.001328438171185553,
      "learning_rate": 1.539922480620155e-05,
      "loss": 0.0001,
      "step": 8927
    },
    {
      "epoch": 34.604651162790695,
      "grad_norm": 28.25667381286621,
      "learning_rate": 1.5395348837209303e-05,
      "loss": 1.2867,
      "step": 8928
    },
    {
      "epoch": 34.60852713178294,
      "grad_norm": 8.009246826171875,
      "learning_rate": 1.5391472868217055e-05,
      "loss": 0.2541,
      "step": 8929
    },
    {
      "epoch": 34.6124031007752,
      "grad_norm": 0.001519983634352684,
      "learning_rate": 1.5387596899224807e-05,
      "loss": 0.0001,
      "step": 8930
    },
    {
      "epoch": 34.616279069767444,
      "grad_norm": 0.0011617484269663692,
      "learning_rate": 1.538372093023256e-05,
      "loss": 0.0001,
      "step": 8931
    },
    {
      "epoch": 34.62015503875969,
      "grad_norm": 0.001102386275306344,
      "learning_rate": 1.5379844961240312e-05,
      "loss": 0.0001,
      "step": 8932
    },
    {
      "epoch": 34.62403100775194,
      "grad_norm": 0.0011037415824830532,
      "learning_rate": 1.5375968992248065e-05,
      "loss": 0.0001,
      "step": 8933
    },
    {
      "epoch": 34.627906976744185,
      "grad_norm": 0.004390934482216835,
      "learning_rate": 1.5372093023255814e-05,
      "loss": 0.0002,
      "step": 8934
    },
    {
      "epoch": 34.63178294573643,
      "grad_norm": 0.0014904708368703723,
      "learning_rate": 1.5368217054263566e-05,
      "loss": 0.0001,
      "step": 8935
    },
    {
      "epoch": 34.63565891472868,
      "grad_norm": 0.001303752069361508,
      "learning_rate": 1.536434108527132e-05,
      "loss": 0.0001,
      "step": 8936
    },
    {
      "epoch": 34.63953488372093,
      "grad_norm": 0.013257712125778198,
      "learning_rate": 1.536046511627907e-05,
      "loss": 0.0006,
      "step": 8937
    },
    {
      "epoch": 34.64341085271318,
      "grad_norm": 0.0013724672608077526,
      "learning_rate": 1.5356589147286823e-05,
      "loss": 0.0001,
      "step": 8938
    },
    {
      "epoch": 34.64728682170543,
      "grad_norm": 6.087861061096191,
      "learning_rate": 1.5352713178294576e-05,
      "loss": 0.1695,
      "step": 8939
    },
    {
      "epoch": 34.651162790697676,
      "grad_norm": 0.0013111617881804705,
      "learning_rate": 1.5348837209302328e-05,
      "loss": 0.0001,
      "step": 8940
    },
    {
      "epoch": 34.65503875968992,
      "grad_norm": 0.001427920302376151,
      "learning_rate": 1.534496124031008e-05,
      "loss": 0.0001,
      "step": 8941
    },
    {
      "epoch": 34.65891472868217,
      "grad_norm": 0.02312329225242138,
      "learning_rate": 1.5341085271317833e-05,
      "loss": 0.0009,
      "step": 8942
    },
    {
      "epoch": 34.66279069767442,
      "grad_norm": 0.9541797637939453,
      "learning_rate": 1.5337209302325582e-05,
      "loss": 0.0439,
      "step": 8943
    },
    {
      "epoch": 34.666666666666664,
      "grad_norm": 0.0012662376975640655,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 0.0001,
      "step": 8944
    },
    {
      "epoch": 34.67054263565891,
      "grad_norm": 0.003610999556258321,
      "learning_rate": 1.5329457364341084e-05,
      "loss": 0.0002,
      "step": 8945
    },
    {
      "epoch": 34.674418604651166,
      "grad_norm": 0.0017590000061318278,
      "learning_rate": 1.5325581395348836e-05,
      "loss": 0.0001,
      "step": 8946
    },
    {
      "epoch": 34.67829457364341,
      "grad_norm": 0.001748776761814952,
      "learning_rate": 1.532170542635659e-05,
      "loss": 0.0001,
      "step": 8947
    },
    {
      "epoch": 34.68217054263566,
      "grad_norm": 0.0022729162592440844,
      "learning_rate": 1.531782945736434e-05,
      "loss": 0.0001,
      "step": 8948
    },
    {
      "epoch": 34.68604651162791,
      "grad_norm": 11.490883827209473,
      "learning_rate": 1.5313953488372093e-05,
      "loss": 0.0349,
      "step": 8949
    },
    {
      "epoch": 34.689922480620154,
      "grad_norm": 1.5019434690475464,
      "learning_rate": 1.5310077519379846e-05,
      "loss": 0.0946,
      "step": 8950
    },
    {
      "epoch": 34.6937984496124,
      "grad_norm": 0.005490380804985762,
      "learning_rate": 1.5306201550387598e-05,
      "loss": 0.0003,
      "step": 8951
    },
    {
      "epoch": 34.69767441860465,
      "grad_norm": 0.007921868935227394,
      "learning_rate": 1.530232558139535e-05,
      "loss": 0.0004,
      "step": 8952
    },
    {
      "epoch": 34.701550387596896,
      "grad_norm": 0.46780091524124146,
      "learning_rate": 1.5298449612403103e-05,
      "loss": 0.0041,
      "step": 8953
    },
    {
      "epoch": 34.70542635658915,
      "grad_norm": 0.0017405218677595258,
      "learning_rate": 1.5294573643410852e-05,
      "loss": 0.0001,
      "step": 8954
    },
    {
      "epoch": 34.7093023255814,
      "grad_norm": 0.023476270958781242,
      "learning_rate": 1.5290697674418604e-05,
      "loss": 0.0009,
      "step": 8955
    },
    {
      "epoch": 34.713178294573645,
      "grad_norm": 0.0017376741161569953,
      "learning_rate": 1.5286821705426357e-05,
      "loss": 0.0002,
      "step": 8956
    },
    {
      "epoch": 34.71705426356589,
      "grad_norm": 0.0013068029657006264,
      "learning_rate": 1.528294573643411e-05,
      "loss": 0.0001,
      "step": 8957
    },
    {
      "epoch": 34.72093023255814,
      "grad_norm": 0.011552848853170872,
      "learning_rate": 1.527906976744186e-05,
      "loss": 0.0005,
      "step": 8958
    },
    {
      "epoch": 34.724806201550386,
      "grad_norm": 0.5028166770935059,
      "learning_rate": 1.5275193798449614e-05,
      "loss": 0.0015,
      "step": 8959
    },
    {
      "epoch": 34.72868217054263,
      "grad_norm": 0.033295802772045135,
      "learning_rate": 1.5271317829457366e-05,
      "loss": 0.0013,
      "step": 8960
    },
    {
      "epoch": 34.73255813953488,
      "grad_norm": 0.005643982440233231,
      "learning_rate": 1.526744186046512e-05,
      "loss": 0.0002,
      "step": 8961
    },
    {
      "epoch": 34.736434108527135,
      "grad_norm": 0.13989920914173126,
      "learning_rate": 1.526356589147287e-05,
      "loss": 0.004,
      "step": 8962
    },
    {
      "epoch": 34.74031007751938,
      "grad_norm": 0.001435804064385593,
      "learning_rate": 1.525968992248062e-05,
      "loss": 0.0001,
      "step": 8963
    },
    {
      "epoch": 34.74418604651163,
      "grad_norm": 12.826629638671875,
      "learning_rate": 1.5255813953488374e-05,
      "loss": 0.0408,
      "step": 8964
    },
    {
      "epoch": 34.748062015503876,
      "grad_norm": 0.0012375636724755168,
      "learning_rate": 1.5251937984496125e-05,
      "loss": 0.0001,
      "step": 8965
    },
    {
      "epoch": 34.751937984496124,
      "grad_norm": 0.005489478353410959,
      "learning_rate": 1.5248062015503878e-05,
      "loss": 0.0003,
      "step": 8966
    },
    {
      "epoch": 34.75581395348837,
      "grad_norm": 0.001314144697971642,
      "learning_rate": 1.524418604651163e-05,
      "loss": 0.0001,
      "step": 8967
    },
    {
      "epoch": 34.75968992248062,
      "grad_norm": 0.2992926239967346,
      "learning_rate": 1.5240310077519382e-05,
      "loss": 0.0126,
      "step": 8968
    },
    {
      "epoch": 34.763565891472865,
      "grad_norm": 0.02707543596625328,
      "learning_rate": 1.5236434108527131e-05,
      "loss": 0.0011,
      "step": 8969
    },
    {
      "epoch": 34.76744186046512,
      "grad_norm": 0.006136817391961813,
      "learning_rate": 1.5232558139534884e-05,
      "loss": 0.0002,
      "step": 8970
    },
    {
      "epoch": 34.77131782945737,
      "grad_norm": 0.020165370777249336,
      "learning_rate": 1.5228682170542635e-05,
      "loss": 0.0007,
      "step": 8971
    },
    {
      "epoch": 34.775193798449614,
      "grad_norm": 2.071572780609131,
      "learning_rate": 1.5224806201550387e-05,
      "loss": 0.0164,
      "step": 8972
    },
    {
      "epoch": 34.77906976744186,
      "grad_norm": 0.0012139056343585253,
      "learning_rate": 1.522093023255814e-05,
      "loss": 0.0001,
      "step": 8973
    },
    {
      "epoch": 34.78294573643411,
      "grad_norm": 0.0013132394524291158,
      "learning_rate": 1.5217054263565892e-05,
      "loss": 0.0001,
      "step": 8974
    },
    {
      "epoch": 34.786821705426355,
      "grad_norm": 0.022789889946579933,
      "learning_rate": 1.5213178294573643e-05,
      "loss": 0.0006,
      "step": 8975
    },
    {
      "epoch": 34.7906976744186,
      "grad_norm": 0.055040713399648666,
      "learning_rate": 1.5209302325581395e-05,
      "loss": 0.0009,
      "step": 8976
    },
    {
      "epoch": 34.79457364341085,
      "grad_norm": 0.002289390889927745,
      "learning_rate": 1.5205426356589147e-05,
      "loss": 0.0002,
      "step": 8977
    },
    {
      "epoch": 34.798449612403104,
      "grad_norm": 1.277022123336792,
      "learning_rate": 1.52015503875969e-05,
      "loss": 0.0649,
      "step": 8978
    },
    {
      "epoch": 34.80232558139535,
      "grad_norm": 0.014519473537802696,
      "learning_rate": 1.5197674418604652e-05,
      "loss": 0.0006,
      "step": 8979
    },
    {
      "epoch": 34.8062015503876,
      "grad_norm": 1.004952073097229,
      "learning_rate": 1.5193798449612403e-05,
      "loss": 0.0506,
      "step": 8980
    },
    {
      "epoch": 34.810077519379846,
      "grad_norm": 0.0020624431781470776,
      "learning_rate": 1.5189922480620155e-05,
      "loss": 0.0001,
      "step": 8981
    },
    {
      "epoch": 34.81395348837209,
      "grad_norm": 0.004598616622388363,
      "learning_rate": 1.5186046511627908e-05,
      "loss": 0.0003,
      "step": 8982
    },
    {
      "epoch": 34.81782945736434,
      "grad_norm": 0.001282544108107686,
      "learning_rate": 1.518217054263566e-05,
      "loss": 0.0001,
      "step": 8983
    },
    {
      "epoch": 34.82170542635659,
      "grad_norm": 0.26343587040901184,
      "learning_rate": 1.5178294573643411e-05,
      "loss": 0.0116,
      "step": 8984
    },
    {
      "epoch": 34.825581395348834,
      "grad_norm": 0.02760053239762783,
      "learning_rate": 1.5174418604651163e-05,
      "loss": 0.0009,
      "step": 8985
    },
    {
      "epoch": 34.82945736434109,
      "grad_norm": 0.001195386634208262,
      "learning_rate": 1.5170542635658916e-05,
      "loss": 0.0001,
      "step": 8986
    },
    {
      "epoch": 34.833333333333336,
      "grad_norm": 0.001833713729865849,
      "learning_rate": 1.5166666666666668e-05,
      "loss": 0.0001,
      "step": 8987
    },
    {
      "epoch": 34.83720930232558,
      "grad_norm": 0.0018548695370554924,
      "learning_rate": 1.516279069767442e-05,
      "loss": 0.0001,
      "step": 8988
    },
    {
      "epoch": 34.84108527131783,
      "grad_norm": 0.007495827041566372,
      "learning_rate": 1.5158914728682171e-05,
      "loss": 0.0004,
      "step": 8989
    },
    {
      "epoch": 34.84496124031008,
      "grad_norm": 0.0014082122361287475,
      "learning_rate": 1.5155038759689924e-05,
      "loss": 0.0001,
      "step": 8990
    },
    {
      "epoch": 34.848837209302324,
      "grad_norm": 0.018506573513150215,
      "learning_rate": 1.5151162790697676e-05,
      "loss": 0.0006,
      "step": 8991
    },
    {
      "epoch": 34.85271317829457,
      "grad_norm": 0.008266096003353596,
      "learning_rate": 1.5147286821705429e-05,
      "loss": 0.0004,
      "step": 8992
    },
    {
      "epoch": 34.85658914728682,
      "grad_norm": 0.002670099725946784,
      "learning_rate": 1.514341085271318e-05,
      "loss": 0.0002,
      "step": 8993
    },
    {
      "epoch": 34.86046511627907,
      "grad_norm": 0.0012770135654136539,
      "learning_rate": 1.5139534883720932e-05,
      "loss": 0.0001,
      "step": 8994
    },
    {
      "epoch": 34.86434108527132,
      "grad_norm": 0.0016669840551912785,
      "learning_rate": 1.5135658914728684e-05,
      "loss": 0.0001,
      "step": 8995
    },
    {
      "epoch": 34.86821705426357,
      "grad_norm": 0.0013540713116526604,
      "learning_rate": 1.5131782945736433e-05,
      "loss": 0.0001,
      "step": 8996
    },
    {
      "epoch": 34.872093023255815,
      "grad_norm": 0.0026896900963038206,
      "learning_rate": 1.5127906976744186e-05,
      "loss": 0.0002,
      "step": 8997
    },
    {
      "epoch": 34.87596899224806,
      "grad_norm": 0.0015860215062275529,
      "learning_rate": 1.5124031007751938e-05,
      "loss": 0.0001,
      "step": 8998
    },
    {
      "epoch": 34.87984496124031,
      "grad_norm": 0.001760866609402001,
      "learning_rate": 1.5120155038759689e-05,
      "loss": 0.0002,
      "step": 8999
    },
    {
      "epoch": 34.883720930232556,
      "grad_norm": 8.174365043640137,
      "learning_rate": 1.5116279069767441e-05,
      "loss": 0.1635,
      "step": 9000
    },
    {
      "epoch": 34.8875968992248,
      "grad_norm": 0.0022393595427274704,
      "learning_rate": 1.5112403100775194e-05,
      "loss": 0.0001,
      "step": 9001
    },
    {
      "epoch": 34.89147286821706,
      "grad_norm": 0.8134602904319763,
      "learning_rate": 1.5108527131782946e-05,
      "loss": 0.032,
      "step": 9002
    },
    {
      "epoch": 34.895348837209305,
      "grad_norm": 0.0016666250303387642,
      "learning_rate": 1.5104651162790699e-05,
      "loss": 0.0001,
      "step": 9003
    },
    {
      "epoch": 34.89922480620155,
      "grad_norm": 0.0014609587378799915,
      "learning_rate": 1.510077519379845e-05,
      "loss": 0.0001,
      "step": 9004
    },
    {
      "epoch": 34.9031007751938,
      "grad_norm": 0.9665650725364685,
      "learning_rate": 1.5096899224806202e-05,
      "loss": 0.0542,
      "step": 9005
    },
    {
      "epoch": 34.906976744186046,
      "grad_norm": 0.0009716793429106474,
      "learning_rate": 1.5093023255813954e-05,
      "loss": 0.0001,
      "step": 9006
    },
    {
      "epoch": 34.91085271317829,
      "grad_norm": 0.0025089706759899855,
      "learning_rate": 1.5089147286821707e-05,
      "loss": 0.0002,
      "step": 9007
    },
    {
      "epoch": 34.91472868217054,
      "grad_norm": 0.0029571643099188805,
      "learning_rate": 1.5085271317829457e-05,
      "loss": 0.0002,
      "step": 9008
    },
    {
      "epoch": 34.91860465116279,
      "grad_norm": 0.0019109746208414435,
      "learning_rate": 1.508139534883721e-05,
      "loss": 0.0001,
      "step": 9009
    },
    {
      "epoch": 34.92248062015504,
      "grad_norm": 0.0038081693928688765,
      "learning_rate": 1.5077519379844962e-05,
      "loss": 0.0002,
      "step": 9010
    },
    {
      "epoch": 34.92635658914729,
      "grad_norm": 0.0011966602178290486,
      "learning_rate": 1.5073643410852715e-05,
      "loss": 0.0001,
      "step": 9011
    },
    {
      "epoch": 34.93023255813954,
      "grad_norm": 0.0012660224456340075,
      "learning_rate": 1.5069767441860467e-05,
      "loss": 0.0001,
      "step": 9012
    },
    {
      "epoch": 34.934108527131784,
      "grad_norm": 0.00116451655048877,
      "learning_rate": 1.5065891472868218e-05,
      "loss": 0.0001,
      "step": 9013
    },
    {
      "epoch": 34.93798449612403,
      "grad_norm": 0.005953051615506411,
      "learning_rate": 1.506201550387597e-05,
      "loss": 0.0003,
      "step": 9014
    },
    {
      "epoch": 34.94186046511628,
      "grad_norm": 0.0013455008156597614,
      "learning_rate": 1.5058139534883723e-05,
      "loss": 0.0001,
      "step": 9015
    },
    {
      "epoch": 34.945736434108525,
      "grad_norm": 0.009124615229666233,
      "learning_rate": 1.5054263565891475e-05,
      "loss": 0.0004,
      "step": 9016
    },
    {
      "epoch": 34.94961240310077,
      "grad_norm": 0.0013036642922088504,
      "learning_rate": 1.5050387596899226e-05,
      "loss": 0.0001,
      "step": 9017
    },
    {
      "epoch": 34.95348837209303,
      "grad_norm": 0.004355395678430796,
      "learning_rate": 1.5046511627906978e-05,
      "loss": 0.0003,
      "step": 9018
    },
    {
      "epoch": 34.957364341085274,
      "grad_norm": 0.0015726637793704867,
      "learning_rate": 1.504263565891473e-05,
      "loss": 0.0001,
      "step": 9019
    },
    {
      "epoch": 34.96124031007752,
      "grad_norm": 0.002339257625862956,
      "learning_rate": 1.5038759689922483e-05,
      "loss": 0.0001,
      "step": 9020
    },
    {
      "epoch": 34.96511627906977,
      "grad_norm": 0.26117241382598877,
      "learning_rate": 1.5034883720930235e-05,
      "loss": 0.0015,
      "step": 9021
    },
    {
      "epoch": 34.968992248062015,
      "grad_norm": 0.0010797269642353058,
      "learning_rate": 1.5031007751937986e-05,
      "loss": 0.0001,
      "step": 9022
    },
    {
      "epoch": 34.97286821705426,
      "grad_norm": 0.08683163672685623,
      "learning_rate": 1.5027131782945735e-05,
      "loss": 0.0005,
      "step": 9023
    },
    {
      "epoch": 34.97674418604651,
      "grad_norm": 0.05166020616889,
      "learning_rate": 1.5023255813953488e-05,
      "loss": 0.0007,
      "step": 9024
    },
    {
      "epoch": 34.98062015503876,
      "grad_norm": 3.8755993843078613,
      "learning_rate": 1.501937984496124e-05,
      "loss": 0.0042,
      "step": 9025
    },
    {
      "epoch": 34.98449612403101,
      "grad_norm": 0.001647938508540392,
      "learning_rate": 1.5015503875968992e-05,
      "loss": 0.0001,
      "step": 9026
    },
    {
      "epoch": 34.98837209302326,
      "grad_norm": 0.005217814818024635,
      "learning_rate": 1.5011627906976745e-05,
      "loss": 0.0003,
      "step": 9027
    },
    {
      "epoch": 34.992248062015506,
      "grad_norm": 0.0017887732246890664,
      "learning_rate": 1.5007751937984496e-05,
      "loss": 0.0002,
      "step": 9028
    },
    {
      "epoch": 34.99612403100775,
      "grad_norm": 0.0016766209155321121,
      "learning_rate": 1.5003875968992248e-05,
      "loss": 0.0001,
      "step": 9029
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.04658683389425278,
      "learning_rate": 1.5e-05,
      "loss": 0.0006,
      "step": 9030
    },
    {
      "epoch": 35.00387596899225,
      "grad_norm": 0.0012632085708901286,
      "learning_rate": 1.4996124031007753e-05,
      "loss": 0.0001,
      "step": 9031
    },
    {
      "epoch": 35.007751937984494,
      "grad_norm": 0.0016315138200297952,
      "learning_rate": 1.4992248062015504e-05,
      "loss": 0.0001,
      "step": 9032
    },
    {
      "epoch": 35.01162790697674,
      "grad_norm": 0.031379975378513336,
      "learning_rate": 1.4988372093023256e-05,
      "loss": 0.0005,
      "step": 9033
    },
    {
      "epoch": 35.01550387596899,
      "grad_norm": 0.001028680824674666,
      "learning_rate": 1.4984496124031008e-05,
      "loss": 0.0001,
      "step": 9034
    },
    {
      "epoch": 35.01937984496124,
      "grad_norm": 0.0010202104458585382,
      "learning_rate": 1.498062015503876e-05,
      "loss": 0.0001,
      "step": 9035
    },
    {
      "epoch": 35.02325581395349,
      "grad_norm": 0.0011135388631373644,
      "learning_rate": 1.4976744186046513e-05,
      "loss": 0.0001,
      "step": 9036
    },
    {
      "epoch": 35.02713178294574,
      "grad_norm": 0.01342627964913845,
      "learning_rate": 1.4972868217054264e-05,
      "loss": 0.0003,
      "step": 9037
    },
    {
      "epoch": 35.031007751937985,
      "grad_norm": 0.005222152452915907,
      "learning_rate": 1.4968992248062016e-05,
      "loss": 0.0003,
      "step": 9038
    },
    {
      "epoch": 35.03488372093023,
      "grad_norm": 0.0018737632781267166,
      "learning_rate": 1.4965116279069769e-05,
      "loss": 0.0002,
      "step": 9039
    },
    {
      "epoch": 35.03875968992248,
      "grad_norm": 0.0014563830336555839,
      "learning_rate": 1.4961240310077521e-05,
      "loss": 0.0001,
      "step": 9040
    },
    {
      "epoch": 35.042635658914726,
      "grad_norm": 0.0012687902199104428,
      "learning_rate": 1.4957364341085272e-05,
      "loss": 0.0001,
      "step": 9041
    },
    {
      "epoch": 35.04651162790697,
      "grad_norm": 0.004006035625934601,
      "learning_rate": 1.4953488372093024e-05,
      "loss": 0.0003,
      "step": 9042
    },
    {
      "epoch": 35.05038759689923,
      "grad_norm": 0.14947788417339325,
      "learning_rate": 1.4949612403100777e-05,
      "loss": 0.006,
      "step": 9043
    },
    {
      "epoch": 35.054263565891475,
      "grad_norm": 0.003911036066710949,
      "learning_rate": 1.494573643410853e-05,
      "loss": 0.0003,
      "step": 9044
    },
    {
      "epoch": 35.05813953488372,
      "grad_norm": 0.001381474663503468,
      "learning_rate": 1.4941860465116282e-05,
      "loss": 0.0001,
      "step": 9045
    },
    {
      "epoch": 35.06201550387597,
      "grad_norm": 0.0011732992716133595,
      "learning_rate": 1.4937984496124032e-05,
      "loss": 0.0001,
      "step": 9046
    },
    {
      "epoch": 35.065891472868216,
      "grad_norm": 0.0012934331316500902,
      "learning_rate": 1.4934108527131785e-05,
      "loss": 0.0001,
      "step": 9047
    },
    {
      "epoch": 35.06976744186046,
      "grad_norm": 0.005853560287505388,
      "learning_rate": 1.4930232558139537e-05,
      "loss": 0.0003,
      "step": 9048
    },
    {
      "epoch": 35.07364341085271,
      "grad_norm": 0.04521289840340614,
      "learning_rate": 1.4926356589147286e-05,
      "loss": 0.0005,
      "step": 9049
    },
    {
      "epoch": 35.07751937984496,
      "grad_norm": 0.0022812599781900644,
      "learning_rate": 1.4922480620155039e-05,
      "loss": 0.0001,
      "step": 9050
    },
    {
      "epoch": 35.08139534883721,
      "grad_norm": 0.5187718868255615,
      "learning_rate": 1.4918604651162791e-05,
      "loss": 0.0219,
      "step": 9051
    },
    {
      "epoch": 35.08527131782946,
      "grad_norm": 0.0038118299562484026,
      "learning_rate": 1.4914728682170542e-05,
      "loss": 0.0002,
      "step": 9052
    },
    {
      "epoch": 35.08914728682171,
      "grad_norm": 0.08369790762662888,
      "learning_rate": 1.4910852713178294e-05,
      "loss": 0.0026,
      "step": 9053
    },
    {
      "epoch": 35.093023255813954,
      "grad_norm": 0.001217551063746214,
      "learning_rate": 1.4906976744186047e-05,
      "loss": 0.0001,
      "step": 9054
    },
    {
      "epoch": 35.0968992248062,
      "grad_norm": 0.001635570777580142,
      "learning_rate": 1.4903100775193799e-05,
      "loss": 0.0001,
      "step": 9055
    },
    {
      "epoch": 35.10077519379845,
      "grad_norm": 0.006464818492531776,
      "learning_rate": 1.489922480620155e-05,
      "loss": 0.0004,
      "step": 9056
    },
    {
      "epoch": 35.104651162790695,
      "grad_norm": 0.0012017317349091172,
      "learning_rate": 1.4895348837209302e-05,
      "loss": 0.0001,
      "step": 9057
    },
    {
      "epoch": 35.10852713178294,
      "grad_norm": 0.0011841353261843324,
      "learning_rate": 1.4891472868217055e-05,
      "loss": 0.0001,
      "step": 9058
    },
    {
      "epoch": 35.1124031007752,
      "grad_norm": 0.0011846863199025393,
      "learning_rate": 1.4887596899224807e-05,
      "loss": 0.0001,
      "step": 9059
    },
    {
      "epoch": 35.116279069767444,
      "grad_norm": 0.006173153407871723,
      "learning_rate": 1.488372093023256e-05,
      "loss": 0.0003,
      "step": 9060
    },
    {
      "epoch": 35.12015503875969,
      "grad_norm": 0.002069563837721944,
      "learning_rate": 1.487984496124031e-05,
      "loss": 0.0002,
      "step": 9061
    },
    {
      "epoch": 35.12403100775194,
      "grad_norm": 0.001558652613312006,
      "learning_rate": 1.4875968992248063e-05,
      "loss": 0.0001,
      "step": 9062
    },
    {
      "epoch": 35.127906976744185,
      "grad_norm": 0.006073698867112398,
      "learning_rate": 1.4872093023255815e-05,
      "loss": 0.0004,
      "step": 9063
    },
    {
      "epoch": 35.13178294573643,
      "grad_norm": 0.002877954626455903,
      "learning_rate": 1.4868217054263567e-05,
      "loss": 0.0002,
      "step": 9064
    },
    {
      "epoch": 35.13565891472868,
      "grad_norm": 0.0010195993818342686,
      "learning_rate": 1.4864341085271318e-05,
      "loss": 0.0001,
      "step": 9065
    },
    {
      "epoch": 35.13953488372093,
      "grad_norm": 0.0016025357181206346,
      "learning_rate": 1.486046511627907e-05,
      "loss": 0.0001,
      "step": 9066
    },
    {
      "epoch": 35.14341085271318,
      "grad_norm": 0.0018911327933892608,
      "learning_rate": 1.4856589147286823e-05,
      "loss": 0.0001,
      "step": 9067
    },
    {
      "epoch": 35.14728682170543,
      "grad_norm": 0.0014611509395763278,
      "learning_rate": 1.4852713178294575e-05,
      "loss": 0.0001,
      "step": 9068
    },
    {
      "epoch": 35.151162790697676,
      "grad_norm": 0.0011172896483913064,
      "learning_rate": 1.4848837209302326e-05,
      "loss": 0.0001,
      "step": 9069
    },
    {
      "epoch": 35.15503875968992,
      "grad_norm": 0.006939387414604425,
      "learning_rate": 1.4844961240310079e-05,
      "loss": 0.0004,
      "step": 9070
    },
    {
      "epoch": 35.15891472868217,
      "grad_norm": 0.0024137746077030897,
      "learning_rate": 1.4841085271317831e-05,
      "loss": 0.0002,
      "step": 9071
    },
    {
      "epoch": 35.16279069767442,
      "grad_norm": 0.24203455448150635,
      "learning_rate": 1.4837209302325583e-05,
      "loss": 0.0087,
      "step": 9072
    },
    {
      "epoch": 35.166666666666664,
      "grad_norm": 0.07988010346889496,
      "learning_rate": 1.4833333333333336e-05,
      "loss": 0.0005,
      "step": 9073
    },
    {
      "epoch": 35.17054263565891,
      "grad_norm": 0.0012037045089527965,
      "learning_rate": 1.4829457364341087e-05,
      "loss": 0.0001,
      "step": 9074
    },
    {
      "epoch": 35.174418604651166,
      "grad_norm": 0.0010812508407980204,
      "learning_rate": 1.4825581395348839e-05,
      "loss": 0.0001,
      "step": 9075
    },
    {
      "epoch": 35.17829457364341,
      "grad_norm": 0.0013468132819980383,
      "learning_rate": 1.4821705426356588e-05,
      "loss": 0.0001,
      "step": 9076
    },
    {
      "epoch": 35.18217054263566,
      "grad_norm": 0.015381968580186367,
      "learning_rate": 1.481782945736434e-05,
      "loss": 0.0004,
      "step": 9077
    },
    {
      "epoch": 35.18604651162791,
      "grad_norm": 0.0039868587628006935,
      "learning_rate": 1.4813953488372093e-05,
      "loss": 0.0003,
      "step": 9078
    },
    {
      "epoch": 35.189922480620154,
      "grad_norm": 0.0010865882504731417,
      "learning_rate": 1.4810077519379845e-05,
      "loss": 0.0001,
      "step": 9079
    },
    {
      "epoch": 35.1937984496124,
      "grad_norm": 0.0033511316869407892,
      "learning_rate": 1.4806201550387596e-05,
      "loss": 0.0003,
      "step": 9080
    },
    {
      "epoch": 35.19767441860465,
      "grad_norm": 0.012146789580583572,
      "learning_rate": 1.4802325581395348e-05,
      "loss": 0.0004,
      "step": 9081
    },
    {
      "epoch": 35.201550387596896,
      "grad_norm": 0.0012532927794381976,
      "learning_rate": 1.4798449612403101e-05,
      "loss": 0.0001,
      "step": 9082
    },
    {
      "epoch": 35.20542635658915,
      "grad_norm": 0.001005783211439848,
      "learning_rate": 1.4794573643410853e-05,
      "loss": 0.0001,
      "step": 9083
    },
    {
      "epoch": 35.2093023255814,
      "grad_norm": 0.0014500054530799389,
      "learning_rate": 1.4790697674418604e-05,
      "loss": 0.0001,
      "step": 9084
    },
    {
      "epoch": 35.213178294573645,
      "grad_norm": 3.8673782348632812,
      "learning_rate": 1.4786821705426356e-05,
      "loss": 0.0574,
      "step": 9085
    },
    {
      "epoch": 35.21705426356589,
      "grad_norm": 0.0017662318423390388,
      "learning_rate": 1.4782945736434109e-05,
      "loss": 0.0001,
      "step": 9086
    },
    {
      "epoch": 35.22093023255814,
      "grad_norm": 0.0033668805845081806,
      "learning_rate": 1.4779069767441861e-05,
      "loss": 0.0002,
      "step": 9087
    },
    {
      "epoch": 35.224806201550386,
      "grad_norm": 0.006233322899788618,
      "learning_rate": 1.4775193798449614e-05,
      "loss": 0.0003,
      "step": 9088
    },
    {
      "epoch": 35.22868217054263,
      "grad_norm": 2.0699269771575928,
      "learning_rate": 1.4771317829457364e-05,
      "loss": 0.2125,
      "step": 9089
    },
    {
      "epoch": 35.23255813953488,
      "grad_norm": 0.0012552845291793346,
      "learning_rate": 1.4767441860465117e-05,
      "loss": 0.0001,
      "step": 9090
    },
    {
      "epoch": 35.236434108527135,
      "grad_norm": 1.62397038936615,
      "learning_rate": 1.476356589147287e-05,
      "loss": 0.2739,
      "step": 9091
    },
    {
      "epoch": 35.24031007751938,
      "grad_norm": 0.001318443682976067,
      "learning_rate": 1.4759689922480622e-05,
      "loss": 0.0001,
      "step": 9092
    },
    {
      "epoch": 35.24418604651163,
      "grad_norm": 0.0014174627140164375,
      "learning_rate": 1.4755813953488372e-05,
      "loss": 0.0001,
      "step": 9093
    },
    {
      "epoch": 35.248062015503876,
      "grad_norm": 0.0012746055144816637,
      "learning_rate": 1.4751937984496125e-05,
      "loss": 0.0001,
      "step": 9094
    },
    {
      "epoch": 35.251937984496124,
      "grad_norm": 0.00196908344514668,
      "learning_rate": 1.4748062015503877e-05,
      "loss": 0.0002,
      "step": 9095
    },
    {
      "epoch": 35.25581395348837,
      "grad_norm": 0.002320066327229142,
      "learning_rate": 1.474418604651163e-05,
      "loss": 0.0001,
      "step": 9096
    },
    {
      "epoch": 35.25968992248062,
      "grad_norm": 0.003259240882471204,
      "learning_rate": 1.4740310077519382e-05,
      "loss": 0.0002,
      "step": 9097
    },
    {
      "epoch": 35.263565891472865,
      "grad_norm": 0.0036587303038686514,
      "learning_rate": 1.4736434108527133e-05,
      "loss": 0.0003,
      "step": 9098
    },
    {
      "epoch": 35.26744186046512,
      "grad_norm": 1.3081914186477661,
      "learning_rate": 1.4732558139534885e-05,
      "loss": 0.0514,
      "step": 9099
    },
    {
      "epoch": 35.27131782945737,
      "grad_norm": 0.033944327384233475,
      "learning_rate": 1.4728682170542638e-05,
      "loss": 0.0005,
      "step": 9100
    },
    {
      "epoch": 35.275193798449614,
      "grad_norm": 0.015010460279881954,
      "learning_rate": 1.472480620155039e-05,
      "loss": 0.0004,
      "step": 9101
    },
    {
      "epoch": 35.27906976744186,
      "grad_norm": 0.020875222980976105,
      "learning_rate": 1.472093023255814e-05,
      "loss": 0.0006,
      "step": 9102
    },
    {
      "epoch": 35.28294573643411,
      "grad_norm": 0.00905783474445343,
      "learning_rate": 1.4717054263565892e-05,
      "loss": 0.0003,
      "step": 9103
    },
    {
      "epoch": 35.286821705426355,
      "grad_norm": 0.02404031716287136,
      "learning_rate": 1.4713178294573642e-05,
      "loss": 0.0005,
      "step": 9104
    },
    {
      "epoch": 35.2906976744186,
      "grad_norm": 0.013257207348942757,
      "learning_rate": 1.4709302325581395e-05,
      "loss": 0.0004,
      "step": 9105
    },
    {
      "epoch": 35.29457364341085,
      "grad_norm": 0.31706562638282776,
      "learning_rate": 1.4705426356589147e-05,
      "loss": 0.0136,
      "step": 9106
    },
    {
      "epoch": 35.298449612403104,
      "grad_norm": 0.011649117805063725,
      "learning_rate": 1.47015503875969e-05,
      "loss": 0.0003,
      "step": 9107
    },
    {
      "epoch": 35.30232558139535,
      "grad_norm": 0.012277740053832531,
      "learning_rate": 1.469767441860465e-05,
      "loss": 0.0004,
      "step": 9108
    },
    {
      "epoch": 35.3062015503876,
      "grad_norm": 0.010013316757977009,
      "learning_rate": 1.4693798449612403e-05,
      "loss": 0.0004,
      "step": 9109
    },
    {
      "epoch": 35.310077519379846,
      "grad_norm": 0.03746330365538597,
      "learning_rate": 1.4689922480620155e-05,
      "loss": 0.0009,
      "step": 9110
    },
    {
      "epoch": 35.31395348837209,
      "grad_norm": 0.00471803592517972,
      "learning_rate": 1.4686046511627908e-05,
      "loss": 0.0002,
      "step": 9111
    },
    {
      "epoch": 35.31782945736434,
      "grad_norm": 0.010595213621854782,
      "learning_rate": 1.468217054263566e-05,
      "loss": 0.0004,
      "step": 9112
    },
    {
      "epoch": 35.32170542635659,
      "grad_norm": 0.007602372206747532,
      "learning_rate": 1.467829457364341e-05,
      "loss": 0.0003,
      "step": 9113
    },
    {
      "epoch": 35.325581395348834,
      "grad_norm": 0.008974334225058556,
      "learning_rate": 1.4674418604651163e-05,
      "loss": 0.0004,
      "step": 9114
    },
    {
      "epoch": 35.32945736434109,
      "grad_norm": 0.004791962914168835,
      "learning_rate": 1.4670542635658916e-05,
      "loss": 0.0002,
      "step": 9115
    },
    {
      "epoch": 35.333333333333336,
      "grad_norm": 6.789959907531738,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 0.6414,
      "step": 9116
    },
    {
      "epoch": 35.33720930232558,
      "grad_norm": 0.0048318104818463326,
      "learning_rate": 1.4662790697674419e-05,
      "loss": 0.0003,
      "step": 9117
    },
    {
      "epoch": 35.34108527131783,
      "grad_norm": 0.005446215160191059,
      "learning_rate": 1.4658914728682171e-05,
      "loss": 0.0002,
      "step": 9118
    },
    {
      "epoch": 35.34496124031008,
      "grad_norm": 0.0025354030076414347,
      "learning_rate": 1.4655038759689924e-05,
      "loss": 0.0002,
      "step": 9119
    },
    {
      "epoch": 35.348837209302324,
      "grad_norm": 0.007967393845319748,
      "learning_rate": 1.4651162790697676e-05,
      "loss": 0.0005,
      "step": 9120
    },
    {
      "epoch": 35.35271317829457,
      "grad_norm": 0.006020101252943277,
      "learning_rate": 1.4647286821705428e-05,
      "loss": 0.0002,
      "step": 9121
    },
    {
      "epoch": 35.35658914728682,
      "grad_norm": 0.004080035723745823,
      "learning_rate": 1.4643410852713179e-05,
      "loss": 0.0002,
      "step": 9122
    },
    {
      "epoch": 35.36046511627907,
      "grad_norm": 0.004694946575909853,
      "learning_rate": 1.4639534883720932e-05,
      "loss": 0.0002,
      "step": 9123
    },
    {
      "epoch": 35.36434108527132,
      "grad_norm": 0.004718627315014601,
      "learning_rate": 1.4635658914728684e-05,
      "loss": 0.0002,
      "step": 9124
    },
    {
      "epoch": 35.36821705426357,
      "grad_norm": 0.002994452603161335,
      "learning_rate": 1.4631782945736436e-05,
      "loss": 0.0003,
      "step": 9125
    },
    {
      "epoch": 35.372093023255815,
      "grad_norm": 0.0019726213067770004,
      "learning_rate": 1.4627906976744187e-05,
      "loss": 0.0001,
      "step": 9126
    },
    {
      "epoch": 35.37596899224806,
      "grad_norm": 0.006314283702522516,
      "learning_rate": 1.462403100775194e-05,
      "loss": 0.0003,
      "step": 9127
    },
    {
      "epoch": 35.37984496124031,
      "grad_norm": 0.001948184217326343,
      "learning_rate": 1.4620155038759692e-05,
      "loss": 0.0001,
      "step": 9128
    },
    {
      "epoch": 35.383720930232556,
      "grad_norm": 0.002086489927023649,
      "learning_rate": 1.4616279069767441e-05,
      "loss": 0.0002,
      "step": 9129
    },
    {
      "epoch": 35.3875968992248,
      "grad_norm": 0.14132392406463623,
      "learning_rate": 1.4612403100775193e-05,
      "loss": 0.003,
      "step": 9130
    },
    {
      "epoch": 35.39147286821706,
      "grad_norm": 0.0015890600625425577,
      "learning_rate": 1.4608527131782946e-05,
      "loss": 0.0001,
      "step": 9131
    },
    {
      "epoch": 35.395348837209305,
      "grad_norm": 0.0019513533916324377,
      "learning_rate": 1.4604651162790697e-05,
      "loss": 0.0001,
      "step": 9132
    },
    {
      "epoch": 35.39922480620155,
      "grad_norm": 0.001111491583287716,
      "learning_rate": 1.4600775193798449e-05,
      "loss": 0.0001,
      "step": 9133
    },
    {
      "epoch": 35.4031007751938,
      "grad_norm": 0.0011139189591631293,
      "learning_rate": 1.4596899224806201e-05,
      "loss": 0.0001,
      "step": 9134
    },
    {
      "epoch": 35.406976744186046,
      "grad_norm": 0.0015393357025459409,
      "learning_rate": 1.4593023255813954e-05,
      "loss": 0.0001,
      "step": 9135
    },
    {
      "epoch": 35.41085271317829,
      "grad_norm": 0.0018574250862002373,
      "learning_rate": 1.4589147286821706e-05,
      "loss": 0.0002,
      "step": 9136
    },
    {
      "epoch": 35.41472868217054,
      "grad_norm": 0.0020426702685654163,
      "learning_rate": 1.4585271317829457e-05,
      "loss": 0.0002,
      "step": 9137
    },
    {
      "epoch": 35.41860465116279,
      "grad_norm": 0.0015856982208788395,
      "learning_rate": 1.458139534883721e-05,
      "loss": 0.0001,
      "step": 9138
    },
    {
      "epoch": 35.42248062015504,
      "grad_norm": 0.001199771766550839,
      "learning_rate": 1.4577519379844962e-05,
      "loss": 0.0001,
      "step": 9139
    },
    {
      "epoch": 35.42635658914729,
      "grad_norm": 0.0016379052540287375,
      "learning_rate": 1.4573643410852714e-05,
      "loss": 0.0001,
      "step": 9140
    },
    {
      "epoch": 35.43023255813954,
      "grad_norm": 40.45695877075195,
      "learning_rate": 1.4569767441860465e-05,
      "loss": 0.0407,
      "step": 9141
    },
    {
      "epoch": 35.434108527131784,
      "grad_norm": 1.5047576427459717,
      "learning_rate": 1.4565891472868217e-05,
      "loss": 0.0427,
      "step": 9142
    },
    {
      "epoch": 35.43798449612403,
      "grad_norm": 0.0017904131673276424,
      "learning_rate": 1.456201550387597e-05,
      "loss": 0.0001,
      "step": 9143
    },
    {
      "epoch": 35.44186046511628,
      "grad_norm": 0.001270062173716724,
      "learning_rate": 1.4558139534883722e-05,
      "loss": 0.0001,
      "step": 9144
    },
    {
      "epoch": 35.445736434108525,
      "grad_norm": 0.0020587914623320103,
      "learning_rate": 1.4554263565891475e-05,
      "loss": 0.0001,
      "step": 9145
    },
    {
      "epoch": 35.44961240310077,
      "grad_norm": 0.0014083608984947205,
      "learning_rate": 1.4550387596899225e-05,
      "loss": 0.0001,
      "step": 9146
    },
    {
      "epoch": 35.45348837209303,
      "grad_norm": 0.0039457641541957855,
      "learning_rate": 1.4546511627906978e-05,
      "loss": 0.0002,
      "step": 9147
    },
    {
      "epoch": 35.457364341085274,
      "grad_norm": 0.004194950684905052,
      "learning_rate": 1.454263565891473e-05,
      "loss": 0.0002,
      "step": 9148
    },
    {
      "epoch": 35.46124031007752,
      "grad_norm": 0.0021899386774748564,
      "learning_rate": 1.4538759689922483e-05,
      "loss": 0.0002,
      "step": 9149
    },
    {
      "epoch": 35.46511627906977,
      "grad_norm": 0.0032814794685691595,
      "learning_rate": 1.4534883720930233e-05,
      "loss": 0.0002,
      "step": 9150
    },
    {
      "epoch": 35.468992248062015,
      "grad_norm": 1.1022107601165771,
      "learning_rate": 1.4531007751937986e-05,
      "loss": 0.105,
      "step": 9151
    },
    {
      "epoch": 35.47286821705426,
      "grad_norm": 0.0010353928664699197,
      "learning_rate": 1.4527131782945738e-05,
      "loss": 0.0001,
      "step": 9152
    },
    {
      "epoch": 35.47674418604651,
      "grad_norm": 0.0012910347431898117,
      "learning_rate": 1.452325581395349e-05,
      "loss": 0.0001,
      "step": 9153
    },
    {
      "epoch": 35.48062015503876,
      "grad_norm": 0.0041606794111430645,
      "learning_rate": 1.4519379844961243e-05,
      "loss": 0.0003,
      "step": 9154
    },
    {
      "epoch": 35.48449612403101,
      "grad_norm": 0.0012266718549653888,
      "learning_rate": 1.4515503875968994e-05,
      "loss": 0.0001,
      "step": 9155
    },
    {
      "epoch": 35.48837209302326,
      "grad_norm": 0.0024390178732573986,
      "learning_rate": 1.4511627906976743e-05,
      "loss": 0.0002,
      "step": 9156
    },
    {
      "epoch": 35.492248062015506,
      "grad_norm": 0.003245594911277294,
      "learning_rate": 1.4507751937984495e-05,
      "loss": 0.0003,
      "step": 9157
    },
    {
      "epoch": 35.49612403100775,
      "grad_norm": 0.0011159295681864023,
      "learning_rate": 1.4503875968992248e-05,
      "loss": 0.0001,
      "step": 9158
    },
    {
      "epoch": 35.5,
      "grad_norm": 0.0011155013926327229,
      "learning_rate": 1.45e-05,
      "loss": 0.0001,
      "step": 9159
    },
    {
      "epoch": 35.50387596899225,
      "grad_norm": 1.4339478015899658,
      "learning_rate": 1.4496124031007753e-05,
      "loss": 0.1476,
      "step": 9160
    },
    {
      "epoch": 35.507751937984494,
      "grad_norm": 0.641014575958252,
      "learning_rate": 1.4492248062015503e-05,
      "loss": 0.0016,
      "step": 9161
    },
    {
      "epoch": 35.51162790697674,
      "grad_norm": 0.0036376365460455418,
      "learning_rate": 1.4488372093023256e-05,
      "loss": 0.0002,
      "step": 9162
    },
    {
      "epoch": 35.51550387596899,
      "grad_norm": 1.6555812358856201,
      "learning_rate": 1.4484496124031008e-05,
      "loss": 0.0044,
      "step": 9163
    },
    {
      "epoch": 35.51937984496124,
      "grad_norm": 0.6651946306228638,
      "learning_rate": 1.448062015503876e-05,
      "loss": 0.0375,
      "step": 9164
    },
    {
      "epoch": 35.52325581395349,
      "grad_norm": 0.02691739983856678,
      "learning_rate": 1.4476744186046511e-05,
      "loss": 0.0003,
      "step": 9165
    },
    {
      "epoch": 35.52713178294574,
      "grad_norm": 0.005943009629845619,
      "learning_rate": 1.4472868217054264e-05,
      "loss": 0.0004,
      "step": 9166
    },
    {
      "epoch": 35.531007751937985,
      "grad_norm": 0.0014754022704437375,
      "learning_rate": 1.4468992248062016e-05,
      "loss": 0.0001,
      "step": 9167
    },
    {
      "epoch": 35.53488372093023,
      "grad_norm": 0.0011212348472326994,
      "learning_rate": 1.4465116279069768e-05,
      "loss": 0.0001,
      "step": 9168
    },
    {
      "epoch": 35.53875968992248,
      "grad_norm": 0.30352890491485596,
      "learning_rate": 1.4461240310077521e-05,
      "loss": 0.0125,
      "step": 9169
    },
    {
      "epoch": 35.542635658914726,
      "grad_norm": 0.0012018013512715697,
      "learning_rate": 1.4457364341085272e-05,
      "loss": 0.0001,
      "step": 9170
    },
    {
      "epoch": 35.54651162790697,
      "grad_norm": 0.001551604364067316,
      "learning_rate": 1.4453488372093024e-05,
      "loss": 0.0001,
      "step": 9171
    },
    {
      "epoch": 35.55038759689923,
      "grad_norm": 0.0016215188661590219,
      "learning_rate": 1.4449612403100776e-05,
      "loss": 0.0001,
      "step": 9172
    },
    {
      "epoch": 35.554263565891475,
      "grad_norm": 0.001972982892766595,
      "learning_rate": 1.4445736434108529e-05,
      "loss": 0.0002,
      "step": 9173
    },
    {
      "epoch": 35.55813953488372,
      "grad_norm": 0.0013129322323948145,
      "learning_rate": 1.444186046511628e-05,
      "loss": 0.0001,
      "step": 9174
    },
    {
      "epoch": 35.56201550387597,
      "grad_norm": 0.0019202415132895112,
      "learning_rate": 1.4437984496124032e-05,
      "loss": 0.0001,
      "step": 9175
    },
    {
      "epoch": 35.565891472868216,
      "grad_norm": 0.0018721036612987518,
      "learning_rate": 1.4434108527131784e-05,
      "loss": 0.0002,
      "step": 9176
    },
    {
      "epoch": 35.56976744186046,
      "grad_norm": 0.002016535960137844,
      "learning_rate": 1.4430232558139537e-05,
      "loss": 0.0002,
      "step": 9177
    },
    {
      "epoch": 35.57364341085271,
      "grad_norm": 0.3317761719226837,
      "learning_rate": 1.442635658914729e-05,
      "loss": 0.0144,
      "step": 9178
    },
    {
      "epoch": 35.57751937984496,
      "grad_norm": 68.8003158569336,
      "learning_rate": 1.442248062015504e-05,
      "loss": 0.0834,
      "step": 9179
    },
    {
      "epoch": 35.58139534883721,
      "grad_norm": 0.0027905022725462914,
      "learning_rate": 1.4418604651162792e-05,
      "loss": 0.0002,
      "step": 9180
    },
    {
      "epoch": 35.58527131782946,
      "grad_norm": 0.002642193576321006,
      "learning_rate": 1.4414728682170545e-05,
      "loss": 0.0002,
      "step": 9181
    },
    {
      "epoch": 35.58914728682171,
      "grad_norm": 0.0012309810845181346,
      "learning_rate": 1.4410852713178294e-05,
      "loss": 0.0001,
      "step": 9182
    },
    {
      "epoch": 35.593023255813954,
      "grad_norm": 0.0016740926075726748,
      "learning_rate": 1.4406976744186046e-05,
      "loss": 0.0002,
      "step": 9183
    },
    {
      "epoch": 35.5968992248062,
      "grad_norm": 0.0009421399445272982,
      "learning_rate": 1.4403100775193799e-05,
      "loss": 0.0001,
      "step": 9184
    },
    {
      "epoch": 35.60077519379845,
      "grad_norm": 0.08012252300977707,
      "learning_rate": 1.439922480620155e-05,
      "loss": 0.0006,
      "step": 9185
    },
    {
      "epoch": 35.604651162790695,
      "grad_norm": 0.0011596372351050377,
      "learning_rate": 1.4395348837209302e-05,
      "loss": 0.0001,
      "step": 9186
    },
    {
      "epoch": 35.60852713178294,
      "grad_norm": 0.009147156029939651,
      "learning_rate": 1.4391472868217054e-05,
      "loss": 0.0004,
      "step": 9187
    },
    {
      "epoch": 35.6124031007752,
      "grad_norm": 0.0012195148738101125,
      "learning_rate": 1.4387596899224807e-05,
      "loss": 0.0001,
      "step": 9188
    },
    {
      "epoch": 35.616279069767444,
      "grad_norm": 2.283177137374878,
      "learning_rate": 1.4383720930232557e-05,
      "loss": 0.2095,
      "step": 9189
    },
    {
      "epoch": 35.62015503875969,
      "grad_norm": 0.005320392083376646,
      "learning_rate": 1.437984496124031e-05,
      "loss": 0.0002,
      "step": 9190
    },
    {
      "epoch": 35.62403100775194,
      "grad_norm": 0.00123325374443084,
      "learning_rate": 1.4375968992248062e-05,
      "loss": 0.0001,
      "step": 9191
    },
    {
      "epoch": 35.627906976744185,
      "grad_norm": 0.002797683235257864,
      "learning_rate": 1.4372093023255815e-05,
      "loss": 0.0001,
      "step": 9192
    },
    {
      "epoch": 35.63178294573643,
      "grad_norm": 0.001162070082500577,
      "learning_rate": 1.4368217054263567e-05,
      "loss": 0.0001,
      "step": 9193
    },
    {
      "epoch": 35.63565891472868,
      "grad_norm": 0.0015649726847186685,
      "learning_rate": 1.4364341085271318e-05,
      "loss": 0.0001,
      "step": 9194
    },
    {
      "epoch": 35.63953488372093,
      "grad_norm": 0.0012174802832305431,
      "learning_rate": 1.436046511627907e-05,
      "loss": 0.0001,
      "step": 9195
    },
    {
      "epoch": 35.64341085271318,
      "grad_norm": 0.0032007002737373114,
      "learning_rate": 1.4356589147286823e-05,
      "loss": 0.0003,
      "step": 9196
    },
    {
      "epoch": 35.64728682170543,
      "grad_norm": 0.007231460884213448,
      "learning_rate": 1.4352713178294575e-05,
      "loss": 0.0004,
      "step": 9197
    },
    {
      "epoch": 35.651162790697676,
      "grad_norm": 2.9357082843780518,
      "learning_rate": 1.4348837209302326e-05,
      "loss": 0.1463,
      "step": 9198
    },
    {
      "epoch": 35.65503875968992,
      "grad_norm": 6.977505207061768,
      "learning_rate": 1.4344961240310078e-05,
      "loss": 1.0228,
      "step": 9199
    },
    {
      "epoch": 35.65891472868217,
      "grad_norm": 0.001260244520381093,
      "learning_rate": 1.434108527131783e-05,
      "loss": 0.0001,
      "step": 9200
    },
    {
      "epoch": 35.66279069767442,
      "grad_norm": 0.0017830501310527325,
      "learning_rate": 1.4337209302325583e-05,
      "loss": 0.0001,
      "step": 9201
    },
    {
      "epoch": 35.666666666666664,
      "grad_norm": 0.0012144747888669372,
      "learning_rate": 1.4333333333333334e-05,
      "loss": 0.0001,
      "step": 9202
    },
    {
      "epoch": 35.67054263565891,
      "grad_norm": 0.0011654867557808757,
      "learning_rate": 1.4329457364341086e-05,
      "loss": 0.0001,
      "step": 9203
    },
    {
      "epoch": 35.674418604651166,
      "grad_norm": 0.7858381867408752,
      "learning_rate": 1.4325581395348839e-05,
      "loss": 0.0446,
      "step": 9204
    },
    {
      "epoch": 35.67829457364341,
      "grad_norm": 0.0018449504859745502,
      "learning_rate": 1.4321705426356591e-05,
      "loss": 0.0002,
      "step": 9205
    },
    {
      "epoch": 35.68217054263566,
      "grad_norm": 0.00143107445910573,
      "learning_rate": 1.4317829457364344e-05,
      "loss": 0.0001,
      "step": 9206
    },
    {
      "epoch": 35.68604651162791,
      "grad_norm": 0.006560624577105045,
      "learning_rate": 1.4313953488372094e-05,
      "loss": 0.0003,
      "step": 9207
    },
    {
      "epoch": 35.689922480620154,
      "grad_norm": 0.0015043640742078424,
      "learning_rate": 1.4310077519379847e-05,
      "loss": 0.0001,
      "step": 9208
    },
    {
      "epoch": 35.6937984496124,
      "grad_norm": 0.0018849836196750402,
      "learning_rate": 1.4306201550387596e-05,
      "loss": 0.0001,
      "step": 9209
    },
    {
      "epoch": 35.69767441860465,
      "grad_norm": 0.0012669966090470552,
      "learning_rate": 1.4302325581395348e-05,
      "loss": 0.0001,
      "step": 9210
    },
    {
      "epoch": 35.701550387596896,
      "grad_norm": 0.0011601945152506232,
      "learning_rate": 1.42984496124031e-05,
      "loss": 0.0001,
      "step": 9211
    },
    {
      "epoch": 35.70542635658915,
      "grad_norm": 0.0013001140905544162,
      "learning_rate": 1.4294573643410853e-05,
      "loss": 0.0001,
      "step": 9212
    },
    {
      "epoch": 35.7093023255814,
      "grad_norm": 0.0010826695943251252,
      "learning_rate": 1.4290697674418604e-05,
      "loss": 0.0001,
      "step": 9213
    },
    {
      "epoch": 35.713178294573645,
      "grad_norm": 0.0011410887818783522,
      "learning_rate": 1.4286821705426356e-05,
      "loss": 0.0001,
      "step": 9214
    },
    {
      "epoch": 35.71705426356589,
      "grad_norm": 0.0018029866041615605,
      "learning_rate": 1.4282945736434109e-05,
      "loss": 0.0001,
      "step": 9215
    },
    {
      "epoch": 35.72093023255814,
      "grad_norm": 0.0014838712522760034,
      "learning_rate": 1.4279069767441861e-05,
      "loss": 0.0001,
      "step": 9216
    },
    {
      "epoch": 35.724806201550386,
      "grad_norm": 0.06775043904781342,
      "learning_rate": 1.4275193798449612e-05,
      "loss": 0.0013,
      "step": 9217
    },
    {
      "epoch": 35.72868217054263,
      "grad_norm": 0.1545768827199936,
      "learning_rate": 1.4271317829457364e-05,
      "loss": 0.0028,
      "step": 9218
    },
    {
      "epoch": 35.73255813953488,
      "grad_norm": 0.0010784330079331994,
      "learning_rate": 1.4267441860465117e-05,
      "loss": 0.0001,
      "step": 9219
    },
    {
      "epoch": 35.736434108527135,
      "grad_norm": 0.12144162505865097,
      "learning_rate": 1.4263565891472869e-05,
      "loss": 0.0021,
      "step": 9220
    },
    {
      "epoch": 35.74031007751938,
      "grad_norm": 0.001192313153296709,
      "learning_rate": 1.4259689922480621e-05,
      "loss": 0.0001,
      "step": 9221
    },
    {
      "epoch": 35.74418604651163,
      "grad_norm": 0.0025389925576746464,
      "learning_rate": 1.4255813953488372e-05,
      "loss": 0.0001,
      "step": 9222
    },
    {
      "epoch": 35.748062015503876,
      "grad_norm": 0.0014903964474797249,
      "learning_rate": 1.4251937984496125e-05,
      "loss": 0.0001,
      "step": 9223
    },
    {
      "epoch": 35.751937984496124,
      "grad_norm": 0.0010653488570824265,
      "learning_rate": 1.4248062015503877e-05,
      "loss": 0.0001,
      "step": 9224
    },
    {
      "epoch": 35.75581395348837,
      "grad_norm": 0.0016087047988548875,
      "learning_rate": 1.424418604651163e-05,
      "loss": 0.0001,
      "step": 9225
    },
    {
      "epoch": 35.75968992248062,
      "grad_norm": 0.0013605969725176692,
      "learning_rate": 1.424031007751938e-05,
      "loss": 0.0001,
      "step": 9226
    },
    {
      "epoch": 35.763565891472865,
      "grad_norm": 1.4739643335342407,
      "learning_rate": 1.4236434108527133e-05,
      "loss": 0.023,
      "step": 9227
    },
    {
      "epoch": 35.76744186046512,
      "grad_norm": 0.0016542997909709811,
      "learning_rate": 1.4232558139534885e-05,
      "loss": 0.0001,
      "step": 9228
    },
    {
      "epoch": 35.77131782945737,
      "grad_norm": 0.012337617576122284,
      "learning_rate": 1.4228682170542637e-05,
      "loss": 0.0002,
      "step": 9229
    },
    {
      "epoch": 35.775193798449614,
      "grad_norm": 0.0010329685173928738,
      "learning_rate": 1.422480620155039e-05,
      "loss": 0.0001,
      "step": 9230
    },
    {
      "epoch": 35.77906976744186,
      "grad_norm": 0.014949345029890537,
      "learning_rate": 1.422093023255814e-05,
      "loss": 0.0003,
      "step": 9231
    },
    {
      "epoch": 35.78294573643411,
      "grad_norm": 0.6409136652946472,
      "learning_rate": 1.4217054263565893e-05,
      "loss": 0.0279,
      "step": 9232
    },
    {
      "epoch": 35.786821705426355,
      "grad_norm": 0.0014035189524292946,
      "learning_rate": 1.4213178294573645e-05,
      "loss": 0.0001,
      "step": 9233
    },
    {
      "epoch": 35.7906976744186,
      "grad_norm": 0.005160959903150797,
      "learning_rate": 1.4209302325581398e-05,
      "loss": 0.0003,
      "step": 9234
    },
    {
      "epoch": 35.79457364341085,
      "grad_norm": 0.0011681256582960486,
      "learning_rate": 1.4205426356589149e-05,
      "loss": 0.0001,
      "step": 9235
    },
    {
      "epoch": 35.798449612403104,
      "grad_norm": 0.0010299611603841186,
      "learning_rate": 1.42015503875969e-05,
      "loss": 0.0001,
      "step": 9236
    },
    {
      "epoch": 35.80232558139535,
      "grad_norm": 0.004354923963546753,
      "learning_rate": 1.419767441860465e-05,
      "loss": 0.0002,
      "step": 9237
    },
    {
      "epoch": 35.8062015503876,
      "grad_norm": 0.0014808548148721457,
      "learning_rate": 1.4193798449612402e-05,
      "loss": 0.0001,
      "step": 9238
    },
    {
      "epoch": 35.810077519379846,
      "grad_norm": 4.516808032989502,
      "learning_rate": 1.4189922480620155e-05,
      "loss": 0.1223,
      "step": 9239
    },
    {
      "epoch": 35.81395348837209,
      "grad_norm": 0.0013027997920289636,
      "learning_rate": 1.4186046511627907e-05,
      "loss": 0.0001,
      "step": 9240
    },
    {
      "epoch": 35.81782945736434,
      "grad_norm": 0.0008873484912328422,
      "learning_rate": 1.4182170542635658e-05,
      "loss": 0.0001,
      "step": 9241
    },
    {
      "epoch": 35.82170542635659,
      "grad_norm": 0.0019769850187003613,
      "learning_rate": 1.417829457364341e-05,
      "loss": 0.0002,
      "step": 9242
    },
    {
      "epoch": 35.825581395348834,
      "grad_norm": 0.01734723336994648,
      "learning_rate": 1.4174418604651163e-05,
      "loss": 0.0005,
      "step": 9243
    },
    {
      "epoch": 35.82945736434109,
      "grad_norm": 0.06460969895124435,
      "learning_rate": 1.4170542635658915e-05,
      "loss": 0.0015,
      "step": 9244
    },
    {
      "epoch": 35.833333333333336,
      "grad_norm": 0.0020632825326174498,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 0.0002,
      "step": 9245
    },
    {
      "epoch": 35.83720930232558,
      "grad_norm": 0.0019790970254689455,
      "learning_rate": 1.4162790697674418e-05,
      "loss": 0.0001,
      "step": 9246
    },
    {
      "epoch": 35.84108527131783,
      "grad_norm": 7.879100322723389,
      "learning_rate": 1.415891472868217e-05,
      "loss": 0.0171,
      "step": 9247
    },
    {
      "epoch": 35.84496124031008,
      "grad_norm": 0.0009712587343528867,
      "learning_rate": 1.4155038759689923e-05,
      "loss": 0.0001,
      "step": 9248
    },
    {
      "epoch": 35.848837209302324,
      "grad_norm": 0.0014500857796519995,
      "learning_rate": 1.4151162790697676e-05,
      "loss": 0.0001,
      "step": 9249
    },
    {
      "epoch": 35.85271317829457,
      "grad_norm": 0.004523208364844322,
      "learning_rate": 1.4147286821705426e-05,
      "loss": 0.0003,
      "step": 9250
    },
    {
      "epoch": 35.85658914728682,
      "grad_norm": 0.0016031550476327538,
      "learning_rate": 1.4143410852713179e-05,
      "loss": 0.0001,
      "step": 9251
    },
    {
      "epoch": 35.86046511627907,
      "grad_norm": 0.0013523083180189133,
      "learning_rate": 1.4139534883720931e-05,
      "loss": 0.0001,
      "step": 9252
    },
    {
      "epoch": 35.86434108527132,
      "grad_norm": 0.0011680381139740348,
      "learning_rate": 1.4135658914728684e-05,
      "loss": 0.0001,
      "step": 9253
    },
    {
      "epoch": 35.86821705426357,
      "grad_norm": 0.0010719512356445193,
      "learning_rate": 1.4131782945736436e-05,
      "loss": 0.0001,
      "step": 9254
    },
    {
      "epoch": 35.872093023255815,
      "grad_norm": 0.001739691593684256,
      "learning_rate": 1.4127906976744187e-05,
      "loss": 0.0001,
      "step": 9255
    },
    {
      "epoch": 35.87596899224806,
      "grad_norm": 0.000979950767941773,
      "learning_rate": 1.412403100775194e-05,
      "loss": 0.0001,
      "step": 9256
    },
    {
      "epoch": 35.87984496124031,
      "grad_norm": 0.004380046855658293,
      "learning_rate": 1.4120155038759692e-05,
      "loss": 0.0003,
      "step": 9257
    },
    {
      "epoch": 35.883720930232556,
      "grad_norm": 0.021261602640151978,
      "learning_rate": 1.4116279069767444e-05,
      "loss": 0.0008,
      "step": 9258
    },
    {
      "epoch": 35.8875968992248,
      "grad_norm": 0.001064223237335682,
      "learning_rate": 1.4112403100775195e-05,
      "loss": 0.0001,
      "step": 9259
    },
    {
      "epoch": 35.89147286821706,
      "grad_norm": 0.0031017225701361895,
      "learning_rate": 1.4108527131782947e-05,
      "loss": 0.0002,
      "step": 9260
    },
    {
      "epoch": 35.895348837209305,
      "grad_norm": 0.009174501523375511,
      "learning_rate": 1.41046511627907e-05,
      "loss": 0.0003,
      "step": 9261
    },
    {
      "epoch": 35.89922480620155,
      "grad_norm": 0.0023546013981103897,
      "learning_rate": 1.4100775193798449e-05,
      "loss": 0.0001,
      "step": 9262
    },
    {
      "epoch": 35.9031007751938,
      "grad_norm": 0.0012078630970790982,
      "learning_rate": 1.4096899224806201e-05,
      "loss": 0.0001,
      "step": 9263
    },
    {
      "epoch": 35.906976744186046,
      "grad_norm": 1.8071784973144531,
      "learning_rate": 1.4093023255813954e-05,
      "loss": 0.1499,
      "step": 9264
    },
    {
      "epoch": 35.91085271317829,
      "grad_norm": 0.001600169576704502,
      "learning_rate": 1.4089147286821704e-05,
      "loss": 0.0002,
      "step": 9265
    },
    {
      "epoch": 35.91472868217054,
      "grad_norm": 0.004593793302774429,
      "learning_rate": 1.4085271317829457e-05,
      "loss": 0.0002,
      "step": 9266
    },
    {
      "epoch": 35.91860465116279,
      "grad_norm": 0.001350000617094338,
      "learning_rate": 1.4081395348837209e-05,
      "loss": 0.0001,
      "step": 9267
    },
    {
      "epoch": 35.92248062015504,
      "grad_norm": 0.0041433461010456085,
      "learning_rate": 1.4077519379844962e-05,
      "loss": 0.0003,
      "step": 9268
    },
    {
      "epoch": 35.92635658914729,
      "grad_norm": 0.0011845540720969439,
      "learning_rate": 1.4073643410852714e-05,
      "loss": 0.0001,
      "step": 9269
    },
    {
      "epoch": 35.93023255813954,
      "grad_norm": 0.007333444897085428,
      "learning_rate": 1.4069767441860465e-05,
      "loss": 0.0004,
      "step": 9270
    },
    {
      "epoch": 35.934108527131784,
      "grad_norm": 0.0011812836164608598,
      "learning_rate": 1.4065891472868217e-05,
      "loss": 0.0001,
      "step": 9271
    },
    {
      "epoch": 35.93798449612403,
      "grad_norm": 0.0013070476707071066,
      "learning_rate": 1.406201550387597e-05,
      "loss": 0.0001,
      "step": 9272
    },
    {
      "epoch": 35.94186046511628,
      "grad_norm": 0.046481262892484665,
      "learning_rate": 1.4058139534883722e-05,
      "loss": 0.0008,
      "step": 9273
    },
    {
      "epoch": 35.945736434108525,
      "grad_norm": 0.01142797153443098,
      "learning_rate": 1.4054263565891473e-05,
      "loss": 0.0004,
      "step": 9274
    },
    {
      "epoch": 35.94961240310077,
      "grad_norm": 0.525506317615509,
      "learning_rate": 1.4050387596899225e-05,
      "loss": 0.0229,
      "step": 9275
    },
    {
      "epoch": 35.95348837209303,
      "grad_norm": 0.003516225842759013,
      "learning_rate": 1.4046511627906978e-05,
      "loss": 0.0002,
      "step": 9276
    },
    {
      "epoch": 35.957364341085274,
      "grad_norm": 0.0011476940708234906,
      "learning_rate": 1.404263565891473e-05,
      "loss": 0.0001,
      "step": 9277
    },
    {
      "epoch": 35.96124031007752,
      "grad_norm": 0.00476432079449296,
      "learning_rate": 1.4038759689922482e-05,
      "loss": 0.0003,
      "step": 9278
    },
    {
      "epoch": 35.96511627906977,
      "grad_norm": 0.0011733820429071784,
      "learning_rate": 1.4034883720930233e-05,
      "loss": 0.0001,
      "step": 9279
    },
    {
      "epoch": 35.968992248062015,
      "grad_norm": 0.0013738343259319663,
      "learning_rate": 1.4031007751937985e-05,
      "loss": 0.0001,
      "step": 9280
    },
    {
      "epoch": 35.97286821705426,
      "grad_norm": 0.004491143859922886,
      "learning_rate": 1.4027131782945738e-05,
      "loss": 0.0002,
      "step": 9281
    },
    {
      "epoch": 35.97674418604651,
      "grad_norm": 0.001508253044448793,
      "learning_rate": 1.402325581395349e-05,
      "loss": 0.0001,
      "step": 9282
    },
    {
      "epoch": 35.98062015503876,
      "grad_norm": 0.38830792903900146,
      "learning_rate": 1.4019379844961241e-05,
      "loss": 0.0118,
      "step": 9283
    },
    {
      "epoch": 35.98449612403101,
      "grad_norm": 0.006361905951052904,
      "learning_rate": 1.4015503875968993e-05,
      "loss": 0.0003,
      "step": 9284
    },
    {
      "epoch": 35.98837209302326,
      "grad_norm": 0.008928311988711357,
      "learning_rate": 1.4011627906976746e-05,
      "loss": 0.0003,
      "step": 9285
    },
    {
      "epoch": 35.992248062015506,
      "grad_norm": 0.14847926795482635,
      "learning_rate": 1.4007751937984498e-05,
      "loss": 0.0027,
      "step": 9286
    },
    {
      "epoch": 35.99612403100775,
      "grad_norm": 0.0020655461121350527,
      "learning_rate": 1.400387596899225e-05,
      "loss": 0.0002,
      "step": 9287
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.0012196387397125363,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0001,
      "step": 9288
    },
    {
      "epoch": 36.00387596899225,
      "grad_norm": 0.0014634362887591124,
      "learning_rate": 1.399612403100775e-05,
      "loss": 0.0001,
      "step": 9289
    },
    {
      "epoch": 36.007751937984494,
      "grad_norm": 0.0013810284435749054,
      "learning_rate": 1.3992248062015503e-05,
      "loss": 0.0001,
      "step": 9290
    },
    {
      "epoch": 36.01162790697674,
      "grad_norm": 0.0010099854553118348,
      "learning_rate": 1.3988372093023255e-05,
      "loss": 0.0001,
      "step": 9291
    },
    {
      "epoch": 36.01550387596899,
      "grad_norm": 0.001118195941671729,
      "learning_rate": 1.3984496124031008e-05,
      "loss": 0.0001,
      "step": 9292
    },
    {
      "epoch": 36.01937984496124,
      "grad_norm": 37.38076400756836,
      "learning_rate": 1.398062015503876e-05,
      "loss": 1.0532,
      "step": 9293
    },
    {
      "epoch": 36.02325581395349,
      "grad_norm": 0.0025224664714187384,
      "learning_rate": 1.3976744186046511e-05,
      "loss": 0.0002,
      "step": 9294
    },
    {
      "epoch": 36.02713178294574,
      "grad_norm": 0.006800719071179628,
      "learning_rate": 1.3972868217054263e-05,
      "loss": 0.0003,
      "step": 9295
    },
    {
      "epoch": 36.031007751937985,
      "grad_norm": 0.0013736012624576688,
      "learning_rate": 1.3968992248062016e-05,
      "loss": 0.0001,
      "step": 9296
    },
    {
      "epoch": 36.03488372093023,
      "grad_norm": 0.021702054888010025,
      "learning_rate": 1.3965116279069768e-05,
      "loss": 0.0006,
      "step": 9297
    },
    {
      "epoch": 36.03875968992248,
      "grad_norm": 0.0011526232119649649,
      "learning_rate": 1.3961240310077519e-05,
      "loss": 0.0001,
      "step": 9298
    },
    {
      "epoch": 36.042635658914726,
      "grad_norm": 0.006263286340981722,
      "learning_rate": 1.3957364341085271e-05,
      "loss": 0.0004,
      "step": 9299
    },
    {
      "epoch": 36.04651162790697,
      "grad_norm": 0.0011631421511992812,
      "learning_rate": 1.3953488372093024e-05,
      "loss": 0.0001,
      "step": 9300
    },
    {
      "epoch": 36.05038759689923,
      "grad_norm": 0.002002612454816699,
      "learning_rate": 1.3949612403100776e-05,
      "loss": 0.0002,
      "step": 9301
    },
    {
      "epoch": 36.054263565891475,
      "grad_norm": 0.0020235427655279636,
      "learning_rate": 1.3945736434108529e-05,
      "loss": 0.0002,
      "step": 9302
    },
    {
      "epoch": 36.05813953488372,
      "grad_norm": 0.0011718535097315907,
      "learning_rate": 1.394186046511628e-05,
      "loss": 0.0001,
      "step": 9303
    },
    {
      "epoch": 36.06201550387597,
      "grad_norm": 0.0011420825030654669,
      "learning_rate": 1.3937984496124032e-05,
      "loss": 0.0001,
      "step": 9304
    },
    {
      "epoch": 36.065891472868216,
      "grad_norm": 0.007961498573422432,
      "learning_rate": 1.3934108527131784e-05,
      "loss": 0.0002,
      "step": 9305
    },
    {
      "epoch": 36.06976744186046,
      "grad_norm": 0.00131861655972898,
      "learning_rate": 1.3930232558139537e-05,
      "loss": 0.0001,
      "step": 9306
    },
    {
      "epoch": 36.07364341085271,
      "grad_norm": 0.0024263078812509775,
      "learning_rate": 1.3926356589147287e-05,
      "loss": 0.0002,
      "step": 9307
    },
    {
      "epoch": 36.07751937984496,
      "grad_norm": 0.004364680033177137,
      "learning_rate": 1.392248062015504e-05,
      "loss": 0.0003,
      "step": 9308
    },
    {
      "epoch": 36.08139534883721,
      "grad_norm": 0.0012621801579371095,
      "learning_rate": 1.3918604651162792e-05,
      "loss": 0.0001,
      "step": 9309
    },
    {
      "epoch": 36.08527131782946,
      "grad_norm": 0.01118289865553379,
      "learning_rate": 1.3914728682170545e-05,
      "loss": 0.0001,
      "step": 9310
    },
    {
      "epoch": 36.08914728682171,
      "grad_norm": 0.0011829434661194682,
      "learning_rate": 1.3910852713178297e-05,
      "loss": 0.0001,
      "step": 9311
    },
    {
      "epoch": 36.093023255813954,
      "grad_norm": 0.0013822801411151886,
      "learning_rate": 1.3906976744186048e-05,
      "loss": 0.0001,
      "step": 9312
    },
    {
      "epoch": 36.0968992248062,
      "grad_norm": 0.0048531838692724705,
      "learning_rate": 1.39031007751938e-05,
      "loss": 0.0002,
      "step": 9313
    },
    {
      "epoch": 36.10077519379845,
      "grad_norm": 0.00416263472288847,
      "learning_rate": 1.3899224806201553e-05,
      "loss": 0.0002,
      "step": 9314
    },
    {
      "epoch": 36.104651162790695,
      "grad_norm": 0.005545096937566996,
      "learning_rate": 1.3895348837209305e-05,
      "loss": 0.0003,
      "step": 9315
    },
    {
      "epoch": 36.10852713178294,
      "grad_norm": 0.0017225189367309213,
      "learning_rate": 1.3891472868217054e-05,
      "loss": 0.0001,
      "step": 9316
    },
    {
      "epoch": 36.1124031007752,
      "grad_norm": 0.0013397310394793749,
      "learning_rate": 1.3887596899224806e-05,
      "loss": 0.0001,
      "step": 9317
    },
    {
      "epoch": 36.116279069767444,
      "grad_norm": 0.0016073313308879733,
      "learning_rate": 1.3883720930232557e-05,
      "loss": 0.0001,
      "step": 9318
    },
    {
      "epoch": 36.12015503875969,
      "grad_norm": 2.1175732612609863,
      "learning_rate": 1.387984496124031e-05,
      "loss": 0.1075,
      "step": 9319
    },
    {
      "epoch": 36.12403100775194,
      "grad_norm": 0.0019014428835362196,
      "learning_rate": 1.3875968992248062e-05,
      "loss": 0.0002,
      "step": 9320
    },
    {
      "epoch": 36.127906976744185,
      "grad_norm": 0.001203517778776586,
      "learning_rate": 1.3872093023255814e-05,
      "loss": 0.0001,
      "step": 9321
    },
    {
      "epoch": 36.13178294573643,
      "grad_norm": 0.0019596389029175043,
      "learning_rate": 1.3868217054263565e-05,
      "loss": 0.0002,
      "step": 9322
    },
    {
      "epoch": 36.13565891472868,
      "grad_norm": 0.0014636163832619786,
      "learning_rate": 1.3864341085271318e-05,
      "loss": 0.0001,
      "step": 9323
    },
    {
      "epoch": 36.13953488372093,
      "grad_norm": 0.1953132003545761,
      "learning_rate": 1.386046511627907e-05,
      "loss": 0.0076,
      "step": 9324
    },
    {
      "epoch": 36.14341085271318,
      "grad_norm": 0.0012762853875756264,
      "learning_rate": 1.3856589147286822e-05,
      "loss": 0.0001,
      "step": 9325
    },
    {
      "epoch": 36.14728682170543,
      "grad_norm": 0.0014275585999712348,
      "learning_rate": 1.3852713178294575e-05,
      "loss": 0.0001,
      "step": 9326
    },
    {
      "epoch": 36.151162790697676,
      "grad_norm": 0.001912696985527873,
      "learning_rate": 1.3848837209302326e-05,
      "loss": 0.0002,
      "step": 9327
    },
    {
      "epoch": 36.15503875968992,
      "grad_norm": 0.008136425167322159,
      "learning_rate": 1.3844961240310078e-05,
      "loss": 0.0003,
      "step": 9328
    },
    {
      "epoch": 36.15891472868217,
      "grad_norm": 0.0019335482502356172,
      "learning_rate": 1.384108527131783e-05,
      "loss": 0.0001,
      "step": 9329
    },
    {
      "epoch": 36.16279069767442,
      "grad_norm": 0.0015466632321476936,
      "learning_rate": 1.3837209302325583e-05,
      "loss": 0.0001,
      "step": 9330
    },
    {
      "epoch": 36.166666666666664,
      "grad_norm": 0.0050168950110673904,
      "learning_rate": 1.3833333333333334e-05,
      "loss": 0.0003,
      "step": 9331
    },
    {
      "epoch": 36.17054263565891,
      "grad_norm": 0.0017553126672282815,
      "learning_rate": 1.3829457364341086e-05,
      "loss": 0.0001,
      "step": 9332
    },
    {
      "epoch": 36.174418604651166,
      "grad_norm": 15.259078025817871,
      "learning_rate": 1.3825581395348838e-05,
      "loss": 0.124,
      "step": 9333
    },
    {
      "epoch": 36.17829457364341,
      "grad_norm": 0.0033358719665557146,
      "learning_rate": 1.3821705426356591e-05,
      "loss": 0.0002,
      "step": 9334
    },
    {
      "epoch": 36.18217054263566,
      "grad_norm": 0.005921835545450449,
      "learning_rate": 1.3817829457364342e-05,
      "loss": 0.0003,
      "step": 9335
    },
    {
      "epoch": 36.18604651162791,
      "grad_norm": 0.0028422526083886623,
      "learning_rate": 1.3813953488372094e-05,
      "loss": 0.0002,
      "step": 9336
    },
    {
      "epoch": 36.189922480620154,
      "grad_norm": 0.0054032341577112675,
      "learning_rate": 1.3810077519379846e-05,
      "loss": 0.0003,
      "step": 9337
    },
    {
      "epoch": 36.1937984496124,
      "grad_norm": 0.0012040501460433006,
      "learning_rate": 1.3806201550387599e-05,
      "loss": 0.0001,
      "step": 9338
    },
    {
      "epoch": 36.19767441860465,
      "grad_norm": 0.9459656476974487,
      "learning_rate": 1.3802325581395351e-05,
      "loss": 0.0344,
      "step": 9339
    },
    {
      "epoch": 36.201550387596896,
      "grad_norm": 0.0029579889960587025,
      "learning_rate": 1.3798449612403102e-05,
      "loss": 0.0002,
      "step": 9340
    },
    {
      "epoch": 36.20542635658915,
      "grad_norm": 0.0011793564772233367,
      "learning_rate": 1.3794573643410854e-05,
      "loss": 0.0001,
      "step": 9341
    },
    {
      "epoch": 36.2093023255814,
      "grad_norm": 0.001377918291836977,
      "learning_rate": 1.3790697674418603e-05,
      "loss": 0.0001,
      "step": 9342
    },
    {
      "epoch": 36.213178294573645,
      "grad_norm": 0.0013596508651971817,
      "learning_rate": 1.3786821705426356e-05,
      "loss": 0.0001,
      "step": 9343
    },
    {
      "epoch": 36.21705426356589,
      "grad_norm": 2.9062108993530273,
      "learning_rate": 1.3782945736434108e-05,
      "loss": 0.0407,
      "step": 9344
    },
    {
      "epoch": 36.22093023255814,
      "grad_norm": 0.0015673988964408636,
      "learning_rate": 1.377906976744186e-05,
      "loss": 0.0001,
      "step": 9345
    },
    {
      "epoch": 36.224806201550386,
      "grad_norm": 0.0012336180079728365,
      "learning_rate": 1.3775193798449611e-05,
      "loss": 0.0001,
      "step": 9346
    },
    {
      "epoch": 36.22868217054263,
      "grad_norm": 0.0026962272822856903,
      "learning_rate": 1.3771317829457364e-05,
      "loss": 0.0002,
      "step": 9347
    },
    {
      "epoch": 36.23255813953488,
      "grad_norm": 0.002235682215541601,
      "learning_rate": 1.3767441860465116e-05,
      "loss": 0.0002,
      "step": 9348
    },
    {
      "epoch": 36.236434108527135,
      "grad_norm": 0.0009431723738089204,
      "learning_rate": 1.3763565891472869e-05,
      "loss": 0.0001,
      "step": 9349
    },
    {
      "epoch": 36.24031007751938,
      "grad_norm": 0.0023935630451887846,
      "learning_rate": 1.375968992248062e-05,
      "loss": 0.0002,
      "step": 9350
    },
    {
      "epoch": 36.24418604651163,
      "grad_norm": 0.0013938297051936388,
      "learning_rate": 1.3755813953488372e-05,
      "loss": 0.0001,
      "step": 9351
    },
    {
      "epoch": 36.248062015503876,
      "grad_norm": 0.001978195970878005,
      "learning_rate": 1.3751937984496124e-05,
      "loss": 0.0002,
      "step": 9352
    },
    {
      "epoch": 36.251937984496124,
      "grad_norm": 0.003019447438418865,
      "learning_rate": 1.3748062015503877e-05,
      "loss": 0.0002,
      "step": 9353
    },
    {
      "epoch": 36.25581395348837,
      "grad_norm": 0.0015371703775599599,
      "learning_rate": 1.3744186046511629e-05,
      "loss": 0.0002,
      "step": 9354
    },
    {
      "epoch": 36.25968992248062,
      "grad_norm": 0.001340118469670415,
      "learning_rate": 1.374031007751938e-05,
      "loss": 0.0001,
      "step": 9355
    },
    {
      "epoch": 36.263565891472865,
      "grad_norm": 0.0013055900344625115,
      "learning_rate": 1.3736434108527132e-05,
      "loss": 0.0001,
      "step": 9356
    },
    {
      "epoch": 36.26744186046512,
      "grad_norm": 0.0010683336295187473,
      "learning_rate": 1.3732558139534885e-05,
      "loss": 0.0001,
      "step": 9357
    },
    {
      "epoch": 36.27131782945737,
      "grad_norm": 2.229555368423462,
      "learning_rate": 1.3728682170542637e-05,
      "loss": 0.0741,
      "step": 9358
    },
    {
      "epoch": 36.275193798449614,
      "grad_norm": 0.0013417676091194153,
      "learning_rate": 1.3724806201550388e-05,
      "loss": 0.0001,
      "step": 9359
    },
    {
      "epoch": 36.27906976744186,
      "grad_norm": 0.0009044156759046018,
      "learning_rate": 1.372093023255814e-05,
      "loss": 0.0001,
      "step": 9360
    },
    {
      "epoch": 36.28294573643411,
      "grad_norm": 0.4933038055896759,
      "learning_rate": 1.3717054263565893e-05,
      "loss": 0.0199,
      "step": 9361
    },
    {
      "epoch": 36.286821705426355,
      "grad_norm": 0.004670396447181702,
      "learning_rate": 1.3713178294573645e-05,
      "loss": 0.0003,
      "step": 9362
    },
    {
      "epoch": 36.2906976744186,
      "grad_norm": 2.086561679840088,
      "learning_rate": 1.3709302325581398e-05,
      "loss": 0.1914,
      "step": 9363
    },
    {
      "epoch": 36.29457364341085,
      "grad_norm": 0.002758817281574011,
      "learning_rate": 1.3705426356589148e-05,
      "loss": 0.0002,
      "step": 9364
    },
    {
      "epoch": 36.298449612403104,
      "grad_norm": 0.0010317035485059023,
      "learning_rate": 1.37015503875969e-05,
      "loss": 0.0001,
      "step": 9365
    },
    {
      "epoch": 36.30232558139535,
      "grad_norm": 0.002964908955618739,
      "learning_rate": 1.3697674418604653e-05,
      "loss": 0.0001,
      "step": 9366
    },
    {
      "epoch": 36.3062015503876,
      "grad_norm": 0.19864968955516815,
      "learning_rate": 1.3693798449612406e-05,
      "loss": 0.0084,
      "step": 9367
    },
    {
      "epoch": 36.310077519379846,
      "grad_norm": 0.0029079653322696686,
      "learning_rate": 1.3689922480620156e-05,
      "loss": 0.0002,
      "step": 9368
    },
    {
      "epoch": 36.31395348837209,
      "grad_norm": 0.0015522298635914922,
      "learning_rate": 1.3686046511627907e-05,
      "loss": 0.0001,
      "step": 9369
    },
    {
      "epoch": 36.31782945736434,
      "grad_norm": 0.0011595761170610785,
      "learning_rate": 1.3682170542635658e-05,
      "loss": 0.0001,
      "step": 9370
    },
    {
      "epoch": 36.32170542635659,
      "grad_norm": 0.001358313369564712,
      "learning_rate": 1.367829457364341e-05,
      "loss": 0.0001,
      "step": 9371
    },
    {
      "epoch": 36.325581395348834,
      "grad_norm": 0.0015557148726657033,
      "learning_rate": 1.3674418604651163e-05,
      "loss": 0.0001,
      "step": 9372
    },
    {
      "epoch": 36.32945736434109,
      "grad_norm": 0.0011926254956051707,
      "learning_rate": 1.3670542635658915e-05,
      "loss": 0.0001,
      "step": 9373
    },
    {
      "epoch": 36.333333333333336,
      "grad_norm": 0.0014546792954206467,
      "learning_rate": 1.3666666666666666e-05,
      "loss": 0.0001,
      "step": 9374
    },
    {
      "epoch": 36.33720930232558,
      "grad_norm": 0.001967822667211294,
      "learning_rate": 1.3662790697674418e-05,
      "loss": 0.0002,
      "step": 9375
    },
    {
      "epoch": 36.34108527131783,
      "grad_norm": 2.5314323902130127,
      "learning_rate": 1.365891472868217e-05,
      "loss": 0.2273,
      "step": 9376
    },
    {
      "epoch": 36.34496124031008,
      "grad_norm": 0.003707390744239092,
      "learning_rate": 1.3655038759689923e-05,
      "loss": 0.0003,
      "step": 9377
    },
    {
      "epoch": 36.348837209302324,
      "grad_norm": 0.0049729738384485245,
      "learning_rate": 1.3651162790697675e-05,
      "loss": 0.0001,
      "step": 9378
    },
    {
      "epoch": 36.35271317829457,
      "grad_norm": 0.0011590808862820268,
      "learning_rate": 1.3647286821705426e-05,
      "loss": 0.0001,
      "step": 9379
    },
    {
      "epoch": 36.35658914728682,
      "grad_norm": 0.0010984085965901613,
      "learning_rate": 1.3643410852713179e-05,
      "loss": 0.0001,
      "step": 9380
    },
    {
      "epoch": 36.36046511627907,
      "grad_norm": 0.0019200114766135812,
      "learning_rate": 1.3639534883720931e-05,
      "loss": 0.0001,
      "step": 9381
    },
    {
      "epoch": 36.36434108527132,
      "grad_norm": 0.0025475432630628347,
      "learning_rate": 1.3635658914728683e-05,
      "loss": 0.0002,
      "step": 9382
    },
    {
      "epoch": 36.36821705426357,
      "grad_norm": 0.001551290974020958,
      "learning_rate": 1.3631782945736434e-05,
      "loss": 0.0001,
      "step": 9383
    },
    {
      "epoch": 36.372093023255815,
      "grad_norm": 0.0011495108483359218,
      "learning_rate": 1.3627906976744187e-05,
      "loss": 0.0001,
      "step": 9384
    },
    {
      "epoch": 36.37596899224806,
      "grad_norm": 0.0023096047807484865,
      "learning_rate": 1.3624031007751939e-05,
      "loss": 0.0002,
      "step": 9385
    },
    {
      "epoch": 36.37984496124031,
      "grad_norm": 0.003118219319730997,
      "learning_rate": 1.3620155038759691e-05,
      "loss": 0.0002,
      "step": 9386
    },
    {
      "epoch": 36.383720930232556,
      "grad_norm": 0.0021018278785049915,
      "learning_rate": 1.3616279069767444e-05,
      "loss": 0.0002,
      "step": 9387
    },
    {
      "epoch": 36.3875968992248,
      "grad_norm": 0.0021327990107238293,
      "learning_rate": 1.3612403100775195e-05,
      "loss": 0.0001,
      "step": 9388
    },
    {
      "epoch": 36.39147286821706,
      "grad_norm": 0.16556254029273987,
      "learning_rate": 1.3608527131782947e-05,
      "loss": 0.0004,
      "step": 9389
    },
    {
      "epoch": 36.395348837209305,
      "grad_norm": 0.003020096803084016,
      "learning_rate": 1.36046511627907e-05,
      "loss": 0.0002,
      "step": 9390
    },
    {
      "epoch": 36.39922480620155,
      "grad_norm": 0.0020756640005856752,
      "learning_rate": 1.3600775193798452e-05,
      "loss": 0.0001,
      "step": 9391
    },
    {
      "epoch": 36.4031007751938,
      "grad_norm": 0.003464706474915147,
      "learning_rate": 1.3596899224806203e-05,
      "loss": 0.0003,
      "step": 9392
    },
    {
      "epoch": 36.406976744186046,
      "grad_norm": 0.0014205242041498423,
      "learning_rate": 1.3593023255813955e-05,
      "loss": 0.0001,
      "step": 9393
    },
    {
      "epoch": 36.41085271317829,
      "grad_norm": 0.001014184788800776,
      "learning_rate": 1.3589147286821707e-05,
      "loss": 0.0001,
      "step": 9394
    },
    {
      "epoch": 36.41472868217054,
      "grad_norm": 0.003194490447640419,
      "learning_rate": 1.358527131782946e-05,
      "loss": 0.0002,
      "step": 9395
    },
    {
      "epoch": 36.41860465116279,
      "grad_norm": 0.0013076418545097113,
      "learning_rate": 1.3581395348837209e-05,
      "loss": 0.0001,
      "step": 9396
    },
    {
      "epoch": 36.42248062015504,
      "grad_norm": 0.006439555902034044,
      "learning_rate": 1.3577519379844961e-05,
      "loss": 0.0003,
      "step": 9397
    },
    {
      "epoch": 36.42635658914729,
      "grad_norm": 0.001149062067270279,
      "learning_rate": 1.3573643410852712e-05,
      "loss": 0.0001,
      "step": 9398
    },
    {
      "epoch": 36.43023255813954,
      "grad_norm": 0.0014636346604675055,
      "learning_rate": 1.3569767441860464e-05,
      "loss": 0.0001,
      "step": 9399
    },
    {
      "epoch": 36.434108527131784,
      "grad_norm": 0.0013320952421054244,
      "learning_rate": 1.3565891472868217e-05,
      "loss": 0.0001,
      "step": 9400
    },
    {
      "epoch": 36.43798449612403,
      "grad_norm": 0.0013036869931966066,
      "learning_rate": 1.356201550387597e-05,
      "loss": 0.0001,
      "step": 9401
    },
    {
      "epoch": 36.44186046511628,
      "grad_norm": 0.001763586071319878,
      "learning_rate": 1.3558139534883722e-05,
      "loss": 0.0001,
      "step": 9402
    },
    {
      "epoch": 36.445736434108525,
      "grad_norm": 0.0014889560407027602,
      "learning_rate": 1.3554263565891472e-05,
      "loss": 0.0001,
      "step": 9403
    },
    {
      "epoch": 36.44961240310077,
      "grad_norm": 3.23146390914917,
      "learning_rate": 1.3550387596899225e-05,
      "loss": 0.3364,
      "step": 9404
    },
    {
      "epoch": 36.45348837209303,
      "grad_norm": 0.00397903798148036,
      "learning_rate": 1.3546511627906977e-05,
      "loss": 0.0002,
      "step": 9405
    },
    {
      "epoch": 36.457364341085274,
      "grad_norm": 0.0013732489896938205,
      "learning_rate": 1.354263565891473e-05,
      "loss": 0.0001,
      "step": 9406
    },
    {
      "epoch": 36.46124031007752,
      "grad_norm": 0.0011297408491373062,
      "learning_rate": 1.353875968992248e-05,
      "loss": 0.0001,
      "step": 9407
    },
    {
      "epoch": 36.46511627906977,
      "grad_norm": 0.0009649661369621754,
      "learning_rate": 1.3534883720930233e-05,
      "loss": 0.0001,
      "step": 9408
    },
    {
      "epoch": 36.468992248062015,
      "grad_norm": 0.0016964932437986135,
      "learning_rate": 1.3531007751937985e-05,
      "loss": 0.0001,
      "step": 9409
    },
    {
      "epoch": 36.47286821705426,
      "grad_norm": 0.0046988604590296745,
      "learning_rate": 1.3527131782945738e-05,
      "loss": 0.0003,
      "step": 9410
    },
    {
      "epoch": 36.47674418604651,
      "grad_norm": 0.0028243092820048332,
      "learning_rate": 1.352325581395349e-05,
      "loss": 0.0002,
      "step": 9411
    },
    {
      "epoch": 36.48062015503876,
      "grad_norm": 0.007766743190586567,
      "learning_rate": 1.351937984496124e-05,
      "loss": 0.0002,
      "step": 9412
    },
    {
      "epoch": 36.48449612403101,
      "grad_norm": 0.0013485902454704046,
      "learning_rate": 1.3515503875968993e-05,
      "loss": 0.0001,
      "step": 9413
    },
    {
      "epoch": 36.48837209302326,
      "grad_norm": 0.0014469354646280408,
      "learning_rate": 1.3511627906976746e-05,
      "loss": 0.0001,
      "step": 9414
    },
    {
      "epoch": 36.492248062015506,
      "grad_norm": 0.012862720526754856,
      "learning_rate": 1.3507751937984498e-05,
      "loss": 0.0003,
      "step": 9415
    },
    {
      "epoch": 36.49612403100775,
      "grad_norm": 0.0019687432795763016,
      "learning_rate": 1.3503875968992249e-05,
      "loss": 0.0001,
      "step": 9416
    },
    {
      "epoch": 36.5,
      "grad_norm": 0.0011373038869351149,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0001,
      "step": 9417
    },
    {
      "epoch": 36.50387596899225,
      "grad_norm": 0.00105157564394176,
      "learning_rate": 1.3496124031007754e-05,
      "loss": 0.0001,
      "step": 9418
    },
    {
      "epoch": 36.507751937984494,
      "grad_norm": 0.0011214850237593055,
      "learning_rate": 1.3492248062015506e-05,
      "loss": 0.0001,
      "step": 9419
    },
    {
      "epoch": 36.51162790697674,
      "grad_norm": 0.0014777356991544366,
      "learning_rate": 1.3488372093023258e-05,
      "loss": 0.0001,
      "step": 9420
    },
    {
      "epoch": 36.51550387596899,
      "grad_norm": 0.0010042343055829406,
      "learning_rate": 1.348449612403101e-05,
      "loss": 0.0001,
      "step": 9421
    },
    {
      "epoch": 36.51937984496124,
      "grad_norm": 0.0014280433533713222,
      "learning_rate": 1.3480620155038758e-05,
      "loss": 0.0001,
      "step": 9422
    },
    {
      "epoch": 36.52325581395349,
      "grad_norm": 0.0016308918129652739,
      "learning_rate": 1.347674418604651e-05,
      "loss": 0.0002,
      "step": 9423
    },
    {
      "epoch": 36.52713178294574,
      "grad_norm": 0.0027757117059081793,
      "learning_rate": 1.3472868217054263e-05,
      "loss": 0.0002,
      "step": 9424
    },
    {
      "epoch": 36.531007751937985,
      "grad_norm": 0.0012605010997503996,
      "learning_rate": 1.3468992248062015e-05,
      "loss": 0.0001,
      "step": 9425
    },
    {
      "epoch": 36.53488372093023,
      "grad_norm": 0.0015908513450995088,
      "learning_rate": 1.3465116279069768e-05,
      "loss": 0.0001,
      "step": 9426
    },
    {
      "epoch": 36.53875968992248,
      "grad_norm": 0.0009712431929074228,
      "learning_rate": 1.3461240310077519e-05,
      "loss": 0.0001,
      "step": 9427
    },
    {
      "epoch": 36.542635658914726,
      "grad_norm": 0.002441602759063244,
      "learning_rate": 1.3457364341085271e-05,
      "loss": 0.0002,
      "step": 9428
    },
    {
      "epoch": 36.54651162790697,
      "grad_norm": 0.0015020633582025766,
      "learning_rate": 1.3453488372093023e-05,
      "loss": 0.0001,
      "step": 9429
    },
    {
      "epoch": 36.55038759689923,
      "grad_norm": 0.0012773026246577501,
      "learning_rate": 1.3449612403100776e-05,
      "loss": 0.0001,
      "step": 9430
    },
    {
      "epoch": 36.554263565891475,
      "grad_norm": 0.003708931151777506,
      "learning_rate": 1.3445736434108527e-05,
      "loss": 0.0003,
      "step": 9431
    },
    {
      "epoch": 36.55813953488372,
      "grad_norm": 0.0011663003824651241,
      "learning_rate": 1.3441860465116279e-05,
      "loss": 0.0001,
      "step": 9432
    },
    {
      "epoch": 36.56201550387597,
      "grad_norm": 0.5643777251243591,
      "learning_rate": 1.3437984496124031e-05,
      "loss": 0.0232,
      "step": 9433
    },
    {
      "epoch": 36.565891472868216,
      "grad_norm": 0.0013797266874462366,
      "learning_rate": 1.3434108527131784e-05,
      "loss": 0.0001,
      "step": 9434
    },
    {
      "epoch": 36.56976744186046,
      "grad_norm": 0.0011832049349322915,
      "learning_rate": 1.3430232558139536e-05,
      "loss": 0.0001,
      "step": 9435
    },
    {
      "epoch": 36.57364341085271,
      "grad_norm": 0.004442530684173107,
      "learning_rate": 1.3426356589147287e-05,
      "loss": 0.0003,
      "step": 9436
    },
    {
      "epoch": 36.57751937984496,
      "grad_norm": 0.0009814861696213484,
      "learning_rate": 1.342248062015504e-05,
      "loss": 0.0001,
      "step": 9437
    },
    {
      "epoch": 36.58139534883721,
      "grad_norm": 0.0010635750368237495,
      "learning_rate": 1.3418604651162792e-05,
      "loss": 0.0001,
      "step": 9438
    },
    {
      "epoch": 36.58527131782946,
      "grad_norm": 0.0009228949784301221,
      "learning_rate": 1.3414728682170544e-05,
      "loss": 0.0001,
      "step": 9439
    },
    {
      "epoch": 36.58914728682171,
      "grad_norm": 0.0010056179016828537,
      "learning_rate": 1.3410852713178295e-05,
      "loss": 0.0001,
      "step": 9440
    },
    {
      "epoch": 36.593023255813954,
      "grad_norm": 0.001107755582779646,
      "learning_rate": 1.3406976744186047e-05,
      "loss": 0.0001,
      "step": 9441
    },
    {
      "epoch": 36.5968992248062,
      "grad_norm": 0.0023193894885480404,
      "learning_rate": 1.34031007751938e-05,
      "loss": 0.0002,
      "step": 9442
    },
    {
      "epoch": 36.60077519379845,
      "grad_norm": 0.0010699564591050148,
      "learning_rate": 1.3399224806201552e-05,
      "loss": 0.0001,
      "step": 9443
    },
    {
      "epoch": 36.604651162790695,
      "grad_norm": 1.7759952545166016,
      "learning_rate": 1.3395348837209305e-05,
      "loss": 0.1247,
      "step": 9444
    },
    {
      "epoch": 36.60852713178294,
      "grad_norm": 0.0024240720085799694,
      "learning_rate": 1.3391472868217055e-05,
      "loss": 0.0002,
      "step": 9445
    },
    {
      "epoch": 36.6124031007752,
      "grad_norm": 0.0030541999731212854,
      "learning_rate": 1.3387596899224808e-05,
      "loss": 0.0002,
      "step": 9446
    },
    {
      "epoch": 36.616279069767444,
      "grad_norm": 0.001013088971376419,
      "learning_rate": 1.338372093023256e-05,
      "loss": 0.0001,
      "step": 9447
    },
    {
      "epoch": 36.62015503875969,
      "grad_norm": 0.0019437117734923959,
      "learning_rate": 1.3379844961240313e-05,
      "loss": 0.0001,
      "step": 9448
    },
    {
      "epoch": 36.62403100775194,
      "grad_norm": 0.0013275851961225271,
      "learning_rate": 1.3375968992248062e-05,
      "loss": 0.0001,
      "step": 9449
    },
    {
      "epoch": 36.627906976744185,
      "grad_norm": 0.002619360340759158,
      "learning_rate": 1.3372093023255814e-05,
      "loss": 0.0001,
      "step": 9450
    },
    {
      "epoch": 36.63178294573643,
      "grad_norm": 0.005205855704843998,
      "learning_rate": 1.3368217054263565e-05,
      "loss": 0.0003,
      "step": 9451
    },
    {
      "epoch": 36.63565891472868,
      "grad_norm": 0.001197508187033236,
      "learning_rate": 1.3364341085271317e-05,
      "loss": 0.0001,
      "step": 9452
    },
    {
      "epoch": 36.63953488372093,
      "grad_norm": 5.638569355010986,
      "learning_rate": 1.336046511627907e-05,
      "loss": 0.0016,
      "step": 9453
    },
    {
      "epoch": 36.64341085271318,
      "grad_norm": 0.00344716664403677,
      "learning_rate": 1.3356589147286822e-05,
      "loss": 0.0002,
      "step": 9454
    },
    {
      "epoch": 36.64728682170543,
      "grad_norm": 0.0015802563866600394,
      "learning_rate": 1.3352713178294573e-05,
      "loss": 0.0001,
      "step": 9455
    },
    {
      "epoch": 36.651162790697676,
      "grad_norm": 0.0013924639206379652,
      "learning_rate": 1.3348837209302325e-05,
      "loss": 0.0001,
      "step": 9456
    },
    {
      "epoch": 36.65503875968992,
      "grad_norm": 0.0023082399275153875,
      "learning_rate": 1.3344961240310078e-05,
      "loss": 0.0002,
      "step": 9457
    },
    {
      "epoch": 36.65891472868217,
      "grad_norm": 0.0013758607674390078,
      "learning_rate": 1.334108527131783e-05,
      "loss": 0.0001,
      "step": 9458
    },
    {
      "epoch": 36.66279069767442,
      "grad_norm": 0.0010599825764074922,
      "learning_rate": 1.3337209302325583e-05,
      "loss": 0.0001,
      "step": 9459
    },
    {
      "epoch": 36.666666666666664,
      "grad_norm": 0.003708508564159274,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0003,
      "step": 9460
    },
    {
      "epoch": 36.67054263565891,
      "grad_norm": 0.001097284723073244,
      "learning_rate": 1.3329457364341086e-05,
      "loss": 0.0001,
      "step": 9461
    },
    {
      "epoch": 36.674418604651166,
      "grad_norm": 0.7488059997558594,
      "learning_rate": 1.3325581395348838e-05,
      "loss": 0.0363,
      "step": 9462
    },
    {
      "epoch": 36.67829457364341,
      "grad_norm": 0.2800345718860626,
      "learning_rate": 1.332170542635659e-05,
      "loss": 0.0113,
      "step": 9463
    },
    {
      "epoch": 36.68217054263566,
      "grad_norm": 0.0012066081399098039,
      "learning_rate": 1.3317829457364341e-05,
      "loss": 0.0001,
      "step": 9464
    },
    {
      "epoch": 36.68604651162791,
      "grad_norm": 0.676357626914978,
      "learning_rate": 1.3313953488372094e-05,
      "loss": 0.0112,
      "step": 9465
    },
    {
      "epoch": 36.689922480620154,
      "grad_norm": 0.0035425841342657804,
      "learning_rate": 1.3310077519379846e-05,
      "loss": 0.0003,
      "step": 9466
    },
    {
      "epoch": 36.6937984496124,
      "grad_norm": 0.001147039933130145,
      "learning_rate": 1.3306201550387599e-05,
      "loss": 0.0001,
      "step": 9467
    },
    {
      "epoch": 36.69767441860465,
      "grad_norm": 0.0012837431859225035,
      "learning_rate": 1.330232558139535e-05,
      "loss": 0.0001,
      "step": 9468
    },
    {
      "epoch": 36.701550387596896,
      "grad_norm": 0.0014583911979570985,
      "learning_rate": 1.3298449612403102e-05,
      "loss": 0.0001,
      "step": 9469
    },
    {
      "epoch": 36.70542635658915,
      "grad_norm": 0.007236381061375141,
      "learning_rate": 1.3294573643410854e-05,
      "loss": 0.0002,
      "step": 9470
    },
    {
      "epoch": 36.7093023255814,
      "grad_norm": 0.0026035320479422808,
      "learning_rate": 1.3290697674418607e-05,
      "loss": 0.0002,
      "step": 9471
    },
    {
      "epoch": 36.713178294573645,
      "grad_norm": 0.001029424136504531,
      "learning_rate": 1.3286821705426359e-05,
      "loss": 0.0001,
      "step": 9472
    },
    {
      "epoch": 36.71705426356589,
      "grad_norm": 0.0010687621543183923,
      "learning_rate": 1.328294573643411e-05,
      "loss": 0.0001,
      "step": 9473
    },
    {
      "epoch": 36.72093023255814,
      "grad_norm": 0.0017338169272989035,
      "learning_rate": 1.3279069767441862e-05,
      "loss": 0.0002,
      "step": 9474
    },
    {
      "epoch": 36.724806201550386,
      "grad_norm": 0.006691033951938152,
      "learning_rate": 1.3275193798449615e-05,
      "loss": 0.0003,
      "step": 9475
    },
    {
      "epoch": 36.72868217054263,
      "grad_norm": 0.003941010683774948,
      "learning_rate": 1.3271317829457364e-05,
      "loss": 0.0003,
      "step": 9476
    },
    {
      "epoch": 36.73255813953488,
      "grad_norm": 0.0009034196264110506,
      "learning_rate": 1.3267441860465116e-05,
      "loss": 0.0001,
      "step": 9477
    },
    {
      "epoch": 36.736434108527135,
      "grad_norm": 0.0015030590584501624,
      "learning_rate": 1.3263565891472868e-05,
      "loss": 0.0001,
      "step": 9478
    },
    {
      "epoch": 36.74031007751938,
      "grad_norm": 0.006356119178235531,
      "learning_rate": 1.3259689922480619e-05,
      "loss": 0.0003,
      "step": 9479
    },
    {
      "epoch": 36.74418604651163,
      "grad_norm": 0.0012248004786670208,
      "learning_rate": 1.3255813953488372e-05,
      "loss": 0.0001,
      "step": 9480
    },
    {
      "epoch": 36.748062015503876,
      "grad_norm": 0.0033957399427890778,
      "learning_rate": 1.3251937984496124e-05,
      "loss": 0.0002,
      "step": 9481
    },
    {
      "epoch": 36.751937984496124,
      "grad_norm": 0.0015756001230329275,
      "learning_rate": 1.3248062015503876e-05,
      "loss": 0.0001,
      "step": 9482
    },
    {
      "epoch": 36.75581395348837,
      "grad_norm": 0.0014039149973541498,
      "learning_rate": 1.3244186046511627e-05,
      "loss": 0.0001,
      "step": 9483
    },
    {
      "epoch": 36.75968992248062,
      "grad_norm": 0.0010348947253078222,
      "learning_rate": 1.324031007751938e-05,
      "loss": 0.0001,
      "step": 9484
    },
    {
      "epoch": 36.763565891472865,
      "grad_norm": 0.0010725152678787708,
      "learning_rate": 1.3236434108527132e-05,
      "loss": 0.0001,
      "step": 9485
    },
    {
      "epoch": 36.76744186046512,
      "grad_norm": 0.02365371771156788,
      "learning_rate": 1.3232558139534884e-05,
      "loss": 0.0004,
      "step": 9486
    },
    {
      "epoch": 36.77131782945737,
      "grad_norm": 0.04626496508717537,
      "learning_rate": 1.3228682170542637e-05,
      "loss": 0.0009,
      "step": 9487
    },
    {
      "epoch": 36.775193798449614,
      "grad_norm": 0.0010394937125965953,
      "learning_rate": 1.3224806201550388e-05,
      "loss": 0.0001,
      "step": 9488
    },
    {
      "epoch": 36.77906976744186,
      "grad_norm": 0.0012117389123886824,
      "learning_rate": 1.322093023255814e-05,
      "loss": 0.0001,
      "step": 9489
    },
    {
      "epoch": 36.78294573643411,
      "grad_norm": 0.0011831428855657578,
      "learning_rate": 1.3217054263565892e-05,
      "loss": 0.0001,
      "step": 9490
    },
    {
      "epoch": 36.786821705426355,
      "grad_norm": 0.0013911707792431116,
      "learning_rate": 1.3213178294573645e-05,
      "loss": 0.0001,
      "step": 9491
    },
    {
      "epoch": 36.7906976744186,
      "grad_norm": 0.0011962349526584148,
      "learning_rate": 1.3209302325581396e-05,
      "loss": 0.0001,
      "step": 9492
    },
    {
      "epoch": 36.79457364341085,
      "grad_norm": 0.001181089668534696,
      "learning_rate": 1.3205426356589148e-05,
      "loss": 0.0001,
      "step": 9493
    },
    {
      "epoch": 36.798449612403104,
      "grad_norm": 0.0011977291433140635,
      "learning_rate": 1.32015503875969e-05,
      "loss": 0.0001,
      "step": 9494
    },
    {
      "epoch": 36.80232558139535,
      "grad_norm": 0.0009150200639851391,
      "learning_rate": 1.3197674418604653e-05,
      "loss": 0.0001,
      "step": 9495
    },
    {
      "epoch": 36.8062015503876,
      "grad_norm": 2.715745210647583,
      "learning_rate": 1.3193798449612405e-05,
      "loss": 0.0779,
      "step": 9496
    },
    {
      "epoch": 36.810077519379846,
      "grad_norm": 0.0012321153189986944,
      "learning_rate": 1.3189922480620156e-05,
      "loss": 0.0001,
      "step": 9497
    },
    {
      "epoch": 36.81395348837209,
      "grad_norm": 0.0019040327752009034,
      "learning_rate": 1.3186046511627908e-05,
      "loss": 0.0002,
      "step": 9498
    },
    {
      "epoch": 36.81782945736434,
      "grad_norm": 0.0015877021942287683,
      "learning_rate": 1.318217054263566e-05,
      "loss": 0.0001,
      "step": 9499
    },
    {
      "epoch": 36.82170542635659,
      "grad_norm": 0.0009498412255197763,
      "learning_rate": 1.3178294573643413e-05,
      "loss": 0.0001,
      "step": 9500
    },
    {
      "epoch": 36.825581395348834,
      "grad_norm": 0.003050807397812605,
      "learning_rate": 1.3174418604651164e-05,
      "loss": 0.0002,
      "step": 9501
    },
    {
      "epoch": 36.82945736434109,
      "grad_norm": 0.0008613885147497058,
      "learning_rate": 1.3170542635658915e-05,
      "loss": 0.0001,
      "step": 9502
    },
    {
      "epoch": 36.833333333333336,
      "grad_norm": 0.0008777961484156549,
      "learning_rate": 1.3166666666666665e-05,
      "loss": 0.0001,
      "step": 9503
    },
    {
      "epoch": 36.83720930232558,
      "grad_norm": 0.000938969780690968,
      "learning_rate": 1.3162790697674418e-05,
      "loss": 0.0001,
      "step": 9504
    },
    {
      "epoch": 36.84108527131783,
      "grad_norm": 0.0008997570839710534,
      "learning_rate": 1.315891472868217e-05,
      "loss": 0.0001,
      "step": 9505
    },
    {
      "epoch": 36.84496124031008,
      "grad_norm": 0.0010036800522357225,
      "learning_rate": 1.3155038759689923e-05,
      "loss": 0.0001,
      "step": 9506
    },
    {
      "epoch": 36.848837209302324,
      "grad_norm": 0.003956243395805359,
      "learning_rate": 1.3151162790697673e-05,
      "loss": 0.0002,
      "step": 9507
    },
    {
      "epoch": 36.85271317829457,
      "grad_norm": 0.004033198580145836,
      "learning_rate": 1.3147286821705426e-05,
      "loss": 0.0002,
      "step": 9508
    },
    {
      "epoch": 36.85658914728682,
      "grad_norm": 0.0016767170745879412,
      "learning_rate": 1.3143410852713178e-05,
      "loss": 0.0001,
      "step": 9509
    },
    {
      "epoch": 36.86046511627907,
      "grad_norm": 0.002489914419129491,
      "learning_rate": 1.313953488372093e-05,
      "loss": 0.0002,
      "step": 9510
    },
    {
      "epoch": 36.86434108527132,
      "grad_norm": 0.0015175967710092664,
      "learning_rate": 1.3135658914728683e-05,
      "loss": 0.0001,
      "step": 9511
    },
    {
      "epoch": 36.86821705426357,
      "grad_norm": 0.0009074016707018018,
      "learning_rate": 1.3131782945736434e-05,
      "loss": 0.0001,
      "step": 9512
    },
    {
      "epoch": 36.872093023255815,
      "grad_norm": 0.001236485200934112,
      "learning_rate": 1.3127906976744186e-05,
      "loss": 0.0001,
      "step": 9513
    },
    {
      "epoch": 36.87596899224806,
      "grad_norm": 0.0027328338474035263,
      "learning_rate": 1.3124031007751939e-05,
      "loss": 0.0002,
      "step": 9514
    },
    {
      "epoch": 36.87984496124031,
      "grad_norm": 0.0009179604239761829,
      "learning_rate": 1.3120155038759691e-05,
      "loss": 0.0001,
      "step": 9515
    },
    {
      "epoch": 36.883720930232556,
      "grad_norm": 0.0008097441750578582,
      "learning_rate": 1.3116279069767442e-05,
      "loss": 0.0001,
      "step": 9516
    },
    {
      "epoch": 36.8875968992248,
      "grad_norm": 0.002554138656705618,
      "learning_rate": 1.3112403100775194e-05,
      "loss": 0.0002,
      "step": 9517
    },
    {
      "epoch": 36.89147286821706,
      "grad_norm": 1.2477333545684814,
      "learning_rate": 1.3108527131782947e-05,
      "loss": 0.0753,
      "step": 9518
    },
    {
      "epoch": 36.895348837209305,
      "grad_norm": 0.0010672734351828694,
      "learning_rate": 1.3104651162790699e-05,
      "loss": 0.0001,
      "step": 9519
    },
    {
      "epoch": 36.89922480620155,
      "grad_norm": 0.0016283189179375768,
      "learning_rate": 1.3100775193798451e-05,
      "loss": 0.0002,
      "step": 9520
    },
    {
      "epoch": 36.9031007751938,
      "grad_norm": 0.0010164502309635282,
      "learning_rate": 1.3096899224806202e-05,
      "loss": 0.0001,
      "step": 9521
    },
    {
      "epoch": 36.906976744186046,
      "grad_norm": 0.33279499411582947,
      "learning_rate": 1.3093023255813955e-05,
      "loss": 0.0134,
      "step": 9522
    },
    {
      "epoch": 36.91085271317829,
      "grad_norm": 0.009779956191778183,
      "learning_rate": 1.3089147286821707e-05,
      "loss": 0.0002,
      "step": 9523
    },
    {
      "epoch": 36.91472868217054,
      "grad_norm": 0.0011376551119610667,
      "learning_rate": 1.308527131782946e-05,
      "loss": 0.0001,
      "step": 9524
    },
    {
      "epoch": 36.91860465116279,
      "grad_norm": 0.0009503476321697235,
      "learning_rate": 1.308139534883721e-05,
      "loss": 0.0001,
      "step": 9525
    },
    {
      "epoch": 36.92248062015504,
      "grad_norm": 0.002610929310321808,
      "learning_rate": 1.3077519379844963e-05,
      "loss": 0.0002,
      "step": 9526
    },
    {
      "epoch": 36.92635658914729,
      "grad_norm": 0.27670159935951233,
      "learning_rate": 1.3073643410852715e-05,
      "loss": 0.011,
      "step": 9527
    },
    {
      "epoch": 36.93023255813954,
      "grad_norm": 0.0011278643505647779,
      "learning_rate": 1.3069767441860467e-05,
      "loss": 0.0001,
      "step": 9528
    },
    {
      "epoch": 36.934108527131784,
      "grad_norm": 0.8272756338119507,
      "learning_rate": 1.3065891472868217e-05,
      "loss": 0.0609,
      "step": 9529
    },
    {
      "epoch": 36.93798449612403,
      "grad_norm": 0.03205953910946846,
      "learning_rate": 1.3062015503875969e-05,
      "loss": 0.0004,
      "step": 9530
    },
    {
      "epoch": 36.94186046511628,
      "grad_norm": 2.548213243484497,
      "learning_rate": 1.305813953488372e-05,
      "loss": 0.0051,
      "step": 9531
    },
    {
      "epoch": 36.945736434108525,
      "grad_norm": 0.015552707947790623,
      "learning_rate": 1.3054263565891472e-05,
      "loss": 0.0003,
      "step": 9532
    },
    {
      "epoch": 36.94961240310077,
      "grad_norm": 0.0010689019691199064,
      "learning_rate": 1.3050387596899224e-05,
      "loss": 0.0001,
      "step": 9533
    },
    {
      "epoch": 36.95348837209303,
      "grad_norm": 0.009729539044201374,
      "learning_rate": 1.3046511627906977e-05,
      "loss": 0.0005,
      "step": 9534
    },
    {
      "epoch": 36.957364341085274,
      "grad_norm": 0.807417631149292,
      "learning_rate": 1.304263565891473e-05,
      "loss": 0.0458,
      "step": 9535
    },
    {
      "epoch": 36.96124031007752,
      "grad_norm": 0.0023388671688735485,
      "learning_rate": 1.303875968992248e-05,
      "loss": 0.0002,
      "step": 9536
    },
    {
      "epoch": 36.96511627906977,
      "grad_norm": 0.0012234755558893085,
      "learning_rate": 1.3034883720930232e-05,
      "loss": 0.0001,
      "step": 9537
    },
    {
      "epoch": 36.968992248062015,
      "grad_norm": 3.4050655364990234,
      "learning_rate": 1.3031007751937985e-05,
      "loss": 0.4785,
      "step": 9538
    },
    {
      "epoch": 36.97286821705426,
      "grad_norm": 0.0012228311970829964,
      "learning_rate": 1.3027131782945737e-05,
      "loss": 0.0001,
      "step": 9539
    },
    {
      "epoch": 36.97674418604651,
      "grad_norm": 0.0010857938323169947,
      "learning_rate": 1.3023255813953488e-05,
      "loss": 0.0001,
      "step": 9540
    },
    {
      "epoch": 36.98062015503876,
      "grad_norm": 1.173943042755127,
      "learning_rate": 1.301937984496124e-05,
      "loss": 0.109,
      "step": 9541
    },
    {
      "epoch": 36.98449612403101,
      "grad_norm": 0.0013266230234876275,
      "learning_rate": 1.3015503875968993e-05,
      "loss": 0.0001,
      "step": 9542
    },
    {
      "epoch": 36.98837209302326,
      "grad_norm": 0.004561970010399818,
      "learning_rate": 1.3011627906976745e-05,
      "loss": 0.0002,
      "step": 9543
    },
    {
      "epoch": 36.992248062015506,
      "grad_norm": 0.0011564557207748294,
      "learning_rate": 1.3007751937984498e-05,
      "loss": 0.0001,
      "step": 9544
    },
    {
      "epoch": 36.99612403100775,
      "grad_norm": 0.0010863818461075425,
      "learning_rate": 1.3003875968992248e-05,
      "loss": 0.0001,
      "step": 9545
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.0017248033545911312,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0001,
      "step": 9546
    },
    {
      "epoch": 37.00387596899225,
      "grad_norm": 0.0008774087764322758,
      "learning_rate": 1.2996124031007753e-05,
      "loss": 0.0001,
      "step": 9547
    },
    {
      "epoch": 37.007751937984494,
      "grad_norm": 0.0007868513348512352,
      "learning_rate": 1.2992248062015506e-05,
      "loss": 0.0001,
      "step": 9548
    },
    {
      "epoch": 37.01162790697674,
      "grad_norm": 0.0009265790577046573,
      "learning_rate": 1.2988372093023256e-05,
      "loss": 0.0001,
      "step": 9549
    },
    {
      "epoch": 37.01550387596899,
      "grad_norm": 0.0010874168947339058,
      "learning_rate": 1.2984496124031009e-05,
      "loss": 0.0001,
      "step": 9550
    },
    {
      "epoch": 37.01937984496124,
      "grad_norm": 0.001146639813669026,
      "learning_rate": 1.2980620155038761e-05,
      "loss": 0.0001,
      "step": 9551
    },
    {
      "epoch": 37.02325581395349,
      "grad_norm": 0.0008524561417289078,
      "learning_rate": 1.2976744186046514e-05,
      "loss": 0.0001,
      "step": 9552
    },
    {
      "epoch": 37.02713178294574,
      "grad_norm": 0.0013516206527128816,
      "learning_rate": 1.2972868217054266e-05,
      "loss": 0.0001,
      "step": 9553
    },
    {
      "epoch": 37.031007751937985,
      "grad_norm": 0.001250470639206469,
      "learning_rate": 1.2968992248062017e-05,
      "loss": 0.0001,
      "step": 9554
    },
    {
      "epoch": 37.03488372093023,
      "grad_norm": 0.8689059019088745,
      "learning_rate": 1.296511627906977e-05,
      "loss": 0.0528,
      "step": 9555
    },
    {
      "epoch": 37.03875968992248,
      "grad_norm": 0.0031844782643020153,
      "learning_rate": 1.2961240310077518e-05,
      "loss": 0.0002,
      "step": 9556
    },
    {
      "epoch": 37.042635658914726,
      "grad_norm": 0.0011901898542419076,
      "learning_rate": 1.295736434108527e-05,
      "loss": 0.0001,
      "step": 9557
    },
    {
      "epoch": 37.04651162790697,
      "grad_norm": 0.0021325501147657633,
      "learning_rate": 1.2953488372093023e-05,
      "loss": 0.0001,
      "step": 9558
    },
    {
      "epoch": 37.05038759689923,
      "grad_norm": 0.0009563704952597618,
      "learning_rate": 1.2949612403100776e-05,
      "loss": 0.0001,
      "step": 9559
    },
    {
      "epoch": 37.054263565891475,
      "grad_norm": 0.0008953658398240805,
      "learning_rate": 1.2945736434108526e-05,
      "loss": 0.0001,
      "step": 9560
    },
    {
      "epoch": 37.05813953488372,
      "grad_norm": 0.0034511727280914783,
      "learning_rate": 1.2941860465116279e-05,
      "loss": 0.0002,
      "step": 9561
    },
    {
      "epoch": 37.06201550387597,
      "grad_norm": 0.0010917724575847387,
      "learning_rate": 1.2937984496124031e-05,
      "loss": 0.0001,
      "step": 9562
    },
    {
      "epoch": 37.065891472868216,
      "grad_norm": 0.001938908826559782,
      "learning_rate": 1.2934108527131784e-05,
      "loss": 0.0001,
      "step": 9563
    },
    {
      "epoch": 37.06976744186046,
      "grad_norm": 0.00099180918186903,
      "learning_rate": 1.2930232558139534e-05,
      "loss": 0.0001,
      "step": 9564
    },
    {
      "epoch": 37.07364341085271,
      "grad_norm": 0.001198170823045075,
      "learning_rate": 1.2926356589147287e-05,
      "loss": 0.0001,
      "step": 9565
    },
    {
      "epoch": 37.07751937984496,
      "grad_norm": 0.0011806474067270756,
      "learning_rate": 1.292248062015504e-05,
      "loss": 0.0001,
      "step": 9566
    },
    {
      "epoch": 37.08139534883721,
      "grad_norm": 0.8639914393424988,
      "learning_rate": 1.2918604651162792e-05,
      "loss": 0.0486,
      "step": 9567
    },
    {
      "epoch": 37.08527131782946,
      "grad_norm": 0.0025268355384469032,
      "learning_rate": 1.2914728682170544e-05,
      "loss": 0.0002,
      "step": 9568
    },
    {
      "epoch": 37.08914728682171,
      "grad_norm": 0.0012256543850526214,
      "learning_rate": 1.2910852713178295e-05,
      "loss": 0.0001,
      "step": 9569
    },
    {
      "epoch": 37.093023255813954,
      "grad_norm": 0.0016303022857755423,
      "learning_rate": 1.2906976744186047e-05,
      "loss": 0.0001,
      "step": 9570
    },
    {
      "epoch": 37.0968992248062,
      "grad_norm": 0.008428782224655151,
      "learning_rate": 1.29031007751938e-05,
      "loss": 0.0001,
      "step": 9571
    },
    {
      "epoch": 37.10077519379845,
      "grad_norm": 0.0009669377468526363,
      "learning_rate": 1.2899224806201552e-05,
      "loss": 0.0001,
      "step": 9572
    },
    {
      "epoch": 37.104651162790695,
      "grad_norm": 0.0011293035931885242,
      "learning_rate": 1.2895348837209303e-05,
      "loss": 0.0001,
      "step": 9573
    },
    {
      "epoch": 37.10852713178294,
      "grad_norm": 0.00095049460651353,
      "learning_rate": 1.2891472868217055e-05,
      "loss": 0.0001,
      "step": 9574
    },
    {
      "epoch": 37.1124031007752,
      "grad_norm": 0.0038314710836857557,
      "learning_rate": 1.2887596899224808e-05,
      "loss": 0.0003,
      "step": 9575
    },
    {
      "epoch": 37.116279069767444,
      "grad_norm": 0.0014138045953586698,
      "learning_rate": 1.288372093023256e-05,
      "loss": 0.0001,
      "step": 9576
    },
    {
      "epoch": 37.12015503875969,
      "grad_norm": 4.432259559631348,
      "learning_rate": 1.2879844961240312e-05,
      "loss": 0.1701,
      "step": 9577
    },
    {
      "epoch": 37.12403100775194,
      "grad_norm": 0.0022618728689849377,
      "learning_rate": 1.2875968992248063e-05,
      "loss": 0.0002,
      "step": 9578
    },
    {
      "epoch": 37.127906976744185,
      "grad_norm": 12.945358276367188,
      "learning_rate": 1.2872093023255816e-05,
      "loss": 0.0429,
      "step": 9579
    },
    {
      "epoch": 37.13178294573643,
      "grad_norm": 0.002220961032435298,
      "learning_rate": 1.2868217054263568e-05,
      "loss": 0.0002,
      "step": 9580
    },
    {
      "epoch": 37.13565891472868,
      "grad_norm": 0.5372591018676758,
      "learning_rate": 1.286434108527132e-05,
      "loss": 0.0203,
      "step": 9581
    },
    {
      "epoch": 37.13953488372093,
      "grad_norm": 0.007504332810640335,
      "learning_rate": 1.286046511627907e-05,
      "loss": 0.0003,
      "step": 9582
    },
    {
      "epoch": 37.14341085271318,
      "grad_norm": 0.0013096155598759651,
      "learning_rate": 1.2856589147286822e-05,
      "loss": 0.0001,
      "step": 9583
    },
    {
      "epoch": 37.14728682170543,
      "grad_norm": 0.004320712294429541,
      "learning_rate": 1.2852713178294573e-05,
      "loss": 0.0002,
      "step": 9584
    },
    {
      "epoch": 37.151162790697676,
      "grad_norm": 0.23396286368370056,
      "learning_rate": 1.2848837209302325e-05,
      "loss": 0.0099,
      "step": 9585
    },
    {
      "epoch": 37.15503875968992,
      "grad_norm": 0.003846127074211836,
      "learning_rate": 1.2844961240310077e-05,
      "loss": 0.0003,
      "step": 9586
    },
    {
      "epoch": 37.15891472868217,
      "grad_norm": 0.6354724168777466,
      "learning_rate": 1.284108527131783e-05,
      "loss": 0.0356,
      "step": 9587
    },
    {
      "epoch": 37.16279069767442,
      "grad_norm": 0.0013864104403182864,
      "learning_rate": 1.283720930232558e-05,
      "loss": 0.0001,
      "step": 9588
    },
    {
      "epoch": 37.166666666666664,
      "grad_norm": 0.0018547570798546076,
      "learning_rate": 1.2833333333333333e-05,
      "loss": 0.0001,
      "step": 9589
    },
    {
      "epoch": 37.17054263565891,
      "grad_norm": 0.0028934369329363108,
      "learning_rate": 1.2829457364341085e-05,
      "loss": 0.0002,
      "step": 9590
    },
    {
      "epoch": 37.174418604651166,
      "grad_norm": 0.00275788689032197,
      "learning_rate": 1.2825581395348838e-05,
      "loss": 0.0002,
      "step": 9591
    },
    {
      "epoch": 37.17829457364341,
      "grad_norm": 0.0019095508614555001,
      "learning_rate": 1.282170542635659e-05,
      "loss": 0.0001,
      "step": 9592
    },
    {
      "epoch": 37.18217054263566,
      "grad_norm": 0.4533385932445526,
      "learning_rate": 1.2817829457364341e-05,
      "loss": 0.0195,
      "step": 9593
    },
    {
      "epoch": 37.18604651162791,
      "grad_norm": 0.004106344189494848,
      "learning_rate": 1.2813953488372093e-05,
      "loss": 0.0002,
      "step": 9594
    },
    {
      "epoch": 37.189922480620154,
      "grad_norm": 0.0015801223926246166,
      "learning_rate": 1.2810077519379846e-05,
      "loss": 0.0001,
      "step": 9595
    },
    {
      "epoch": 37.1937984496124,
      "grad_norm": 0.0069862729869782925,
      "learning_rate": 1.2806201550387598e-05,
      "loss": 0.0003,
      "step": 9596
    },
    {
      "epoch": 37.19767441860465,
      "grad_norm": 0.0015867131296545267,
      "learning_rate": 1.2802325581395349e-05,
      "loss": 0.0001,
      "step": 9597
    },
    {
      "epoch": 37.201550387596896,
      "grad_norm": 0.003265886567533016,
      "learning_rate": 1.2798449612403101e-05,
      "loss": 0.0002,
      "step": 9598
    },
    {
      "epoch": 37.20542635658915,
      "grad_norm": 0.0025000907480716705,
      "learning_rate": 1.2794573643410854e-05,
      "loss": 0.0002,
      "step": 9599
    },
    {
      "epoch": 37.2093023255814,
      "grad_norm": 0.004262676928192377,
      "learning_rate": 1.2790697674418606e-05,
      "loss": 0.0002,
      "step": 9600
    },
    {
      "epoch": 37.213178294573645,
      "grad_norm": 0.0018951398087665439,
      "learning_rate": 1.2786821705426357e-05,
      "loss": 0.0001,
      "step": 9601
    },
    {
      "epoch": 37.21705426356589,
      "grad_norm": 0.01040517445653677,
      "learning_rate": 1.278294573643411e-05,
      "loss": 0.0002,
      "step": 9602
    },
    {
      "epoch": 37.22093023255814,
      "grad_norm": 0.003395764622837305,
      "learning_rate": 1.2779069767441862e-05,
      "loss": 0.0002,
      "step": 9603
    },
    {
      "epoch": 37.224806201550386,
      "grad_norm": 0.0021738114301115274,
      "learning_rate": 1.2775193798449614e-05,
      "loss": 0.0001,
      "step": 9604
    },
    {
      "epoch": 37.22868217054263,
      "grad_norm": 0.0032236892729997635,
      "learning_rate": 1.2771317829457367e-05,
      "loss": 0.0003,
      "step": 9605
    },
    {
      "epoch": 37.23255813953488,
      "grad_norm": 0.0013972718734294176,
      "learning_rate": 1.2767441860465117e-05,
      "loss": 0.0001,
      "step": 9606
    },
    {
      "epoch": 37.236434108527135,
      "grad_norm": 0.00169723154976964,
      "learning_rate": 1.276356589147287e-05,
      "loss": 0.0001,
      "step": 9607
    },
    {
      "epoch": 37.24031007751938,
      "grad_norm": 0.00341974850744009,
      "learning_rate": 1.2759689922480622e-05,
      "loss": 0.0002,
      "step": 9608
    },
    {
      "epoch": 37.24418604651163,
      "grad_norm": 0.0028349764179438353,
      "learning_rate": 1.2755813953488371e-05,
      "loss": 0.0002,
      "step": 9609
    },
    {
      "epoch": 37.248062015503876,
      "grad_norm": 0.0016410587122663856,
      "learning_rate": 1.2751937984496124e-05,
      "loss": 0.0001,
      "step": 9610
    },
    {
      "epoch": 37.251937984496124,
      "grad_norm": 0.0020324147772043943,
      "learning_rate": 1.2748062015503876e-05,
      "loss": 0.0001,
      "step": 9611
    },
    {
      "epoch": 37.25581395348837,
      "grad_norm": 0.004534257110208273,
      "learning_rate": 1.2744186046511627e-05,
      "loss": 0.0003,
      "step": 9612
    },
    {
      "epoch": 37.25968992248062,
      "grad_norm": 0.0013327375054359436,
      "learning_rate": 1.274031007751938e-05,
      "loss": 0.0001,
      "step": 9613
    },
    {
      "epoch": 37.263565891472865,
      "grad_norm": 0.0012405224842950702,
      "learning_rate": 1.2736434108527132e-05,
      "loss": 0.0001,
      "step": 9614
    },
    {
      "epoch": 37.26744186046512,
      "grad_norm": 0.002341337502002716,
      "learning_rate": 1.2732558139534884e-05,
      "loss": 0.0001,
      "step": 9615
    },
    {
      "epoch": 37.27131782945737,
      "grad_norm": 0.0018784133717417717,
      "learning_rate": 1.2728682170542635e-05,
      "loss": 0.0001,
      "step": 9616
    },
    {
      "epoch": 37.275193798449614,
      "grad_norm": 0.0437089242041111,
      "learning_rate": 1.2724806201550387e-05,
      "loss": 0.0009,
      "step": 9617
    },
    {
      "epoch": 37.27906976744186,
      "grad_norm": 0.0015456059481948614,
      "learning_rate": 1.272093023255814e-05,
      "loss": 0.0001,
      "step": 9618
    },
    {
      "epoch": 37.28294573643411,
      "grad_norm": 0.0011764918453991413,
      "learning_rate": 1.2717054263565892e-05,
      "loss": 0.0001,
      "step": 9619
    },
    {
      "epoch": 37.286821705426355,
      "grad_norm": 0.0019298349507153034,
      "learning_rate": 1.2713178294573645e-05,
      "loss": 0.0001,
      "step": 9620
    },
    {
      "epoch": 37.2906976744186,
      "grad_norm": 0.0026054359041154385,
      "learning_rate": 1.2709302325581395e-05,
      "loss": 0.0001,
      "step": 9621
    },
    {
      "epoch": 37.29457364341085,
      "grad_norm": 0.0012952520046383142,
      "learning_rate": 1.2705426356589148e-05,
      "loss": 0.0001,
      "step": 9622
    },
    {
      "epoch": 37.298449612403104,
      "grad_norm": 0.0012893248349428177,
      "learning_rate": 1.27015503875969e-05,
      "loss": 0.0001,
      "step": 9623
    },
    {
      "epoch": 37.30232558139535,
      "grad_norm": 0.0013450704282149673,
      "learning_rate": 1.2697674418604653e-05,
      "loss": 0.0001,
      "step": 9624
    },
    {
      "epoch": 37.3062015503876,
      "grad_norm": 0.01248922199010849,
      "learning_rate": 1.2693798449612403e-05,
      "loss": 0.0002,
      "step": 9625
    },
    {
      "epoch": 37.310077519379846,
      "grad_norm": 0.0015203463844954967,
      "learning_rate": 1.2689922480620156e-05,
      "loss": 0.0001,
      "step": 9626
    },
    {
      "epoch": 37.31395348837209,
      "grad_norm": 0.0014730053953826427,
      "learning_rate": 1.2686046511627908e-05,
      "loss": 0.0001,
      "step": 9627
    },
    {
      "epoch": 37.31782945736434,
      "grad_norm": 0.06757650524377823,
      "learning_rate": 1.268217054263566e-05,
      "loss": 0.0011,
      "step": 9628
    },
    {
      "epoch": 37.32170542635659,
      "grad_norm": 0.001932729035615921,
      "learning_rate": 1.2678294573643413e-05,
      "loss": 0.0002,
      "step": 9629
    },
    {
      "epoch": 37.325581395348834,
      "grad_norm": 0.002887397538870573,
      "learning_rate": 1.2674418604651164e-05,
      "loss": 0.0002,
      "step": 9630
    },
    {
      "epoch": 37.32945736434109,
      "grad_norm": 0.0019136961782351136,
      "learning_rate": 1.2670542635658916e-05,
      "loss": 0.0001,
      "step": 9631
    },
    {
      "epoch": 37.333333333333336,
      "grad_norm": 0.001599772833287716,
      "learning_rate": 1.2666666666666668e-05,
      "loss": 0.0001,
      "step": 9632
    },
    {
      "epoch": 37.33720930232558,
      "grad_norm": 0.0013214073842391372,
      "learning_rate": 1.2662790697674421e-05,
      "loss": 0.0001,
      "step": 9633
    },
    {
      "epoch": 37.34108527131783,
      "grad_norm": 0.001701878383755684,
      "learning_rate": 1.2658914728682172e-05,
      "loss": 0.0002,
      "step": 9634
    },
    {
      "epoch": 37.34496124031008,
      "grad_norm": 0.0025458247400820255,
      "learning_rate": 1.2655038759689924e-05,
      "loss": 0.0001,
      "step": 9635
    },
    {
      "epoch": 37.348837209302324,
      "grad_norm": 0.0012839750852435827,
      "learning_rate": 1.2651162790697673e-05,
      "loss": 0.0001,
      "step": 9636
    },
    {
      "epoch": 37.35271317829457,
      "grad_norm": 0.0020374730229377747,
      "learning_rate": 1.2647286821705426e-05,
      "loss": 0.0001,
      "step": 9637
    },
    {
      "epoch": 37.35658914728682,
      "grad_norm": 0.0027314573526382446,
      "learning_rate": 1.2643410852713178e-05,
      "loss": 0.0002,
      "step": 9638
    },
    {
      "epoch": 37.36046511627907,
      "grad_norm": 0.0009459015564061701,
      "learning_rate": 1.263953488372093e-05,
      "loss": 0.0001,
      "step": 9639
    },
    {
      "epoch": 37.36434108527132,
      "grad_norm": 0.3880598843097687,
      "learning_rate": 1.2635658914728681e-05,
      "loss": 0.0162,
      "step": 9640
    },
    {
      "epoch": 37.36821705426357,
      "grad_norm": 0.0009364139405079186,
      "learning_rate": 1.2631782945736434e-05,
      "loss": 0.0001,
      "step": 9641
    },
    {
      "epoch": 37.372093023255815,
      "grad_norm": 0.0018468701746314764,
      "learning_rate": 1.2627906976744186e-05,
      "loss": 0.0001,
      "step": 9642
    },
    {
      "epoch": 37.37596899224806,
      "grad_norm": 0.8801907896995544,
      "learning_rate": 1.2624031007751938e-05,
      "loss": 0.048,
      "step": 9643
    },
    {
      "epoch": 37.37984496124031,
      "grad_norm": 0.006175071932375431,
      "learning_rate": 1.262015503875969e-05,
      "loss": 0.0004,
      "step": 9644
    },
    {
      "epoch": 37.383720930232556,
      "grad_norm": 0.0016437966842204332,
      "learning_rate": 1.2616279069767442e-05,
      "loss": 0.0001,
      "step": 9645
    },
    {
      "epoch": 37.3875968992248,
      "grad_norm": 0.003880121046677232,
      "learning_rate": 1.2612403100775194e-05,
      "loss": 0.0001,
      "step": 9646
    },
    {
      "epoch": 37.39147286821706,
      "grad_norm": 0.001005479833111167,
      "learning_rate": 1.2608527131782946e-05,
      "loss": 0.0001,
      "step": 9647
    },
    {
      "epoch": 37.395348837209305,
      "grad_norm": 0.0016188689041882753,
      "learning_rate": 1.2604651162790699e-05,
      "loss": 0.0001,
      "step": 9648
    },
    {
      "epoch": 37.39922480620155,
      "grad_norm": 0.00508820591494441,
      "learning_rate": 1.260077519379845e-05,
      "loss": 0.0003,
      "step": 9649
    },
    {
      "epoch": 37.4031007751938,
      "grad_norm": 0.005333875305950642,
      "learning_rate": 1.2596899224806202e-05,
      "loss": 0.0003,
      "step": 9650
    },
    {
      "epoch": 37.406976744186046,
      "grad_norm": 0.003046624595299363,
      "learning_rate": 1.2593023255813954e-05,
      "loss": 0.0002,
      "step": 9651
    },
    {
      "epoch": 37.41085271317829,
      "grad_norm": 0.0010773191461339593,
      "learning_rate": 1.2589147286821707e-05,
      "loss": 0.0001,
      "step": 9652
    },
    {
      "epoch": 37.41472868217054,
      "grad_norm": 0.006798844784498215,
      "learning_rate": 1.258527131782946e-05,
      "loss": 0.0004,
      "step": 9653
    },
    {
      "epoch": 37.41860465116279,
      "grad_norm": 0.001218500081449747,
      "learning_rate": 1.258139534883721e-05,
      "loss": 0.0001,
      "step": 9654
    },
    {
      "epoch": 37.42248062015504,
      "grad_norm": 0.001299574039876461,
      "learning_rate": 1.2577519379844962e-05,
      "loss": 0.0001,
      "step": 9655
    },
    {
      "epoch": 37.42635658914729,
      "grad_norm": 0.5468416213989258,
      "learning_rate": 1.2573643410852715e-05,
      "loss": 0.0219,
      "step": 9656
    },
    {
      "epoch": 37.43023255813954,
      "grad_norm": 0.002094251336529851,
      "learning_rate": 1.2569767441860467e-05,
      "loss": 0.0002,
      "step": 9657
    },
    {
      "epoch": 37.434108527131784,
      "grad_norm": 0.30826595425605774,
      "learning_rate": 1.2565891472868218e-05,
      "loss": 0.0122,
      "step": 9658
    },
    {
      "epoch": 37.43798449612403,
      "grad_norm": 0.0011193404207006097,
      "learning_rate": 1.256201550387597e-05,
      "loss": 0.0001,
      "step": 9659
    },
    {
      "epoch": 37.44186046511628,
      "grad_norm": 2.6755869388580322,
      "learning_rate": 1.2558139534883723e-05,
      "loss": 0.0981,
      "step": 9660
    },
    {
      "epoch": 37.445736434108525,
      "grad_norm": 2.3042848110198975,
      "learning_rate": 1.2554263565891475e-05,
      "loss": 0.0172,
      "step": 9661
    },
    {
      "epoch": 37.44961240310077,
      "grad_norm": 0.0010400637984275818,
      "learning_rate": 1.2550387596899224e-05,
      "loss": 0.0001,
      "step": 9662
    },
    {
      "epoch": 37.45348837209303,
      "grad_norm": 0.8138318657875061,
      "learning_rate": 1.2546511627906977e-05,
      "loss": 0.1404,
      "step": 9663
    },
    {
      "epoch": 37.457364341085274,
      "grad_norm": 0.0017539471155032516,
      "learning_rate": 1.2542635658914727e-05,
      "loss": 0.0001,
      "step": 9664
    },
    {
      "epoch": 37.46124031007752,
      "grad_norm": 0.0024120358284562826,
      "learning_rate": 1.253875968992248e-05,
      "loss": 0.0002,
      "step": 9665
    },
    {
      "epoch": 37.46511627906977,
      "grad_norm": 0.025043103843927383,
      "learning_rate": 1.2534883720930232e-05,
      "loss": 0.0006,
      "step": 9666
    },
    {
      "epoch": 37.468992248062015,
      "grad_norm": 0.0026101034600287676,
      "learning_rate": 1.2531007751937985e-05,
      "loss": 0.0002,
      "step": 9667
    },
    {
      "epoch": 37.47286821705426,
      "grad_norm": 0.001449426868930459,
      "learning_rate": 1.2527131782945737e-05,
      "loss": 0.0001,
      "step": 9668
    },
    {
      "epoch": 37.47674418604651,
      "grad_norm": 0.0011922094272449613,
      "learning_rate": 1.2523255813953488e-05,
      "loss": 0.0001,
      "step": 9669
    },
    {
      "epoch": 37.48062015503876,
      "grad_norm": 0.04529453068971634,
      "learning_rate": 1.251937984496124e-05,
      "loss": 0.0007,
      "step": 9670
    },
    {
      "epoch": 37.48449612403101,
      "grad_norm": 0.00498013524338603,
      "learning_rate": 1.2515503875968993e-05,
      "loss": 0.0003,
      "step": 9671
    },
    {
      "epoch": 37.48837209302326,
      "grad_norm": 0.0032426821999251842,
      "learning_rate": 1.2511627906976745e-05,
      "loss": 0.0002,
      "step": 9672
    },
    {
      "epoch": 37.492248062015506,
      "grad_norm": 0.0014589388156309724,
      "learning_rate": 1.2507751937984496e-05,
      "loss": 0.0001,
      "step": 9673
    },
    {
      "epoch": 37.49612403100775,
      "grad_norm": 0.7038546800613403,
      "learning_rate": 1.2503875968992248e-05,
      "loss": 0.0312,
      "step": 9674
    },
    {
      "epoch": 37.5,
      "grad_norm": 0.002444126410409808,
      "learning_rate": 1.25e-05,
      "loss": 0.0001,
      "step": 9675
    },
    {
      "epoch": 37.50387596899225,
      "grad_norm": 0.31273579597473145,
      "learning_rate": 1.2496124031007753e-05,
      "loss": 0.0011,
      "step": 9676
    },
    {
      "epoch": 37.507751937984494,
      "grad_norm": 0.0023000144865363836,
      "learning_rate": 1.2492248062015505e-05,
      "loss": 0.0001,
      "step": 9677
    },
    {
      "epoch": 37.51162790697674,
      "grad_norm": 0.016634175553917885,
      "learning_rate": 1.2488372093023256e-05,
      "loss": 0.0006,
      "step": 9678
    },
    {
      "epoch": 37.51550387596899,
      "grad_norm": 0.002209222177043557,
      "learning_rate": 1.2484496124031009e-05,
      "loss": 0.0002,
      "step": 9679
    },
    {
      "epoch": 37.51937984496124,
      "grad_norm": 0.009574095718562603,
      "learning_rate": 1.2480620155038761e-05,
      "loss": 0.0003,
      "step": 9680
    },
    {
      "epoch": 37.52325581395349,
      "grad_norm": 0.0013206279836595058,
      "learning_rate": 1.2476744186046513e-05,
      "loss": 0.0001,
      "step": 9681
    },
    {
      "epoch": 37.52713178294574,
      "grad_norm": 0.002918474841862917,
      "learning_rate": 1.2472868217054264e-05,
      "loss": 0.0001,
      "step": 9682
    },
    {
      "epoch": 37.531007751937985,
      "grad_norm": 0.0015367534942924976,
      "learning_rate": 1.2468992248062015e-05,
      "loss": 0.0002,
      "step": 9683
    },
    {
      "epoch": 37.53488372093023,
      "grad_norm": 0.005399376153945923,
      "learning_rate": 1.2465116279069767e-05,
      "loss": 0.0002,
      "step": 9684
    },
    {
      "epoch": 37.53875968992248,
      "grad_norm": 0.0012976927682757378,
      "learning_rate": 1.246124031007752e-05,
      "loss": 0.0001,
      "step": 9685
    },
    {
      "epoch": 37.542635658914726,
      "grad_norm": 0.0010992216411978006,
      "learning_rate": 1.2457364341085272e-05,
      "loss": 0.0001,
      "step": 9686
    },
    {
      "epoch": 37.54651162790697,
      "grad_norm": 0.004761817399412394,
      "learning_rate": 1.2453488372093023e-05,
      "loss": 0.0003,
      "step": 9687
    },
    {
      "epoch": 37.55038759689923,
      "grad_norm": 0.0015574292046949267,
      "learning_rate": 1.2449612403100775e-05,
      "loss": 0.0001,
      "step": 9688
    },
    {
      "epoch": 37.554263565891475,
      "grad_norm": 0.0023030750453472137,
      "learning_rate": 1.2445736434108528e-05,
      "loss": 0.0001,
      "step": 9689
    },
    {
      "epoch": 37.55813953488372,
      "grad_norm": 0.001650587422773242,
      "learning_rate": 1.244186046511628e-05,
      "loss": 0.0001,
      "step": 9690
    },
    {
      "epoch": 37.56201550387597,
      "grad_norm": 0.001288508647121489,
      "learning_rate": 1.2437984496124033e-05,
      "loss": 0.0001,
      "step": 9691
    },
    {
      "epoch": 37.565891472868216,
      "grad_norm": 0.0016849281964823604,
      "learning_rate": 1.2434108527131783e-05,
      "loss": 0.0001,
      "step": 9692
    },
    {
      "epoch": 37.56976744186046,
      "grad_norm": 0.0012387593742460012,
      "learning_rate": 1.2430232558139536e-05,
      "loss": 0.0001,
      "step": 9693
    },
    {
      "epoch": 37.57364341085271,
      "grad_norm": 0.0035861253272742033,
      "learning_rate": 1.2426356589147288e-05,
      "loss": 0.0002,
      "step": 9694
    },
    {
      "epoch": 37.57751937984496,
      "grad_norm": 0.0026042768731713295,
      "learning_rate": 1.2422480620155039e-05,
      "loss": 0.0002,
      "step": 9695
    },
    {
      "epoch": 37.58139534883721,
      "grad_norm": 0.0021517020650207996,
      "learning_rate": 1.2418604651162791e-05,
      "loss": 0.0002,
      "step": 9696
    },
    {
      "epoch": 37.58527131782946,
      "grad_norm": 0.0011787149123847485,
      "learning_rate": 1.2414728682170542e-05,
      "loss": 0.0001,
      "step": 9697
    },
    {
      "epoch": 37.58914728682171,
      "grad_norm": 0.0013383139157667756,
      "learning_rate": 1.2410852713178294e-05,
      "loss": 0.0001,
      "step": 9698
    },
    {
      "epoch": 37.593023255813954,
      "grad_norm": 0.001264113700017333,
      "learning_rate": 1.2406976744186047e-05,
      "loss": 0.0001,
      "step": 9699
    },
    {
      "epoch": 37.5968992248062,
      "grad_norm": 0.051848024129867554,
      "learning_rate": 1.24031007751938e-05,
      "loss": 0.0002,
      "step": 9700
    },
    {
      "epoch": 37.60077519379845,
      "grad_norm": 0.0015271619195118546,
      "learning_rate": 1.2399224806201552e-05,
      "loss": 0.0001,
      "step": 9701
    },
    {
      "epoch": 37.604651162790695,
      "grad_norm": 0.001034139539115131,
      "learning_rate": 1.2395348837209302e-05,
      "loss": 0.0001,
      "step": 9702
    },
    {
      "epoch": 37.60852713178294,
      "grad_norm": 0.0018567711813375354,
      "learning_rate": 1.2391472868217055e-05,
      "loss": 0.0001,
      "step": 9703
    },
    {
      "epoch": 37.6124031007752,
      "grad_norm": 0.0012963303597643971,
      "learning_rate": 1.2387596899224807e-05,
      "loss": 0.0001,
      "step": 9704
    },
    {
      "epoch": 37.616279069767444,
      "grad_norm": 0.0010117385536432266,
      "learning_rate": 1.238372093023256e-05,
      "loss": 0.0001,
      "step": 9705
    },
    {
      "epoch": 37.62015503875969,
      "grad_norm": 0.0011981073766946793,
      "learning_rate": 1.237984496124031e-05,
      "loss": 0.0001,
      "step": 9706
    },
    {
      "epoch": 37.62403100775194,
      "grad_norm": 0.0009584974613972008,
      "learning_rate": 1.2375968992248063e-05,
      "loss": 0.0001,
      "step": 9707
    },
    {
      "epoch": 37.627906976744185,
      "grad_norm": 1.8341578245162964,
      "learning_rate": 1.2372093023255815e-05,
      "loss": 0.2266,
      "step": 9708
    },
    {
      "epoch": 37.63178294573643,
      "grad_norm": 0.0012946375645697117,
      "learning_rate": 1.2368217054263566e-05,
      "loss": 0.0001,
      "step": 9709
    },
    {
      "epoch": 37.63565891472868,
      "grad_norm": 0.0011736650485545397,
      "learning_rate": 1.2364341085271318e-05,
      "loss": 0.0001,
      "step": 9710
    },
    {
      "epoch": 37.63953488372093,
      "grad_norm": 0.43780434131622314,
      "learning_rate": 1.2360465116279069e-05,
      "loss": 0.019,
      "step": 9711
    },
    {
      "epoch": 37.64341085271318,
      "grad_norm": 0.6971363425254822,
      "learning_rate": 1.2356589147286822e-05,
      "loss": 0.0104,
      "step": 9712
    },
    {
      "epoch": 37.64728682170543,
      "grad_norm": 0.03342580422759056,
      "learning_rate": 1.2352713178294574e-05,
      "loss": 0.0003,
      "step": 9713
    },
    {
      "epoch": 37.651162790697676,
      "grad_norm": 8.116901397705078,
      "learning_rate": 1.2348837209302326e-05,
      "loss": 0.0273,
      "step": 9714
    },
    {
      "epoch": 37.65503875968992,
      "grad_norm": 0.0011690598912537098,
      "learning_rate": 1.2344961240310079e-05,
      "loss": 0.0001,
      "step": 9715
    },
    {
      "epoch": 37.65891472868217,
      "grad_norm": 0.0011952423956245184,
      "learning_rate": 1.234108527131783e-05,
      "loss": 0.0001,
      "step": 9716
    },
    {
      "epoch": 37.66279069767442,
      "grad_norm": 0.0015970412641763687,
      "learning_rate": 1.2337209302325582e-05,
      "loss": 0.0001,
      "step": 9717
    },
    {
      "epoch": 37.666666666666664,
      "grad_norm": 0.001032150350511074,
      "learning_rate": 1.2333333333333334e-05,
      "loss": 0.0001,
      "step": 9718
    },
    {
      "epoch": 37.67054263565891,
      "grad_norm": 0.0012490323279052973,
      "learning_rate": 1.2329457364341087e-05,
      "loss": 0.0001,
      "step": 9719
    },
    {
      "epoch": 37.674418604651166,
      "grad_norm": 1.2897553443908691,
      "learning_rate": 1.2325581395348838e-05,
      "loss": 0.1025,
      "step": 9720
    },
    {
      "epoch": 37.67829457364341,
      "grad_norm": 0.001047392375767231,
      "learning_rate": 1.232170542635659e-05,
      "loss": 0.0001,
      "step": 9721
    },
    {
      "epoch": 37.68217054263566,
      "grad_norm": 0.0014661212917417288,
      "learning_rate": 1.231782945736434e-05,
      "loss": 0.0001,
      "step": 9722
    },
    {
      "epoch": 37.68604651162791,
      "grad_norm": 0.001634000102058053,
      "learning_rate": 1.2313953488372093e-05,
      "loss": 0.0001,
      "step": 9723
    },
    {
      "epoch": 37.689922480620154,
      "grad_norm": 0.0009095375426113605,
      "learning_rate": 1.2310077519379846e-05,
      "loss": 0.0001,
      "step": 9724
    },
    {
      "epoch": 37.6937984496124,
      "grad_norm": 0.0028208112344145775,
      "learning_rate": 1.2306201550387598e-05,
      "loss": 0.0001,
      "step": 9725
    },
    {
      "epoch": 37.69767441860465,
      "grad_norm": 0.0018871776992455125,
      "learning_rate": 1.2302325581395349e-05,
      "loss": 0.0002,
      "step": 9726
    },
    {
      "epoch": 37.701550387596896,
      "grad_norm": 0.0040977285243570805,
      "learning_rate": 1.2298449612403101e-05,
      "loss": 0.0002,
      "step": 9727
    },
    {
      "epoch": 37.70542635658915,
      "grad_norm": 0.004965800791978836,
      "learning_rate": 1.2294573643410854e-05,
      "loss": 0.0002,
      "step": 9728
    },
    {
      "epoch": 37.7093023255814,
      "grad_norm": 0.0009873450035229325,
      "learning_rate": 1.2290697674418606e-05,
      "loss": 0.0001,
      "step": 9729
    },
    {
      "epoch": 37.713178294573645,
      "grad_norm": 0.001090425648726523,
      "learning_rate": 1.2286821705426357e-05,
      "loss": 0.0001,
      "step": 9730
    },
    {
      "epoch": 37.71705426356589,
      "grad_norm": 0.000906098575796932,
      "learning_rate": 1.2282945736434109e-05,
      "loss": 0.0001,
      "step": 9731
    },
    {
      "epoch": 37.72093023255814,
      "grad_norm": 0.002756349742412567,
      "learning_rate": 1.2279069767441862e-05,
      "loss": 0.0002,
      "step": 9732
    },
    {
      "epoch": 37.724806201550386,
      "grad_norm": 0.0034444164484739304,
      "learning_rate": 1.2275193798449614e-05,
      "loss": 0.0002,
      "step": 9733
    },
    {
      "epoch": 37.72868217054263,
      "grad_norm": 0.0015524144982919097,
      "learning_rate": 1.2271317829457366e-05,
      "loss": 0.0001,
      "step": 9734
    },
    {
      "epoch": 37.73255813953488,
      "grad_norm": 0.0011761290952563286,
      "learning_rate": 1.2267441860465115e-05,
      "loss": 0.0001,
      "step": 9735
    },
    {
      "epoch": 37.736434108527135,
      "grad_norm": 0.0033448345493525267,
      "learning_rate": 1.2263565891472868e-05,
      "loss": 0.0002,
      "step": 9736
    },
    {
      "epoch": 37.74031007751938,
      "grad_norm": 0.0013376171700656414,
      "learning_rate": 1.225968992248062e-05,
      "loss": 0.0001,
      "step": 9737
    },
    {
      "epoch": 37.74418604651163,
      "grad_norm": 0.0011150656500831246,
      "learning_rate": 1.2255813953488373e-05,
      "loss": 0.0001,
      "step": 9738
    },
    {
      "epoch": 37.748062015503876,
      "grad_norm": 0.0035537148360162973,
      "learning_rate": 1.2251937984496125e-05,
      "loss": 0.0001,
      "step": 9739
    },
    {
      "epoch": 37.751937984496124,
      "grad_norm": 0.0011587011395022273,
      "learning_rate": 1.2248062015503876e-05,
      "loss": 0.0001,
      "step": 9740
    },
    {
      "epoch": 37.75581395348837,
      "grad_norm": 0.0012744958512485027,
      "learning_rate": 1.2244186046511628e-05,
      "loss": 0.0001,
      "step": 9741
    },
    {
      "epoch": 37.75968992248062,
      "grad_norm": 37.06292724609375,
      "learning_rate": 1.224031007751938e-05,
      "loss": 0.0167,
      "step": 9742
    },
    {
      "epoch": 37.763565891472865,
      "grad_norm": 0.0011537831742316484,
      "learning_rate": 1.2236434108527133e-05,
      "loss": 0.0001,
      "step": 9743
    },
    {
      "epoch": 37.76744186046512,
      "grad_norm": 0.0014355841558426619,
      "learning_rate": 1.2232558139534884e-05,
      "loss": 0.0001,
      "step": 9744
    },
    {
      "epoch": 37.77131782945737,
      "grad_norm": 0.0012779466342180967,
      "learning_rate": 1.2228682170542636e-05,
      "loss": 0.0001,
      "step": 9745
    },
    {
      "epoch": 37.775193798449614,
      "grad_norm": 0.0009125657379627228,
      "learning_rate": 1.2224806201550389e-05,
      "loss": 0.0001,
      "step": 9746
    },
    {
      "epoch": 37.77906976744186,
      "grad_norm": 0.002558206208050251,
      "learning_rate": 1.2220930232558141e-05,
      "loss": 0.0002,
      "step": 9747
    },
    {
      "epoch": 37.78294573643411,
      "grad_norm": 0.001380033092573285,
      "learning_rate": 1.2217054263565893e-05,
      "loss": 0.0001,
      "step": 9748
    },
    {
      "epoch": 37.786821705426355,
      "grad_norm": 0.0010048741241917014,
      "learning_rate": 1.2213178294573644e-05,
      "loss": 0.0001,
      "step": 9749
    },
    {
      "epoch": 37.7906976744186,
      "grad_norm": 0.0017007115529850125,
      "learning_rate": 1.2209302325581395e-05,
      "loss": 0.0001,
      "step": 9750
    },
    {
      "epoch": 37.79457364341085,
      "grad_norm": 0.0009301104000769556,
      "learning_rate": 1.2205426356589147e-05,
      "loss": 0.0001,
      "step": 9751
    },
    {
      "epoch": 37.798449612403104,
      "grad_norm": 0.0013080353382974863,
      "learning_rate": 1.22015503875969e-05,
      "loss": 0.0001,
      "step": 9752
    },
    {
      "epoch": 37.80232558139535,
      "grad_norm": 3.0280299186706543,
      "learning_rate": 1.2197674418604652e-05,
      "loss": 0.4443,
      "step": 9753
    },
    {
      "epoch": 37.8062015503876,
      "grad_norm": 0.003359045134857297,
      "learning_rate": 1.2193798449612403e-05,
      "loss": 0.0002,
      "step": 9754
    },
    {
      "epoch": 37.810077519379846,
      "grad_norm": 0.004581555258482695,
      "learning_rate": 1.2189922480620155e-05,
      "loss": 0.0003,
      "step": 9755
    },
    {
      "epoch": 37.81395348837209,
      "grad_norm": 0.0014387054834514856,
      "learning_rate": 1.2186046511627908e-05,
      "loss": 0.0001,
      "step": 9756
    },
    {
      "epoch": 37.81782945736434,
      "grad_norm": 0.001002566539682448,
      "learning_rate": 1.218217054263566e-05,
      "loss": 0.0001,
      "step": 9757
    },
    {
      "epoch": 37.82170542635659,
      "grad_norm": 0.0012256860500201583,
      "learning_rate": 1.2178294573643411e-05,
      "loss": 0.0001,
      "step": 9758
    },
    {
      "epoch": 37.825581395348834,
      "grad_norm": 0.002112192800268531,
      "learning_rate": 1.2174418604651163e-05,
      "loss": 0.0002,
      "step": 9759
    },
    {
      "epoch": 37.82945736434109,
      "grad_norm": 0.0024704737588763237,
      "learning_rate": 1.2170542635658916e-05,
      "loss": 0.0002,
      "step": 9760
    },
    {
      "epoch": 37.833333333333336,
      "grad_norm": 0.0053491657599806786,
      "learning_rate": 1.2166666666666668e-05,
      "loss": 0.0003,
      "step": 9761
    },
    {
      "epoch": 37.83720930232558,
      "grad_norm": 0.0009720398811623454,
      "learning_rate": 1.2162790697674419e-05,
      "loss": 0.0001,
      "step": 9762
    },
    {
      "epoch": 37.84108527131783,
      "grad_norm": 0.0011166427284479141,
      "learning_rate": 1.2158914728682171e-05,
      "loss": 0.0001,
      "step": 9763
    },
    {
      "epoch": 37.84496124031008,
      "grad_norm": 0.6904599666595459,
      "learning_rate": 1.2155038759689922e-05,
      "loss": 0.0097,
      "step": 9764
    },
    {
      "epoch": 37.848837209302324,
      "grad_norm": 0.0013189215678721666,
      "learning_rate": 1.2151162790697674e-05,
      "loss": 0.0001,
      "step": 9765
    },
    {
      "epoch": 37.85271317829457,
      "grad_norm": 0.0009839704725891352,
      "learning_rate": 1.2147286821705427e-05,
      "loss": 0.0001,
      "step": 9766
    },
    {
      "epoch": 37.85658914728682,
      "grad_norm": 0.05273980274796486,
      "learning_rate": 1.214341085271318e-05,
      "loss": 0.0009,
      "step": 9767
    },
    {
      "epoch": 37.86046511627907,
      "grad_norm": 0.001458559650927782,
      "learning_rate": 1.213953488372093e-05,
      "loss": 0.0001,
      "step": 9768
    },
    {
      "epoch": 37.86434108527132,
      "grad_norm": 0.0027176884468644857,
      "learning_rate": 1.2135658914728682e-05,
      "loss": 0.0002,
      "step": 9769
    },
    {
      "epoch": 37.86821705426357,
      "grad_norm": 0.0019256779924035072,
      "learning_rate": 1.2131782945736435e-05,
      "loss": 0.0001,
      "step": 9770
    },
    {
      "epoch": 37.872093023255815,
      "grad_norm": 0.0009085115161724389,
      "learning_rate": 1.2127906976744187e-05,
      "loss": 0.0001,
      "step": 9771
    },
    {
      "epoch": 37.87596899224806,
      "grad_norm": 0.0018065670737996697,
      "learning_rate": 1.212403100775194e-05,
      "loss": 0.0002,
      "step": 9772
    },
    {
      "epoch": 37.87984496124031,
      "grad_norm": 0.000861484557390213,
      "learning_rate": 1.212015503875969e-05,
      "loss": 0.0001,
      "step": 9773
    },
    {
      "epoch": 37.883720930232556,
      "grad_norm": 0.0064219520427286625,
      "learning_rate": 1.2116279069767443e-05,
      "loss": 0.0003,
      "step": 9774
    },
    {
      "epoch": 37.8875968992248,
      "grad_norm": 0.0009469573269598186,
      "learning_rate": 1.2112403100775194e-05,
      "loss": 0.0001,
      "step": 9775
    },
    {
      "epoch": 37.89147286821706,
      "grad_norm": 0.00918611977249384,
      "learning_rate": 1.2108527131782946e-05,
      "loss": 0.0003,
      "step": 9776
    },
    {
      "epoch": 37.895348837209305,
      "grad_norm": 0.0012638565385714173,
      "learning_rate": 1.2104651162790698e-05,
      "loss": 0.0001,
      "step": 9777
    },
    {
      "epoch": 37.89922480620155,
      "grad_norm": 0.0009543872438371181,
      "learning_rate": 1.210077519379845e-05,
      "loss": 0.0001,
      "step": 9778
    },
    {
      "epoch": 37.9031007751938,
      "grad_norm": 0.001318416092544794,
      "learning_rate": 1.2096899224806202e-05,
      "loss": 0.0001,
      "step": 9779
    },
    {
      "epoch": 37.906976744186046,
      "grad_norm": 0.0018527178326621652,
      "learning_rate": 1.2093023255813954e-05,
      "loss": 0.0001,
      "step": 9780
    },
    {
      "epoch": 37.91085271317829,
      "grad_norm": 0.001909824786707759,
      "learning_rate": 1.2089147286821706e-05,
      "loss": 0.0001,
      "step": 9781
    },
    {
      "epoch": 37.91472868217054,
      "grad_norm": 0.0022670223843306303,
      "learning_rate": 1.2085271317829457e-05,
      "loss": 0.0001,
      "step": 9782
    },
    {
      "epoch": 37.91860465116279,
      "grad_norm": 0.001311656553298235,
      "learning_rate": 1.208139534883721e-05,
      "loss": 0.0001,
      "step": 9783
    },
    {
      "epoch": 37.92248062015504,
      "grad_norm": 2.3909246921539307,
      "learning_rate": 1.2077519379844962e-05,
      "loss": 0.2591,
      "step": 9784
    },
    {
      "epoch": 37.92635658914729,
      "grad_norm": 0.004538022913038731,
      "learning_rate": 1.2073643410852714e-05,
      "loss": 0.0003,
      "step": 9785
    },
    {
      "epoch": 37.93023255813954,
      "grad_norm": 8.143104553222656,
      "learning_rate": 1.2069767441860467e-05,
      "loss": 0.1229,
      "step": 9786
    },
    {
      "epoch": 37.934108527131784,
      "grad_norm": 0.002126232022419572,
      "learning_rate": 1.2065891472868218e-05,
      "loss": 0.0001,
      "step": 9787
    },
    {
      "epoch": 37.93798449612403,
      "grad_norm": 0.0009766366565600038,
      "learning_rate": 1.206201550387597e-05,
      "loss": 0.0001,
      "step": 9788
    },
    {
      "epoch": 37.94186046511628,
      "grad_norm": 0.007548343390226364,
      "learning_rate": 1.205813953488372e-05,
      "loss": 0.0003,
      "step": 9789
    },
    {
      "epoch": 37.945736434108525,
      "grad_norm": 0.00109666190110147,
      "learning_rate": 1.2054263565891473e-05,
      "loss": 0.0001,
      "step": 9790
    },
    {
      "epoch": 37.94961240310077,
      "grad_norm": 0.00786578468978405,
      "learning_rate": 1.2050387596899226e-05,
      "loss": 0.0003,
      "step": 9791
    },
    {
      "epoch": 37.95348837209303,
      "grad_norm": 0.0011380480136722326,
      "learning_rate": 1.2046511627906976e-05,
      "loss": 0.0001,
      "step": 9792
    },
    {
      "epoch": 37.957364341085274,
      "grad_norm": 0.005321663338690996,
      "learning_rate": 1.2042635658914729e-05,
      "loss": 0.0003,
      "step": 9793
    },
    {
      "epoch": 37.96124031007752,
      "grad_norm": 0.001704675261862576,
      "learning_rate": 1.2038759689922481e-05,
      "loss": 0.0001,
      "step": 9794
    },
    {
      "epoch": 37.96511627906977,
      "grad_norm": 0.20191818475723267,
      "learning_rate": 1.2034883720930234e-05,
      "loss": 0.0083,
      "step": 9795
    },
    {
      "epoch": 37.968992248062015,
      "grad_norm": 0.0010256385430693626,
      "learning_rate": 1.2031007751937986e-05,
      "loss": 0.0001,
      "step": 9796
    },
    {
      "epoch": 37.97286821705426,
      "grad_norm": 0.0016055178130045533,
      "learning_rate": 1.2027131782945737e-05,
      "loss": 0.0001,
      "step": 9797
    },
    {
      "epoch": 37.97674418604651,
      "grad_norm": 6.194638252258301,
      "learning_rate": 1.202325581395349e-05,
      "loss": 0.6129,
      "step": 9798
    },
    {
      "epoch": 37.98062015503876,
      "grad_norm": 0.001699749263934791,
      "learning_rate": 1.2019379844961242e-05,
      "loss": 0.0001,
      "step": 9799
    },
    {
      "epoch": 37.98449612403101,
      "grad_norm": 0.0029281675815582275,
      "learning_rate": 1.2015503875968994e-05,
      "loss": 0.0001,
      "step": 9800
    },
    {
      "epoch": 37.98837209302326,
      "grad_norm": 0.001366589218378067,
      "learning_rate": 1.2011627906976745e-05,
      "loss": 0.0001,
      "step": 9801
    },
    {
      "epoch": 37.992248062015506,
      "grad_norm": 0.001119922730140388,
      "learning_rate": 1.2007751937984495e-05,
      "loss": 0.0001,
      "step": 9802
    },
    {
      "epoch": 37.99612403100775,
      "grad_norm": 0.0009105828939937055,
      "learning_rate": 1.2003875968992248e-05,
      "loss": 0.0001,
      "step": 9803
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.001196481054648757,
      "learning_rate": 1.2e-05,
      "loss": 0.0001,
      "step": 9804
    },
    {
      "epoch": 38.00387596899225,
      "grad_norm": 0.00407329760491848,
      "learning_rate": 1.1996124031007753e-05,
      "loss": 0.0002,
      "step": 9805
    },
    {
      "epoch": 38.007751937984494,
      "grad_norm": 0.001361739938147366,
      "learning_rate": 1.1992248062015503e-05,
      "loss": 0.0001,
      "step": 9806
    },
    {
      "epoch": 38.01162790697674,
      "grad_norm": 0.0012295190244913101,
      "learning_rate": 1.1988372093023256e-05,
      "loss": 0.0001,
      "step": 9807
    },
    {
      "epoch": 38.01550387596899,
      "grad_norm": 0.001776703167706728,
      "learning_rate": 1.1984496124031008e-05,
      "loss": 0.0001,
      "step": 9808
    },
    {
      "epoch": 38.01937984496124,
      "grad_norm": 0.0016080409986898303,
      "learning_rate": 1.198062015503876e-05,
      "loss": 0.0001,
      "step": 9809
    },
    {
      "epoch": 38.02325581395349,
      "grad_norm": 0.0012864756863564253,
      "learning_rate": 1.1976744186046513e-05,
      "loss": 0.0001,
      "step": 9810
    },
    {
      "epoch": 38.02713178294574,
      "grad_norm": 0.002536885440349579,
      "learning_rate": 1.1972868217054264e-05,
      "loss": 0.0002,
      "step": 9811
    },
    {
      "epoch": 38.031007751937985,
      "grad_norm": 0.0012736298376694322,
      "learning_rate": 1.1968992248062016e-05,
      "loss": 0.0001,
      "step": 9812
    },
    {
      "epoch": 38.03488372093023,
      "grad_norm": 0.001650388352572918,
      "learning_rate": 1.1965116279069769e-05,
      "loss": 0.0001,
      "step": 9813
    },
    {
      "epoch": 38.03875968992248,
      "grad_norm": 0.002469762461259961,
      "learning_rate": 1.1961240310077521e-05,
      "loss": 0.0002,
      "step": 9814
    },
    {
      "epoch": 38.042635658914726,
      "grad_norm": 0.0012311009922996163,
      "learning_rate": 1.1957364341085272e-05,
      "loss": 0.0001,
      "step": 9815
    },
    {
      "epoch": 38.04651162790697,
      "grad_norm": 0.0019344027386978269,
      "learning_rate": 1.1953488372093023e-05,
      "loss": 0.0002,
      "step": 9816
    },
    {
      "epoch": 38.05038759689923,
      "grad_norm": 0.13873818516731262,
      "learning_rate": 1.1949612403100775e-05,
      "loss": 0.0014,
      "step": 9817
    },
    {
      "epoch": 38.054263565891475,
      "grad_norm": 0.0010934065794572234,
      "learning_rate": 1.1945736434108527e-05,
      "loss": 0.0001,
      "step": 9818
    },
    {
      "epoch": 38.05813953488372,
      "grad_norm": 0.0034444548655301332,
      "learning_rate": 1.194186046511628e-05,
      "loss": 0.0002,
      "step": 9819
    },
    {
      "epoch": 38.06201550387597,
      "grad_norm": 0.004834660794585943,
      "learning_rate": 1.193798449612403e-05,
      "loss": 0.0003,
      "step": 9820
    },
    {
      "epoch": 38.065891472868216,
      "grad_norm": 0.0009583857608959079,
      "learning_rate": 1.1934108527131783e-05,
      "loss": 0.0001,
      "step": 9821
    },
    {
      "epoch": 38.06976744186046,
      "grad_norm": 0.00504254549741745,
      "learning_rate": 1.1930232558139535e-05,
      "loss": 0.0002,
      "step": 9822
    },
    {
      "epoch": 38.07364341085271,
      "grad_norm": 0.018961694091558456,
      "learning_rate": 1.1926356589147288e-05,
      "loss": 0.0003,
      "step": 9823
    },
    {
      "epoch": 38.07751937984496,
      "grad_norm": 0.0014205016195774078,
      "learning_rate": 1.192248062015504e-05,
      "loss": 0.0001,
      "step": 9824
    },
    {
      "epoch": 38.08139534883721,
      "grad_norm": 0.00530607346445322,
      "learning_rate": 1.1918604651162791e-05,
      "loss": 0.0003,
      "step": 9825
    },
    {
      "epoch": 38.08527131782946,
      "grad_norm": 0.4899275302886963,
      "learning_rate": 1.1914728682170543e-05,
      "loss": 0.021,
      "step": 9826
    },
    {
      "epoch": 38.08914728682171,
      "grad_norm": 0.002728942548856139,
      "learning_rate": 1.1910852713178296e-05,
      "loss": 0.0001,
      "step": 9827
    },
    {
      "epoch": 38.093023255813954,
      "grad_norm": 0.003343976568430662,
      "learning_rate": 1.1906976744186048e-05,
      "loss": 0.0002,
      "step": 9828
    },
    {
      "epoch": 38.0968992248062,
      "grad_norm": 0.002547679701820016,
      "learning_rate": 1.1903100775193799e-05,
      "loss": 0.0002,
      "step": 9829
    },
    {
      "epoch": 38.10077519379845,
      "grad_norm": 0.001879344112239778,
      "learning_rate": 1.189922480620155e-05,
      "loss": 0.0001,
      "step": 9830
    },
    {
      "epoch": 38.104651162790695,
      "grad_norm": 0.004404257982969284,
      "learning_rate": 1.1895348837209302e-05,
      "loss": 0.0002,
      "step": 9831
    },
    {
      "epoch": 38.10852713178294,
      "grad_norm": 0.001086353906430304,
      "learning_rate": 1.1891472868217055e-05,
      "loss": 0.0001,
      "step": 9832
    },
    {
      "epoch": 38.1124031007752,
      "grad_norm": 0.0012793148634955287,
      "learning_rate": 1.1887596899224807e-05,
      "loss": 0.0001,
      "step": 9833
    },
    {
      "epoch": 38.116279069767444,
      "grad_norm": 0.5844908952713013,
      "learning_rate": 1.188372093023256e-05,
      "loss": 0.0239,
      "step": 9834
    },
    {
      "epoch": 38.12015503875969,
      "grad_norm": 0.0022955851163715124,
      "learning_rate": 1.187984496124031e-05,
      "loss": 0.0002,
      "step": 9835
    },
    {
      "epoch": 38.12403100775194,
      "grad_norm": 0.0011183514725416899,
      "learning_rate": 1.1875968992248063e-05,
      "loss": 0.0001,
      "step": 9836
    },
    {
      "epoch": 38.127906976744185,
      "grad_norm": 0.002029689960181713,
      "learning_rate": 1.1872093023255815e-05,
      "loss": 0.0001,
      "step": 9837
    },
    {
      "epoch": 38.13178294573643,
      "grad_norm": 0.009989381767809391,
      "learning_rate": 1.1868217054263567e-05,
      "loss": 0.0003,
      "step": 9838
    },
    {
      "epoch": 38.13565891472868,
      "grad_norm": 0.0021508350037038326,
      "learning_rate": 1.1864341085271318e-05,
      "loss": 0.0002,
      "step": 9839
    },
    {
      "epoch": 38.13953488372093,
      "grad_norm": 0.0035321065224707127,
      "learning_rate": 1.186046511627907e-05,
      "loss": 0.0002,
      "step": 9840
    },
    {
      "epoch": 38.14341085271318,
      "grad_norm": 0.0012878982815891504,
      "learning_rate": 1.1856589147286823e-05,
      "loss": 0.0001,
      "step": 9841
    },
    {
      "epoch": 38.14728682170543,
      "grad_norm": 0.0013602889375761151,
      "learning_rate": 1.1852713178294574e-05,
      "loss": 0.0001,
      "step": 9842
    },
    {
      "epoch": 38.151162790697676,
      "grad_norm": 0.0009180788183584809,
      "learning_rate": 1.1848837209302326e-05,
      "loss": 0.0001,
      "step": 9843
    },
    {
      "epoch": 38.15503875968992,
      "grad_norm": 0.000932903669308871,
      "learning_rate": 1.1844961240310077e-05,
      "loss": 0.0001,
      "step": 9844
    },
    {
      "epoch": 38.15891472868217,
      "grad_norm": 0.0009350748732686043,
      "learning_rate": 1.184108527131783e-05,
      "loss": 0.0001,
      "step": 9845
    },
    {
      "epoch": 38.16279069767442,
      "grad_norm": 3.9576637744903564,
      "learning_rate": 1.1837209302325582e-05,
      "loss": 0.4858,
      "step": 9846
    },
    {
      "epoch": 38.166666666666664,
      "grad_norm": 0.0013227147283032537,
      "learning_rate": 1.1833333333333334e-05,
      "loss": 0.0001,
      "step": 9847
    },
    {
      "epoch": 38.17054263565891,
      "grad_norm": 3.1697611808776855,
      "learning_rate": 1.1829457364341087e-05,
      "loss": 0.2616,
      "step": 9848
    },
    {
      "epoch": 38.174418604651166,
      "grad_norm": 0.0015545827336609364,
      "learning_rate": 1.1825581395348837e-05,
      "loss": 0.0001,
      "step": 9849
    },
    {
      "epoch": 38.17829457364341,
      "grad_norm": 0.001111782155930996,
      "learning_rate": 1.182170542635659e-05,
      "loss": 0.0001,
      "step": 9850
    },
    {
      "epoch": 38.18217054263566,
      "grad_norm": 0.001260647433809936,
      "learning_rate": 1.1817829457364342e-05,
      "loss": 0.0001,
      "step": 9851
    },
    {
      "epoch": 38.18604651162791,
      "grad_norm": 0.0012532189721241593,
      "learning_rate": 1.1813953488372095e-05,
      "loss": 0.0001,
      "step": 9852
    },
    {
      "epoch": 38.189922480620154,
      "grad_norm": 0.001216164673678577,
      "learning_rate": 1.1810077519379845e-05,
      "loss": 0.0001,
      "step": 9853
    },
    {
      "epoch": 38.1937984496124,
      "grad_norm": 0.001366405631415546,
      "learning_rate": 1.1806201550387598e-05,
      "loss": 0.0001,
      "step": 9854
    },
    {
      "epoch": 38.19767441860465,
      "grad_norm": 0.002084837295114994,
      "learning_rate": 1.1802325581395348e-05,
      "loss": 0.0001,
      "step": 9855
    },
    {
      "epoch": 38.201550387596896,
      "grad_norm": 0.0009368696482852101,
      "learning_rate": 1.17984496124031e-05,
      "loss": 0.0001,
      "step": 9856
    },
    {
      "epoch": 38.20542635658915,
      "grad_norm": 0.01113778818398714,
      "learning_rate": 1.1794573643410853e-05,
      "loss": 0.0002,
      "step": 9857
    },
    {
      "epoch": 38.2093023255814,
      "grad_norm": 0.0018851461354643106,
      "learning_rate": 1.1790697674418606e-05,
      "loss": 0.0001,
      "step": 9858
    },
    {
      "epoch": 38.213178294573645,
      "grad_norm": 0.9213189482688904,
      "learning_rate": 1.1786821705426356e-05,
      "loss": 0.0625,
      "step": 9859
    },
    {
      "epoch": 38.21705426356589,
      "grad_norm": 0.002853633603081107,
      "learning_rate": 1.1782945736434109e-05,
      "loss": 0.0001,
      "step": 9860
    },
    {
      "epoch": 38.22093023255814,
      "grad_norm": 0.0009813924552872777,
      "learning_rate": 1.1779069767441861e-05,
      "loss": 0.0001,
      "step": 9861
    },
    {
      "epoch": 38.224806201550386,
      "grad_norm": 0.004113445989787579,
      "learning_rate": 1.1775193798449614e-05,
      "loss": 0.0002,
      "step": 9862
    },
    {
      "epoch": 38.22868217054263,
      "grad_norm": 0.001420698594301939,
      "learning_rate": 1.1771317829457364e-05,
      "loss": 0.0001,
      "step": 9863
    },
    {
      "epoch": 38.23255813953488,
      "grad_norm": 0.0011340639321133494,
      "learning_rate": 1.1767441860465117e-05,
      "loss": 0.0001,
      "step": 9864
    },
    {
      "epoch": 38.236434108527135,
      "grad_norm": 0.0011967314640060067,
      "learning_rate": 1.176356589147287e-05,
      "loss": 0.0001,
      "step": 9865
    },
    {
      "epoch": 38.24031007751938,
      "grad_norm": 0.0016154740005731583,
      "learning_rate": 1.1759689922480622e-05,
      "loss": 0.0001,
      "step": 9866
    },
    {
      "epoch": 38.24418604651163,
      "grad_norm": 3.9604363441467285,
      "learning_rate": 1.1755813953488374e-05,
      "loss": 0.2919,
      "step": 9867
    },
    {
      "epoch": 38.248062015503876,
      "grad_norm": 0.0448799729347229,
      "learning_rate": 1.1751937984496125e-05,
      "loss": 0.0006,
      "step": 9868
    },
    {
      "epoch": 38.251937984496124,
      "grad_norm": 0.004641799721866846,
      "learning_rate": 1.1748062015503876e-05,
      "loss": 0.0003,
      "step": 9869
    },
    {
      "epoch": 38.25581395348837,
      "grad_norm": 0.008967969566583633,
      "learning_rate": 1.1744186046511628e-05,
      "loss": 0.0005,
      "step": 9870
    },
    {
      "epoch": 38.25968992248062,
      "grad_norm": 0.002776926616206765,
      "learning_rate": 1.174031007751938e-05,
      "loss": 0.0001,
      "step": 9871
    },
    {
      "epoch": 38.263565891472865,
      "grad_norm": 0.003740668995305896,
      "learning_rate": 1.1736434108527133e-05,
      "loss": 0.0003,
      "step": 9872
    },
    {
      "epoch": 38.26744186046512,
      "grad_norm": 0.7953160405158997,
      "learning_rate": 1.1732558139534884e-05,
      "loss": 0.0423,
      "step": 9873
    },
    {
      "epoch": 38.27131782945737,
      "grad_norm": 0.001164406887255609,
      "learning_rate": 1.1728682170542636e-05,
      "loss": 0.0001,
      "step": 9874
    },
    {
      "epoch": 38.275193798449614,
      "grad_norm": 1.2896959781646729,
      "learning_rate": 1.1724806201550388e-05,
      "loss": 0.0544,
      "step": 9875
    },
    {
      "epoch": 38.27906976744186,
      "grad_norm": 0.0014077640371397138,
      "learning_rate": 1.172093023255814e-05,
      "loss": 0.0001,
      "step": 9876
    },
    {
      "epoch": 38.28294573643411,
      "grad_norm": 0.007159833796322346,
      "learning_rate": 1.1717054263565892e-05,
      "loss": 0.0003,
      "step": 9877
    },
    {
      "epoch": 38.286821705426355,
      "grad_norm": 0.002277367515489459,
      "learning_rate": 1.1713178294573644e-05,
      "loss": 0.0001,
      "step": 9878
    },
    {
      "epoch": 38.2906976744186,
      "grad_norm": 0.004133516922593117,
      "learning_rate": 1.1709302325581396e-05,
      "loss": 0.0002,
      "step": 9879
    },
    {
      "epoch": 38.29457364341085,
      "grad_norm": 1.8349940776824951,
      "learning_rate": 1.1705426356589149e-05,
      "loss": 0.1207,
      "step": 9880
    },
    {
      "epoch": 38.298449612403104,
      "grad_norm": 0.00103701651096344,
      "learning_rate": 1.1701550387596901e-05,
      "loss": 0.0001,
      "step": 9881
    },
    {
      "epoch": 38.30232558139535,
      "grad_norm": 0.004000896587967873,
      "learning_rate": 1.1697674418604652e-05,
      "loss": 0.0002,
      "step": 9882
    },
    {
      "epoch": 38.3062015503876,
      "grad_norm": 0.0016687515890225768,
      "learning_rate": 1.1693798449612403e-05,
      "loss": 0.0001,
      "step": 9883
    },
    {
      "epoch": 38.310077519379846,
      "grad_norm": 0.0019074194133281708,
      "learning_rate": 1.1689922480620155e-05,
      "loss": 0.0002,
      "step": 9884
    },
    {
      "epoch": 38.31395348837209,
      "grad_norm": 0.001103367074392736,
      "learning_rate": 1.1686046511627907e-05,
      "loss": 0.0001,
      "step": 9885
    },
    {
      "epoch": 38.31782945736434,
      "grad_norm": 0.0010236852103844285,
      "learning_rate": 1.168217054263566e-05,
      "loss": 0.0001,
      "step": 9886
    },
    {
      "epoch": 38.32170542635659,
      "grad_norm": 0.004987817723304033,
      "learning_rate": 1.167829457364341e-05,
      "loss": 0.0003,
      "step": 9887
    },
    {
      "epoch": 38.325581395348834,
      "grad_norm": 0.005257348529994488,
      "learning_rate": 1.1674418604651163e-05,
      "loss": 0.0003,
      "step": 9888
    },
    {
      "epoch": 38.32945736434109,
      "grad_norm": 0.0020811562426388264,
      "learning_rate": 1.1670542635658915e-05,
      "loss": 0.0002,
      "step": 9889
    },
    {
      "epoch": 38.333333333333336,
      "grad_norm": 0.0010834407294169068,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.0001,
      "step": 9890
    },
    {
      "epoch": 38.33720930232558,
      "grad_norm": 0.00104871008079499,
      "learning_rate": 1.1662790697674419e-05,
      "loss": 0.0001,
      "step": 9891
    },
    {
      "epoch": 38.34108527131783,
      "grad_norm": 0.005148863419890404,
      "learning_rate": 1.1658914728682171e-05,
      "loss": 0.0003,
      "step": 9892
    },
    {
      "epoch": 38.34496124031008,
      "grad_norm": 0.0024971074890345335,
      "learning_rate": 1.1655038759689923e-05,
      "loss": 0.0002,
      "step": 9893
    },
    {
      "epoch": 38.348837209302324,
      "grad_norm": 0.001632726052775979,
      "learning_rate": 1.1651162790697676e-05,
      "loss": 0.0001,
      "step": 9894
    },
    {
      "epoch": 38.35271317829457,
      "grad_norm": 0.0025181868113577366,
      "learning_rate": 1.1647286821705427e-05,
      "loss": 0.0002,
      "step": 9895
    },
    {
      "epoch": 38.35658914728682,
      "grad_norm": 0.001534395618364215,
      "learning_rate": 1.1643410852713179e-05,
      "loss": 0.0002,
      "step": 9896
    },
    {
      "epoch": 38.36046511627907,
      "grad_norm": 0.05005398765206337,
      "learning_rate": 1.163953488372093e-05,
      "loss": 0.0004,
      "step": 9897
    },
    {
      "epoch": 38.36434108527132,
      "grad_norm": 1.2590276002883911,
      "learning_rate": 1.1635658914728682e-05,
      "loss": 0.0775,
      "step": 9898
    },
    {
      "epoch": 38.36821705426357,
      "grad_norm": 0.0030424403958022594,
      "learning_rate": 1.1631782945736435e-05,
      "loss": 0.0001,
      "step": 9899
    },
    {
      "epoch": 38.372093023255815,
      "grad_norm": 0.0018687521805986762,
      "learning_rate": 1.1627906976744187e-05,
      "loss": 0.0001,
      "step": 9900
    },
    {
      "epoch": 38.37596899224806,
      "grad_norm": 0.0010587809374555945,
      "learning_rate": 1.1624031007751938e-05,
      "loss": 0.0001,
      "step": 9901
    },
    {
      "epoch": 38.37984496124031,
      "grad_norm": 0.003095088293775916,
      "learning_rate": 1.162015503875969e-05,
      "loss": 0.0002,
      "step": 9902
    },
    {
      "epoch": 38.383720930232556,
      "grad_norm": 0.002745643025264144,
      "learning_rate": 1.1616279069767443e-05,
      "loss": 0.0002,
      "step": 9903
    },
    {
      "epoch": 38.3875968992248,
      "grad_norm": 0.0024309558793902397,
      "learning_rate": 1.1612403100775195e-05,
      "loss": 0.0002,
      "step": 9904
    },
    {
      "epoch": 38.39147286821706,
      "grad_norm": 0.01589391939342022,
      "learning_rate": 1.1608527131782947e-05,
      "loss": 0.0004,
      "step": 9905
    },
    {
      "epoch": 38.395348837209305,
      "grad_norm": 0.0027698250487446785,
      "learning_rate": 1.1604651162790698e-05,
      "loss": 0.0001,
      "step": 9906
    },
    {
      "epoch": 38.39922480620155,
      "grad_norm": 0.0020099589601159096,
      "learning_rate": 1.160077519379845e-05,
      "loss": 0.0001,
      "step": 9907
    },
    {
      "epoch": 38.4031007751938,
      "grad_norm": 0.15826326608657837,
      "learning_rate": 1.1596899224806203e-05,
      "loss": 0.0004,
      "step": 9908
    },
    {
      "epoch": 38.406976744186046,
      "grad_norm": 0.08210929483175278,
      "learning_rate": 1.1593023255813954e-05,
      "loss": 0.0004,
      "step": 9909
    },
    {
      "epoch": 38.41085271317829,
      "grad_norm": 0.001043695374391973,
      "learning_rate": 1.1589147286821706e-05,
      "loss": 0.0001,
      "step": 9910
    },
    {
      "epoch": 38.41472868217054,
      "grad_norm": 0.001027345540933311,
      "learning_rate": 1.1585271317829457e-05,
      "loss": 0.0001,
      "step": 9911
    },
    {
      "epoch": 38.41860465116279,
      "grad_norm": 0.0019618684891611338,
      "learning_rate": 1.158139534883721e-05,
      "loss": 0.0002,
      "step": 9912
    },
    {
      "epoch": 38.42248062015504,
      "grad_norm": 0.0011514897923916578,
      "learning_rate": 1.1577519379844962e-05,
      "loss": 0.0001,
      "step": 9913
    },
    {
      "epoch": 38.42635658914729,
      "grad_norm": 0.0009410547791048884,
      "learning_rate": 1.1573643410852714e-05,
      "loss": 0.0001,
      "step": 9914
    },
    {
      "epoch": 38.43023255813954,
      "grad_norm": 0.0008082510903477669,
      "learning_rate": 1.1569767441860465e-05,
      "loss": 0.0001,
      "step": 9915
    },
    {
      "epoch": 38.434108527131784,
      "grad_norm": 0.0009085966157726943,
      "learning_rate": 1.1565891472868217e-05,
      "loss": 0.0001,
      "step": 9916
    },
    {
      "epoch": 38.43798449612403,
      "grad_norm": 0.0010843415511772037,
      "learning_rate": 1.156201550387597e-05,
      "loss": 0.0001,
      "step": 9917
    },
    {
      "epoch": 38.44186046511628,
      "grad_norm": 0.001062350464053452,
      "learning_rate": 1.1558139534883722e-05,
      "loss": 0.0001,
      "step": 9918
    },
    {
      "epoch": 38.445736434108525,
      "grad_norm": 0.0058321766555309296,
      "learning_rate": 1.1554263565891475e-05,
      "loss": 0.0001,
      "step": 9919
    },
    {
      "epoch": 38.44961240310077,
      "grad_norm": 0.00115524313878268,
      "learning_rate": 1.1550387596899225e-05,
      "loss": 0.0001,
      "step": 9920
    },
    {
      "epoch": 38.45348837209303,
      "grad_norm": 3.4412472248077393,
      "learning_rate": 1.1546511627906978e-05,
      "loss": 0.016,
      "step": 9921
    },
    {
      "epoch": 38.457364341085274,
      "grad_norm": 0.0009301927639171481,
      "learning_rate": 1.1542635658914728e-05,
      "loss": 0.0001,
      "step": 9922
    },
    {
      "epoch": 38.46124031007752,
      "grad_norm": 0.8974776864051819,
      "learning_rate": 1.1538759689922481e-05,
      "loss": 0.0037,
      "step": 9923
    },
    {
      "epoch": 38.46511627906977,
      "grad_norm": 0.0015026378678157926,
      "learning_rate": 1.1534883720930233e-05,
      "loss": 0.0001,
      "step": 9924
    },
    {
      "epoch": 38.468992248062015,
      "grad_norm": 0.005207868292927742,
      "learning_rate": 1.1531007751937984e-05,
      "loss": 0.0002,
      "step": 9925
    },
    {
      "epoch": 38.47286821705426,
      "grad_norm": 0.0013942673103883862,
      "learning_rate": 1.1527131782945736e-05,
      "loss": 0.0001,
      "step": 9926
    },
    {
      "epoch": 38.47674418604651,
      "grad_norm": 0.0011938537936657667,
      "learning_rate": 1.1523255813953489e-05,
      "loss": 0.0001,
      "step": 9927
    },
    {
      "epoch": 38.48062015503876,
      "grad_norm": 0.002956698415800929,
      "learning_rate": 1.1519379844961241e-05,
      "loss": 0.0002,
      "step": 9928
    },
    {
      "epoch": 38.48449612403101,
      "grad_norm": 0.0030435496009886265,
      "learning_rate": 1.1515503875968994e-05,
      "loss": 0.0002,
      "step": 9929
    },
    {
      "epoch": 38.48837209302326,
      "grad_norm": 0.005931139457970858,
      "learning_rate": 1.1511627906976744e-05,
      "loss": 0.0003,
      "step": 9930
    },
    {
      "epoch": 38.492248062015506,
      "grad_norm": 0.0010766745544970036,
      "learning_rate": 1.1507751937984497e-05,
      "loss": 0.0001,
      "step": 9931
    },
    {
      "epoch": 38.49612403100775,
      "grad_norm": 0.0013135746121406555,
      "learning_rate": 1.150387596899225e-05,
      "loss": 0.0001,
      "step": 9932
    },
    {
      "epoch": 38.5,
      "grad_norm": 0.878528356552124,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 0.0306,
      "step": 9933
    },
    {
      "epoch": 38.50387596899225,
      "grad_norm": 0.001039744820445776,
      "learning_rate": 1.1496124031007752e-05,
      "loss": 0.0001,
      "step": 9934
    },
    {
      "epoch": 38.507751937984494,
      "grad_norm": 0.0011938052484765649,
      "learning_rate": 1.1492248062015503e-05,
      "loss": 0.0001,
      "step": 9935
    },
    {
      "epoch": 38.51162790697674,
      "grad_norm": 0.001095884246751666,
      "learning_rate": 1.1488372093023256e-05,
      "loss": 0.0001,
      "step": 9936
    },
    {
      "epoch": 38.51550387596899,
      "grad_norm": 0.0036010057665407658,
      "learning_rate": 1.1484496124031008e-05,
      "loss": 0.0002,
      "step": 9937
    },
    {
      "epoch": 38.51937984496124,
      "grad_norm": 0.0009914122056216002,
      "learning_rate": 1.148062015503876e-05,
      "loss": 0.0001,
      "step": 9938
    },
    {
      "epoch": 38.52325581395349,
      "grad_norm": 0.0016556372866034508,
      "learning_rate": 1.1476744186046511e-05,
      "loss": 0.0002,
      "step": 9939
    },
    {
      "epoch": 38.52713178294574,
      "grad_norm": 0.0011708583915606141,
      "learning_rate": 1.1472868217054264e-05,
      "loss": 0.0001,
      "step": 9940
    },
    {
      "epoch": 38.531007751937985,
      "grad_norm": 0.001862852368503809,
      "learning_rate": 1.1468992248062016e-05,
      "loss": 0.0002,
      "step": 9941
    },
    {
      "epoch": 38.53488372093023,
      "grad_norm": 0.0014820031356066465,
      "learning_rate": 1.1465116279069768e-05,
      "loss": 0.0001,
      "step": 9942
    },
    {
      "epoch": 38.53875968992248,
      "grad_norm": 0.0017491007456555963,
      "learning_rate": 1.146124031007752e-05,
      "loss": 0.0001,
      "step": 9943
    },
    {
      "epoch": 38.542635658914726,
      "grad_norm": 0.001020703581161797,
      "learning_rate": 1.1457364341085272e-05,
      "loss": 0.0001,
      "step": 9944
    },
    {
      "epoch": 38.54651162790697,
      "grad_norm": 0.001291594933718443,
      "learning_rate": 1.1453488372093024e-05,
      "loss": 0.0001,
      "step": 9945
    },
    {
      "epoch": 38.55038759689923,
      "grad_norm": 0.0013170792954042554,
      "learning_rate": 1.1449612403100776e-05,
      "loss": 0.0001,
      "step": 9946
    },
    {
      "epoch": 38.554263565891475,
      "grad_norm": 0.0012186056701466441,
      "learning_rate": 1.1445736434108529e-05,
      "loss": 0.0001,
      "step": 9947
    },
    {
      "epoch": 38.55813953488372,
      "grad_norm": 0.001265262020751834,
      "learning_rate": 1.144186046511628e-05,
      "loss": 0.0001,
      "step": 9948
    },
    {
      "epoch": 38.56201550387597,
      "grad_norm": 0.0011085926089435816,
      "learning_rate": 1.143798449612403e-05,
      "loss": 0.0001,
      "step": 9949
    },
    {
      "epoch": 38.565891472868216,
      "grad_norm": 0.0008767649997025728,
      "learning_rate": 1.1434108527131783e-05,
      "loss": 0.0001,
      "step": 9950
    },
    {
      "epoch": 38.56976744186046,
      "grad_norm": 0.0009965160861611366,
      "learning_rate": 1.1430232558139535e-05,
      "loss": 0.0001,
      "step": 9951
    },
    {
      "epoch": 38.57364341085271,
      "grad_norm": 0.001047348021529615,
      "learning_rate": 1.1426356589147288e-05,
      "loss": 0.0001,
      "step": 9952
    },
    {
      "epoch": 38.57751937984496,
      "grad_norm": 0.0016960182692855597,
      "learning_rate": 1.1422480620155038e-05,
      "loss": 0.0002,
      "step": 9953
    },
    {
      "epoch": 38.58139534883721,
      "grad_norm": 0.0016338597051799297,
      "learning_rate": 1.141860465116279e-05,
      "loss": 0.0001,
      "step": 9954
    },
    {
      "epoch": 38.58527131782946,
      "grad_norm": 1.0037657022476196,
      "learning_rate": 1.1414728682170543e-05,
      "loss": 0.1234,
      "step": 9955
    },
    {
      "epoch": 38.58914728682171,
      "grad_norm": 0.0010776956332847476,
      "learning_rate": 1.1410852713178296e-05,
      "loss": 0.0001,
      "step": 9956
    },
    {
      "epoch": 38.593023255813954,
      "grad_norm": 0.011297676712274551,
      "learning_rate": 1.1406976744186048e-05,
      "loss": 0.0002,
      "step": 9957
    },
    {
      "epoch": 38.5968992248062,
      "grad_norm": 0.24571743607521057,
      "learning_rate": 1.1403100775193799e-05,
      "loss": 0.0016,
      "step": 9958
    },
    {
      "epoch": 38.60077519379845,
      "grad_norm": 0.002788069425150752,
      "learning_rate": 1.1399224806201551e-05,
      "loss": 0.0001,
      "step": 9959
    },
    {
      "epoch": 38.604651162790695,
      "grad_norm": 0.0010879713809117675,
      "learning_rate": 1.1395348837209304e-05,
      "loss": 0.0001,
      "step": 9960
    },
    {
      "epoch": 38.60852713178294,
      "grad_norm": 0.5677609443664551,
      "learning_rate": 1.1391472868217056e-05,
      "loss": 0.024,
      "step": 9961
    },
    {
      "epoch": 38.6124031007752,
      "grad_norm": 0.0008435572381131351,
      "learning_rate": 1.1387596899224807e-05,
      "loss": 0.0001,
      "step": 9962
    },
    {
      "epoch": 38.616279069767444,
      "grad_norm": 0.5124709606170654,
      "learning_rate": 1.1383720930232557e-05,
      "loss": 0.0217,
      "step": 9963
    },
    {
      "epoch": 38.62015503875969,
      "grad_norm": 0.0019739505369216204,
      "learning_rate": 1.137984496124031e-05,
      "loss": 0.0001,
      "step": 9964
    },
    {
      "epoch": 38.62403100775194,
      "grad_norm": 0.004362557083368301,
      "learning_rate": 1.1375968992248062e-05,
      "loss": 0.0003,
      "step": 9965
    },
    {
      "epoch": 38.627906976744185,
      "grad_norm": 0.006082668900489807,
      "learning_rate": 1.1372093023255815e-05,
      "loss": 0.0003,
      "step": 9966
    },
    {
      "epoch": 38.63178294573643,
      "grad_norm": 0.0013960425276309252,
      "learning_rate": 1.1368217054263567e-05,
      "loss": 0.0001,
      "step": 9967
    },
    {
      "epoch": 38.63565891472868,
      "grad_norm": 0.000883027445524931,
      "learning_rate": 1.1364341085271318e-05,
      "loss": 0.0001,
      "step": 9968
    },
    {
      "epoch": 38.63953488372093,
      "grad_norm": 0.0010549480793997645,
      "learning_rate": 1.136046511627907e-05,
      "loss": 0.0001,
      "step": 9969
    },
    {
      "epoch": 38.64341085271318,
      "grad_norm": 0.0010504559613764286,
      "learning_rate": 1.1356589147286823e-05,
      "loss": 0.0001,
      "step": 9970
    },
    {
      "epoch": 38.64728682170543,
      "grad_norm": 0.000991995562799275,
      "learning_rate": 1.1352713178294575e-05,
      "loss": 0.0001,
      "step": 9971
    },
    {
      "epoch": 38.651162790697676,
      "grad_norm": 0.0012944621266797185,
      "learning_rate": 1.1348837209302326e-05,
      "loss": 0.0001,
      "step": 9972
    },
    {
      "epoch": 38.65503875968992,
      "grad_norm": 0.0008030474418774247,
      "learning_rate": 1.1344961240310078e-05,
      "loss": 0.0001,
      "step": 9973
    },
    {
      "epoch": 38.65891472868217,
      "grad_norm": 0.0012604602379724383,
      "learning_rate": 1.134108527131783e-05,
      "loss": 0.0001,
      "step": 9974
    },
    {
      "epoch": 38.66279069767442,
      "grad_norm": 0.0015975020360201597,
      "learning_rate": 1.1337209302325581e-05,
      "loss": 0.0002,
      "step": 9975
    },
    {
      "epoch": 38.666666666666664,
      "grad_norm": 0.004368835594505072,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.0003,
      "step": 9976
    },
    {
      "epoch": 38.67054263565891,
      "grad_norm": 0.012353215366601944,
      "learning_rate": 1.1329457364341085e-05,
      "loss": 0.0001,
      "step": 9977
    },
    {
      "epoch": 38.674418604651166,
      "grad_norm": 0.0010832392144948244,
      "learning_rate": 1.1325581395348837e-05,
      "loss": 0.0001,
      "step": 9978
    },
    {
      "epoch": 38.67829457364341,
      "grad_norm": 0.6605605483055115,
      "learning_rate": 1.132170542635659e-05,
      "loss": 0.0342,
      "step": 9979
    },
    {
      "epoch": 38.68217054263566,
      "grad_norm": 0.5811114311218262,
      "learning_rate": 1.1317829457364342e-05,
      "loss": 0.0159,
      "step": 9980
    },
    {
      "epoch": 38.68604651162791,
      "grad_norm": 0.0009728504810482264,
      "learning_rate": 1.1313953488372094e-05,
      "loss": 0.0001,
      "step": 9981
    },
    {
      "epoch": 38.689922480620154,
      "grad_norm": 0.0009749134769663215,
      "learning_rate": 1.1310077519379845e-05,
      "loss": 0.0001,
      "step": 9982
    },
    {
      "epoch": 38.6937984496124,
      "grad_norm": 0.005814634263515472,
      "learning_rate": 1.1306201550387597e-05,
      "loss": 0.0002,
      "step": 9983
    },
    {
      "epoch": 38.69767441860465,
      "grad_norm": 0.00213377526961267,
      "learning_rate": 1.130232558139535e-05,
      "loss": 0.0002,
      "step": 9984
    },
    {
      "epoch": 38.701550387596896,
      "grad_norm": 0.0015285564586520195,
      "learning_rate": 1.1298449612403102e-05,
      "loss": 0.0001,
      "step": 9985
    },
    {
      "epoch": 38.70542635658915,
      "grad_norm": 0.0025906332302838564,
      "learning_rate": 1.1294573643410853e-05,
      "loss": 0.0002,
      "step": 9986
    },
    {
      "epoch": 38.7093023255814,
      "grad_norm": 0.0008746571256779134,
      "learning_rate": 1.1290697674418605e-05,
      "loss": 0.0001,
      "step": 9987
    },
    {
      "epoch": 38.713178294573645,
      "grad_norm": 0.0010149867739528418,
      "learning_rate": 1.1286821705426358e-05,
      "loss": 0.0001,
      "step": 9988
    },
    {
      "epoch": 38.71705426356589,
      "grad_norm": 0.475686639547348,
      "learning_rate": 1.1282945736434109e-05,
      "loss": 0.0203,
      "step": 9989
    },
    {
      "epoch": 38.72093023255814,
      "grad_norm": 0.0007952461019158363,
      "learning_rate": 1.1279069767441861e-05,
      "loss": 0.0001,
      "step": 9990
    },
    {
      "epoch": 38.724806201550386,
      "grad_norm": 0.39057108759880066,
      "learning_rate": 1.1275193798449613e-05,
      "loss": 0.0161,
      "step": 9991
    },
    {
      "epoch": 38.72868217054263,
      "grad_norm": 0.0011789754498749971,
      "learning_rate": 1.1271317829457364e-05,
      "loss": 0.0001,
      "step": 9992
    },
    {
      "epoch": 38.73255813953488,
      "grad_norm": 0.0013910223497077823,
      "learning_rate": 1.1267441860465117e-05,
      "loss": 0.0001,
      "step": 9993
    },
    {
      "epoch": 38.736434108527135,
      "grad_norm": 0.0031948168762028217,
      "learning_rate": 1.1263565891472869e-05,
      "loss": 0.0002,
      "step": 9994
    },
    {
      "epoch": 38.74031007751938,
      "grad_norm": 0.0014278951566666365,
      "learning_rate": 1.1259689922480621e-05,
      "loss": 0.0001,
      "step": 9995
    },
    {
      "epoch": 38.74418604651163,
      "grad_norm": 0.0013119654031470418,
      "learning_rate": 1.1255813953488372e-05,
      "loss": 0.0001,
      "step": 9996
    },
    {
      "epoch": 38.748062015503876,
      "grad_norm": 0.0014310164842754602,
      "learning_rate": 1.1251937984496124e-05,
      "loss": 0.0001,
      "step": 9997
    },
    {
      "epoch": 38.751937984496124,
      "grad_norm": 0.0021656265016645193,
      "learning_rate": 1.1248062015503877e-05,
      "loss": 0.0002,
      "step": 9998
    },
    {
      "epoch": 38.75581395348837,
      "grad_norm": 0.0014698747545480728,
      "learning_rate": 1.124418604651163e-05,
      "loss": 0.0002,
      "step": 9999
    },
    {
      "epoch": 38.75968992248062,
      "grad_norm": 0.0008382229134440422,
      "learning_rate": 1.1240310077519382e-05,
      "loss": 0.0001,
      "step": 10000
    },
    {
      "epoch": 38.763565891472865,
      "grad_norm": 0.003002781420946121,
      "learning_rate": 1.1236434108527132e-05,
      "loss": 0.0002,
      "step": 10001
    },
    {
      "epoch": 38.76744186046512,
      "grad_norm": 0.0015710783191025257,
      "learning_rate": 1.1232558139534883e-05,
      "loss": 0.0001,
      "step": 10002
    },
    {
      "epoch": 38.77131782945737,
      "grad_norm": 0.0009511452517472208,
      "learning_rate": 1.1228682170542636e-05,
      "loss": 0.0001,
      "step": 10003
    },
    {
      "epoch": 38.775193798449614,
      "grad_norm": 0.0009635365568101406,
      "learning_rate": 1.1224806201550388e-05,
      "loss": 0.0001,
      "step": 10004
    },
    {
      "epoch": 38.77906976744186,
      "grad_norm": 0.001237405464053154,
      "learning_rate": 1.122093023255814e-05,
      "loss": 0.0001,
      "step": 10005
    },
    {
      "epoch": 38.78294573643411,
      "grad_norm": 0.0009815904777497053,
      "learning_rate": 1.1217054263565891e-05,
      "loss": 0.0001,
      "step": 10006
    },
    {
      "epoch": 38.786821705426355,
      "grad_norm": 0.0008678767480887473,
      "learning_rate": 1.1213178294573644e-05,
      "loss": 0.0001,
      "step": 10007
    },
    {
      "epoch": 38.7906976744186,
      "grad_norm": 0.0031453012488782406,
      "learning_rate": 1.1209302325581396e-05,
      "loss": 0.0002,
      "step": 10008
    },
    {
      "epoch": 38.79457364341085,
      "grad_norm": 0.0009990059770643711,
      "learning_rate": 1.1205426356589148e-05,
      "loss": 0.0001,
      "step": 10009
    },
    {
      "epoch": 38.798449612403104,
      "grad_norm": 0.5103404521942139,
      "learning_rate": 1.12015503875969e-05,
      "loss": 0.0024,
      "step": 10010
    },
    {
      "epoch": 38.80232558139535,
      "grad_norm": 0.47536617517471313,
      "learning_rate": 1.1197674418604652e-05,
      "loss": 0.0226,
      "step": 10011
    },
    {
      "epoch": 38.8062015503876,
      "grad_norm": 0.0012999800965189934,
      "learning_rate": 1.1193798449612404e-05,
      "loss": 0.0001,
      "step": 10012
    },
    {
      "epoch": 38.810077519379846,
      "grad_norm": 0.002396632684394717,
      "learning_rate": 1.1189922480620156e-05,
      "loss": 0.0001,
      "step": 10013
    },
    {
      "epoch": 38.81395348837209,
      "grad_norm": 0.0008243766496889293,
      "learning_rate": 1.1186046511627909e-05,
      "loss": 0.0001,
      "step": 10014
    },
    {
      "epoch": 38.81782945736434,
      "grad_norm": 0.00194078148342669,
      "learning_rate": 1.118217054263566e-05,
      "loss": 0.0001,
      "step": 10015
    },
    {
      "epoch": 38.82170542635659,
      "grad_norm": 0.0011039470555260777,
      "learning_rate": 1.117829457364341e-05,
      "loss": 0.0001,
      "step": 10016
    },
    {
      "epoch": 38.825581395348834,
      "grad_norm": 0.003390977857634425,
      "learning_rate": 1.1174418604651163e-05,
      "loss": 0.0002,
      "step": 10017
    },
    {
      "epoch": 38.82945736434109,
      "grad_norm": 0.0010547684505581856,
      "learning_rate": 1.1170542635658915e-05,
      "loss": 0.0001,
      "step": 10018
    },
    {
      "epoch": 38.833333333333336,
      "grad_norm": 0.0008400477818213403,
      "learning_rate": 1.1166666666666668e-05,
      "loss": 0.0001,
      "step": 10019
    },
    {
      "epoch": 38.83720930232558,
      "grad_norm": 0.0010060921777039766,
      "learning_rate": 1.1162790697674418e-05,
      "loss": 0.0001,
      "step": 10020
    },
    {
      "epoch": 38.84108527131783,
      "grad_norm": 0.0021428365726023912,
      "learning_rate": 1.115891472868217e-05,
      "loss": 0.0002,
      "step": 10021
    },
    {
      "epoch": 38.84496124031008,
      "grad_norm": 0.0009932683315128088,
      "learning_rate": 1.1155038759689923e-05,
      "loss": 0.0001,
      "step": 10022
    },
    {
      "epoch": 38.848837209302324,
      "grad_norm": 0.002281371271237731,
      "learning_rate": 1.1151162790697676e-05,
      "loss": 0.0002,
      "step": 10023
    },
    {
      "epoch": 38.85271317829457,
      "grad_norm": 0.0009398229885846376,
      "learning_rate": 1.1147286821705426e-05,
      "loss": 0.0001,
      "step": 10024
    },
    {
      "epoch": 38.85658914728682,
      "grad_norm": 0.001857822760939598,
      "learning_rate": 1.1143410852713179e-05,
      "loss": 0.0001,
      "step": 10025
    },
    {
      "epoch": 38.86046511627907,
      "grad_norm": 0.001827835338190198,
      "learning_rate": 1.1139534883720931e-05,
      "loss": 0.0002,
      "step": 10026
    },
    {
      "epoch": 38.86434108527132,
      "grad_norm": 0.0009667119011282921,
      "learning_rate": 1.1135658914728684e-05,
      "loss": 0.0001,
      "step": 10027
    },
    {
      "epoch": 38.86821705426357,
      "grad_norm": 0.0008397879428230226,
      "learning_rate": 1.1131782945736436e-05,
      "loss": 0.0001,
      "step": 10028
    },
    {
      "epoch": 38.872093023255815,
      "grad_norm": 46.48406219482422,
      "learning_rate": 1.1127906976744187e-05,
      "loss": 0.05,
      "step": 10029
    },
    {
      "epoch": 38.87596899224806,
      "grad_norm": 0.0008332172874361277,
      "learning_rate": 1.1124031007751937e-05,
      "loss": 0.0001,
      "step": 10030
    },
    {
      "epoch": 38.87984496124031,
      "grad_norm": 0.0008763970108702779,
      "learning_rate": 1.112015503875969e-05,
      "loss": 0.0001,
      "step": 10031
    },
    {
      "epoch": 38.883720930232556,
      "grad_norm": 0.0011016401695087552,
      "learning_rate": 1.1116279069767442e-05,
      "loss": 0.0001,
      "step": 10032
    },
    {
      "epoch": 38.8875968992248,
      "grad_norm": 0.0008515338413417339,
      "learning_rate": 1.1112403100775195e-05,
      "loss": 0.0001,
      "step": 10033
    },
    {
      "epoch": 38.89147286821706,
      "grad_norm": 0.0008242407930083573,
      "learning_rate": 1.1108527131782945e-05,
      "loss": 0.0001,
      "step": 10034
    },
    {
      "epoch": 38.895348837209305,
      "grad_norm": 0.001187393325380981,
      "learning_rate": 1.1104651162790698e-05,
      "loss": 0.0001,
      "step": 10035
    },
    {
      "epoch": 38.89922480620155,
      "grad_norm": 0.0013888221001252532,
      "learning_rate": 1.110077519379845e-05,
      "loss": 0.0001,
      "step": 10036
    },
    {
      "epoch": 38.9031007751938,
      "grad_norm": 0.0011473738122731447,
      "learning_rate": 1.1096899224806203e-05,
      "loss": 0.0001,
      "step": 10037
    },
    {
      "epoch": 38.906976744186046,
      "grad_norm": 0.0010887158568948507,
      "learning_rate": 1.1093023255813955e-05,
      "loss": 0.0001,
      "step": 10038
    },
    {
      "epoch": 38.91085271317829,
      "grad_norm": 0.0007910921704024076,
      "learning_rate": 1.1089147286821706e-05,
      "loss": 0.0001,
      "step": 10039
    },
    {
      "epoch": 38.91472868217054,
      "grad_norm": 0.0021089755464345217,
      "learning_rate": 1.1085271317829458e-05,
      "loss": 0.0001,
      "step": 10040
    },
    {
      "epoch": 38.91860465116279,
      "grad_norm": 0.0009808611357584596,
      "learning_rate": 1.108139534883721e-05,
      "loss": 0.0001,
      "step": 10041
    },
    {
      "epoch": 38.92248062015504,
      "grad_norm": 0.0017452192259952426,
      "learning_rate": 1.1077519379844961e-05,
      "loss": 0.0002,
      "step": 10042
    },
    {
      "epoch": 38.92635658914729,
      "grad_norm": 0.0007728195050731301,
      "learning_rate": 1.1073643410852714e-05,
      "loss": 0.0001,
      "step": 10043
    },
    {
      "epoch": 38.93023255813954,
      "grad_norm": 0.0010937753831967711,
      "learning_rate": 1.1069767441860465e-05,
      "loss": 0.0001,
      "step": 10044
    },
    {
      "epoch": 38.934108527131784,
      "grad_norm": 0.01751970872282982,
      "learning_rate": 1.1065891472868217e-05,
      "loss": 0.0001,
      "step": 10045
    },
    {
      "epoch": 38.93798449612403,
      "grad_norm": 0.0013335177209228277,
      "learning_rate": 1.106201550387597e-05,
      "loss": 0.0001,
      "step": 10046
    },
    {
      "epoch": 38.94186046511628,
      "grad_norm": 0.654700756072998,
      "learning_rate": 1.1058139534883722e-05,
      "loss": 0.0362,
      "step": 10047
    },
    {
      "epoch": 38.945736434108525,
      "grad_norm": 0.0037217841017991304,
      "learning_rate": 1.1054263565891473e-05,
      "loss": 0.0003,
      "step": 10048
    },
    {
      "epoch": 38.94961240310077,
      "grad_norm": 0.0009044742910191417,
      "learning_rate": 1.1050387596899225e-05,
      "loss": 0.0001,
      "step": 10049
    },
    {
      "epoch": 38.95348837209303,
      "grad_norm": 0.30307498574256897,
      "learning_rate": 1.1046511627906977e-05,
      "loss": 0.0043,
      "step": 10050
    },
    {
      "epoch": 38.957364341085274,
      "grad_norm": 0.0011850306764245033,
      "learning_rate": 1.104263565891473e-05,
      "loss": 0.0001,
      "step": 10051
    },
    {
      "epoch": 38.96124031007752,
      "grad_norm": 0.2007426619529724,
      "learning_rate": 1.1038759689922482e-05,
      "loss": 0.0012,
      "step": 10052
    },
    {
      "epoch": 38.96511627906977,
      "grad_norm": 0.0010739240096881986,
      "learning_rate": 1.1034883720930233e-05,
      "loss": 0.0001,
      "step": 10053
    },
    {
      "epoch": 38.968992248062015,
      "grad_norm": 0.0009041392477229238,
      "learning_rate": 1.1031007751937985e-05,
      "loss": 0.0001,
      "step": 10054
    },
    {
      "epoch": 38.97286821705426,
      "grad_norm": 0.0027523029129952192,
      "learning_rate": 1.1027131782945736e-05,
      "loss": 0.0002,
      "step": 10055
    },
    {
      "epoch": 38.97674418604651,
      "grad_norm": 0.0013658074894919991,
      "learning_rate": 1.1023255813953489e-05,
      "loss": 0.0001,
      "step": 10056
    },
    {
      "epoch": 38.98062015503876,
      "grad_norm": 0.22931407392024994,
      "learning_rate": 1.1019379844961241e-05,
      "loss": 0.0004,
      "step": 10057
    },
    {
      "epoch": 38.98449612403101,
      "grad_norm": 0.0025980661157518625,
      "learning_rate": 1.1015503875968992e-05,
      "loss": 0.0002,
      "step": 10058
    },
    {
      "epoch": 38.98837209302326,
      "grad_norm": 0.0009949753293767571,
      "learning_rate": 1.1011627906976744e-05,
      "loss": 0.0001,
      "step": 10059
    },
    {
      "epoch": 38.992248062015506,
      "grad_norm": 0.0008469884633086622,
      "learning_rate": 1.1007751937984497e-05,
      "loss": 0.0001,
      "step": 10060
    },
    {
      "epoch": 38.99612403100775,
      "grad_norm": 0.0007998945657163858,
      "learning_rate": 1.1003875968992249e-05,
      "loss": 0.0001,
      "step": 10061
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.0019449589308351278,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0001,
      "step": 10062
    },
    {
      "epoch": 39.00387596899225,
      "grad_norm": 0.001258370466530323,
      "learning_rate": 1.0996124031007752e-05,
      "loss": 0.0001,
      "step": 10063
    },
    {
      "epoch": 39.007751937984494,
      "grad_norm": 0.0009381708805449307,
      "learning_rate": 1.0992248062015505e-05,
      "loss": 0.0001,
      "step": 10064
    },
    {
      "epoch": 39.01162790697674,
      "grad_norm": 0.001305658370256424,
      "learning_rate": 1.0988372093023257e-05,
      "loss": 0.0001,
      "step": 10065
    },
    {
      "epoch": 39.01550387596899,
      "grad_norm": 0.0032896294724196196,
      "learning_rate": 1.098449612403101e-05,
      "loss": 0.0002,
      "step": 10066
    },
    {
      "epoch": 39.01937984496124,
      "grad_norm": 0.0009278390789404511,
      "learning_rate": 1.098062015503876e-05,
      "loss": 0.0001,
      "step": 10067
    },
    {
      "epoch": 39.02325581395349,
      "grad_norm": 0.0009302102844230831,
      "learning_rate": 1.0976744186046513e-05,
      "loss": 0.0001,
      "step": 10068
    },
    {
      "epoch": 39.02713178294574,
      "grad_norm": 0.0010083526140078902,
      "learning_rate": 1.0972868217054263e-05,
      "loss": 0.0001,
      "step": 10069
    },
    {
      "epoch": 39.031007751937985,
      "grad_norm": 0.0007529165013693273,
      "learning_rate": 1.0968992248062016e-05,
      "loss": 0.0001,
      "step": 10070
    },
    {
      "epoch": 39.03488372093023,
      "grad_norm": 0.023992475122213364,
      "learning_rate": 1.0965116279069768e-05,
      "loss": 0.0003,
      "step": 10071
    },
    {
      "epoch": 39.03875968992248,
      "grad_norm": 0.003096256172284484,
      "learning_rate": 1.0961240310077519e-05,
      "loss": 0.0002,
      "step": 10072
    },
    {
      "epoch": 39.042635658914726,
      "grad_norm": 0.0018771226750686765,
      "learning_rate": 1.0957364341085271e-05,
      "loss": 0.0001,
      "step": 10073
    },
    {
      "epoch": 39.04651162790697,
      "grad_norm": 0.0009625774691812694,
      "learning_rate": 1.0953488372093024e-05,
      "loss": 0.0001,
      "step": 10074
    },
    {
      "epoch": 39.05038759689923,
      "grad_norm": 0.000952117086853832,
      "learning_rate": 1.0949612403100776e-05,
      "loss": 0.0001,
      "step": 10075
    },
    {
      "epoch": 39.054263565891475,
      "grad_norm": 1.0247493982315063,
      "learning_rate": 1.0945736434108529e-05,
      "loss": 0.0529,
      "step": 10076
    },
    {
      "epoch": 39.05813953488372,
      "grad_norm": 0.00203226157464087,
      "learning_rate": 1.094186046511628e-05,
      "loss": 0.0001,
      "step": 10077
    },
    {
      "epoch": 39.06201550387597,
      "grad_norm": 0.010646688751876354,
      "learning_rate": 1.0937984496124032e-05,
      "loss": 0.0003,
      "step": 10078
    },
    {
      "epoch": 39.065891472868216,
      "grad_norm": 0.002765248529613018,
      "learning_rate": 1.0934108527131784e-05,
      "loss": 0.0002,
      "step": 10079
    },
    {
      "epoch": 39.06976744186046,
      "grad_norm": 0.0009196131723001599,
      "learning_rate": 1.0930232558139537e-05,
      "loss": 0.0001,
      "step": 10080
    },
    {
      "epoch": 39.07364341085271,
      "grad_norm": 0.001243413076736033,
      "learning_rate": 1.0926356589147287e-05,
      "loss": 0.0001,
      "step": 10081
    },
    {
      "epoch": 39.07751937984496,
      "grad_norm": 1.9176876544952393,
      "learning_rate": 1.0922480620155038e-05,
      "loss": 0.136,
      "step": 10082
    },
    {
      "epoch": 39.08139534883721,
      "grad_norm": 0.4111577570438385,
      "learning_rate": 1.091860465116279e-05,
      "loss": 0.0166,
      "step": 10083
    },
    {
      "epoch": 39.08527131782946,
      "grad_norm": 0.0007905911188572645,
      "learning_rate": 1.0914728682170543e-05,
      "loss": 0.0001,
      "step": 10084
    },
    {
      "epoch": 39.08914728682171,
      "grad_norm": 0.0013060657074674964,
      "learning_rate": 1.0910852713178295e-05,
      "loss": 0.0001,
      "step": 10085
    },
    {
      "epoch": 39.093023255813954,
      "grad_norm": 0.0007973448955453932,
      "learning_rate": 1.0906976744186046e-05,
      "loss": 0.0001,
      "step": 10086
    },
    {
      "epoch": 39.0968992248062,
      "grad_norm": 0.018705932423472404,
      "learning_rate": 1.0903100775193798e-05,
      "loss": 0.0005,
      "step": 10087
    },
    {
      "epoch": 39.10077519379845,
      "grad_norm": 0.0011047967709600925,
      "learning_rate": 1.089922480620155e-05,
      "loss": 0.0001,
      "step": 10088
    },
    {
      "epoch": 39.104651162790695,
      "grad_norm": 0.0015170694096013904,
      "learning_rate": 1.0895348837209303e-05,
      "loss": 0.0001,
      "step": 10089
    },
    {
      "epoch": 39.10852713178294,
      "grad_norm": 0.0032146440353244543,
      "learning_rate": 1.0891472868217056e-05,
      "loss": 0.0002,
      "step": 10090
    },
    {
      "epoch": 39.1124031007752,
      "grad_norm": 0.0019885357469320297,
      "learning_rate": 1.0887596899224806e-05,
      "loss": 0.0001,
      "step": 10091
    },
    {
      "epoch": 39.116279069767444,
      "grad_norm": 0.0014100607950240374,
      "learning_rate": 1.0883720930232559e-05,
      "loss": 0.0001,
      "step": 10092
    },
    {
      "epoch": 39.12015503875969,
      "grad_norm": 0.0009609284461475909,
      "learning_rate": 1.0879844961240311e-05,
      "loss": 0.0001,
      "step": 10093
    },
    {
      "epoch": 39.12403100775194,
      "grad_norm": 0.0019757200498133898,
      "learning_rate": 1.0875968992248064e-05,
      "loss": 0.0002,
      "step": 10094
    },
    {
      "epoch": 39.127906976744185,
      "grad_norm": 0.000949214561842382,
      "learning_rate": 1.0872093023255814e-05,
      "loss": 0.0001,
      "step": 10095
    },
    {
      "epoch": 39.13178294573643,
      "grad_norm": 0.0008454201160930097,
      "learning_rate": 1.0868217054263565e-05,
      "loss": 0.0001,
      "step": 10096
    },
    {
      "epoch": 39.13565891472868,
      "grad_norm": 0.15586979687213898,
      "learning_rate": 1.0864341085271318e-05,
      "loss": 0.0005,
      "step": 10097
    },
    {
      "epoch": 39.13953488372093,
      "grad_norm": 0.0037220548838377,
      "learning_rate": 1.086046511627907e-05,
      "loss": 0.0002,
      "step": 10098
    },
    {
      "epoch": 39.14341085271318,
      "grad_norm": 0.358399361371994,
      "learning_rate": 1.0856589147286822e-05,
      "loss": 0.0007,
      "step": 10099
    },
    {
      "epoch": 39.14728682170543,
      "grad_norm": 0.002177279908210039,
      "learning_rate": 1.0852713178294575e-05,
      "loss": 0.0001,
      "step": 10100
    },
    {
      "epoch": 39.151162790697676,
      "grad_norm": 0.005720986519008875,
      "learning_rate": 1.0848837209302326e-05,
      "loss": 0.0002,
      "step": 10101
    },
    {
      "epoch": 39.15503875968992,
      "grad_norm": 0.000936857599299401,
      "learning_rate": 1.0844961240310078e-05,
      "loss": 0.0001,
      "step": 10102
    },
    {
      "epoch": 39.15891472868217,
      "grad_norm": 0.0008214967674575746,
      "learning_rate": 1.084108527131783e-05,
      "loss": 0.0001,
      "step": 10103
    },
    {
      "epoch": 39.16279069767442,
      "grad_norm": 0.0020209671929478645,
      "learning_rate": 1.0837209302325583e-05,
      "loss": 0.0001,
      "step": 10104
    },
    {
      "epoch": 39.166666666666664,
      "grad_norm": 0.001197477919049561,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 0.0001,
      "step": 10105
    },
    {
      "epoch": 39.17054263565891,
      "grad_norm": 0.1698245257139206,
      "learning_rate": 1.0829457364341086e-05,
      "loss": 0.0067,
      "step": 10106
    },
    {
      "epoch": 39.174418604651166,
      "grad_norm": 0.0021651796996593475,
      "learning_rate": 1.0825581395348838e-05,
      "loss": 0.0002,
      "step": 10107
    },
    {
      "epoch": 39.17829457364341,
      "grad_norm": 0.002210375154390931,
      "learning_rate": 1.082170542635659e-05,
      "loss": 0.0002,
      "step": 10108
    },
    {
      "epoch": 39.18217054263566,
      "grad_norm": 0.0010310678044334054,
      "learning_rate": 1.0817829457364342e-05,
      "loss": 0.0001,
      "step": 10109
    },
    {
      "epoch": 39.18604651162791,
      "grad_norm": 0.0011027117725461721,
      "learning_rate": 1.0813953488372092e-05,
      "loss": 0.0001,
      "step": 10110
    },
    {
      "epoch": 39.189922480620154,
      "grad_norm": 0.0009022112935781479,
      "learning_rate": 1.0810077519379845e-05,
      "loss": 0.0001,
      "step": 10111
    },
    {
      "epoch": 39.1937984496124,
      "grad_norm": 0.0012538883602246642,
      "learning_rate": 1.0806201550387597e-05,
      "loss": 0.0001,
      "step": 10112
    },
    {
      "epoch": 39.19767441860465,
      "grad_norm": 0.0011697063455358148,
      "learning_rate": 1.080232558139535e-05,
      "loss": 0.0001,
      "step": 10113
    },
    {
      "epoch": 39.201550387596896,
      "grad_norm": 0.0009242121013812721,
      "learning_rate": 1.0798449612403102e-05,
      "loss": 0.0001,
      "step": 10114
    },
    {
      "epoch": 39.20542635658915,
      "grad_norm": 0.0008925861329771578,
      "learning_rate": 1.0794573643410853e-05,
      "loss": 0.0001,
      "step": 10115
    },
    {
      "epoch": 39.2093023255814,
      "grad_norm": 0.002699628472328186,
      "learning_rate": 1.0790697674418605e-05,
      "loss": 0.0002,
      "step": 10116
    },
    {
      "epoch": 39.213178294573645,
      "grad_norm": 0.0038169536273926497,
      "learning_rate": 1.0786821705426357e-05,
      "loss": 0.0001,
      "step": 10117
    },
    {
      "epoch": 39.21705426356589,
      "grad_norm": 0.0009393980726599693,
      "learning_rate": 1.078294573643411e-05,
      "loss": 0.0001,
      "step": 10118
    },
    {
      "epoch": 39.22093023255814,
      "grad_norm": 0.0007873974391259253,
      "learning_rate": 1.077906976744186e-05,
      "loss": 0.0001,
      "step": 10119
    },
    {
      "epoch": 39.224806201550386,
      "grad_norm": 0.0010756045812740922,
      "learning_rate": 1.0775193798449613e-05,
      "loss": 0.0001,
      "step": 10120
    },
    {
      "epoch": 39.22868217054263,
      "grad_norm": 0.0007942001102492213,
      "learning_rate": 1.0771317829457365e-05,
      "loss": 0.0001,
      "step": 10121
    },
    {
      "epoch": 39.23255813953488,
      "grad_norm": 0.004795114975422621,
      "learning_rate": 1.0767441860465116e-05,
      "loss": 0.0003,
      "step": 10122
    },
    {
      "epoch": 39.236434108527135,
      "grad_norm": 0.1647861748933792,
      "learning_rate": 1.0763565891472869e-05,
      "loss": 0.0064,
      "step": 10123
    },
    {
      "epoch": 39.24031007751938,
      "grad_norm": 0.0008631515665911138,
      "learning_rate": 1.0759689922480621e-05,
      "loss": 0.0001,
      "step": 10124
    },
    {
      "epoch": 39.24418604651163,
      "grad_norm": 0.0010952542070299387,
      "learning_rate": 1.0755813953488372e-05,
      "loss": 0.0001,
      "step": 10125
    },
    {
      "epoch": 39.248062015503876,
      "grad_norm": 0.0009391876519657671,
      "learning_rate": 1.0751937984496124e-05,
      "loss": 0.0001,
      "step": 10126
    },
    {
      "epoch": 39.251937984496124,
      "grad_norm": 0.0010871447157114744,
      "learning_rate": 1.0748062015503877e-05,
      "loss": 0.0001,
      "step": 10127
    },
    {
      "epoch": 39.25581395348837,
      "grad_norm": 0.0011473266640678048,
      "learning_rate": 1.0744186046511629e-05,
      "loss": 0.0001,
      "step": 10128
    },
    {
      "epoch": 39.25968992248062,
      "grad_norm": 0.0022638391237705946,
      "learning_rate": 1.074031007751938e-05,
      "loss": 0.0001,
      "step": 10129
    },
    {
      "epoch": 39.263565891472865,
      "grad_norm": 0.0007887695101089776,
      "learning_rate": 1.0736434108527132e-05,
      "loss": 0.0001,
      "step": 10130
    },
    {
      "epoch": 39.26744186046512,
      "grad_norm": 0.0011481557739898562,
      "learning_rate": 1.0732558139534885e-05,
      "loss": 0.0001,
      "step": 10131
    },
    {
      "epoch": 39.27131782945737,
      "grad_norm": 0.001606354140676558,
      "learning_rate": 1.0728682170542637e-05,
      "loss": 0.0001,
      "step": 10132
    },
    {
      "epoch": 39.275193798449614,
      "grad_norm": 0.09009111672639847,
      "learning_rate": 1.072480620155039e-05,
      "loss": 0.0004,
      "step": 10133
    },
    {
      "epoch": 39.27906976744186,
      "grad_norm": 0.0018858766416087747,
      "learning_rate": 1.072093023255814e-05,
      "loss": 0.0001,
      "step": 10134
    },
    {
      "epoch": 39.28294573643411,
      "grad_norm": 0.0013052801368758082,
      "learning_rate": 1.0717054263565891e-05,
      "loss": 0.0001,
      "step": 10135
    },
    {
      "epoch": 39.286821705426355,
      "grad_norm": 0.0010078123304992914,
      "learning_rate": 1.0713178294573643e-05,
      "loss": 0.0001,
      "step": 10136
    },
    {
      "epoch": 39.2906976744186,
      "grad_norm": 0.0012732428731396794,
      "learning_rate": 1.0709302325581396e-05,
      "loss": 0.0001,
      "step": 10137
    },
    {
      "epoch": 39.29457364341085,
      "grad_norm": 0.0008647989598102868,
      "learning_rate": 1.0705426356589148e-05,
      "loss": 0.0001,
      "step": 10138
    },
    {
      "epoch": 39.298449612403104,
      "grad_norm": 0.001846532803028822,
      "learning_rate": 1.0701550387596899e-05,
      "loss": 0.0001,
      "step": 10139
    },
    {
      "epoch": 39.30232558139535,
      "grad_norm": 0.0012286233250051737,
      "learning_rate": 1.0697674418604651e-05,
      "loss": 0.0001,
      "step": 10140
    },
    {
      "epoch": 39.3062015503876,
      "grad_norm": 0.0008933497010730207,
      "learning_rate": 1.0693798449612404e-05,
      "loss": 0.0001,
      "step": 10141
    },
    {
      "epoch": 39.310077519379846,
      "grad_norm": 0.007676822133362293,
      "learning_rate": 1.0689922480620156e-05,
      "loss": 0.0002,
      "step": 10142
    },
    {
      "epoch": 39.31395348837209,
      "grad_norm": 0.0012570450780913234,
      "learning_rate": 1.0686046511627907e-05,
      "loss": 0.0001,
      "step": 10143
    },
    {
      "epoch": 39.31782945736434,
      "grad_norm": 0.0009683473617769778,
      "learning_rate": 1.068217054263566e-05,
      "loss": 0.0001,
      "step": 10144
    },
    {
      "epoch": 39.32170542635659,
      "grad_norm": 0.0008254405693151057,
      "learning_rate": 1.0678294573643412e-05,
      "loss": 0.0001,
      "step": 10145
    },
    {
      "epoch": 39.325581395348834,
      "grad_norm": 2.12858247756958,
      "learning_rate": 1.0674418604651164e-05,
      "loss": 0.0973,
      "step": 10146
    },
    {
      "epoch": 39.32945736434109,
      "grad_norm": 0.0009931093081831932,
      "learning_rate": 1.0670542635658917e-05,
      "loss": 0.0001,
      "step": 10147
    },
    {
      "epoch": 39.333333333333336,
      "grad_norm": 0.0012701089726760983,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.0001,
      "step": 10148
    },
    {
      "epoch": 39.33720930232558,
      "grad_norm": 0.001194017007946968,
      "learning_rate": 1.0662790697674418e-05,
      "loss": 0.0001,
      "step": 10149
    },
    {
      "epoch": 39.34108527131783,
      "grad_norm": 0.0012005770113319159,
      "learning_rate": 1.065891472868217e-05,
      "loss": 0.0001,
      "step": 10150
    },
    {
      "epoch": 39.34496124031008,
      "grad_norm": 0.0009440736030228436,
      "learning_rate": 1.0655038759689923e-05,
      "loss": 0.0001,
      "step": 10151
    },
    {
      "epoch": 39.348837209302324,
      "grad_norm": 0.1275421679019928,
      "learning_rate": 1.0651162790697675e-05,
      "loss": 0.0053,
      "step": 10152
    },
    {
      "epoch": 39.35271317829457,
      "grad_norm": 0.0012500648153945804,
      "learning_rate": 1.0647286821705426e-05,
      "loss": 0.0001,
      "step": 10153
    },
    {
      "epoch": 39.35658914728682,
      "grad_norm": 0.0011358632473275065,
      "learning_rate": 1.0643410852713178e-05,
      "loss": 0.0001,
      "step": 10154
    },
    {
      "epoch": 39.36046511627907,
      "grad_norm": 0.0012101035099476576,
      "learning_rate": 1.0639534883720931e-05,
      "loss": 0.0001,
      "step": 10155
    },
    {
      "epoch": 39.36434108527132,
      "grad_norm": 0.0012891244841739535,
      "learning_rate": 1.0635658914728683e-05,
      "loss": 0.0001,
      "step": 10156
    },
    {
      "epoch": 39.36821705426357,
      "grad_norm": 0.0008602851303294301,
      "learning_rate": 1.0631782945736434e-05,
      "loss": 0.0001,
      "step": 10157
    },
    {
      "epoch": 39.372093023255815,
      "grad_norm": 0.0008007996948435903,
      "learning_rate": 1.0627906976744186e-05,
      "loss": 0.0001,
      "step": 10158
    },
    {
      "epoch": 39.37596899224806,
      "grad_norm": 0.0026859380304813385,
      "learning_rate": 1.0624031007751939e-05,
      "loss": 0.0002,
      "step": 10159
    },
    {
      "epoch": 39.37984496124031,
      "grad_norm": 0.0010376357240602374,
      "learning_rate": 1.0620155038759691e-05,
      "loss": 0.0001,
      "step": 10160
    },
    {
      "epoch": 39.383720930232556,
      "grad_norm": 0.0014067328302189708,
      "learning_rate": 1.0616279069767444e-05,
      "loss": 0.0001,
      "step": 10161
    },
    {
      "epoch": 39.3875968992248,
      "grad_norm": 0.0009027683408930898,
      "learning_rate": 1.0612403100775194e-05,
      "loss": 0.0001,
      "step": 10162
    },
    {
      "epoch": 39.39147286821706,
      "grad_norm": 0.0008723597857169807,
      "learning_rate": 1.0608527131782945e-05,
      "loss": 0.0001,
      "step": 10163
    },
    {
      "epoch": 39.395348837209305,
      "grad_norm": 0.0012623514048755169,
      "learning_rate": 1.0604651162790698e-05,
      "loss": 0.0001,
      "step": 10164
    },
    {
      "epoch": 39.39922480620155,
      "grad_norm": 0.001518645673058927,
      "learning_rate": 1.060077519379845e-05,
      "loss": 0.0001,
      "step": 10165
    },
    {
      "epoch": 39.4031007751938,
      "grad_norm": 0.00199634931050241,
      "learning_rate": 1.0596899224806202e-05,
      "loss": 0.0002,
      "step": 10166
    },
    {
      "epoch": 39.406976744186046,
      "grad_norm": 0.0018891750369220972,
      "learning_rate": 1.0593023255813953e-05,
      "loss": 0.0001,
      "step": 10167
    },
    {
      "epoch": 39.41085271317829,
      "grad_norm": 0.0012479092692956328,
      "learning_rate": 1.0589147286821706e-05,
      "loss": 0.0001,
      "step": 10168
    },
    {
      "epoch": 39.41472868217054,
      "grad_norm": 0.0011611463269218802,
      "learning_rate": 1.0585271317829458e-05,
      "loss": 0.0001,
      "step": 10169
    },
    {
      "epoch": 39.41860465116279,
      "grad_norm": 0.0010227643651887774,
      "learning_rate": 1.058139534883721e-05,
      "loss": 0.0001,
      "step": 10170
    },
    {
      "epoch": 39.42248062015504,
      "grad_norm": 0.0007294238894246519,
      "learning_rate": 1.0577519379844963e-05,
      "loss": 0.0001,
      "step": 10171
    },
    {
      "epoch": 39.42635658914729,
      "grad_norm": 0.0007512134616263211,
      "learning_rate": 1.0573643410852714e-05,
      "loss": 0.0001,
      "step": 10172
    },
    {
      "epoch": 39.43023255813954,
      "grad_norm": 0.0031238936353474855,
      "learning_rate": 1.0569767441860466e-05,
      "loss": 0.0003,
      "step": 10173
    },
    {
      "epoch": 39.434108527131784,
      "grad_norm": 0.001383720664307475,
      "learning_rate": 1.0565891472868218e-05,
      "loss": 0.0001,
      "step": 10174
    },
    {
      "epoch": 39.43798449612403,
      "grad_norm": 0.0008796584443189204,
      "learning_rate": 1.0562015503875969e-05,
      "loss": 0.0001,
      "step": 10175
    },
    {
      "epoch": 39.44186046511628,
      "grad_norm": 0.1457117199897766,
      "learning_rate": 1.0558139534883722e-05,
      "loss": 0.0062,
      "step": 10176
    },
    {
      "epoch": 39.445736434108525,
      "grad_norm": 0.0010336836567148566,
      "learning_rate": 1.0554263565891472e-05,
      "loss": 0.0001,
      "step": 10177
    },
    {
      "epoch": 39.44961240310077,
      "grad_norm": 0.0010354528203606606,
      "learning_rate": 1.0550387596899225e-05,
      "loss": 0.0001,
      "step": 10178
    },
    {
      "epoch": 39.45348837209303,
      "grad_norm": 0.001495251664891839,
      "learning_rate": 1.0546511627906977e-05,
      "loss": 0.0001,
      "step": 10179
    },
    {
      "epoch": 39.457364341085274,
      "grad_norm": 0.001857874565757811,
      "learning_rate": 1.054263565891473e-05,
      "loss": 0.0002,
      "step": 10180
    },
    {
      "epoch": 39.46124031007752,
      "grad_norm": 0.0016185288550332189,
      "learning_rate": 1.053875968992248e-05,
      "loss": 0.0002,
      "step": 10181
    },
    {
      "epoch": 39.46511627906977,
      "grad_norm": 0.15719132125377655,
      "learning_rate": 1.0534883720930233e-05,
      "loss": 0.0076,
      "step": 10182
    },
    {
      "epoch": 39.468992248062015,
      "grad_norm": 0.002231815829873085,
      "learning_rate": 1.0531007751937985e-05,
      "loss": 0.0001,
      "step": 10183
    },
    {
      "epoch": 39.47286821705426,
      "grad_norm": 0.0017286530928686261,
      "learning_rate": 1.0527131782945738e-05,
      "loss": 0.0002,
      "step": 10184
    },
    {
      "epoch": 39.47674418604651,
      "grad_norm": 0.0010965225519612432,
      "learning_rate": 1.052325581395349e-05,
      "loss": 0.0001,
      "step": 10185
    },
    {
      "epoch": 39.48062015503876,
      "grad_norm": 0.0026783833745867014,
      "learning_rate": 1.051937984496124e-05,
      "loss": 0.0002,
      "step": 10186
    },
    {
      "epoch": 39.48449612403101,
      "grad_norm": 0.0021443553268909454,
      "learning_rate": 1.0515503875968993e-05,
      "loss": 0.0001,
      "step": 10187
    },
    {
      "epoch": 39.48837209302326,
      "grad_norm": 0.0011158832348883152,
      "learning_rate": 1.0511627906976746e-05,
      "loss": 0.0001,
      "step": 10188
    },
    {
      "epoch": 39.492248062015506,
      "grad_norm": 0.0017964034341275692,
      "learning_rate": 1.0507751937984496e-05,
      "loss": 0.0001,
      "step": 10189
    },
    {
      "epoch": 39.49612403100775,
      "grad_norm": 0.0011236324207857251,
      "learning_rate": 1.0503875968992249e-05,
      "loss": 0.0001,
      "step": 10190
    },
    {
      "epoch": 39.5,
      "grad_norm": 0.0009312658803537488,
      "learning_rate": 1.05e-05,
      "loss": 0.0001,
      "step": 10191
    },
    {
      "epoch": 39.50387596899225,
      "grad_norm": 0.0010743013117462397,
      "learning_rate": 1.0496124031007752e-05,
      "loss": 0.0001,
      "step": 10192
    },
    {
      "epoch": 39.507751937984494,
      "grad_norm": 0.0009703173418529332,
      "learning_rate": 1.0492248062015504e-05,
      "loss": 0.0001,
      "step": 10193
    },
    {
      "epoch": 39.51162790697674,
      "grad_norm": 0.0011990739731118083,
      "learning_rate": 1.0488372093023257e-05,
      "loss": 0.0001,
      "step": 10194
    },
    {
      "epoch": 39.51550387596899,
      "grad_norm": 0.0008956067031249404,
      "learning_rate": 1.0484496124031009e-05,
      "loss": 0.0001,
      "step": 10195
    },
    {
      "epoch": 39.51937984496124,
      "grad_norm": 0.0008821982191875577,
      "learning_rate": 1.048062015503876e-05,
      "loss": 0.0001,
      "step": 10196
    },
    {
      "epoch": 39.52325581395349,
      "grad_norm": 0.001718035782687366,
      "learning_rate": 1.0476744186046512e-05,
      "loss": 0.0002,
      "step": 10197
    },
    {
      "epoch": 39.52713178294574,
      "grad_norm": 1.5967808961868286,
      "learning_rate": 1.0472868217054265e-05,
      "loss": 0.1774,
      "step": 10198
    },
    {
      "epoch": 39.531007751937985,
      "grad_norm": 0.0014798373449593782,
      "learning_rate": 1.0468992248062017e-05,
      "loss": 0.0001,
      "step": 10199
    },
    {
      "epoch": 39.53488372093023,
      "grad_norm": 0.0007574444753117859,
      "learning_rate": 1.0465116279069768e-05,
      "loss": 0.0001,
      "step": 10200
    },
    {
      "epoch": 39.53875968992248,
      "grad_norm": 0.001593131455592811,
      "learning_rate": 1.046124031007752e-05,
      "loss": 0.0002,
      "step": 10201
    },
    {
      "epoch": 39.542635658914726,
      "grad_norm": 0.0009045192273333669,
      "learning_rate": 1.0457364341085271e-05,
      "loss": 0.0001,
      "step": 10202
    },
    {
      "epoch": 39.54651162790697,
      "grad_norm": 0.0012704788241535425,
      "learning_rate": 1.0453488372093023e-05,
      "loss": 0.0001,
      "step": 10203
    },
    {
      "epoch": 39.55038759689923,
      "grad_norm": 0.0012958773877471685,
      "learning_rate": 1.0449612403100776e-05,
      "loss": 0.0001,
      "step": 10204
    },
    {
      "epoch": 39.554263565891475,
      "grad_norm": 0.0013203800190240145,
      "learning_rate": 1.0445736434108527e-05,
      "loss": 0.0001,
      "step": 10205
    },
    {
      "epoch": 39.55813953488372,
      "grad_norm": 0.0007699485868215561,
      "learning_rate": 1.0441860465116279e-05,
      "loss": 0.0001,
      "step": 10206
    },
    {
      "epoch": 39.56201550387597,
      "grad_norm": 0.007817930541932583,
      "learning_rate": 1.0437984496124031e-05,
      "loss": 0.0001,
      "step": 10207
    },
    {
      "epoch": 39.565891472868216,
      "grad_norm": 0.0010000519687309861,
      "learning_rate": 1.0434108527131784e-05,
      "loss": 0.0001,
      "step": 10208
    },
    {
      "epoch": 39.56976744186046,
      "grad_norm": 0.0008880924433469772,
      "learning_rate": 1.0430232558139536e-05,
      "loss": 0.0001,
      "step": 10209
    },
    {
      "epoch": 39.57364341085271,
      "grad_norm": 0.005954957567155361,
      "learning_rate": 1.0426356589147287e-05,
      "loss": 0.0001,
      "step": 10210
    },
    {
      "epoch": 39.57751937984496,
      "grad_norm": 0.869927167892456,
      "learning_rate": 1.042248062015504e-05,
      "loss": 0.0489,
      "step": 10211
    },
    {
      "epoch": 39.58139534883721,
      "grad_norm": 0.0010587633587419987,
      "learning_rate": 1.0418604651162792e-05,
      "loss": 0.0001,
      "step": 10212
    },
    {
      "epoch": 39.58527131782946,
      "grad_norm": 2.934096336364746,
      "learning_rate": 1.0414728682170544e-05,
      "loss": 0.3212,
      "step": 10213
    },
    {
      "epoch": 39.58914728682171,
      "grad_norm": 0.0008062768029049039,
      "learning_rate": 1.0410852713178295e-05,
      "loss": 0.0001,
      "step": 10214
    },
    {
      "epoch": 39.593023255813954,
      "grad_norm": 0.0008255003485828638,
      "learning_rate": 1.0406976744186046e-05,
      "loss": 0.0001,
      "step": 10215
    },
    {
      "epoch": 39.5968992248062,
      "grad_norm": 0.0011642405297607183,
      "learning_rate": 1.0403100775193798e-05,
      "loss": 0.0001,
      "step": 10216
    },
    {
      "epoch": 39.60077519379845,
      "grad_norm": 0.0007549982401542366,
      "learning_rate": 1.039922480620155e-05,
      "loss": 0.0001,
      "step": 10217
    },
    {
      "epoch": 39.604651162790695,
      "grad_norm": 0.0012436725664883852,
      "learning_rate": 1.0395348837209303e-05,
      "loss": 0.0001,
      "step": 10218
    },
    {
      "epoch": 39.60852713178294,
      "grad_norm": 0.42616888880729675,
      "learning_rate": 1.0391472868217054e-05,
      "loss": 0.0165,
      "step": 10219
    },
    {
      "epoch": 39.6124031007752,
      "grad_norm": 0.001560495002195239,
      "learning_rate": 1.0387596899224806e-05,
      "loss": 0.0002,
      "step": 10220
    },
    {
      "epoch": 39.616279069767444,
      "grad_norm": 0.0013828299706801772,
      "learning_rate": 1.0383720930232559e-05,
      "loss": 0.0001,
      "step": 10221
    },
    {
      "epoch": 39.62015503875969,
      "grad_norm": 0.0044358521699905396,
      "learning_rate": 1.0379844961240311e-05,
      "loss": 0.0002,
      "step": 10222
    },
    {
      "epoch": 39.62403100775194,
      "grad_norm": 0.0006866286275908351,
      "learning_rate": 1.0375968992248063e-05,
      "loss": 0.0001,
      "step": 10223
    },
    {
      "epoch": 39.627906976744185,
      "grad_norm": 0.0008335232269018888,
      "learning_rate": 1.0372093023255814e-05,
      "loss": 0.0001,
      "step": 10224
    },
    {
      "epoch": 39.63178294573643,
      "grad_norm": 0.001066430937498808,
      "learning_rate": 1.0368217054263567e-05,
      "loss": 0.0001,
      "step": 10225
    },
    {
      "epoch": 39.63565891472868,
      "grad_norm": 0.0015553251141682267,
      "learning_rate": 1.0364341085271319e-05,
      "loss": 0.0001,
      "step": 10226
    },
    {
      "epoch": 39.63953488372093,
      "grad_norm": 0.0011339121265336871,
      "learning_rate": 1.0360465116279071e-05,
      "loss": 0.0001,
      "step": 10227
    },
    {
      "epoch": 39.64341085271318,
      "grad_norm": 0.0015072240494191647,
      "learning_rate": 1.0356589147286822e-05,
      "loss": 0.0002,
      "step": 10228
    },
    {
      "epoch": 39.64728682170543,
      "grad_norm": 0.0015675053000450134,
      "learning_rate": 1.0352713178294573e-05,
      "loss": 0.0001,
      "step": 10229
    },
    {
      "epoch": 39.651162790697676,
      "grad_norm": 0.0008977376855909824,
      "learning_rate": 1.0348837209302325e-05,
      "loss": 0.0001,
      "step": 10230
    },
    {
      "epoch": 39.65503875968992,
      "grad_norm": 0.0014682098990306258,
      "learning_rate": 1.0344961240310078e-05,
      "loss": 0.0001,
      "step": 10231
    },
    {
      "epoch": 39.65891472868217,
      "grad_norm": 0.0009756861836649477,
      "learning_rate": 1.034108527131783e-05,
      "loss": 0.0001,
      "step": 10232
    },
    {
      "epoch": 39.66279069767442,
      "grad_norm": 2.66003155708313,
      "learning_rate": 1.0337209302325582e-05,
      "loss": 0.0081,
      "step": 10233
    },
    {
      "epoch": 39.666666666666664,
      "grad_norm": 0.0012523093027994037,
      "learning_rate": 1.0333333333333333e-05,
      "loss": 0.0001,
      "step": 10234
    },
    {
      "epoch": 39.67054263565891,
      "grad_norm": 0.3764650523662567,
      "learning_rate": 1.0329457364341086e-05,
      "loss": 0.0107,
      "step": 10235
    },
    {
      "epoch": 39.674418604651166,
      "grad_norm": 0.0008417206699959934,
      "learning_rate": 1.0325581395348838e-05,
      "loss": 0.0001,
      "step": 10236
    },
    {
      "epoch": 39.67829457364341,
      "grad_norm": 0.0008005609852261841,
      "learning_rate": 1.032170542635659e-05,
      "loss": 0.0001,
      "step": 10237
    },
    {
      "epoch": 39.68217054263566,
      "grad_norm": 0.0007829603855498135,
      "learning_rate": 1.0317829457364341e-05,
      "loss": 0.0001,
      "step": 10238
    },
    {
      "epoch": 39.68604651162791,
      "grad_norm": 0.005780534353107214,
      "learning_rate": 1.0313953488372094e-05,
      "loss": 0.0003,
      "step": 10239
    },
    {
      "epoch": 39.689922480620154,
      "grad_norm": 0.001094718580134213,
      "learning_rate": 1.0310077519379846e-05,
      "loss": 0.0001,
      "step": 10240
    },
    {
      "epoch": 39.6937984496124,
      "grad_norm": 0.0008674563723616302,
      "learning_rate": 1.0306201550387598e-05,
      "loss": 0.0001,
      "step": 10241
    },
    {
      "epoch": 39.69767441860465,
      "grad_norm": 0.0015166574157774448,
      "learning_rate": 1.030232558139535e-05,
      "loss": 0.0001,
      "step": 10242
    },
    {
      "epoch": 39.701550387596896,
      "grad_norm": 0.0010881564812734723,
      "learning_rate": 1.02984496124031e-05,
      "loss": 0.0001,
      "step": 10243
    },
    {
      "epoch": 39.70542635658915,
      "grad_norm": 0.0008507170714437962,
      "learning_rate": 1.0294573643410852e-05,
      "loss": 0.0001,
      "step": 10244
    },
    {
      "epoch": 39.7093023255814,
      "grad_norm": 0.0007737779524177313,
      "learning_rate": 1.0290697674418605e-05,
      "loss": 0.0001,
      "step": 10245
    },
    {
      "epoch": 39.713178294573645,
      "grad_norm": 0.004322593100368977,
      "learning_rate": 1.0286821705426357e-05,
      "loss": 0.0002,
      "step": 10246
    },
    {
      "epoch": 39.71705426356589,
      "grad_norm": 0.0009616856696084142,
      "learning_rate": 1.028294573643411e-05,
      "loss": 0.0001,
      "step": 10247
    },
    {
      "epoch": 39.72093023255814,
      "grad_norm": 0.0016130126314237714,
      "learning_rate": 1.027906976744186e-05,
      "loss": 0.0001,
      "step": 10248
    },
    {
      "epoch": 39.724806201550386,
      "grad_norm": 0.0014428362483158708,
      "learning_rate": 1.0275193798449613e-05,
      "loss": 0.0001,
      "step": 10249
    },
    {
      "epoch": 39.72868217054263,
      "grad_norm": 0.0014982265420258045,
      "learning_rate": 1.0271317829457365e-05,
      "loss": 0.0001,
      "step": 10250
    },
    {
      "epoch": 39.73255813953488,
      "grad_norm": 0.0007326066843234003,
      "learning_rate": 1.0267441860465118e-05,
      "loss": 0.0001,
      "step": 10251
    },
    {
      "epoch": 39.736434108527135,
      "grad_norm": 0.0009239261853508651,
      "learning_rate": 1.0263565891472868e-05,
      "loss": 0.0001,
      "step": 10252
    },
    {
      "epoch": 39.74031007751938,
      "grad_norm": 0.0007991230813786387,
      "learning_rate": 1.025968992248062e-05,
      "loss": 0.0001,
      "step": 10253
    },
    {
      "epoch": 39.74418604651163,
      "grad_norm": 0.002475669141858816,
      "learning_rate": 1.0255813953488373e-05,
      "loss": 0.0002,
      "step": 10254
    },
    {
      "epoch": 39.748062015503876,
      "grad_norm": 0.0007562424871139228,
      "learning_rate": 1.0251937984496124e-05,
      "loss": 0.0001,
      "step": 10255
    },
    {
      "epoch": 39.751937984496124,
      "grad_norm": 0.002354111522436142,
      "learning_rate": 1.0248062015503876e-05,
      "loss": 0.0002,
      "step": 10256
    },
    {
      "epoch": 39.75581395348837,
      "grad_norm": 0.000760377268306911,
      "learning_rate": 1.0244186046511629e-05,
      "loss": 0.0001,
      "step": 10257
    },
    {
      "epoch": 39.75968992248062,
      "grad_norm": 0.001110943267121911,
      "learning_rate": 1.024031007751938e-05,
      "loss": 0.0001,
      "step": 10258
    },
    {
      "epoch": 39.763565891472865,
      "grad_norm": 8.632000923156738,
      "learning_rate": 1.0236434108527132e-05,
      "loss": 0.8347,
      "step": 10259
    },
    {
      "epoch": 39.76744186046512,
      "grad_norm": 0.002407232066616416,
      "learning_rate": 1.0232558139534884e-05,
      "loss": 0.0002,
      "step": 10260
    },
    {
      "epoch": 39.77131782945737,
      "grad_norm": 0.0011947458842769265,
      "learning_rate": 1.0228682170542637e-05,
      "loss": 0.0001,
      "step": 10261
    },
    {
      "epoch": 39.775193798449614,
      "grad_norm": 0.0009847983019426465,
      "learning_rate": 1.0224806201550387e-05,
      "loss": 0.0001,
      "step": 10262
    },
    {
      "epoch": 39.77906976744186,
      "grad_norm": 0.0011808170238509774,
      "learning_rate": 1.022093023255814e-05,
      "loss": 0.0001,
      "step": 10263
    },
    {
      "epoch": 39.78294573643411,
      "grad_norm": 0.9181156754493713,
      "learning_rate": 1.0217054263565892e-05,
      "loss": 0.001,
      "step": 10264
    },
    {
      "epoch": 39.786821705426355,
      "grad_norm": 0.001319019473157823,
      "learning_rate": 1.0213178294573645e-05,
      "loss": 0.0001,
      "step": 10265
    },
    {
      "epoch": 39.7906976744186,
      "grad_norm": 0.00087341497419402,
      "learning_rate": 1.0209302325581397e-05,
      "loss": 0.0001,
      "step": 10266
    },
    {
      "epoch": 39.79457364341085,
      "grad_norm": 0.0007784266490489244,
      "learning_rate": 1.0205426356589148e-05,
      "loss": 0.0001,
      "step": 10267
    },
    {
      "epoch": 39.798449612403104,
      "grad_norm": 0.7107896208763123,
      "learning_rate": 1.02015503875969e-05,
      "loss": 0.0376,
      "step": 10268
    },
    {
      "epoch": 39.80232558139535,
      "grad_norm": 0.0016796833369880915,
      "learning_rate": 1.0197674418604651e-05,
      "loss": 0.0001,
      "step": 10269
    },
    {
      "epoch": 39.8062015503876,
      "grad_norm": 0.0007766473572701216,
      "learning_rate": 1.0193798449612403e-05,
      "loss": 0.0001,
      "step": 10270
    },
    {
      "epoch": 39.810077519379846,
      "grad_norm": 0.0010790621163323522,
      "learning_rate": 1.0189922480620156e-05,
      "loss": 0.0001,
      "step": 10271
    },
    {
      "epoch": 39.81395348837209,
      "grad_norm": 0.0007735912222415209,
      "learning_rate": 1.0186046511627907e-05,
      "loss": 0.0001,
      "step": 10272
    },
    {
      "epoch": 39.81782945736434,
      "grad_norm": 0.0011389502324163914,
      "learning_rate": 1.0182170542635659e-05,
      "loss": 0.0001,
      "step": 10273
    },
    {
      "epoch": 39.82170542635659,
      "grad_norm": 0.0007555577321909368,
      "learning_rate": 1.0178294573643411e-05,
      "loss": 0.0001,
      "step": 10274
    },
    {
      "epoch": 39.825581395348834,
      "grad_norm": 0.0007085445104166865,
      "learning_rate": 1.0174418604651164e-05,
      "loss": 0.0001,
      "step": 10275
    },
    {
      "epoch": 39.82945736434109,
      "grad_norm": 0.00085360900266096,
      "learning_rate": 1.0170542635658915e-05,
      "loss": 0.0001,
      "step": 10276
    },
    {
      "epoch": 39.833333333333336,
      "grad_norm": 0.003695869818329811,
      "learning_rate": 1.0166666666666667e-05,
      "loss": 0.0002,
      "step": 10277
    },
    {
      "epoch": 39.83720930232558,
      "grad_norm": 2.437267541885376,
      "learning_rate": 1.016279069767442e-05,
      "loss": 0.0091,
      "step": 10278
    },
    {
      "epoch": 39.84108527131783,
      "grad_norm": 0.7572028040885925,
      "learning_rate": 1.0158914728682172e-05,
      "loss": 0.0546,
      "step": 10279
    },
    {
      "epoch": 39.84496124031008,
      "grad_norm": 0.0009618217591196299,
      "learning_rate": 1.0155038759689924e-05,
      "loss": 0.0001,
      "step": 10280
    },
    {
      "epoch": 39.848837209302324,
      "grad_norm": 0.00234904233366251,
      "learning_rate": 1.0151162790697675e-05,
      "loss": 0.0002,
      "step": 10281
    },
    {
      "epoch": 39.85271317829457,
      "grad_norm": 0.0009414366795681417,
      "learning_rate": 1.0147286821705426e-05,
      "loss": 0.0001,
      "step": 10282
    },
    {
      "epoch": 39.85658914728682,
      "grad_norm": 0.01976812817156315,
      "learning_rate": 1.0143410852713178e-05,
      "loss": 0.0001,
      "step": 10283
    },
    {
      "epoch": 39.86046511627907,
      "grad_norm": 0.03140898421406746,
      "learning_rate": 1.013953488372093e-05,
      "loss": 0.0004,
      "step": 10284
    },
    {
      "epoch": 39.86434108527132,
      "grad_norm": 0.0014107037568464875,
      "learning_rate": 1.0135658914728683e-05,
      "loss": 0.0001,
      "step": 10285
    },
    {
      "epoch": 39.86821705426357,
      "grad_norm": 0.0008400945225730538,
      "learning_rate": 1.0131782945736434e-05,
      "loss": 0.0001,
      "step": 10286
    },
    {
      "epoch": 39.872093023255815,
      "grad_norm": 0.004284549038857222,
      "learning_rate": 1.0127906976744186e-05,
      "loss": 0.0003,
      "step": 10287
    },
    {
      "epoch": 39.87596899224806,
      "grad_norm": 0.004423289094120264,
      "learning_rate": 1.0124031007751939e-05,
      "loss": 0.0002,
      "step": 10288
    },
    {
      "epoch": 39.87984496124031,
      "grad_norm": 0.0009182429639622569,
      "learning_rate": 1.0120155038759691e-05,
      "loss": 0.0001,
      "step": 10289
    },
    {
      "epoch": 39.883720930232556,
      "grad_norm": 0.012290623970329762,
      "learning_rate": 1.0116279069767442e-05,
      "loss": 0.0004,
      "step": 10290
    },
    {
      "epoch": 39.8875968992248,
      "grad_norm": 3.2596330642700195,
      "learning_rate": 1.0112403100775194e-05,
      "loss": 0.4638,
      "step": 10291
    },
    {
      "epoch": 39.89147286821706,
      "grad_norm": 0.0010765971383079886,
      "learning_rate": 1.0108527131782947e-05,
      "loss": 0.0001,
      "step": 10292
    },
    {
      "epoch": 39.895348837209305,
      "grad_norm": 5.838362693786621,
      "learning_rate": 1.0104651162790699e-05,
      "loss": 0.0392,
      "step": 10293
    },
    {
      "epoch": 39.89922480620155,
      "grad_norm": 0.002039743820205331,
      "learning_rate": 1.0100775193798451e-05,
      "loss": 0.0002,
      "step": 10294
    },
    {
      "epoch": 39.9031007751938,
      "grad_norm": 0.0011507029412314296,
      "learning_rate": 1.0096899224806202e-05,
      "loss": 0.0001,
      "step": 10295
    },
    {
      "epoch": 39.906976744186046,
      "grad_norm": 0.0010157468495890498,
      "learning_rate": 1.0093023255813953e-05,
      "loss": 0.0001,
      "step": 10296
    },
    {
      "epoch": 39.91085271317829,
      "grad_norm": 0.0009705095435492694,
      "learning_rate": 1.0089147286821705e-05,
      "loss": 0.0001,
      "step": 10297
    },
    {
      "epoch": 39.91472868217054,
      "grad_norm": 0.0007990990416146815,
      "learning_rate": 1.0085271317829458e-05,
      "loss": 0.0001,
      "step": 10298
    },
    {
      "epoch": 39.91860465116279,
      "grad_norm": 0.00252491794526577,
      "learning_rate": 1.008139534883721e-05,
      "loss": 0.0001,
      "step": 10299
    },
    {
      "epoch": 39.92248062015504,
      "grad_norm": 0.0009336784132756293,
      "learning_rate": 1.0077519379844961e-05,
      "loss": 0.0001,
      "step": 10300
    },
    {
      "epoch": 39.92635658914729,
      "grad_norm": 0.0029735653661191463,
      "learning_rate": 1.0073643410852713e-05,
      "loss": 0.0002,
      "step": 10301
    },
    {
      "epoch": 39.93023255813954,
      "grad_norm": 0.0009154595318250358,
      "learning_rate": 1.0069767441860466e-05,
      "loss": 0.0001,
      "step": 10302
    },
    {
      "epoch": 39.934108527131784,
      "grad_norm": 0.0008676606230437756,
      "learning_rate": 1.0065891472868218e-05,
      "loss": 0.0001,
      "step": 10303
    },
    {
      "epoch": 39.93798449612403,
      "grad_norm": 0.020133083686232567,
      "learning_rate": 1.006201550387597e-05,
      "loss": 0.0004,
      "step": 10304
    },
    {
      "epoch": 39.94186046511628,
      "grad_norm": 0.895484983921051,
      "learning_rate": 1.0058139534883721e-05,
      "loss": 0.0424,
      "step": 10305
    },
    {
      "epoch": 39.945736434108525,
      "grad_norm": 0.0007753065438009799,
      "learning_rate": 1.0054263565891474e-05,
      "loss": 0.0001,
      "step": 10306
    },
    {
      "epoch": 39.94961240310077,
      "grad_norm": 0.0020187399350106716,
      "learning_rate": 1.0050387596899226e-05,
      "loss": 0.0002,
      "step": 10307
    },
    {
      "epoch": 39.95348837209303,
      "grad_norm": 0.001885513192974031,
      "learning_rate": 1.0046511627906979e-05,
      "loss": 0.0002,
      "step": 10308
    },
    {
      "epoch": 39.957364341085274,
      "grad_norm": 0.0012115291319787502,
      "learning_rate": 1.004263565891473e-05,
      "loss": 0.0001,
      "step": 10309
    },
    {
      "epoch": 39.96124031007752,
      "grad_norm": 0.001227130531333387,
      "learning_rate": 1.003875968992248e-05,
      "loss": 0.0001,
      "step": 10310
    },
    {
      "epoch": 39.96511627906977,
      "grad_norm": 0.00139285356272012,
      "learning_rate": 1.0034883720930232e-05,
      "loss": 0.0001,
      "step": 10311
    },
    {
      "epoch": 39.968992248062015,
      "grad_norm": 0.0025661862455308437,
      "learning_rate": 1.0031007751937985e-05,
      "loss": 0.0002,
      "step": 10312
    },
    {
      "epoch": 39.97286821705426,
      "grad_norm": 0.0008866265998221934,
      "learning_rate": 1.0027131782945737e-05,
      "loss": 0.0001,
      "step": 10313
    },
    {
      "epoch": 39.97674418604651,
      "grad_norm": 0.0008619197178632021,
      "learning_rate": 1.0023255813953488e-05,
      "loss": 0.0001,
      "step": 10314
    },
    {
      "epoch": 39.98062015503876,
      "grad_norm": 0.000855088816024363,
      "learning_rate": 1.001937984496124e-05,
      "loss": 0.0001,
      "step": 10315
    },
    {
      "epoch": 39.98449612403101,
      "grad_norm": 0.0014459239318966866,
      "learning_rate": 1.0015503875968993e-05,
      "loss": 0.0001,
      "step": 10316
    },
    {
      "epoch": 39.98837209302326,
      "grad_norm": 0.0016348843928426504,
      "learning_rate": 1.0011627906976745e-05,
      "loss": 0.0001,
      "step": 10317
    },
    {
      "epoch": 39.992248062015506,
      "grad_norm": 0.4996705949306488,
      "learning_rate": 1.0007751937984498e-05,
      "loss": 0.0227,
      "step": 10318
    },
    {
      "epoch": 39.99612403100775,
      "grad_norm": 0.0009523964836262167,
      "learning_rate": 1.0003875968992248e-05,
      "loss": 0.0001,
      "step": 10319
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.001882841344922781,
      "learning_rate": 1e-05,
      "loss": 0.0001,
      "step": 10320
    },
    {
      "epoch": 40.00387596899225,
      "grad_norm": 0.0008020154782570899,
      "learning_rate": 9.996124031007753e-06,
      "loss": 0.0001,
      "step": 10321
    },
    {
      "epoch": 40.007751937984494,
      "grad_norm": 0.003174389712512493,
      "learning_rate": 9.992248062015504e-06,
      "loss": 0.0002,
      "step": 10322
    },
    {
      "epoch": 40.01162790697674,
      "grad_norm": 0.0009144736104644835,
      "learning_rate": 9.988372093023256e-06,
      "loss": 0.0001,
      "step": 10323
    },
    {
      "epoch": 40.01550387596899,
      "grad_norm": 0.0010915132006630301,
      "learning_rate": 9.984496124031007e-06,
      "loss": 0.0001,
      "step": 10324
    },
    {
      "epoch": 40.01937984496124,
      "grad_norm": 0.0027325504925101995,
      "learning_rate": 9.98062015503876e-06,
      "loss": 0.0001,
      "step": 10325
    },
    {
      "epoch": 40.02325581395349,
      "grad_norm": 0.0007954759057611227,
      "learning_rate": 9.976744186046512e-06,
      "loss": 0.0001,
      "step": 10326
    },
    {
      "epoch": 40.02713178294574,
      "grad_norm": 0.008174403570592403,
      "learning_rate": 9.972868217054264e-06,
      "loss": 0.0002,
      "step": 10327
    },
    {
      "epoch": 40.031007751937985,
      "grad_norm": 0.0012043544556945562,
      "learning_rate": 9.968992248062017e-06,
      "loss": 0.0001,
      "step": 10328
    },
    {
      "epoch": 40.03488372093023,
      "grad_norm": 0.5325084924697876,
      "learning_rate": 9.965116279069768e-06,
      "loss": 0.0249,
      "step": 10329
    },
    {
      "epoch": 40.03875968992248,
      "grad_norm": 0.0023171433713287115,
      "learning_rate": 9.96124031007752e-06,
      "loss": 0.0002,
      "step": 10330
    },
    {
      "epoch": 40.042635658914726,
      "grad_norm": 0.002782954601570964,
      "learning_rate": 9.957364341085272e-06,
      "loss": 0.0002,
      "step": 10331
    },
    {
      "epoch": 40.04651162790697,
      "grad_norm": 0.6688113808631897,
      "learning_rate": 9.953488372093025e-06,
      "loss": 0.0286,
      "step": 10332
    },
    {
      "epoch": 40.05038759689923,
      "grad_norm": 0.001902062096633017,
      "learning_rate": 9.949612403100776e-06,
      "loss": 0.0002,
      "step": 10333
    },
    {
      "epoch": 40.054263565891475,
      "grad_norm": 0.0011227194918319583,
      "learning_rate": 9.945736434108528e-06,
      "loss": 0.0001,
      "step": 10334
    },
    {
      "epoch": 40.05813953488372,
      "grad_norm": 0.008815532550215721,
      "learning_rate": 9.941860465116279e-06,
      "loss": 0.0003,
      "step": 10335
    },
    {
      "epoch": 40.06201550387597,
      "grad_norm": 0.002233098028227687,
      "learning_rate": 9.937984496124031e-06,
      "loss": 0.0002,
      "step": 10336
    },
    {
      "epoch": 40.065891472868216,
      "grad_norm": 0.0019024055218324065,
      "learning_rate": 9.934108527131784e-06,
      "loss": 0.0002,
      "step": 10337
    },
    {
      "epoch": 40.06976744186046,
      "grad_norm": 0.0011391041334718466,
      "learning_rate": 9.930232558139534e-06,
      "loss": 0.0001,
      "step": 10338
    },
    {
      "epoch": 40.07364341085271,
      "grad_norm": 0.5105353593826294,
      "learning_rate": 9.926356589147287e-06,
      "loss": 0.0216,
      "step": 10339
    },
    {
      "epoch": 40.07751937984496,
      "grad_norm": 0.05503860116004944,
      "learning_rate": 9.922480620155039e-06,
      "loss": 0.0002,
      "step": 10340
    },
    {
      "epoch": 40.08139534883721,
      "grad_norm": 0.0007628253661096096,
      "learning_rate": 9.918604651162792e-06,
      "loss": 0.0001,
      "step": 10341
    },
    {
      "epoch": 40.08527131782946,
      "grad_norm": 0.007923102006316185,
      "learning_rate": 9.914728682170544e-06,
      "loss": 0.0002,
      "step": 10342
    },
    {
      "epoch": 40.08914728682171,
      "grad_norm": 0.0030178867746144533,
      "learning_rate": 9.910852713178295e-06,
      "loss": 0.0002,
      "step": 10343
    },
    {
      "epoch": 40.093023255813954,
      "grad_norm": 0.0013382136821746826,
      "learning_rate": 9.906976744186047e-06,
      "loss": 0.0001,
      "step": 10344
    },
    {
      "epoch": 40.0968992248062,
      "grad_norm": 0.0008498593815602362,
      "learning_rate": 9.9031007751938e-06,
      "loss": 0.0001,
      "step": 10345
    },
    {
      "epoch": 40.10077519379845,
      "grad_norm": 0.0008259829482994974,
      "learning_rate": 9.899224806201552e-06,
      "loss": 0.0001,
      "step": 10346
    },
    {
      "epoch": 40.104651162790695,
      "grad_norm": 0.0013510608114302158,
      "learning_rate": 9.895348837209303e-06,
      "loss": 0.0001,
      "step": 10347
    },
    {
      "epoch": 40.10852713178294,
      "grad_norm": 0.4172949194908142,
      "learning_rate": 9.891472868217053e-06,
      "loss": 0.0163,
      "step": 10348
    },
    {
      "epoch": 40.1124031007752,
      "grad_norm": 0.0012832732172682881,
      "learning_rate": 9.887596899224806e-06,
      "loss": 0.0001,
      "step": 10349
    },
    {
      "epoch": 40.116279069767444,
      "grad_norm": 0.0023762150667607784,
      "learning_rate": 9.883720930232558e-06,
      "loss": 0.0002,
      "step": 10350
    },
    {
      "epoch": 40.12015503875969,
      "grad_norm": 0.0008559457492083311,
      "learning_rate": 9.87984496124031e-06,
      "loss": 0.0001,
      "step": 10351
    },
    {
      "epoch": 40.12403100775194,
      "grad_norm": 0.0012588088866323233,
      "learning_rate": 9.875968992248061e-06,
      "loss": 0.0001,
      "step": 10352
    },
    {
      "epoch": 40.127906976744185,
      "grad_norm": 0.0008611106313765049,
      "learning_rate": 9.872093023255814e-06,
      "loss": 0.0001,
      "step": 10353
    },
    {
      "epoch": 40.13178294573643,
      "grad_norm": 0.001643002382479608,
      "learning_rate": 9.868217054263566e-06,
      "loss": 0.0001,
      "step": 10354
    },
    {
      "epoch": 40.13565891472868,
      "grad_norm": 0.0016608815640211105,
      "learning_rate": 9.864341085271319e-06,
      "loss": 0.0002,
      "step": 10355
    },
    {
      "epoch": 40.13953488372093,
      "grad_norm": 0.0018977768486365676,
      "learning_rate": 9.860465116279071e-06,
      "loss": 0.0002,
      "step": 10356
    },
    {
      "epoch": 40.14341085271318,
      "grad_norm": 0.0007385123753920197,
      "learning_rate": 9.856589147286822e-06,
      "loss": 0.0001,
      "step": 10357
    },
    {
      "epoch": 40.14728682170543,
      "grad_norm": 0.0007638577953912318,
      "learning_rate": 9.852713178294574e-06,
      "loss": 0.0001,
      "step": 10358
    },
    {
      "epoch": 40.151162790697676,
      "grad_norm": 0.000967932865023613,
      "learning_rate": 9.848837209302327e-06,
      "loss": 0.0001,
      "step": 10359
    },
    {
      "epoch": 40.15503875968992,
      "grad_norm": 0.0010067070834338665,
      "learning_rate": 9.844961240310079e-06,
      "loss": 0.0001,
      "step": 10360
    },
    {
      "epoch": 40.15891472868217,
      "grad_norm": 0.3111848533153534,
      "learning_rate": 9.84108527131783e-06,
      "loss": 0.0173,
      "step": 10361
    },
    {
      "epoch": 40.16279069767442,
      "grad_norm": 0.0008423147955909371,
      "learning_rate": 9.83720930232558e-06,
      "loss": 0.0001,
      "step": 10362
    },
    {
      "epoch": 40.166666666666664,
      "grad_norm": 0.000758287264034152,
      "learning_rate": 9.833333333333333e-06,
      "loss": 0.0001,
      "step": 10363
    },
    {
      "epoch": 40.17054263565891,
      "grad_norm": 0.0008623208268545568,
      "learning_rate": 9.829457364341085e-06,
      "loss": 0.0001,
      "step": 10364
    },
    {
      "epoch": 40.174418604651166,
      "grad_norm": 0.001149984309449792,
      "learning_rate": 9.825581395348838e-06,
      "loss": 0.0001,
      "step": 10365
    },
    {
      "epoch": 40.17829457364341,
      "grad_norm": 0.0007947440026327968,
      "learning_rate": 9.82170542635659e-06,
      "loss": 0.0001,
      "step": 10366
    },
    {
      "epoch": 40.18217054263566,
      "grad_norm": 0.0009342179400846362,
      "learning_rate": 9.817829457364341e-06,
      "loss": 0.0001,
      "step": 10367
    },
    {
      "epoch": 40.18604651162791,
      "grad_norm": 0.0019993409514427185,
      "learning_rate": 9.813953488372093e-06,
      "loss": 0.0001,
      "step": 10368
    },
    {
      "epoch": 40.189922480620154,
      "grad_norm": 0.000879547034855932,
      "learning_rate": 9.810077519379846e-06,
      "loss": 0.0001,
      "step": 10369
    },
    {
      "epoch": 40.1937984496124,
      "grad_norm": 0.0015898249112069607,
      "learning_rate": 9.806201550387598e-06,
      "loss": 0.0001,
      "step": 10370
    },
    {
      "epoch": 40.19767441860465,
      "grad_norm": 0.002298136707395315,
      "learning_rate": 9.802325581395349e-06,
      "loss": 0.0002,
      "step": 10371
    },
    {
      "epoch": 40.201550387596896,
      "grad_norm": 0.0010131907183676958,
      "learning_rate": 9.798449612403101e-06,
      "loss": 0.0001,
      "step": 10372
    },
    {
      "epoch": 40.20542635658915,
      "grad_norm": 0.0035529620945453644,
      "learning_rate": 9.794573643410854e-06,
      "loss": 0.0002,
      "step": 10373
    },
    {
      "epoch": 40.2093023255814,
      "grad_norm": 0.0021365622524172068,
      "learning_rate": 9.790697674418606e-06,
      "loss": 0.0002,
      "step": 10374
    },
    {
      "epoch": 40.213178294573645,
      "grad_norm": 0.004002471920102835,
      "learning_rate": 9.786821705426357e-06,
      "loss": 0.0002,
      "step": 10375
    },
    {
      "epoch": 40.21705426356589,
      "grad_norm": 0.0008368308190256357,
      "learning_rate": 9.782945736434108e-06,
      "loss": 0.0001,
      "step": 10376
    },
    {
      "epoch": 40.22093023255814,
      "grad_norm": 0.0009517085854895413,
      "learning_rate": 9.77906976744186e-06,
      "loss": 0.0001,
      "step": 10377
    },
    {
      "epoch": 40.224806201550386,
      "grad_norm": 0.000965351180639118,
      "learning_rate": 9.775193798449612e-06,
      "loss": 0.0001,
      "step": 10378
    },
    {
      "epoch": 40.22868217054263,
      "grad_norm": 0.0012513342080637813,
      "learning_rate": 9.771317829457365e-06,
      "loss": 0.0001,
      "step": 10379
    },
    {
      "epoch": 40.23255813953488,
      "grad_norm": 0.0009734957711771131,
      "learning_rate": 9.767441860465117e-06,
      "loss": 0.0001,
      "step": 10380
    },
    {
      "epoch": 40.236434108527135,
      "grad_norm": 0.000992809422314167,
      "learning_rate": 9.763565891472868e-06,
      "loss": 0.0001,
      "step": 10381
    },
    {
      "epoch": 40.24031007751938,
      "grad_norm": 0.0036426978185772896,
      "learning_rate": 9.75968992248062e-06,
      "loss": 0.0002,
      "step": 10382
    },
    {
      "epoch": 40.24418604651163,
      "grad_norm": 0.0009887183550745249,
      "learning_rate": 9.755813953488373e-06,
      "loss": 0.0001,
      "step": 10383
    },
    {
      "epoch": 40.248062015503876,
      "grad_norm": 0.0007461096975021064,
      "learning_rate": 9.751937984496125e-06,
      "loss": 0.0001,
      "step": 10384
    },
    {
      "epoch": 40.251937984496124,
      "grad_norm": 0.10685385763645172,
      "learning_rate": 9.748062015503876e-06,
      "loss": 0.001,
      "step": 10385
    },
    {
      "epoch": 40.25581395348837,
      "grad_norm": 0.000824093003757298,
      "learning_rate": 9.744186046511628e-06,
      "loss": 0.0001,
      "step": 10386
    },
    {
      "epoch": 40.25968992248062,
      "grad_norm": 0.0008087606984190643,
      "learning_rate": 9.740310077519381e-06,
      "loss": 0.0001,
      "step": 10387
    },
    {
      "epoch": 40.263565891472865,
      "grad_norm": 0.0009290581219829619,
      "learning_rate": 9.736434108527132e-06,
      "loss": 0.0001,
      "step": 10388
    },
    {
      "epoch": 40.26744186046512,
      "grad_norm": 0.0022216634824872017,
      "learning_rate": 9.732558139534884e-06,
      "loss": 0.0001,
      "step": 10389
    },
    {
      "epoch": 40.27131782945737,
      "grad_norm": 0.0029837400652468204,
      "learning_rate": 9.728682170542636e-06,
      "loss": 0.0002,
      "step": 10390
    },
    {
      "epoch": 40.275193798449614,
      "grad_norm": 0.0007041182834655046,
      "learning_rate": 9.724806201550387e-06,
      "loss": 0.0001,
      "step": 10391
    },
    {
      "epoch": 40.27906976744186,
      "grad_norm": 0.0008376291953027248,
      "learning_rate": 9.72093023255814e-06,
      "loss": 0.0001,
      "step": 10392
    },
    {
      "epoch": 40.28294573643411,
      "grad_norm": 0.0008937433012761176,
      "learning_rate": 9.717054263565892e-06,
      "loss": 0.0001,
      "step": 10393
    },
    {
      "epoch": 40.286821705426355,
      "grad_norm": 0.001272726571187377,
      "learning_rate": 9.713178294573644e-06,
      "loss": 0.0001,
      "step": 10394
    },
    {
      "epoch": 40.2906976744186,
      "grad_norm": 0.003220048500224948,
      "learning_rate": 9.709302325581395e-06,
      "loss": 0.0002,
      "step": 10395
    },
    {
      "epoch": 40.29457364341085,
      "grad_norm": 23.26053810119629,
      "learning_rate": 9.705426356589148e-06,
      "loss": 0.0624,
      "step": 10396
    },
    {
      "epoch": 40.298449612403104,
      "grad_norm": 0.0007836479926481843,
      "learning_rate": 9.7015503875969e-06,
      "loss": 0.0001,
      "step": 10397
    },
    {
      "epoch": 40.30232558139535,
      "grad_norm": 0.0008203351171687245,
      "learning_rate": 9.697674418604652e-06,
      "loss": 0.0001,
      "step": 10398
    },
    {
      "epoch": 40.3062015503876,
      "grad_norm": 0.0018324573757126927,
      "learning_rate": 9.693798449612405e-06,
      "loss": 0.0002,
      "step": 10399
    },
    {
      "epoch": 40.310077519379846,
      "grad_norm": 0.003881624434143305,
      "learning_rate": 9.689922480620156e-06,
      "loss": 0.0002,
      "step": 10400
    },
    {
      "epoch": 40.31395348837209,
      "grad_norm": 0.006161089986562729,
      "learning_rate": 9.686046511627908e-06,
      "loss": 0.0002,
      "step": 10401
    },
    {
      "epoch": 40.31782945736434,
      "grad_norm": 0.009006265550851822,
      "learning_rate": 9.682170542635659e-06,
      "loss": 0.0002,
      "step": 10402
    },
    {
      "epoch": 40.32170542635659,
      "grad_norm": 0.0007698970148339868,
      "learning_rate": 9.678294573643411e-06,
      "loss": 0.0001,
      "step": 10403
    },
    {
      "epoch": 40.325581395348834,
      "grad_norm": 0.04260065406560898,
      "learning_rate": 9.674418604651164e-06,
      "loss": 0.0004,
      "step": 10404
    },
    {
      "epoch": 40.32945736434109,
      "grad_norm": 0.000855575839523226,
      "learning_rate": 9.670542635658914e-06,
      "loss": 0.0001,
      "step": 10405
    },
    {
      "epoch": 40.333333333333336,
      "grad_norm": 0.9660529494285583,
      "learning_rate": 9.666666666666667e-06,
      "loss": 0.0588,
      "step": 10406
    },
    {
      "epoch": 40.33720930232558,
      "grad_norm": 0.0010566218988969922,
      "learning_rate": 9.662790697674419e-06,
      "loss": 0.0001,
      "step": 10407
    },
    {
      "epoch": 40.34108527131783,
      "grad_norm": 0.0017096661031246185,
      "learning_rate": 9.658914728682172e-06,
      "loss": 0.0002,
      "step": 10408
    },
    {
      "epoch": 40.34496124031008,
      "grad_norm": 0.0011374468449503183,
      "learning_rate": 9.655038759689922e-06,
      "loss": 0.0001,
      "step": 10409
    },
    {
      "epoch": 40.348837209302324,
      "grad_norm": 0.001101651112549007,
      "learning_rate": 9.651162790697675e-06,
      "loss": 0.0001,
      "step": 10410
    },
    {
      "epoch": 40.35271317829457,
      "grad_norm": 0.007003805600106716,
      "learning_rate": 9.647286821705427e-06,
      "loss": 0.0004,
      "step": 10411
    },
    {
      "epoch": 40.35658914728682,
      "grad_norm": 0.0010765423066914082,
      "learning_rate": 9.64341085271318e-06,
      "loss": 0.0001,
      "step": 10412
    },
    {
      "epoch": 40.36046511627907,
      "grad_norm": 0.0007306367624551058,
      "learning_rate": 9.639534883720932e-06,
      "loss": 0.0001,
      "step": 10413
    },
    {
      "epoch": 40.36434108527132,
      "grad_norm": 0.0007220147526822984,
      "learning_rate": 9.635658914728683e-06,
      "loss": 0.0001,
      "step": 10414
    },
    {
      "epoch": 40.36821705426357,
      "grad_norm": 0.001241556485183537,
      "learning_rate": 9.631782945736433e-06,
      "loss": 0.0001,
      "step": 10415
    },
    {
      "epoch": 40.372093023255815,
      "grad_norm": 0.001153822522610426,
      "learning_rate": 9.627906976744186e-06,
      "loss": 0.0001,
      "step": 10416
    },
    {
      "epoch": 40.37596899224806,
      "grad_norm": 0.0010811655083671212,
      "learning_rate": 9.624031007751938e-06,
      "loss": 0.0001,
      "step": 10417
    },
    {
      "epoch": 40.37984496124031,
      "grad_norm": 0.0012509414227679372,
      "learning_rate": 9.62015503875969e-06,
      "loss": 0.0001,
      "step": 10418
    },
    {
      "epoch": 40.383720930232556,
      "grad_norm": 0.002052068244665861,
      "learning_rate": 9.616279069767441e-06,
      "loss": 0.0001,
      "step": 10419
    },
    {
      "epoch": 40.3875968992248,
      "grad_norm": 0.0009779476094990969,
      "learning_rate": 9.612403100775194e-06,
      "loss": 0.0001,
      "step": 10420
    },
    {
      "epoch": 40.39147286821706,
      "grad_norm": 0.002373985480517149,
      "learning_rate": 9.608527131782946e-06,
      "loss": 0.0001,
      "step": 10421
    },
    {
      "epoch": 40.395348837209305,
      "grad_norm": 0.0009672435116954148,
      "learning_rate": 9.604651162790699e-06,
      "loss": 0.0001,
      "step": 10422
    },
    {
      "epoch": 40.39922480620155,
      "grad_norm": 0.0008576810359954834,
      "learning_rate": 9.60077519379845e-06,
      "loss": 0.0001,
      "step": 10423
    },
    {
      "epoch": 40.4031007751938,
      "grad_norm": 0.0017340817721560597,
      "learning_rate": 9.596899224806202e-06,
      "loss": 0.0001,
      "step": 10424
    },
    {
      "epoch": 40.406976744186046,
      "grad_norm": 0.0007445657975040376,
      "learning_rate": 9.593023255813954e-06,
      "loss": 0.0001,
      "step": 10425
    },
    {
      "epoch": 40.41085271317829,
      "grad_norm": 0.0009710458107292652,
      "learning_rate": 9.589147286821707e-06,
      "loss": 0.0001,
      "step": 10426
    },
    {
      "epoch": 40.41472868217054,
      "grad_norm": 2.1874754428863525,
      "learning_rate": 9.585271317829459e-06,
      "loss": 0.2102,
      "step": 10427
    },
    {
      "epoch": 40.41860465116279,
      "grad_norm": 0.0009259070502594113,
      "learning_rate": 9.58139534883721e-06,
      "loss": 0.0001,
      "step": 10428
    },
    {
      "epoch": 40.42248062015504,
      "grad_norm": 0.0007653504726476967,
      "learning_rate": 9.57751937984496e-06,
      "loss": 0.0001,
      "step": 10429
    },
    {
      "epoch": 40.42635658914729,
      "grad_norm": 0.0011784001253545284,
      "learning_rate": 9.573643410852713e-06,
      "loss": 0.0001,
      "step": 10430
    },
    {
      "epoch": 40.43023255813954,
      "grad_norm": 0.0007301237201318145,
      "learning_rate": 9.569767441860465e-06,
      "loss": 0.0001,
      "step": 10431
    },
    {
      "epoch": 40.434108527131784,
      "grad_norm": 0.0008568096673116088,
      "learning_rate": 9.565891472868218e-06,
      "loss": 0.0001,
      "step": 10432
    },
    {
      "epoch": 40.43798449612403,
      "grad_norm": 0.0009049665532074869,
      "learning_rate": 9.562015503875969e-06,
      "loss": 0.0001,
      "step": 10433
    },
    {
      "epoch": 40.44186046511628,
      "grad_norm": 0.0008993824594654143,
      "learning_rate": 9.558139534883721e-06,
      "loss": 0.0001,
      "step": 10434
    },
    {
      "epoch": 40.445736434108525,
      "grad_norm": 4.596017360687256,
      "learning_rate": 9.554263565891473e-06,
      "loss": 0.0077,
      "step": 10435
    },
    {
      "epoch": 40.44961240310077,
      "grad_norm": 0.0011056894436478615,
      "learning_rate": 9.550387596899226e-06,
      "loss": 0.0001,
      "step": 10436
    },
    {
      "epoch": 40.45348837209303,
      "grad_norm": 0.0024888128973543644,
      "learning_rate": 9.546511627906978e-06,
      "loss": 0.0002,
      "step": 10437
    },
    {
      "epoch": 40.457364341085274,
      "grad_norm": 0.0008418471552431583,
      "learning_rate": 9.542635658914729e-06,
      "loss": 0.0001,
      "step": 10438
    },
    {
      "epoch": 40.46124031007752,
      "grad_norm": 0.0009730011224746704,
      "learning_rate": 9.538759689922481e-06,
      "loss": 0.0001,
      "step": 10439
    },
    {
      "epoch": 40.46511627906977,
      "grad_norm": 0.000889582559466362,
      "learning_rate": 9.534883720930234e-06,
      "loss": 0.0001,
      "step": 10440
    },
    {
      "epoch": 40.468992248062015,
      "grad_norm": 0.004169709514826536,
      "learning_rate": 9.531007751937986e-06,
      "loss": 0.0002,
      "step": 10441
    },
    {
      "epoch": 40.47286821705426,
      "grad_norm": 0.002283234614878893,
      "learning_rate": 9.527131782945737e-06,
      "loss": 0.0002,
      "step": 10442
    },
    {
      "epoch": 40.47674418604651,
      "grad_norm": 0.0009145711665041745,
      "learning_rate": 9.523255813953488e-06,
      "loss": 0.0001,
      "step": 10443
    },
    {
      "epoch": 40.48062015503876,
      "grad_norm": 0.0007805599016137421,
      "learning_rate": 9.51937984496124e-06,
      "loss": 0.0001,
      "step": 10444
    },
    {
      "epoch": 40.48449612403101,
      "grad_norm": 0.0009008785709738731,
      "learning_rate": 9.515503875968993e-06,
      "loss": 0.0001,
      "step": 10445
    },
    {
      "epoch": 40.48837209302326,
      "grad_norm": 0.002206243574619293,
      "learning_rate": 9.511627906976745e-06,
      "loss": 0.0001,
      "step": 10446
    },
    {
      "epoch": 40.492248062015506,
      "grad_norm": 0.0014670835807919502,
      "learning_rate": 9.507751937984496e-06,
      "loss": 0.0001,
      "step": 10447
    },
    {
      "epoch": 40.49612403100775,
      "grad_norm": 0.0008510421612299979,
      "learning_rate": 9.503875968992248e-06,
      "loss": 0.0001,
      "step": 10448
    },
    {
      "epoch": 40.5,
      "grad_norm": 0.0015095470007508993,
      "learning_rate": 9.5e-06,
      "loss": 0.0001,
      "step": 10449
    },
    {
      "epoch": 40.50387596899225,
      "grad_norm": 0.001407356932759285,
      "learning_rate": 9.496124031007753e-06,
      "loss": 0.0001,
      "step": 10450
    },
    {
      "epoch": 40.507751937984494,
      "grad_norm": 0.0008233074913732708,
      "learning_rate": 9.492248062015505e-06,
      "loss": 0.0001,
      "step": 10451
    },
    {
      "epoch": 40.51162790697674,
      "grad_norm": 0.5065047740936279,
      "learning_rate": 9.488372093023256e-06,
      "loss": 0.0208,
      "step": 10452
    },
    {
      "epoch": 40.51550387596899,
      "grad_norm": 0.1246066465973854,
      "learning_rate": 9.484496124031009e-06,
      "loss": 0.006,
      "step": 10453
    },
    {
      "epoch": 40.51937984496124,
      "grad_norm": 0.0009387153550051153,
      "learning_rate": 9.480620155038761e-06,
      "loss": 0.0001,
      "step": 10454
    },
    {
      "epoch": 40.52325581395349,
      "grad_norm": 0.0008201667806133628,
      "learning_rate": 9.476744186046512e-06,
      "loss": 0.0001,
      "step": 10455
    },
    {
      "epoch": 40.52713178294574,
      "grad_norm": 0.0007458397885784507,
      "learning_rate": 9.472868217054264e-06,
      "loss": 0.0001,
      "step": 10456
    },
    {
      "epoch": 40.531007751937985,
      "grad_norm": 0.0014961626147851348,
      "learning_rate": 9.468992248062015e-06,
      "loss": 0.0001,
      "step": 10457
    },
    {
      "epoch": 40.53488372093023,
      "grad_norm": 0.0009077967260964215,
      "learning_rate": 9.465116279069767e-06,
      "loss": 0.0001,
      "step": 10458
    },
    {
      "epoch": 40.53875968992248,
      "grad_norm": 0.0008614711696282029,
      "learning_rate": 9.46124031007752e-06,
      "loss": 0.0001,
      "step": 10459
    },
    {
      "epoch": 40.542635658914726,
      "grad_norm": 0.005011825822293758,
      "learning_rate": 9.457364341085272e-06,
      "loss": 0.0003,
      "step": 10460
    },
    {
      "epoch": 40.54651162790697,
      "grad_norm": 0.0009894738905131817,
      "learning_rate": 9.453488372093024e-06,
      "loss": 0.0001,
      "step": 10461
    },
    {
      "epoch": 40.55038759689923,
      "grad_norm": 0.0011125762248411775,
      "learning_rate": 9.449612403100775e-06,
      "loss": 0.0001,
      "step": 10462
    },
    {
      "epoch": 40.554263565891475,
      "grad_norm": 0.0012407638132572174,
      "learning_rate": 9.445736434108528e-06,
      "loss": 0.0001,
      "step": 10463
    },
    {
      "epoch": 40.55813953488372,
      "grad_norm": 0.0008906786097213626,
      "learning_rate": 9.44186046511628e-06,
      "loss": 0.0001,
      "step": 10464
    },
    {
      "epoch": 40.56201550387597,
      "grad_norm": 0.0009154960280284286,
      "learning_rate": 9.437984496124032e-06,
      "loss": 0.0001,
      "step": 10465
    },
    {
      "epoch": 40.565891472868216,
      "grad_norm": 0.0029819230549037457,
      "learning_rate": 9.434108527131783e-06,
      "loss": 0.0002,
      "step": 10466
    },
    {
      "epoch": 40.56976744186046,
      "grad_norm": 0.0008923970744945109,
      "learning_rate": 9.430232558139536e-06,
      "loss": 0.0001,
      "step": 10467
    },
    {
      "epoch": 40.57364341085271,
      "grad_norm": 0.0019701430574059486,
      "learning_rate": 9.426356589147286e-06,
      "loss": 0.0001,
      "step": 10468
    },
    {
      "epoch": 40.57751937984496,
      "grad_norm": 0.0008260905742645264,
      "learning_rate": 9.422480620155039e-06,
      "loss": 0.0001,
      "step": 10469
    },
    {
      "epoch": 40.58139534883721,
      "grad_norm": 0.0007342218887060881,
      "learning_rate": 9.418604651162791e-06,
      "loss": 0.0001,
      "step": 10470
    },
    {
      "epoch": 40.58527131782946,
      "grad_norm": 0.001182505744509399,
      "learning_rate": 9.414728682170542e-06,
      "loss": 0.0001,
      "step": 10471
    },
    {
      "epoch": 40.58914728682171,
      "grad_norm": 0.0007820567698217928,
      "learning_rate": 9.410852713178294e-06,
      "loss": 0.0001,
      "step": 10472
    },
    {
      "epoch": 40.593023255813954,
      "grad_norm": 0.0016583972610533237,
      "learning_rate": 9.406976744186047e-06,
      "loss": 0.0001,
      "step": 10473
    },
    {
      "epoch": 40.5968992248062,
      "grad_norm": 0.014780471101403236,
      "learning_rate": 9.4031007751938e-06,
      "loss": 0.0002,
      "step": 10474
    },
    {
      "epoch": 40.60077519379845,
      "grad_norm": 2.0184013843536377,
      "learning_rate": 9.399224806201552e-06,
      "loss": 0.1723,
      "step": 10475
    },
    {
      "epoch": 40.604651162790695,
      "grad_norm": 0.0013699226547032595,
      "learning_rate": 9.395348837209302e-06,
      "loss": 0.0001,
      "step": 10476
    },
    {
      "epoch": 40.60852713178294,
      "grad_norm": 0.0023906887508928776,
      "learning_rate": 9.391472868217055e-06,
      "loss": 0.0002,
      "step": 10477
    },
    {
      "epoch": 40.6124031007752,
      "grad_norm": 0.0008573197992518544,
      "learning_rate": 9.387596899224807e-06,
      "loss": 0.0001,
      "step": 10478
    },
    {
      "epoch": 40.616279069767444,
      "grad_norm": 0.0012118142331019044,
      "learning_rate": 9.38372093023256e-06,
      "loss": 0.0001,
      "step": 10479
    },
    {
      "epoch": 40.62015503875969,
      "grad_norm": 0.0013849009992554784,
      "learning_rate": 9.37984496124031e-06,
      "loss": 0.0001,
      "step": 10480
    },
    {
      "epoch": 40.62403100775194,
      "grad_norm": 0.0013163205003365874,
      "learning_rate": 9.375968992248063e-06,
      "loss": 0.0001,
      "step": 10481
    },
    {
      "epoch": 40.627906976744185,
      "grad_norm": 0.000841861532535404,
      "learning_rate": 9.372093023255813e-06,
      "loss": 0.0001,
      "step": 10482
    },
    {
      "epoch": 40.63178294573643,
      "grad_norm": 0.0008521052077412605,
      "learning_rate": 9.368217054263566e-06,
      "loss": 0.0001,
      "step": 10483
    },
    {
      "epoch": 40.63565891472868,
      "grad_norm": 0.0014877483481541276,
      "learning_rate": 9.364341085271318e-06,
      "loss": 0.0001,
      "step": 10484
    },
    {
      "epoch": 40.63953488372093,
      "grad_norm": 0.0007871853886172175,
      "learning_rate": 9.360465116279069e-06,
      "loss": 0.0001,
      "step": 10485
    },
    {
      "epoch": 40.64341085271318,
      "grad_norm": 0.0013457962777465582,
      "learning_rate": 9.356589147286821e-06,
      "loss": 0.0001,
      "step": 10486
    },
    {
      "epoch": 40.64728682170543,
      "grad_norm": 0.0036325447726994753,
      "learning_rate": 9.352713178294574e-06,
      "loss": 0.0002,
      "step": 10487
    },
    {
      "epoch": 40.651162790697676,
      "grad_norm": 0.4996373951435089,
      "learning_rate": 9.348837209302326e-06,
      "loss": 0.0118,
      "step": 10488
    },
    {
      "epoch": 40.65503875968992,
      "grad_norm": 0.0008321100031025708,
      "learning_rate": 9.344961240310079e-06,
      "loss": 0.0001,
      "step": 10489
    },
    {
      "epoch": 40.65891472868217,
      "grad_norm": 0.007170813158154488,
      "learning_rate": 9.34108527131783e-06,
      "loss": 0.0002,
      "step": 10490
    },
    {
      "epoch": 40.66279069767442,
      "grad_norm": 0.0008053196361288428,
      "learning_rate": 9.337209302325582e-06,
      "loss": 0.0001,
      "step": 10491
    },
    {
      "epoch": 40.666666666666664,
      "grad_norm": 0.0008304110961034894,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.0001,
      "step": 10492
    },
    {
      "epoch": 40.67054263565891,
      "grad_norm": 731.9102783203125,
      "learning_rate": 9.329457364341087e-06,
      "loss": 0.0688,
      "step": 10493
    },
    {
      "epoch": 40.674418604651166,
      "grad_norm": 0.0008319181506522,
      "learning_rate": 9.325581395348837e-06,
      "loss": 0.0001,
      "step": 10494
    },
    {
      "epoch": 40.67829457364341,
      "grad_norm": 0.0032740335445851088,
      "learning_rate": 9.321705426356588e-06,
      "loss": 0.0001,
      "step": 10495
    },
    {
      "epoch": 40.68217054263566,
      "grad_norm": 0.0007567047141492367,
      "learning_rate": 9.31782945736434e-06,
      "loss": 0.0001,
      "step": 10496
    },
    {
      "epoch": 40.68604651162791,
      "grad_norm": 0.0007831555558368564,
      "learning_rate": 9.313953488372093e-06,
      "loss": 0.0001,
      "step": 10497
    },
    {
      "epoch": 40.689922480620154,
      "grad_norm": 0.0020198842976242304,
      "learning_rate": 9.310077519379845e-06,
      "loss": 0.0001,
      "step": 10498
    },
    {
      "epoch": 40.6937984496124,
      "grad_norm": 0.0016305167227983475,
      "learning_rate": 9.306201550387598e-06,
      "loss": 0.0002,
      "step": 10499
    },
    {
      "epoch": 40.69767441860465,
      "grad_norm": 0.0007725062314420938,
      "learning_rate": 9.302325581395349e-06,
      "loss": 0.0001,
      "step": 10500
    },
    {
      "epoch": 40.701550387596896,
      "grad_norm": 0.0008446265710517764,
      "learning_rate": 9.298449612403101e-06,
      "loss": 0.0001,
      "step": 10501
    },
    {
      "epoch": 40.70542635658915,
      "grad_norm": 0.0008178286370821297,
      "learning_rate": 9.294573643410853e-06,
      "loss": 0.0001,
      "step": 10502
    },
    {
      "epoch": 40.7093023255814,
      "grad_norm": 0.0025901491753757,
      "learning_rate": 9.290697674418606e-06,
      "loss": 0.0002,
      "step": 10503
    },
    {
      "epoch": 40.713178294573645,
      "grad_norm": 0.0009674921748228371,
      "learning_rate": 9.286821705426357e-06,
      "loss": 0.0001,
      "step": 10504
    },
    {
      "epoch": 40.71705426356589,
      "grad_norm": 0.0007253466174006462,
      "learning_rate": 9.282945736434109e-06,
      "loss": 0.0001,
      "step": 10505
    },
    {
      "epoch": 40.72093023255814,
      "grad_norm": 0.0008526172023266554,
      "learning_rate": 9.279069767441861e-06,
      "loss": 0.0001,
      "step": 10506
    },
    {
      "epoch": 40.724806201550386,
      "grad_norm": 0.0007770043448545039,
      "learning_rate": 9.275193798449614e-06,
      "loss": 0.0001,
      "step": 10507
    },
    {
      "epoch": 40.72868217054263,
      "grad_norm": 2.885315418243408,
      "learning_rate": 9.271317829457365e-06,
      "loss": 0.0035,
      "step": 10508
    },
    {
      "epoch": 40.73255813953488,
      "grad_norm": 0.0787334144115448,
      "learning_rate": 9.267441860465115e-06,
      "loss": 0.0002,
      "step": 10509
    },
    {
      "epoch": 40.736434108527135,
      "grad_norm": 0.0007296960684470832,
      "learning_rate": 9.263565891472868e-06,
      "loss": 0.0001,
      "step": 10510
    },
    {
      "epoch": 40.74031007751938,
      "grad_norm": 0.0030609036330133677,
      "learning_rate": 9.25968992248062e-06,
      "loss": 0.0002,
      "step": 10511
    },
    {
      "epoch": 40.74418604651163,
      "grad_norm": 0.0011774197919294238,
      "learning_rate": 9.255813953488373e-06,
      "loss": 0.0001,
      "step": 10512
    },
    {
      "epoch": 40.748062015503876,
      "grad_norm": 0.0008475356153212488,
      "learning_rate": 9.251937984496125e-06,
      "loss": 0.0001,
      "step": 10513
    },
    {
      "epoch": 40.751937984496124,
      "grad_norm": 0.0022549943532794714,
      "learning_rate": 9.248062015503876e-06,
      "loss": 0.0002,
      "step": 10514
    },
    {
      "epoch": 40.75581395348837,
      "grad_norm": 0.0011866858694702387,
      "learning_rate": 9.244186046511628e-06,
      "loss": 0.0001,
      "step": 10515
    },
    {
      "epoch": 40.75968992248062,
      "grad_norm": 0.001056936103850603,
      "learning_rate": 9.24031007751938e-06,
      "loss": 0.0001,
      "step": 10516
    },
    {
      "epoch": 40.763565891472865,
      "grad_norm": 0.001201897975988686,
      "learning_rate": 9.236434108527133e-06,
      "loss": 0.0001,
      "step": 10517
    },
    {
      "epoch": 40.76744186046512,
      "grad_norm": 0.0008775482419878244,
      "learning_rate": 9.232558139534884e-06,
      "loss": 0.0001,
      "step": 10518
    },
    {
      "epoch": 40.77131782945737,
      "grad_norm": 0.001134852529503405,
      "learning_rate": 9.228682170542636e-06,
      "loss": 0.0001,
      "step": 10519
    },
    {
      "epoch": 40.775193798449614,
      "grad_norm": 0.44324174523353577,
      "learning_rate": 9.224806201550389e-06,
      "loss": 0.0183,
      "step": 10520
    },
    {
      "epoch": 40.77906976744186,
      "grad_norm": 0.001005062134936452,
      "learning_rate": 9.220930232558141e-06,
      "loss": 0.0001,
      "step": 10521
    },
    {
      "epoch": 40.78294573643411,
      "grad_norm": 0.0008871702011674643,
      "learning_rate": 9.217054263565892e-06,
      "loss": 0.0001,
      "step": 10522
    },
    {
      "epoch": 40.786821705426355,
      "grad_norm": 0.0007979063666425645,
      "learning_rate": 9.213178294573644e-06,
      "loss": 0.0001,
      "step": 10523
    },
    {
      "epoch": 40.7906976744186,
      "grad_norm": 0.0015116139547899365,
      "learning_rate": 9.209302325581395e-06,
      "loss": 0.0001,
      "step": 10524
    },
    {
      "epoch": 40.79457364341085,
      "grad_norm": 2.874370574951172,
      "learning_rate": 9.205426356589147e-06,
      "loss": 0.2977,
      "step": 10525
    },
    {
      "epoch": 40.798449612403104,
      "grad_norm": 0.003912310115993023,
      "learning_rate": 9.2015503875969e-06,
      "loss": 0.0002,
      "step": 10526
    },
    {
      "epoch": 40.80232558139535,
      "grad_norm": 1.5818074941635132,
      "learning_rate": 9.197674418604652e-06,
      "loss": 0.0022,
      "step": 10527
    },
    {
      "epoch": 40.8062015503876,
      "grad_norm": 1.9727028608322144,
      "learning_rate": 9.193798449612403e-06,
      "loss": 0.02,
      "step": 10528
    },
    {
      "epoch": 40.810077519379846,
      "grad_norm": 0.05385018140077591,
      "learning_rate": 9.189922480620155e-06,
      "loss": 0.0003,
      "step": 10529
    },
    {
      "epoch": 40.81395348837209,
      "grad_norm": 0.0009308284497819841,
      "learning_rate": 9.186046511627908e-06,
      "loss": 0.0001,
      "step": 10530
    },
    {
      "epoch": 40.81782945736434,
      "grad_norm": 0.002370342845097184,
      "learning_rate": 9.18217054263566e-06,
      "loss": 0.0002,
      "step": 10531
    },
    {
      "epoch": 40.82170542635659,
      "grad_norm": 0.0008615951519459486,
      "learning_rate": 9.178294573643413e-06,
      "loss": 0.0001,
      "step": 10532
    },
    {
      "epoch": 40.825581395348834,
      "grad_norm": 0.0010546845151111484,
      "learning_rate": 9.174418604651163e-06,
      "loss": 0.0001,
      "step": 10533
    },
    {
      "epoch": 40.82945736434109,
      "grad_norm": 0.0007460275664925575,
      "learning_rate": 9.170542635658916e-06,
      "loss": 0.0001,
      "step": 10534
    },
    {
      "epoch": 40.833333333333336,
      "grad_norm": 3.1546430587768555,
      "learning_rate": 9.166666666666666e-06,
      "loss": 0.3302,
      "step": 10535
    },
    {
      "epoch": 40.83720930232558,
      "grad_norm": 0.000787503959145397,
      "learning_rate": 9.162790697674419e-06,
      "loss": 0.0001,
      "step": 10536
    },
    {
      "epoch": 40.84108527131783,
      "grad_norm": 0.0011161577422171831,
      "learning_rate": 9.158914728682171e-06,
      "loss": 0.0001,
      "step": 10537
    },
    {
      "epoch": 40.84496124031008,
      "grad_norm": 1.3607100248336792,
      "learning_rate": 9.155038759689922e-06,
      "loss": 0.0125,
      "step": 10538
    },
    {
      "epoch": 40.848837209302324,
      "grad_norm": 0.0023144034203141928,
      "learning_rate": 9.151162790697674e-06,
      "loss": 0.0002,
      "step": 10539
    },
    {
      "epoch": 40.85271317829457,
      "grad_norm": 0.0034390739165246487,
      "learning_rate": 9.147286821705427e-06,
      "loss": 0.0002,
      "step": 10540
    },
    {
      "epoch": 40.85658914728682,
      "grad_norm": 0.0023580219130963087,
      "learning_rate": 9.14341085271318e-06,
      "loss": 0.0001,
      "step": 10541
    },
    {
      "epoch": 40.86046511627907,
      "grad_norm": 0.0009720372618176043,
      "learning_rate": 9.13953488372093e-06,
      "loss": 0.0001,
      "step": 10542
    },
    {
      "epoch": 40.86434108527132,
      "grad_norm": 0.003845046041533351,
      "learning_rate": 9.135658914728682e-06,
      "loss": 0.0002,
      "step": 10543
    },
    {
      "epoch": 40.86821705426357,
      "grad_norm": 0.003709433600306511,
      "learning_rate": 9.131782945736435e-06,
      "loss": 0.0002,
      "step": 10544
    },
    {
      "epoch": 40.872093023255815,
      "grad_norm": 0.6545504331588745,
      "learning_rate": 9.127906976744187e-06,
      "loss": 0.0014,
      "step": 10545
    },
    {
      "epoch": 40.87596899224806,
      "grad_norm": 0.0008434748742729425,
      "learning_rate": 9.12403100775194e-06,
      "loss": 0.0001,
      "step": 10546
    },
    {
      "epoch": 40.87984496124031,
      "grad_norm": 0.0007352811517193913,
      "learning_rate": 9.12015503875969e-06,
      "loss": 0.0001,
      "step": 10547
    },
    {
      "epoch": 40.883720930232556,
      "grad_norm": 0.0010460485937073827,
      "learning_rate": 9.116279069767441e-06,
      "loss": 0.0001,
      "step": 10548
    },
    {
      "epoch": 40.8875968992248,
      "grad_norm": 0.0017755440203472972,
      "learning_rate": 9.112403100775194e-06,
      "loss": 0.0001,
      "step": 10549
    },
    {
      "epoch": 40.89147286821706,
      "grad_norm": 0.005383955780416727,
      "learning_rate": 9.108527131782946e-06,
      "loss": 0.0002,
      "step": 10550
    },
    {
      "epoch": 40.895348837209305,
      "grad_norm": 0.0008897234802134335,
      "learning_rate": 9.104651162790698e-06,
      "loss": 0.0001,
      "step": 10551
    },
    {
      "epoch": 40.89922480620155,
      "grad_norm": 0.00899586547166109,
      "learning_rate": 9.100775193798449e-06,
      "loss": 0.0004,
      "step": 10552
    },
    {
      "epoch": 40.9031007751938,
      "grad_norm": 0.044384755194187164,
      "learning_rate": 9.096899224806202e-06,
      "loss": 0.0004,
      "step": 10553
    },
    {
      "epoch": 40.906976744186046,
      "grad_norm": 0.001364920986816287,
      "learning_rate": 9.093023255813954e-06,
      "loss": 0.0001,
      "step": 10554
    },
    {
      "epoch": 40.91085271317829,
      "grad_norm": 0.0007707644836045802,
      "learning_rate": 9.089147286821706e-06,
      "loss": 0.0001,
      "step": 10555
    },
    {
      "epoch": 40.91472868217054,
      "grad_norm": 0.0007517262129113078,
      "learning_rate": 9.085271317829457e-06,
      "loss": 0.0001,
      "step": 10556
    },
    {
      "epoch": 40.91860465116279,
      "grad_norm": 0.0008337291656062007,
      "learning_rate": 9.08139534883721e-06,
      "loss": 0.0001,
      "step": 10557
    },
    {
      "epoch": 40.92248062015504,
      "grad_norm": 0.0016681632259860635,
      "learning_rate": 9.077519379844962e-06,
      "loss": 0.0002,
      "step": 10558
    },
    {
      "epoch": 40.92635658914729,
      "grad_norm": 0.000952963950112462,
      "learning_rate": 9.073643410852714e-06,
      "loss": 0.0001,
      "step": 10559
    },
    {
      "epoch": 40.93023255813954,
      "grad_norm": 5.6996588706970215,
      "learning_rate": 9.069767441860467e-06,
      "loss": 0.7792,
      "step": 10560
    },
    {
      "epoch": 40.934108527131784,
      "grad_norm": 0.001413345686160028,
      "learning_rate": 9.065891472868218e-06,
      "loss": 0.0001,
      "step": 10561
    },
    {
      "epoch": 40.93798449612403,
      "grad_norm": 0.0009233788587152958,
      "learning_rate": 9.062015503875968e-06,
      "loss": 0.0001,
      "step": 10562
    },
    {
      "epoch": 40.94186046511628,
      "grad_norm": 2.043752670288086,
      "learning_rate": 9.05813953488372e-06,
      "loss": 0.0755,
      "step": 10563
    },
    {
      "epoch": 40.945736434108525,
      "grad_norm": 0.0008116894168779254,
      "learning_rate": 9.054263565891473e-06,
      "loss": 0.0001,
      "step": 10564
    },
    {
      "epoch": 40.94961240310077,
      "grad_norm": 0.7062693238258362,
      "learning_rate": 9.050387596899226e-06,
      "loss": 0.0371,
      "step": 10565
    },
    {
      "epoch": 40.95348837209303,
      "grad_norm": 0.3735639750957489,
      "learning_rate": 9.046511627906976e-06,
      "loss": 0.016,
      "step": 10566
    },
    {
      "epoch": 40.957364341085274,
      "grad_norm": 0.0013772982638329268,
      "learning_rate": 9.042635658914729e-06,
      "loss": 0.0001,
      "step": 10567
    },
    {
      "epoch": 40.96124031007752,
      "grad_norm": 0.0008373690652661026,
      "learning_rate": 9.038759689922481e-06,
      "loss": 0.0001,
      "step": 10568
    },
    {
      "epoch": 40.96511627906977,
      "grad_norm": 0.0016743241576477885,
      "learning_rate": 9.034883720930234e-06,
      "loss": 0.0002,
      "step": 10569
    },
    {
      "epoch": 40.968992248062015,
      "grad_norm": 0.001216089935041964,
      "learning_rate": 9.031007751937986e-06,
      "loss": 0.0001,
      "step": 10570
    },
    {
      "epoch": 40.97286821705426,
      "grad_norm": 0.3343121111392975,
      "learning_rate": 9.027131782945737e-06,
      "loss": 0.0142,
      "step": 10571
    },
    {
      "epoch": 40.97674418604651,
      "grad_norm": 0.0008650272502563894,
      "learning_rate": 9.023255813953489e-06,
      "loss": 0.0001,
      "step": 10572
    },
    {
      "epoch": 40.98062015503876,
      "grad_norm": 0.0007659707916900516,
      "learning_rate": 9.019379844961242e-06,
      "loss": 0.0001,
      "step": 10573
    },
    {
      "epoch": 40.98449612403101,
      "grad_norm": 0.001166362315416336,
      "learning_rate": 9.015503875968994e-06,
      "loss": 0.0001,
      "step": 10574
    },
    {
      "epoch": 40.98837209302326,
      "grad_norm": 0.0007774988771416247,
      "learning_rate": 9.011627906976745e-06,
      "loss": 0.0001,
      "step": 10575
    },
    {
      "epoch": 40.992248062015506,
      "grad_norm": 0.0009228932904079556,
      "learning_rate": 9.007751937984495e-06,
      "loss": 0.0001,
      "step": 10576
    },
    {
      "epoch": 40.99612403100775,
      "grad_norm": 0.0008063963614404202,
      "learning_rate": 9.003875968992248e-06,
      "loss": 0.0001,
      "step": 10577
    },
    {
      "epoch": 41.0,
      "grad_norm": 0.021036572754383087,
      "learning_rate": 9e-06,
      "loss": 0.0005,
      "step": 10578
    },
    {
      "epoch": 41.00387596899225,
      "grad_norm": 0.0013225614093244076,
      "learning_rate": 8.996124031007753e-06,
      "loss": 0.0001,
      "step": 10579
    },
    {
      "epoch": 41.007751937984494,
      "grad_norm": 0.0013306544860824943,
      "learning_rate": 8.992248062015503e-06,
      "loss": 0.0001,
      "step": 10580
    },
    {
      "epoch": 41.01162790697674,
      "grad_norm": 0.0008680954924784601,
      "learning_rate": 8.988372093023256e-06,
      "loss": 0.0001,
      "step": 10581
    },
    {
      "epoch": 41.01550387596899,
      "grad_norm": 0.0007665097946301103,
      "learning_rate": 8.984496124031008e-06,
      "loss": 0.0001,
      "step": 10582
    },
    {
      "epoch": 41.01937984496124,
      "grad_norm": 0.0008592057274654508,
      "learning_rate": 8.98062015503876e-06,
      "loss": 0.0001,
      "step": 10583
    },
    {
      "epoch": 41.02325581395349,
      "grad_norm": 0.0075409603305161,
      "learning_rate": 8.976744186046513e-06,
      "loss": 0.0001,
      "step": 10584
    },
    {
      "epoch": 41.02713178294574,
      "grad_norm": 0.0007288052584044635,
      "learning_rate": 8.972868217054264e-06,
      "loss": 0.0001,
      "step": 10585
    },
    {
      "epoch": 41.031007751937985,
      "grad_norm": 0.0017737449379637837,
      "learning_rate": 8.968992248062016e-06,
      "loss": 0.0002,
      "step": 10586
    },
    {
      "epoch": 41.03488372093023,
      "grad_norm": 0.0017324056243523955,
      "learning_rate": 8.965116279069769e-06,
      "loss": 0.0001,
      "step": 10587
    },
    {
      "epoch": 41.03875968992248,
      "grad_norm": 0.012657826766371727,
      "learning_rate": 8.96124031007752e-06,
      "loss": 0.0004,
      "step": 10588
    },
    {
      "epoch": 41.042635658914726,
      "grad_norm": 0.0007997379289008677,
      "learning_rate": 8.957364341085272e-06,
      "loss": 0.0001,
      "step": 10589
    },
    {
      "epoch": 41.04651162790697,
      "grad_norm": 0.0006523345364257693,
      "learning_rate": 8.953488372093023e-06,
      "loss": 0.0001,
      "step": 10590
    },
    {
      "epoch": 41.05038759689923,
      "grad_norm": 0.0009256760240532458,
      "learning_rate": 8.949612403100775e-06,
      "loss": 0.0001,
      "step": 10591
    },
    {
      "epoch": 41.054263565891475,
      "grad_norm": 0.002753531327471137,
      "learning_rate": 8.945736434108527e-06,
      "loss": 0.0001,
      "step": 10592
    },
    {
      "epoch": 41.05813953488372,
      "grad_norm": 0.0008496188675053418,
      "learning_rate": 8.94186046511628e-06,
      "loss": 0.0001,
      "step": 10593
    },
    {
      "epoch": 41.06201550387597,
      "grad_norm": 0.0009967639343813062,
      "learning_rate": 8.937984496124032e-06,
      "loss": 0.0001,
      "step": 10594
    },
    {
      "epoch": 41.065891472868216,
      "grad_norm": 0.0010225882288068533,
      "learning_rate": 8.934108527131783e-06,
      "loss": 0.0001,
      "step": 10595
    },
    {
      "epoch": 41.06976744186046,
      "grad_norm": 0.0008714334690012038,
      "learning_rate": 8.930232558139535e-06,
      "loss": 0.0001,
      "step": 10596
    },
    {
      "epoch": 41.07364341085271,
      "grad_norm": 0.0016703526489436626,
      "learning_rate": 8.926356589147288e-06,
      "loss": 0.0002,
      "step": 10597
    },
    {
      "epoch": 41.07751937984496,
      "grad_norm": 0.0010099251521751285,
      "learning_rate": 8.92248062015504e-06,
      "loss": 0.0001,
      "step": 10598
    },
    {
      "epoch": 41.08139534883721,
      "grad_norm": 0.0008201490272767842,
      "learning_rate": 8.918604651162791e-06,
      "loss": 0.0001,
      "step": 10599
    },
    {
      "epoch": 41.08527131782946,
      "grad_norm": 0.0029012449085712433,
      "learning_rate": 8.914728682170543e-06,
      "loss": 0.0002,
      "step": 10600
    },
    {
      "epoch": 41.08914728682171,
      "grad_norm": 0.0007076762849465013,
      "learning_rate": 8.910852713178296e-06,
      "loss": 0.0001,
      "step": 10601
    },
    {
      "epoch": 41.093023255813954,
      "grad_norm": 0.005875254049897194,
      "learning_rate": 8.906976744186046e-06,
      "loss": 0.0001,
      "step": 10602
    },
    {
      "epoch": 41.0968992248062,
      "grad_norm": 0.0011845375411212444,
      "learning_rate": 8.903100775193799e-06,
      "loss": 0.0001,
      "step": 10603
    },
    {
      "epoch": 41.10077519379845,
      "grad_norm": 0.0015345870051532984,
      "learning_rate": 8.89922480620155e-06,
      "loss": 0.0001,
      "step": 10604
    },
    {
      "epoch": 41.104651162790695,
      "grad_norm": 0.001082726987078786,
      "learning_rate": 8.895348837209302e-06,
      "loss": 0.0001,
      "step": 10605
    },
    {
      "epoch": 41.10852713178294,
      "grad_norm": 0.0008689041715115309,
      "learning_rate": 8.891472868217054e-06,
      "loss": 0.0001,
      "step": 10606
    },
    {
      "epoch": 41.1124031007752,
      "grad_norm": 0.5706307888031006,
      "learning_rate": 8.887596899224807e-06,
      "loss": 0.0317,
      "step": 10607
    },
    {
      "epoch": 41.116279069767444,
      "grad_norm": 0.0012120779138058424,
      "learning_rate": 8.88372093023256e-06,
      "loss": 0.0001,
      "step": 10608
    },
    {
      "epoch": 41.12015503875969,
      "grad_norm": 0.0006904490874148905,
      "learning_rate": 8.87984496124031e-06,
      "loss": 0.0001,
      "step": 10609
    },
    {
      "epoch": 41.12403100775194,
      "grad_norm": 0.0009892317466437817,
      "learning_rate": 8.875968992248062e-06,
      "loss": 0.0001,
      "step": 10610
    },
    {
      "epoch": 41.127906976744185,
      "grad_norm": 0.0007483686204068363,
      "learning_rate": 8.872093023255815e-06,
      "loss": 0.0001,
      "step": 10611
    },
    {
      "epoch": 41.13178294573643,
      "grad_norm": 0.000807904580142349,
      "learning_rate": 8.868217054263567e-06,
      "loss": 0.0001,
      "step": 10612
    },
    {
      "epoch": 41.13565891472868,
      "grad_norm": 0.0010687157046049833,
      "learning_rate": 8.864341085271318e-06,
      "loss": 0.0001,
      "step": 10613
    },
    {
      "epoch": 41.13953488372093,
      "grad_norm": 0.0008062540437094867,
      "learning_rate": 8.86046511627907e-06,
      "loss": 0.0001,
      "step": 10614
    },
    {
      "epoch": 41.14341085271318,
      "grad_norm": 0.050994981080293655,
      "learning_rate": 8.856589147286821e-06,
      "loss": 0.0005,
      "step": 10615
    },
    {
      "epoch": 41.14728682170543,
      "grad_norm": 0.0010793824912980199,
      "learning_rate": 8.852713178294574e-06,
      "loss": 0.0001,
      "step": 10616
    },
    {
      "epoch": 41.151162790697676,
      "grad_norm": 10.643386840820312,
      "learning_rate": 8.848837209302326e-06,
      "loss": 0.2206,
      "step": 10617
    },
    {
      "epoch": 41.15503875968992,
      "grad_norm": 0.0014842537930235267,
      "learning_rate": 8.844961240310078e-06,
      "loss": 0.0001,
      "step": 10618
    },
    {
      "epoch": 41.15891472868217,
      "grad_norm": 0.0013087562983855605,
      "learning_rate": 8.84108527131783e-06,
      "loss": 0.0001,
      "step": 10619
    },
    {
      "epoch": 41.16279069767442,
      "grad_norm": 0.0010062122019007802,
      "learning_rate": 8.837209302325582e-06,
      "loss": 0.0001,
      "step": 10620
    },
    {
      "epoch": 41.166666666666664,
      "grad_norm": 0.0017544639995321631,
      "learning_rate": 8.833333333333334e-06,
      "loss": 0.0001,
      "step": 10621
    },
    {
      "epoch": 41.17054263565891,
      "grad_norm": 0.0007649024482816458,
      "learning_rate": 8.829457364341086e-06,
      "loss": 0.0001,
      "step": 10622
    },
    {
      "epoch": 41.174418604651166,
      "grad_norm": 0.0009302538237534463,
      "learning_rate": 8.825581395348837e-06,
      "loss": 0.0001,
      "step": 10623
    },
    {
      "epoch": 41.17829457364341,
      "grad_norm": 0.0007527403067797422,
      "learning_rate": 8.82170542635659e-06,
      "loss": 0.0001,
      "step": 10624
    },
    {
      "epoch": 41.18217054263566,
      "grad_norm": 0.0008601652807556093,
      "learning_rate": 8.817829457364342e-06,
      "loss": 0.0001,
      "step": 10625
    },
    {
      "epoch": 41.18604651162791,
      "grad_norm": 0.0008830432198010385,
      "learning_rate": 8.813953488372094e-06,
      "loss": 0.0001,
      "step": 10626
    },
    {
      "epoch": 41.189922480620154,
      "grad_norm": 0.0014276200672611594,
      "learning_rate": 8.810077519379845e-06,
      "loss": 0.0001,
      "step": 10627
    },
    {
      "epoch": 41.1937984496124,
      "grad_norm": 0.000788364908657968,
      "learning_rate": 8.806201550387596e-06,
      "loss": 0.0001,
      "step": 10628
    },
    {
      "epoch": 41.19767441860465,
      "grad_norm": 0.0007326910854317248,
      "learning_rate": 8.802325581395348e-06,
      "loss": 0.0001,
      "step": 10629
    },
    {
      "epoch": 41.201550387596896,
      "grad_norm": 0.0035568787716329098,
      "learning_rate": 8.7984496124031e-06,
      "loss": 0.0002,
      "step": 10630
    },
    {
      "epoch": 41.20542635658915,
      "grad_norm": 0.0007011483539827168,
      "learning_rate": 8.794573643410853e-06,
      "loss": 0.0001,
      "step": 10631
    },
    {
      "epoch": 41.2093023255814,
      "grad_norm": 0.001077342196367681,
      "learning_rate": 8.790697674418606e-06,
      "loss": 0.0001,
      "step": 10632
    },
    {
      "epoch": 41.213178294573645,
      "grad_norm": 0.0007925003301352262,
      "learning_rate": 8.786821705426356e-06,
      "loss": 0.0001,
      "step": 10633
    },
    {
      "epoch": 41.21705426356589,
      "grad_norm": 0.000961960235144943,
      "learning_rate": 8.782945736434109e-06,
      "loss": 0.0001,
      "step": 10634
    },
    {
      "epoch": 41.22093023255814,
      "grad_norm": 0.0008461116813123226,
      "learning_rate": 8.779069767441861e-06,
      "loss": 0.0001,
      "step": 10635
    },
    {
      "epoch": 41.224806201550386,
      "grad_norm": 0.001316839479841292,
      "learning_rate": 8.775193798449614e-06,
      "loss": 0.0001,
      "step": 10636
    },
    {
      "epoch": 41.22868217054263,
      "grad_norm": 0.0019277441315352917,
      "learning_rate": 8.771317829457364e-06,
      "loss": 0.0002,
      "step": 10637
    },
    {
      "epoch": 41.23255813953488,
      "grad_norm": 0.0068855928257107735,
      "learning_rate": 8.767441860465117e-06,
      "loss": 0.0002,
      "step": 10638
    },
    {
      "epoch": 41.236434108527135,
      "grad_norm": 0.009588037617504597,
      "learning_rate": 8.763565891472869e-06,
      "loss": 0.0002,
      "step": 10639
    },
    {
      "epoch": 41.24031007751938,
      "grad_norm": 0.0008514821529388428,
      "learning_rate": 8.759689922480622e-06,
      "loss": 0.0001,
      "step": 10640
    },
    {
      "epoch": 41.24418604651163,
      "grad_norm": 0.0011929437750950456,
      "learning_rate": 8.755813953488374e-06,
      "loss": 0.0001,
      "step": 10641
    },
    {
      "epoch": 41.248062015503876,
      "grad_norm": 0.0008361961226910353,
      "learning_rate": 8.751937984496123e-06,
      "loss": 0.0001,
      "step": 10642
    },
    {
      "epoch": 41.251937984496124,
      "grad_norm": 0.21559368073940277,
      "learning_rate": 8.748062015503875e-06,
      "loss": 0.0009,
      "step": 10643
    },
    {
      "epoch": 41.25581395348837,
      "grad_norm": 0.0007871519774198532,
      "learning_rate": 8.744186046511628e-06,
      "loss": 0.0001,
      "step": 10644
    },
    {
      "epoch": 41.25968992248062,
      "grad_norm": 0.0008550130878575146,
      "learning_rate": 8.74031007751938e-06,
      "loss": 0.0001,
      "step": 10645
    },
    {
      "epoch": 41.263565891472865,
      "grad_norm": 0.0007150035817176104,
      "learning_rate": 8.736434108527133e-06,
      "loss": 0.0001,
      "step": 10646
    },
    {
      "epoch": 41.26744186046512,
      "grad_norm": 0.000756961468141526,
      "learning_rate": 8.732558139534883e-06,
      "loss": 0.0001,
      "step": 10647
    },
    {
      "epoch": 41.27131782945737,
      "grad_norm": 0.0012966037029400468,
      "learning_rate": 8.728682170542636e-06,
      "loss": 0.0001,
      "step": 10648
    },
    {
      "epoch": 41.275193798449614,
      "grad_norm": 0.0007350390078499913,
      "learning_rate": 8.724806201550388e-06,
      "loss": 0.0001,
      "step": 10649
    },
    {
      "epoch": 41.27906976744186,
      "grad_norm": 0.0010793167166411877,
      "learning_rate": 8.72093023255814e-06,
      "loss": 0.0001,
      "step": 10650
    },
    {
      "epoch": 41.28294573643411,
      "grad_norm": 0.0010379436425864697,
      "learning_rate": 8.717054263565891e-06,
      "loss": 0.0001,
      "step": 10651
    },
    {
      "epoch": 41.286821705426355,
      "grad_norm": 0.003132722806185484,
      "learning_rate": 8.713178294573644e-06,
      "loss": 0.0002,
      "step": 10652
    },
    {
      "epoch": 41.2906976744186,
      "grad_norm": 0.0009382697753608227,
      "learning_rate": 8.709302325581396e-06,
      "loss": 0.0001,
      "step": 10653
    },
    {
      "epoch": 41.29457364341085,
      "grad_norm": 0.010367653332650661,
      "learning_rate": 8.705426356589149e-06,
      "loss": 0.0003,
      "step": 10654
    },
    {
      "epoch": 41.298449612403104,
      "grad_norm": 0.00102072989102453,
      "learning_rate": 8.7015503875969e-06,
      "loss": 0.0001,
      "step": 10655
    },
    {
      "epoch": 41.30232558139535,
      "grad_norm": 0.0011095873778685927,
      "learning_rate": 8.697674418604652e-06,
      "loss": 0.0001,
      "step": 10656
    },
    {
      "epoch": 41.3062015503876,
      "grad_norm": 0.0007420165929943323,
      "learning_rate": 8.693798449612403e-06,
      "loss": 0.0001,
      "step": 10657
    },
    {
      "epoch": 41.310077519379846,
      "grad_norm": 0.0010506745893508196,
      "learning_rate": 8.689922480620155e-06,
      "loss": 0.0001,
      "step": 10658
    },
    {
      "epoch": 41.31395348837209,
      "grad_norm": 0.0009083189070224762,
      "learning_rate": 8.686046511627907e-06,
      "loss": 0.0001,
      "step": 10659
    },
    {
      "epoch": 41.31782945736434,
      "grad_norm": 0.001167229493148625,
      "learning_rate": 8.68217054263566e-06,
      "loss": 0.0001,
      "step": 10660
    },
    {
      "epoch": 41.32170542635659,
      "grad_norm": 0.0009643259691074491,
      "learning_rate": 8.67829457364341e-06,
      "loss": 0.0001,
      "step": 10661
    },
    {
      "epoch": 41.325581395348834,
      "grad_norm": 0.007499856408685446,
      "learning_rate": 8.674418604651163e-06,
      "loss": 0.0004,
      "step": 10662
    },
    {
      "epoch": 41.32945736434109,
      "grad_norm": 0.0008687872323207557,
      "learning_rate": 8.670542635658915e-06,
      "loss": 0.0001,
      "step": 10663
    },
    {
      "epoch": 41.333333333333336,
      "grad_norm": 0.001074430299922824,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.0001,
      "step": 10664
    },
    {
      "epoch": 41.33720930232558,
      "grad_norm": 0.0006855853134766221,
      "learning_rate": 8.66279069767442e-06,
      "loss": 0.0001,
      "step": 10665
    },
    {
      "epoch": 41.34108527131783,
      "grad_norm": 0.017066137865185738,
      "learning_rate": 8.658914728682171e-06,
      "loss": 0.0003,
      "step": 10666
    },
    {
      "epoch": 41.34496124031008,
      "grad_norm": 0.00814262218773365,
      "learning_rate": 8.655038759689923e-06,
      "loss": 0.0003,
      "step": 10667
    },
    {
      "epoch": 41.348837209302324,
      "grad_norm": 2.8158740997314453,
      "learning_rate": 8.651162790697674e-06,
      "loss": 0.2968,
      "step": 10668
    },
    {
      "epoch": 41.35271317829457,
      "grad_norm": 0.0010210706386715174,
      "learning_rate": 8.647286821705427e-06,
      "loss": 0.0001,
      "step": 10669
    },
    {
      "epoch": 41.35658914728682,
      "grad_norm": 0.0016046235105022788,
      "learning_rate": 8.643410852713179e-06,
      "loss": 0.0001,
      "step": 10670
    },
    {
      "epoch": 41.36046511627907,
      "grad_norm": 3.4166996479034424,
      "learning_rate": 8.63953488372093e-06,
      "loss": 0.136,
      "step": 10671
    },
    {
      "epoch": 41.36434108527132,
      "grad_norm": 0.0008363049128092825,
      "learning_rate": 8.635658914728682e-06,
      "loss": 0.0001,
      "step": 10672
    },
    {
      "epoch": 41.36821705426357,
      "grad_norm": 0.002384837483987212,
      "learning_rate": 8.631782945736435e-06,
      "loss": 0.0002,
      "step": 10673
    },
    {
      "epoch": 41.372093023255815,
      "grad_norm": 0.311474472284317,
      "learning_rate": 8.627906976744187e-06,
      "loss": 0.0104,
      "step": 10674
    },
    {
      "epoch": 41.37596899224806,
      "grad_norm": 0.0009042085730470717,
      "learning_rate": 8.624031007751938e-06,
      "loss": 0.0001,
      "step": 10675
    },
    {
      "epoch": 41.37984496124031,
      "grad_norm": 0.00077914132270962,
      "learning_rate": 8.62015503875969e-06,
      "loss": 0.0001,
      "step": 10676
    },
    {
      "epoch": 41.383720930232556,
      "grad_norm": 0.983380913734436,
      "learning_rate": 8.616279069767443e-06,
      "loss": 0.0194,
      "step": 10677
    },
    {
      "epoch": 41.3875968992248,
      "grad_norm": 0.15757478773593903,
      "learning_rate": 8.612403100775195e-06,
      "loss": 0.0002,
      "step": 10678
    },
    {
      "epoch": 41.39147286821706,
      "grad_norm": 14.579556465148926,
      "learning_rate": 8.608527131782947e-06,
      "loss": 0.0695,
      "step": 10679
    },
    {
      "epoch": 41.395348837209305,
      "grad_norm": 0.0025946630630642176,
      "learning_rate": 8.604651162790698e-06,
      "loss": 0.0002,
      "step": 10680
    },
    {
      "epoch": 41.39922480620155,
      "grad_norm": 0.0008134364034049213,
      "learning_rate": 8.60077519379845e-06,
      "loss": 0.0001,
      "step": 10681
    },
    {
      "epoch": 41.4031007751938,
      "grad_norm": 0.0031521476339548826,
      "learning_rate": 8.596899224806201e-06,
      "loss": 0.0002,
      "step": 10682
    },
    {
      "epoch": 41.406976744186046,
      "grad_norm": 0.0008041781838983297,
      "learning_rate": 8.593023255813954e-06,
      "loss": 0.0001,
      "step": 10683
    },
    {
      "epoch": 41.41085271317829,
      "grad_norm": 0.0009851796785369515,
      "learning_rate": 8.589147286821706e-06,
      "loss": 0.0001,
      "step": 10684
    },
    {
      "epoch": 41.41472868217054,
      "grad_norm": 0.0007381277973763645,
      "learning_rate": 8.585271317829457e-06,
      "loss": 0.0001,
      "step": 10685
    },
    {
      "epoch": 41.41860465116279,
      "grad_norm": 0.0032427895348519087,
      "learning_rate": 8.58139534883721e-06,
      "loss": 0.0001,
      "step": 10686
    },
    {
      "epoch": 41.42248062015504,
      "grad_norm": 0.003149593248963356,
      "learning_rate": 8.577519379844962e-06,
      "loss": 0.0002,
      "step": 10687
    },
    {
      "epoch": 41.42635658914729,
      "grad_norm": 0.0007853732095099986,
      "learning_rate": 8.573643410852714e-06,
      "loss": 0.0001,
      "step": 10688
    },
    {
      "epoch": 41.43023255813954,
      "grad_norm": 0.000748152902815491,
      "learning_rate": 8.569767441860465e-06,
      "loss": 0.0001,
      "step": 10689
    },
    {
      "epoch": 41.434108527131784,
      "grad_norm": 0.0014575655804947019,
      "learning_rate": 8.565891472868217e-06,
      "loss": 0.0001,
      "step": 10690
    },
    {
      "epoch": 41.43798449612403,
      "grad_norm": 0.18967369198799133,
      "learning_rate": 8.56201550387597e-06,
      "loss": 0.0064,
      "step": 10691
    },
    {
      "epoch": 41.44186046511628,
      "grad_norm": 0.0014783202204853296,
      "learning_rate": 8.558139534883722e-06,
      "loss": 0.0001,
      "step": 10692
    },
    {
      "epoch": 41.445736434108525,
      "grad_norm": 0.0008690841495990753,
      "learning_rate": 8.554263565891475e-06,
      "loss": 0.0001,
      "step": 10693
    },
    {
      "epoch": 41.44961240310077,
      "grad_norm": 0.7268452048301697,
      "learning_rate": 8.550387596899225e-06,
      "loss": 0.0392,
      "step": 10694
    },
    {
      "epoch": 41.45348837209303,
      "grad_norm": 0.0008936260710470378,
      "learning_rate": 8.546511627906976e-06,
      "loss": 0.0001,
      "step": 10695
    },
    {
      "epoch": 41.457364341085274,
      "grad_norm": 0.0008372305892407894,
      "learning_rate": 8.542635658914728e-06,
      "loss": 0.0001,
      "step": 10696
    },
    {
      "epoch": 41.46124031007752,
      "grad_norm": 0.8478211164474487,
      "learning_rate": 8.53875968992248e-06,
      "loss": 0.0377,
      "step": 10697
    },
    {
      "epoch": 41.46511627906977,
      "grad_norm": 0.0020142921712249517,
      "learning_rate": 8.534883720930233e-06,
      "loss": 0.0002,
      "step": 10698
    },
    {
      "epoch": 41.468992248062015,
      "grad_norm": 0.0008035868522711098,
      "learning_rate": 8.531007751937984e-06,
      "loss": 0.0001,
      "step": 10699
    },
    {
      "epoch": 41.47286821705426,
      "grad_norm": 0.0009295381605625153,
      "learning_rate": 8.527131782945736e-06,
      "loss": 0.0001,
      "step": 10700
    },
    {
      "epoch": 41.47674418604651,
      "grad_norm": 0.6451258659362793,
      "learning_rate": 8.523255813953489e-06,
      "loss": 0.0009,
      "step": 10701
    },
    {
      "epoch": 41.48062015503876,
      "grad_norm": 0.0017214288236573339,
      "learning_rate": 8.519379844961241e-06,
      "loss": 0.0001,
      "step": 10702
    },
    {
      "epoch": 41.48449612403101,
      "grad_norm": 0.0007348055951297283,
      "learning_rate": 8.515503875968994e-06,
      "loss": 0.0001,
      "step": 10703
    },
    {
      "epoch": 41.48837209302326,
      "grad_norm": 0.013637006282806396,
      "learning_rate": 8.511627906976744e-06,
      "loss": 0.0004,
      "step": 10704
    },
    {
      "epoch": 41.492248062015506,
      "grad_norm": 0.0013445507502183318,
      "learning_rate": 8.507751937984497e-06,
      "loss": 0.0001,
      "step": 10705
    },
    {
      "epoch": 41.49612403100775,
      "grad_norm": 0.0026193216908723116,
      "learning_rate": 8.50387596899225e-06,
      "loss": 0.0002,
      "step": 10706
    },
    {
      "epoch": 41.5,
      "grad_norm": 0.0007728589116595685,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.0001,
      "step": 10707
    },
    {
      "epoch": 41.50387596899225,
      "grad_norm": 0.8394075632095337,
      "learning_rate": 8.496124031007752e-06,
      "loss": 0.0632,
      "step": 10708
    },
    {
      "epoch": 41.507751937984494,
      "grad_norm": 0.002239063149318099,
      "learning_rate": 8.492248062015503e-06,
      "loss": 0.0002,
      "step": 10709
    },
    {
      "epoch": 41.51162790697674,
      "grad_norm": 0.001667545409873128,
      "learning_rate": 8.488372093023256e-06,
      "loss": 0.0001,
      "step": 10710
    },
    {
      "epoch": 41.51550387596899,
      "grad_norm": 0.001336354180239141,
      "learning_rate": 8.484496124031008e-06,
      "loss": 0.0001,
      "step": 10711
    },
    {
      "epoch": 41.51937984496124,
      "grad_norm": 0.017786065116524696,
      "learning_rate": 8.48062015503876e-06,
      "loss": 0.0002,
      "step": 10712
    },
    {
      "epoch": 41.52325581395349,
      "grad_norm": 0.0009233401506207883,
      "learning_rate": 8.476744186046511e-06,
      "loss": 0.0001,
      "step": 10713
    },
    {
      "epoch": 41.52713178294574,
      "grad_norm": 0.002434920286759734,
      "learning_rate": 8.472868217054263e-06,
      "loss": 0.0002,
      "step": 10714
    },
    {
      "epoch": 41.531007751937985,
      "grad_norm": 0.0008492750348523259,
      "learning_rate": 8.468992248062016e-06,
      "loss": 0.0001,
      "step": 10715
    },
    {
      "epoch": 41.53488372093023,
      "grad_norm": 0.0011253224220126867,
      "learning_rate": 8.465116279069768e-06,
      "loss": 0.0001,
      "step": 10716
    },
    {
      "epoch": 41.53875968992248,
      "grad_norm": 0.0008014329359866679,
      "learning_rate": 8.46124031007752e-06,
      "loss": 0.0001,
      "step": 10717
    },
    {
      "epoch": 41.542635658914726,
      "grad_norm": 0.0030718103516846895,
      "learning_rate": 8.457364341085271e-06,
      "loss": 0.0002,
      "step": 10718
    },
    {
      "epoch": 41.54651162790697,
      "grad_norm": 0.0008240590686909854,
      "learning_rate": 8.453488372093024e-06,
      "loss": 0.0001,
      "step": 10719
    },
    {
      "epoch": 41.55038759689923,
      "grad_norm": 0.0012849497143179178,
      "learning_rate": 8.449612403100776e-06,
      "loss": 0.0001,
      "step": 10720
    },
    {
      "epoch": 41.554263565891475,
      "grad_norm": 0.0011660961899906397,
      "learning_rate": 8.445736434108529e-06,
      "loss": 0.0001,
      "step": 10721
    },
    {
      "epoch": 41.55813953488372,
      "grad_norm": 0.0007006537634879351,
      "learning_rate": 8.44186046511628e-06,
      "loss": 0.0001,
      "step": 10722
    },
    {
      "epoch": 41.56201550387597,
      "grad_norm": 0.0011139637790620327,
      "learning_rate": 8.43798449612403e-06,
      "loss": 0.0001,
      "step": 10723
    },
    {
      "epoch": 41.565891472868216,
      "grad_norm": 0.0010445216903463006,
      "learning_rate": 8.434108527131783e-06,
      "loss": 0.0001,
      "step": 10724
    },
    {
      "epoch": 41.56976744186046,
      "grad_norm": 0.0006848417688161135,
      "learning_rate": 8.430232558139535e-06,
      "loss": 0.0001,
      "step": 10725
    },
    {
      "epoch": 41.57364341085271,
      "grad_norm": 0.0008023919654078782,
      "learning_rate": 8.426356589147287e-06,
      "loss": 0.0001,
      "step": 10726
    },
    {
      "epoch": 41.57751937984496,
      "grad_norm": 0.0010995900956913829,
      "learning_rate": 8.42248062015504e-06,
      "loss": 0.0001,
      "step": 10727
    },
    {
      "epoch": 41.58139534883721,
      "grad_norm": 0.0010187977459281683,
      "learning_rate": 8.41860465116279e-06,
      "loss": 0.0001,
      "step": 10728
    },
    {
      "epoch": 41.58527131782946,
      "grad_norm": 0.18414245545864105,
      "learning_rate": 8.414728682170543e-06,
      "loss": 0.0069,
      "step": 10729
    },
    {
      "epoch": 41.58914728682171,
      "grad_norm": 0.0015302977990359068,
      "learning_rate": 8.410852713178295e-06,
      "loss": 0.0001,
      "step": 10730
    },
    {
      "epoch": 41.593023255813954,
      "grad_norm": 0.00087791180703789,
      "learning_rate": 8.406976744186048e-06,
      "loss": 0.0001,
      "step": 10731
    },
    {
      "epoch": 41.5968992248062,
      "grad_norm": 0.0018935755360871553,
      "learning_rate": 8.403100775193799e-06,
      "loss": 0.0002,
      "step": 10732
    },
    {
      "epoch": 41.60077519379845,
      "grad_norm": 0.0009820122504606843,
      "learning_rate": 8.399224806201551e-06,
      "loss": 0.0001,
      "step": 10733
    },
    {
      "epoch": 41.604651162790695,
      "grad_norm": 0.0008145600440911949,
      "learning_rate": 8.395348837209303e-06,
      "loss": 0.0001,
      "step": 10734
    },
    {
      "epoch": 41.60852713178294,
      "grad_norm": 0.0007841193000786006,
      "learning_rate": 8.391472868217054e-06,
      "loss": 0.0001,
      "step": 10735
    },
    {
      "epoch": 41.6124031007752,
      "grad_norm": 0.002046341309323907,
      "learning_rate": 8.387596899224807e-06,
      "loss": 0.0001,
      "step": 10736
    },
    {
      "epoch": 41.616279069767444,
      "grad_norm": 0.0007733094971626997,
      "learning_rate": 8.383720930232557e-06,
      "loss": 0.0001,
      "step": 10737
    },
    {
      "epoch": 41.62015503875969,
      "grad_norm": 3.544660806655884,
      "learning_rate": 8.37984496124031e-06,
      "loss": 0.4459,
      "step": 10738
    },
    {
      "epoch": 41.62403100775194,
      "grad_norm": 0.001091525424271822,
      "learning_rate": 8.375968992248062e-06,
      "loss": 0.0001,
      "step": 10739
    },
    {
      "epoch": 41.627906976744185,
      "grad_norm": 0.0007786811329424381,
      "learning_rate": 8.372093023255815e-06,
      "loss": 0.0001,
      "step": 10740
    },
    {
      "epoch": 41.63178294573643,
      "grad_norm": 0.0008984304731711745,
      "learning_rate": 8.368217054263567e-06,
      "loss": 0.0001,
      "step": 10741
    },
    {
      "epoch": 41.63565891472868,
      "grad_norm": 0.47847238183021545,
      "learning_rate": 8.364341085271318e-06,
      "loss": 0.0062,
      "step": 10742
    },
    {
      "epoch": 41.63953488372093,
      "grad_norm": 0.0007611411274410784,
      "learning_rate": 8.36046511627907e-06,
      "loss": 0.0001,
      "step": 10743
    },
    {
      "epoch": 41.64341085271318,
      "grad_norm": 0.0006894286489114165,
      "learning_rate": 8.356589147286823e-06,
      "loss": 0.0001,
      "step": 10744
    },
    {
      "epoch": 41.64728682170543,
      "grad_norm": 0.0009550328250043094,
      "learning_rate": 8.352713178294575e-06,
      "loss": 0.0001,
      "step": 10745
    },
    {
      "epoch": 41.651162790697676,
      "grad_norm": 0.0008196344715543091,
      "learning_rate": 8.348837209302326e-06,
      "loss": 0.0001,
      "step": 10746
    },
    {
      "epoch": 41.65503875968992,
      "grad_norm": 0.0074286507442593575,
      "learning_rate": 8.344961240310078e-06,
      "loss": 0.0003,
      "step": 10747
    },
    {
      "epoch": 41.65891472868217,
      "grad_norm": 0.0013636096846312284,
      "learning_rate": 8.341085271317829e-06,
      "loss": 0.0001,
      "step": 10748
    },
    {
      "epoch": 41.66279069767442,
      "grad_norm": 0.0014843924436718225,
      "learning_rate": 8.337209302325581e-06,
      "loss": 0.0001,
      "step": 10749
    },
    {
      "epoch": 41.666666666666664,
      "grad_norm": 0.2281244993209839,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0092,
      "step": 10750
    },
    {
      "epoch": 41.67054263565891,
      "grad_norm": 0.2202705293893814,
      "learning_rate": 8.329457364341086e-06,
      "loss": 0.0099,
      "step": 10751
    },
    {
      "epoch": 41.674418604651166,
      "grad_norm": 0.000921997765544802,
      "learning_rate": 8.325581395348837e-06,
      "loss": 0.0001,
      "step": 10752
    },
    {
      "epoch": 41.67829457364341,
      "grad_norm": 0.0008247998193837702,
      "learning_rate": 8.32170542635659e-06,
      "loss": 0.0001,
      "step": 10753
    },
    {
      "epoch": 41.68217054263566,
      "grad_norm": 0.004846075549721718,
      "learning_rate": 8.317829457364342e-06,
      "loss": 0.0002,
      "step": 10754
    },
    {
      "epoch": 41.68604651162791,
      "grad_norm": 0.66948002576828,
      "learning_rate": 8.313953488372094e-06,
      "loss": 0.046,
      "step": 10755
    },
    {
      "epoch": 41.689922480620154,
      "grad_norm": 0.0009353537461720407,
      "learning_rate": 8.310077519379845e-06,
      "loss": 0.0001,
      "step": 10756
    },
    {
      "epoch": 41.6937984496124,
      "grad_norm": 0.000908543705008924,
      "learning_rate": 8.306201550387597e-06,
      "loss": 0.0001,
      "step": 10757
    },
    {
      "epoch": 41.69767441860465,
      "grad_norm": 0.4887986481189728,
      "learning_rate": 8.30232558139535e-06,
      "loss": 0.0019,
      "step": 10758
    },
    {
      "epoch": 41.701550387596896,
      "grad_norm": 0.0019974883180111647,
      "learning_rate": 8.298449612403102e-06,
      "loss": 0.0001,
      "step": 10759
    },
    {
      "epoch": 41.70542635658915,
      "grad_norm": 0.0014897374203428626,
      "learning_rate": 8.294573643410853e-06,
      "loss": 0.0001,
      "step": 10760
    },
    {
      "epoch": 41.7093023255814,
      "grad_norm": 0.0009958308655768633,
      "learning_rate": 8.290697674418605e-06,
      "loss": 0.0001,
      "step": 10761
    },
    {
      "epoch": 41.713178294573645,
      "grad_norm": 0.0007036703173071146,
      "learning_rate": 8.286821705426356e-06,
      "loss": 0.0001,
      "step": 10762
    },
    {
      "epoch": 41.71705426356589,
      "grad_norm": 0.002155248075723648,
      "learning_rate": 8.282945736434108e-06,
      "loss": 0.0001,
      "step": 10763
    },
    {
      "epoch": 41.72093023255814,
      "grad_norm": 0.0012651984579861164,
      "learning_rate": 8.279069767441861e-06,
      "loss": 0.0001,
      "step": 10764
    },
    {
      "epoch": 41.724806201550386,
      "grad_norm": 0.0010585159761831164,
      "learning_rate": 8.275193798449613e-06,
      "loss": 0.0001,
      "step": 10765
    },
    {
      "epoch": 41.72868217054263,
      "grad_norm": 0.0008527482277713716,
      "learning_rate": 8.271317829457364e-06,
      "loss": 0.0001,
      "step": 10766
    },
    {
      "epoch": 41.73255813953488,
      "grad_norm": 0.0008005493436940014,
      "learning_rate": 8.267441860465116e-06,
      "loss": 0.0001,
      "step": 10767
    },
    {
      "epoch": 41.736434108527135,
      "grad_norm": 0.001746349036693573,
      "learning_rate": 8.263565891472869e-06,
      "loss": 0.0001,
      "step": 10768
    },
    {
      "epoch": 41.74031007751938,
      "grad_norm": 0.0010767393978312612,
      "learning_rate": 8.259689922480621e-06,
      "loss": 0.0001,
      "step": 10769
    },
    {
      "epoch": 41.74418604651163,
      "grad_norm": 0.0009128328529186547,
      "learning_rate": 8.255813953488372e-06,
      "loss": 0.0001,
      "step": 10770
    },
    {
      "epoch": 41.748062015503876,
      "grad_norm": 0.0007553016184829175,
      "learning_rate": 8.251937984496124e-06,
      "loss": 0.0001,
      "step": 10771
    },
    {
      "epoch": 41.751937984496124,
      "grad_norm": 0.0010749296052381396,
      "learning_rate": 8.248062015503877e-06,
      "loss": 0.0001,
      "step": 10772
    },
    {
      "epoch": 41.75581395348837,
      "grad_norm": 0.0008271297556348145,
      "learning_rate": 8.24418604651163e-06,
      "loss": 0.0001,
      "step": 10773
    },
    {
      "epoch": 41.75968992248062,
      "grad_norm": 0.0008079969557002187,
      "learning_rate": 8.240310077519382e-06,
      "loss": 0.0001,
      "step": 10774
    },
    {
      "epoch": 41.763565891472865,
      "grad_norm": 0.0018972218967974186,
      "learning_rate": 8.23643410852713e-06,
      "loss": 0.0001,
      "step": 10775
    },
    {
      "epoch": 41.76744186046512,
      "grad_norm": 0.001353234052658081,
      "learning_rate": 8.232558139534883e-06,
      "loss": 0.0001,
      "step": 10776
    },
    {
      "epoch": 41.77131782945737,
      "grad_norm": 0.0007903009536676109,
      "learning_rate": 8.228682170542636e-06,
      "loss": 0.0001,
      "step": 10777
    },
    {
      "epoch": 41.775193798449614,
      "grad_norm": 0.0018401620909571648,
      "learning_rate": 8.224806201550388e-06,
      "loss": 0.0002,
      "step": 10778
    },
    {
      "epoch": 41.77906976744186,
      "grad_norm": 0.002227958757430315,
      "learning_rate": 8.22093023255814e-06,
      "loss": 0.0002,
      "step": 10779
    },
    {
      "epoch": 41.78294573643411,
      "grad_norm": 0.488258957862854,
      "learning_rate": 8.217054263565891e-06,
      "loss": 0.0211,
      "step": 10780
    },
    {
      "epoch": 41.786821705426355,
      "grad_norm": 0.0008791490690782666,
      "learning_rate": 8.213178294573644e-06,
      "loss": 0.0001,
      "step": 10781
    },
    {
      "epoch": 41.7906976744186,
      "grad_norm": 0.001015754765830934,
      "learning_rate": 8.209302325581396e-06,
      "loss": 0.0001,
      "step": 10782
    },
    {
      "epoch": 41.79457364341085,
      "grad_norm": 0.0008233790867961943,
      "learning_rate": 8.205426356589148e-06,
      "loss": 0.0001,
      "step": 10783
    },
    {
      "epoch": 41.798449612403104,
      "grad_norm": 0.0008538817055523396,
      "learning_rate": 8.201550387596899e-06,
      "loss": 0.0001,
      "step": 10784
    },
    {
      "epoch": 41.80232558139535,
      "grad_norm": 0.007191730197519064,
      "learning_rate": 8.197674418604652e-06,
      "loss": 0.0004,
      "step": 10785
    },
    {
      "epoch": 41.8062015503876,
      "grad_norm": 0.0006944976630620658,
      "learning_rate": 8.193798449612404e-06,
      "loss": 0.0001,
      "step": 10786
    },
    {
      "epoch": 41.810077519379846,
      "grad_norm": 0.0008879196248017251,
      "learning_rate": 8.189922480620156e-06,
      "loss": 0.0001,
      "step": 10787
    },
    {
      "epoch": 41.81395348837209,
      "grad_norm": 0.0009710346348583698,
      "learning_rate": 8.186046511627907e-06,
      "loss": 0.0001,
      "step": 10788
    },
    {
      "epoch": 41.81782945736434,
      "grad_norm": 2.2405714988708496,
      "learning_rate": 8.18217054263566e-06,
      "loss": 0.2116,
      "step": 10789
    },
    {
      "epoch": 41.82170542635659,
      "grad_norm": 0.0014694171259179711,
      "learning_rate": 8.17829457364341e-06,
      "loss": 0.0001,
      "step": 10790
    },
    {
      "epoch": 41.825581395348834,
      "grad_norm": 0.0010900526540353894,
      "learning_rate": 8.174418604651163e-06,
      "loss": 0.0001,
      "step": 10791
    },
    {
      "epoch": 41.82945736434109,
      "grad_norm": 0.0013165338896214962,
      "learning_rate": 8.170542635658915e-06,
      "loss": 0.0001,
      "step": 10792
    },
    {
      "epoch": 41.833333333333336,
      "grad_norm": 0.0007745451875962317,
      "learning_rate": 8.166666666666668e-06,
      "loss": 0.0001,
      "step": 10793
    },
    {
      "epoch": 41.83720930232558,
      "grad_norm": 0.0016388862859457731,
      "learning_rate": 8.162790697674418e-06,
      "loss": 0.0001,
      "step": 10794
    },
    {
      "epoch": 41.84108527131783,
      "grad_norm": 0.0012837230460718274,
      "learning_rate": 8.15891472868217e-06,
      "loss": 0.0001,
      "step": 10795
    },
    {
      "epoch": 41.84496124031008,
      "grad_norm": 0.0010748103959485888,
      "learning_rate": 8.155038759689923e-06,
      "loss": 0.0001,
      "step": 10796
    },
    {
      "epoch": 41.848837209302324,
      "grad_norm": 0.0006654515746049583,
      "learning_rate": 8.151162790697676e-06,
      "loss": 0.0001,
      "step": 10797
    },
    {
      "epoch": 41.85271317829457,
      "grad_norm": 0.0008462066762149334,
      "learning_rate": 8.147286821705428e-06,
      "loss": 0.0001,
      "step": 10798
    },
    {
      "epoch": 41.85658914728682,
      "grad_norm": 0.0016449233517050743,
      "learning_rate": 8.143410852713179e-06,
      "loss": 0.0001,
      "step": 10799
    },
    {
      "epoch": 41.86046511627907,
      "grad_norm": 0.01752557046711445,
      "learning_rate": 8.139534883720931e-06,
      "loss": 0.0004,
      "step": 10800
    },
    {
      "epoch": 41.86434108527132,
      "grad_norm": 0.2643846273422241,
      "learning_rate": 8.135658914728684e-06,
      "loss": 0.0105,
      "step": 10801
    },
    {
      "epoch": 41.86821705426357,
      "grad_norm": 0.0008811877341940999,
      "learning_rate": 8.131782945736434e-06,
      "loss": 0.0001,
      "step": 10802
    },
    {
      "epoch": 41.872093023255815,
      "grad_norm": 0.48780158162117004,
      "learning_rate": 8.127906976744187e-06,
      "loss": 0.02,
      "step": 10803
    },
    {
      "epoch": 41.87596899224806,
      "grad_norm": 0.001081372844055295,
      "learning_rate": 8.124031007751937e-06,
      "loss": 0.0001,
      "step": 10804
    },
    {
      "epoch": 41.87984496124031,
      "grad_norm": 0.0015231723664328456,
      "learning_rate": 8.12015503875969e-06,
      "loss": 0.0001,
      "step": 10805
    },
    {
      "epoch": 41.883720930232556,
      "grad_norm": 0.001006291015073657,
      "learning_rate": 8.116279069767442e-06,
      "loss": 0.0001,
      "step": 10806
    },
    {
      "epoch": 41.8875968992248,
      "grad_norm": 0.0008914551581256092,
      "learning_rate": 8.112403100775195e-06,
      "loss": 0.0001,
      "step": 10807
    },
    {
      "epoch": 41.89147286821706,
      "grad_norm": 0.001062480267137289,
      "learning_rate": 8.108527131782945e-06,
      "loss": 0.0001,
      "step": 10808
    },
    {
      "epoch": 41.895348837209305,
      "grad_norm": 0.0014293455751612782,
      "learning_rate": 8.104651162790698e-06,
      "loss": 0.0001,
      "step": 10809
    },
    {
      "epoch": 41.89922480620155,
      "grad_norm": 0.0010587337892502546,
      "learning_rate": 8.10077519379845e-06,
      "loss": 0.0001,
      "step": 10810
    },
    {
      "epoch": 41.9031007751938,
      "grad_norm": 0.0015231901779770851,
      "learning_rate": 8.096899224806203e-06,
      "loss": 0.0001,
      "step": 10811
    },
    {
      "epoch": 41.906976744186046,
      "grad_norm": 0.010501614771783352,
      "learning_rate": 8.093023255813955e-06,
      "loss": 0.0003,
      "step": 10812
    },
    {
      "epoch": 41.91085271317829,
      "grad_norm": 3.4278147220611572,
      "learning_rate": 8.089147286821706e-06,
      "loss": 0.1702,
      "step": 10813
    },
    {
      "epoch": 41.91472868217054,
      "grad_norm": 0.0007225070148706436,
      "learning_rate": 8.085271317829458e-06,
      "loss": 0.0001,
      "step": 10814
    },
    {
      "epoch": 41.91860465116279,
      "grad_norm": 0.7047826647758484,
      "learning_rate": 8.081395348837209e-06,
      "loss": 0.0021,
      "step": 10815
    },
    {
      "epoch": 41.92248062015504,
      "grad_norm": 0.0006798706017434597,
      "learning_rate": 8.077519379844961e-06,
      "loss": 0.0001,
      "step": 10816
    },
    {
      "epoch": 41.92635658914729,
      "grad_norm": 0.0009216245380230248,
      "learning_rate": 8.073643410852714e-06,
      "loss": 0.0001,
      "step": 10817
    },
    {
      "epoch": 41.93023255813954,
      "grad_norm": 0.000687273102812469,
      "learning_rate": 8.069767441860465e-06,
      "loss": 0.0001,
      "step": 10818
    },
    {
      "epoch": 41.934108527131784,
      "grad_norm": 0.000805932970251888,
      "learning_rate": 8.065891472868217e-06,
      "loss": 0.0001,
      "step": 10819
    },
    {
      "epoch": 41.93798449612403,
      "grad_norm": 0.0006874422542750835,
      "learning_rate": 8.06201550387597e-06,
      "loss": 0.0001,
      "step": 10820
    },
    {
      "epoch": 41.94186046511628,
      "grad_norm": 0.6353378891944885,
      "learning_rate": 8.058139534883722e-06,
      "loss": 0.0256,
      "step": 10821
    },
    {
      "epoch": 41.945736434108525,
      "grad_norm": 0.0009469383512623608,
      "learning_rate": 8.054263565891473e-06,
      "loss": 0.0001,
      "step": 10822
    },
    {
      "epoch": 41.94961240310077,
      "grad_norm": 0.0007869270048104227,
      "learning_rate": 8.050387596899225e-06,
      "loss": 0.0001,
      "step": 10823
    },
    {
      "epoch": 41.95348837209303,
      "grad_norm": 3.4559578895568848,
      "learning_rate": 8.046511627906977e-06,
      "loss": 0.3354,
      "step": 10824
    },
    {
      "epoch": 41.957364341085274,
      "grad_norm": 0.0009495738777332008,
      "learning_rate": 8.04263565891473e-06,
      "loss": 0.0001,
      "step": 10825
    },
    {
      "epoch": 41.96124031007752,
      "grad_norm": 0.0007974508916959167,
      "learning_rate": 8.038759689922482e-06,
      "loss": 0.0001,
      "step": 10826
    },
    {
      "epoch": 41.96511627906977,
      "grad_norm": 0.0013166057178750634,
      "learning_rate": 8.034883720930233e-06,
      "loss": 0.0001,
      "step": 10827
    },
    {
      "epoch": 41.968992248062015,
      "grad_norm": 0.0025229814928025007,
      "learning_rate": 8.031007751937984e-06,
      "loss": 0.0002,
      "step": 10828
    },
    {
      "epoch": 41.97286821705426,
      "grad_norm": 0.0028953535947948694,
      "learning_rate": 8.027131782945736e-06,
      "loss": 0.0002,
      "step": 10829
    },
    {
      "epoch": 41.97674418604651,
      "grad_norm": 0.0009723540861159563,
      "learning_rate": 8.023255813953488e-06,
      "loss": 0.0001,
      "step": 10830
    },
    {
      "epoch": 41.98062015503876,
      "grad_norm": 0.0009794895304366946,
      "learning_rate": 8.019379844961241e-06,
      "loss": 0.0001,
      "step": 10831
    },
    {
      "epoch": 41.98449612403101,
      "grad_norm": 0.0023610214702785015,
      "learning_rate": 8.015503875968992e-06,
      "loss": 0.0002,
      "step": 10832
    },
    {
      "epoch": 41.98837209302326,
      "grad_norm": 0.0009500326705165207,
      "learning_rate": 8.011627906976744e-06,
      "loss": 0.0001,
      "step": 10833
    },
    {
      "epoch": 41.992248062015506,
      "grad_norm": 0.002297287108376622,
      "learning_rate": 8.007751937984496e-06,
      "loss": 0.0002,
      "step": 10834
    },
    {
      "epoch": 41.99612403100775,
      "grad_norm": 0.002795036882162094,
      "learning_rate": 8.003875968992249e-06,
      "loss": 0.0001,
      "step": 10835
    },
    {
      "epoch": 42.0,
      "grad_norm": 0.0017264224588871002,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0001,
      "step": 10836
    },
    {
      "epoch": 42.00387596899225,
      "grad_norm": 0.000825529801659286,
      "learning_rate": 7.996124031007752e-06,
      "loss": 0.0001,
      "step": 10837
    },
    {
      "epoch": 42.007751937984494,
      "grad_norm": 0.006701161619275808,
      "learning_rate": 7.992248062015504e-06,
      "loss": 0.0002,
      "step": 10838
    },
    {
      "epoch": 42.01162790697674,
      "grad_norm": 0.0009178905165754259,
      "learning_rate": 7.988372093023257e-06,
      "loss": 0.0001,
      "step": 10839
    },
    {
      "epoch": 42.01550387596899,
      "grad_norm": 0.0017079752869904041,
      "learning_rate": 7.98449612403101e-06,
      "loss": 0.0001,
      "step": 10840
    },
    {
      "epoch": 42.01937984496124,
      "grad_norm": 0.0008885835995897651,
      "learning_rate": 7.98062015503876e-06,
      "loss": 0.0001,
      "step": 10841
    },
    {
      "epoch": 42.02325581395349,
      "grad_norm": 0.0010451708221808076,
      "learning_rate": 7.97674418604651e-06,
      "loss": 0.0001,
      "step": 10842
    },
    {
      "epoch": 42.02713178294574,
      "grad_norm": 0.001135880476795137,
      "learning_rate": 7.972868217054263e-06,
      "loss": 0.0001,
      "step": 10843
    },
    {
      "epoch": 42.031007751937985,
      "grad_norm": 0.0087818568572402,
      "learning_rate": 7.968992248062016e-06,
      "loss": 0.0003,
      "step": 10844
    },
    {
      "epoch": 42.03488372093023,
      "grad_norm": 0.0010467417305335402,
      "learning_rate": 7.965116279069768e-06,
      "loss": 0.0001,
      "step": 10845
    },
    {
      "epoch": 42.03875968992248,
      "grad_norm": 0.0009265679982490838,
      "learning_rate": 7.961240310077519e-06,
      "loss": 0.0001,
      "step": 10846
    },
    {
      "epoch": 42.042635658914726,
      "grad_norm": 0.000931823393329978,
      "learning_rate": 7.957364341085271e-06,
      "loss": 0.0001,
      "step": 10847
    },
    {
      "epoch": 42.04651162790697,
      "grad_norm": 0.0008392918389290571,
      "learning_rate": 7.953488372093024e-06,
      "loss": 0.0001,
      "step": 10848
    },
    {
      "epoch": 42.05038759689923,
      "grad_norm": 0.003586644073948264,
      "learning_rate": 7.949612403100776e-06,
      "loss": 0.0001,
      "step": 10849
    },
    {
      "epoch": 42.054263565891475,
      "grad_norm": 0.0013378498842939734,
      "learning_rate": 7.945736434108528e-06,
      "loss": 0.0001,
      "step": 10850
    },
    {
      "epoch": 42.05813953488372,
      "grad_norm": 2.596834182739258,
      "learning_rate": 7.94186046511628e-06,
      "loss": 0.0551,
      "step": 10851
    },
    {
      "epoch": 42.06201550387597,
      "grad_norm": 0.0007999870576895773,
      "learning_rate": 7.937984496124032e-06,
      "loss": 0.0001,
      "step": 10852
    },
    {
      "epoch": 42.065891472868216,
      "grad_norm": 0.005238601006567478,
      "learning_rate": 7.934108527131784e-06,
      "loss": 0.0002,
      "step": 10853
    },
    {
      "epoch": 42.06976744186046,
      "grad_norm": 0.0009099994204007089,
      "learning_rate": 7.930232558139536e-06,
      "loss": 0.0001,
      "step": 10854
    },
    {
      "epoch": 42.07364341085271,
      "grad_norm": 0.0010136605706065893,
      "learning_rate": 7.926356589147287e-06,
      "loss": 0.0001,
      "step": 10855
    },
    {
      "epoch": 42.07751937984496,
      "grad_norm": 0.0016227997839450836,
      "learning_rate": 7.922480620155038e-06,
      "loss": 0.0001,
      "step": 10856
    },
    {
      "epoch": 42.08139534883721,
      "grad_norm": 0.0010614852653816342,
      "learning_rate": 7.91860465116279e-06,
      "loss": 0.0001,
      "step": 10857
    },
    {
      "epoch": 42.08527131782946,
      "grad_norm": 0.0008966210880316794,
      "learning_rate": 7.914728682170543e-06,
      "loss": 0.0001,
      "step": 10858
    },
    {
      "epoch": 42.08914728682171,
      "grad_norm": 0.001969323493540287,
      "learning_rate": 7.910852713178295e-06,
      "loss": 0.0001,
      "step": 10859
    },
    {
      "epoch": 42.093023255813954,
      "grad_norm": 0.0009198930347338319,
      "learning_rate": 7.906976744186048e-06,
      "loss": 0.0001,
      "step": 10860
    },
    {
      "epoch": 42.0968992248062,
      "grad_norm": 0.001421985449269414,
      "learning_rate": 7.903100775193798e-06,
      "loss": 0.0001,
      "step": 10861
    },
    {
      "epoch": 42.10077519379845,
      "grad_norm": 0.0008679620805196464,
      "learning_rate": 7.89922480620155e-06,
      "loss": 0.0001,
      "step": 10862
    },
    {
      "epoch": 42.104651162790695,
      "grad_norm": 0.000972182082477957,
      "learning_rate": 7.895348837209303e-06,
      "loss": 0.0001,
      "step": 10863
    },
    {
      "epoch": 42.10852713178294,
      "grad_norm": 2.0019149780273438,
      "learning_rate": 7.891472868217056e-06,
      "loss": 0.2186,
      "step": 10864
    },
    {
      "epoch": 42.1124031007752,
      "grad_norm": 0.0029105795547366142,
      "learning_rate": 7.887596899224806e-06,
      "loss": 0.0002,
      "step": 10865
    },
    {
      "epoch": 42.116279069767444,
      "grad_norm": 0.0007621257682330906,
      "learning_rate": 7.883720930232559e-06,
      "loss": 0.0001,
      "step": 10866
    },
    {
      "epoch": 42.12015503875969,
      "grad_norm": 0.0009355538641102612,
      "learning_rate": 7.879844961240311e-06,
      "loss": 0.0001,
      "step": 10867
    },
    {
      "epoch": 42.12403100775194,
      "grad_norm": 0.0031050473917275667,
      "learning_rate": 7.875968992248062e-06,
      "loss": 0.0002,
      "step": 10868
    },
    {
      "epoch": 42.127906976744185,
      "grad_norm": 0.0009299649391323328,
      "learning_rate": 7.872093023255814e-06,
      "loss": 0.0001,
      "step": 10869
    },
    {
      "epoch": 42.13178294573643,
      "grad_norm": 0.005245925858616829,
      "learning_rate": 7.868217054263565e-06,
      "loss": 0.0003,
      "step": 10870
    },
    {
      "epoch": 42.13565891472868,
      "grad_norm": 0.0010009711841121316,
      "learning_rate": 7.864341085271317e-06,
      "loss": 0.0001,
      "step": 10871
    },
    {
      "epoch": 42.13953488372093,
      "grad_norm": 0.00110626348759979,
      "learning_rate": 7.86046511627907e-06,
      "loss": 0.0001,
      "step": 10872
    },
    {
      "epoch": 42.14341085271318,
      "grad_norm": 0.0015707110287621617,
      "learning_rate": 7.856589147286822e-06,
      "loss": 0.0001,
      "step": 10873
    },
    {
      "epoch": 42.14728682170543,
      "grad_norm": 0.0010535296751186252,
      "learning_rate": 7.852713178294575e-06,
      "loss": 0.0001,
      "step": 10874
    },
    {
      "epoch": 42.151162790697676,
      "grad_norm": 0.0008598295389674604,
      "learning_rate": 7.848837209302325e-06,
      "loss": 0.0001,
      "step": 10875
    },
    {
      "epoch": 42.15503875968992,
      "grad_norm": 0.2672940194606781,
      "learning_rate": 7.844961240310078e-06,
      "loss": 0.0107,
      "step": 10876
    },
    {
      "epoch": 42.15891472868217,
      "grad_norm": 0.0011568042682483792,
      "learning_rate": 7.84108527131783e-06,
      "loss": 0.0001,
      "step": 10877
    },
    {
      "epoch": 42.16279069767442,
      "grad_norm": 22.715612411499023,
      "learning_rate": 7.837209302325583e-06,
      "loss": 0.0944,
      "step": 10878
    },
    {
      "epoch": 42.166666666666664,
      "grad_norm": 0.0019488396355882287,
      "learning_rate": 7.833333333333333e-06,
      "loss": 0.0001,
      "step": 10879
    },
    {
      "epoch": 42.17054263565891,
      "grad_norm": 0.0011682520853355527,
      "learning_rate": 7.829457364341086e-06,
      "loss": 0.0001,
      "step": 10880
    },
    {
      "epoch": 42.174418604651166,
      "grad_norm": 0.0013341250596567988,
      "learning_rate": 7.825581395348838e-06,
      "loss": 0.0001,
      "step": 10881
    },
    {
      "epoch": 42.17829457364341,
      "grad_norm": 0.0009091785177588463,
      "learning_rate": 7.821705426356589e-06,
      "loss": 0.0001,
      "step": 10882
    },
    {
      "epoch": 42.18217054263566,
      "grad_norm": 0.0008841152302920818,
      "learning_rate": 7.817829457364341e-06,
      "loss": 0.0001,
      "step": 10883
    },
    {
      "epoch": 42.18604651162791,
      "grad_norm": 0.001013732049614191,
      "learning_rate": 7.813953488372094e-06,
      "loss": 0.0001,
      "step": 10884
    },
    {
      "epoch": 42.189922480620154,
      "grad_norm": 0.0007802483742125332,
      "learning_rate": 7.810077519379845e-06,
      "loss": 0.0001,
      "step": 10885
    },
    {
      "epoch": 42.1937984496124,
      "grad_norm": 0.0022300099954009056,
      "learning_rate": 7.806201550387597e-06,
      "loss": 0.0002,
      "step": 10886
    },
    {
      "epoch": 42.19767441860465,
      "grad_norm": 0.00079247762914747,
      "learning_rate": 7.80232558139535e-06,
      "loss": 0.0001,
      "step": 10887
    },
    {
      "epoch": 42.201550387596896,
      "grad_norm": 0.0009208378032781184,
      "learning_rate": 7.798449612403102e-06,
      "loss": 0.0001,
      "step": 10888
    },
    {
      "epoch": 42.20542635658915,
      "grad_norm": 0.0007522974046878517,
      "learning_rate": 7.794573643410853e-06,
      "loss": 0.0001,
      "step": 10889
    },
    {
      "epoch": 42.2093023255814,
      "grad_norm": 0.0007292642258107662,
      "learning_rate": 7.790697674418605e-06,
      "loss": 0.0001,
      "step": 10890
    },
    {
      "epoch": 42.213178294573645,
      "grad_norm": 0.0007782119791954756,
      "learning_rate": 7.786821705426357e-06,
      "loss": 0.0001,
      "step": 10891
    },
    {
      "epoch": 42.21705426356589,
      "grad_norm": 0.001226515625603497,
      "learning_rate": 7.78294573643411e-06,
      "loss": 0.0001,
      "step": 10892
    },
    {
      "epoch": 42.22093023255814,
      "grad_norm": 0.00409519812092185,
      "learning_rate": 7.77906976744186e-06,
      "loss": 0.0002,
      "step": 10893
    },
    {
      "epoch": 42.224806201550386,
      "grad_norm": 0.0009766939328983426,
      "learning_rate": 7.775193798449613e-06,
      "loss": 0.0001,
      "step": 10894
    },
    {
      "epoch": 42.22868217054263,
      "grad_norm": 0.036220818758010864,
      "learning_rate": 7.771317829457364e-06,
      "loss": 0.0006,
      "step": 10895
    },
    {
      "epoch": 42.23255813953488,
      "grad_norm": 0.0022489577531814575,
      "learning_rate": 7.767441860465116e-06,
      "loss": 0.0002,
      "step": 10896
    },
    {
      "epoch": 42.236434108527135,
      "grad_norm": 0.0010823128977790475,
      "learning_rate": 7.763565891472869e-06,
      "loss": 0.0001,
      "step": 10897
    },
    {
      "epoch": 42.24031007751938,
      "grad_norm": 0.000954683986492455,
      "learning_rate": 7.759689922480621e-06,
      "loss": 0.0001,
      "step": 10898
    },
    {
      "epoch": 42.24418604651163,
      "grad_norm": 0.002892581047490239,
      "learning_rate": 7.755813953488372e-06,
      "loss": 0.0002,
      "step": 10899
    },
    {
      "epoch": 42.248062015503876,
      "grad_norm": 0.0009956150315701962,
      "learning_rate": 7.751937984496124e-06,
      "loss": 0.0001,
      "step": 10900
    },
    {
      "epoch": 42.251937984496124,
      "grad_norm": 0.0007573991897515953,
      "learning_rate": 7.748062015503877e-06,
      "loss": 0.0001,
      "step": 10901
    },
    {
      "epoch": 42.25581395348837,
      "grad_norm": 0.0008153162780217826,
      "learning_rate": 7.744186046511629e-06,
      "loss": 0.0001,
      "step": 10902
    },
    {
      "epoch": 42.25968992248062,
      "grad_norm": 1.7022960186004639,
      "learning_rate": 7.74031007751938e-06,
      "loss": 0.1814,
      "step": 10903
    },
    {
      "epoch": 42.263565891472865,
      "grad_norm": 0.0010150830494239926,
      "learning_rate": 7.736434108527132e-06,
      "loss": 0.0001,
      "step": 10904
    },
    {
      "epoch": 42.26744186046512,
      "grad_norm": 0.0008759296615608037,
      "learning_rate": 7.732558139534885e-06,
      "loss": 0.0001,
      "step": 10905
    },
    {
      "epoch": 42.27131782945737,
      "grad_norm": 2.8936729431152344,
      "learning_rate": 7.728682170542637e-06,
      "loss": 0.2962,
      "step": 10906
    },
    {
      "epoch": 42.275193798449614,
      "grad_norm": 0.0020700383465737104,
      "learning_rate": 7.72480620155039e-06,
      "loss": 0.0001,
      "step": 10907
    },
    {
      "epoch": 42.27906976744186,
      "grad_norm": 0.005238124635070562,
      "learning_rate": 7.720930232558138e-06,
      "loss": 0.0002,
      "step": 10908
    },
    {
      "epoch": 42.28294573643411,
      "grad_norm": 0.0008448579465039074,
      "learning_rate": 7.71705426356589e-06,
      "loss": 0.0001,
      "step": 10909
    },
    {
      "epoch": 42.286821705426355,
      "grad_norm": 0.0007920843199826777,
      "learning_rate": 7.713178294573643e-06,
      "loss": 0.0001,
      "step": 10910
    },
    {
      "epoch": 42.2906976744186,
      "grad_norm": 0.001018259208649397,
      "learning_rate": 7.709302325581396e-06,
      "loss": 0.0001,
      "step": 10911
    },
    {
      "epoch": 42.29457364341085,
      "grad_norm": 0.0007789075025357306,
      "learning_rate": 7.705426356589148e-06,
      "loss": 0.0001,
      "step": 10912
    },
    {
      "epoch": 42.298449612403104,
      "grad_norm": 0.0006848726770840585,
      "learning_rate": 7.701550387596899e-06,
      "loss": 0.0001,
      "step": 10913
    },
    {
      "epoch": 42.30232558139535,
      "grad_norm": 0.0016357684507966042,
      "learning_rate": 7.697674418604651e-06,
      "loss": 0.0001,
      "step": 10914
    },
    {
      "epoch": 42.3062015503876,
      "grad_norm": 0.0007520258077420294,
      "learning_rate": 7.693798449612404e-06,
      "loss": 0.0001,
      "step": 10915
    },
    {
      "epoch": 42.310077519379846,
      "grad_norm": 0.0019754564855247736,
      "learning_rate": 7.689922480620156e-06,
      "loss": 0.0002,
      "step": 10916
    },
    {
      "epoch": 42.31395348837209,
      "grad_norm": 0.0028326220344752073,
      "learning_rate": 7.686046511627907e-06,
      "loss": 0.0002,
      "step": 10917
    },
    {
      "epoch": 42.31782945736434,
      "grad_norm": 0.001665824675001204,
      "learning_rate": 7.68217054263566e-06,
      "loss": 0.0001,
      "step": 10918
    },
    {
      "epoch": 42.32170542635659,
      "grad_norm": 0.0008576256223022938,
      "learning_rate": 7.678294573643412e-06,
      "loss": 0.0001,
      "step": 10919
    },
    {
      "epoch": 42.325581395348834,
      "grad_norm": 0.0008501180564053357,
      "learning_rate": 7.674418604651164e-06,
      "loss": 0.0001,
      "step": 10920
    },
    {
      "epoch": 42.32945736434109,
      "grad_norm": 0.0007866055238991976,
      "learning_rate": 7.670542635658917e-06,
      "loss": 0.0001,
      "step": 10921
    },
    {
      "epoch": 42.333333333333336,
      "grad_norm": 0.0028781292494386435,
      "learning_rate": 7.666666666666667e-06,
      "loss": 0.0002,
      "step": 10922
    },
    {
      "epoch": 42.33720930232558,
      "grad_norm": 0.0015046022599563003,
      "learning_rate": 7.662790697674418e-06,
      "loss": 0.0001,
      "step": 10923
    },
    {
      "epoch": 42.34108527131783,
      "grad_norm": 0.000905665336176753,
      "learning_rate": 7.65891472868217e-06,
      "loss": 0.0001,
      "step": 10924
    },
    {
      "epoch": 42.34496124031008,
      "grad_norm": 0.0007566041313111782,
      "learning_rate": 7.655038759689923e-06,
      "loss": 0.0001,
      "step": 10925
    },
    {
      "epoch": 42.348837209302324,
      "grad_norm": 0.0009048242354765534,
      "learning_rate": 7.651162790697675e-06,
      "loss": 0.0001,
      "step": 10926
    },
    {
      "epoch": 42.35271317829457,
      "grad_norm": 0.12162207812070847,
      "learning_rate": 7.647286821705426e-06,
      "loss": 0.0019,
      "step": 10927
    },
    {
      "epoch": 42.35658914728682,
      "grad_norm": 0.0012909217039123178,
      "learning_rate": 7.643410852713178e-06,
      "loss": 0.0001,
      "step": 10928
    },
    {
      "epoch": 42.36046511627907,
      "grad_norm": 0.0008285760413855314,
      "learning_rate": 7.63953488372093e-06,
      "loss": 0.0001,
      "step": 10929
    },
    {
      "epoch": 42.36434108527132,
      "grad_norm": 0.0011470166500657797,
      "learning_rate": 7.635658914728683e-06,
      "loss": 0.0001,
      "step": 10930
    },
    {
      "epoch": 42.36821705426357,
      "grad_norm": 0.0017170654609799385,
      "learning_rate": 7.631782945736436e-06,
      "loss": 0.0001,
      "step": 10931
    },
    {
      "epoch": 42.372093023255815,
      "grad_norm": 0.0009891868103295565,
      "learning_rate": 7.627906976744187e-06,
      "loss": 0.0001,
      "step": 10932
    },
    {
      "epoch": 42.37596899224806,
      "grad_norm": 0.0020740674808621407,
      "learning_rate": 7.624031007751939e-06,
      "loss": 0.0001,
      "step": 10933
    },
    {
      "epoch": 42.37984496124031,
      "grad_norm": 0.001071687787771225,
      "learning_rate": 7.620155038759691e-06,
      "loss": 0.0001,
      "step": 10934
    },
    {
      "epoch": 42.383720930232556,
      "grad_norm": 0.0007552048191428185,
      "learning_rate": 7.616279069767442e-06,
      "loss": 0.0001,
      "step": 10935
    },
    {
      "epoch": 42.3875968992248,
      "grad_norm": 0.001146842259913683,
      "learning_rate": 7.6124031007751935e-06,
      "loss": 0.0001,
      "step": 10936
    },
    {
      "epoch": 42.39147286821706,
      "grad_norm": 0.000934899493586272,
      "learning_rate": 7.608527131782946e-06,
      "loss": 0.0001,
      "step": 10937
    },
    {
      "epoch": 42.395348837209305,
      "grad_norm": 0.0007928748964332044,
      "learning_rate": 7.6046511627906975e-06,
      "loss": 0.0001,
      "step": 10938
    },
    {
      "epoch": 42.39922480620155,
      "grad_norm": 0.41578409075737,
      "learning_rate": 7.60077519379845e-06,
      "loss": 0.0176,
      "step": 10939
    },
    {
      "epoch": 42.4031007751938,
      "grad_norm": 0.3566650450229645,
      "learning_rate": 7.5968992248062015e-06,
      "loss": 0.0153,
      "step": 10940
    },
    {
      "epoch": 42.406976744186046,
      "grad_norm": 0.0007270139176398516,
      "learning_rate": 7.593023255813954e-06,
      "loss": 0.0001,
      "step": 10941
    },
    {
      "epoch": 42.41085271317829,
      "grad_norm": 0.0007514011231251061,
      "learning_rate": 7.5891472868217055e-06,
      "loss": 0.0001,
      "step": 10942
    },
    {
      "epoch": 42.41472868217054,
      "grad_norm": 0.0007197682862170041,
      "learning_rate": 7.585271317829458e-06,
      "loss": 0.0001,
      "step": 10943
    },
    {
      "epoch": 42.41860465116279,
      "grad_norm": 0.01887829415500164,
      "learning_rate": 7.58139534883721e-06,
      "loss": 0.0005,
      "step": 10944
    },
    {
      "epoch": 42.42248062015504,
      "grad_norm": 0.0011955840745940804,
      "learning_rate": 7.577519379844962e-06,
      "loss": 0.0001,
      "step": 10945
    },
    {
      "epoch": 42.42635658914729,
      "grad_norm": 0.0017933669732883573,
      "learning_rate": 7.573643410852714e-06,
      "loss": 0.0002,
      "step": 10946
    },
    {
      "epoch": 42.43023255813954,
      "grad_norm": 0.006409002467989922,
      "learning_rate": 7.569767441860466e-06,
      "loss": 0.0002,
      "step": 10947
    },
    {
      "epoch": 42.434108527131784,
      "grad_norm": 0.0008710908005014062,
      "learning_rate": 7.565891472868217e-06,
      "loss": 0.0001,
      "step": 10948
    },
    {
      "epoch": 42.43798449612403,
      "grad_norm": 0.0007054705056361854,
      "learning_rate": 7.562015503875969e-06,
      "loss": 0.0001,
      "step": 10949
    },
    {
      "epoch": 42.44186046511628,
      "grad_norm": 0.0016054712468758225,
      "learning_rate": 7.558139534883721e-06,
      "loss": 0.0001,
      "step": 10950
    },
    {
      "epoch": 42.445736434108525,
      "grad_norm": 0.0007560295052826405,
      "learning_rate": 7.554263565891473e-06,
      "loss": 0.0001,
      "step": 10951
    },
    {
      "epoch": 42.44961240310077,
      "grad_norm": 0.007012253161519766,
      "learning_rate": 7.550387596899225e-06,
      "loss": 0.0002,
      "step": 10952
    },
    {
      "epoch": 42.45348837209303,
      "grad_norm": 0.0009662064840085804,
      "learning_rate": 7.546511627906977e-06,
      "loss": 0.0001,
      "step": 10953
    },
    {
      "epoch": 42.457364341085274,
      "grad_norm": 0.0006612903671339154,
      "learning_rate": 7.542635658914729e-06,
      "loss": 0.0001,
      "step": 10954
    },
    {
      "epoch": 42.46124031007752,
      "grad_norm": 0.0011620881268754601,
      "learning_rate": 7.538759689922481e-06,
      "loss": 0.0001,
      "step": 10955
    },
    {
      "epoch": 42.46511627906977,
      "grad_norm": 0.00233505223877728,
      "learning_rate": 7.5348837209302335e-06,
      "loss": 0.0002,
      "step": 10956
    },
    {
      "epoch": 42.468992248062015,
      "grad_norm": 0.0022495195735245943,
      "learning_rate": 7.531007751937985e-06,
      "loss": 0.0002,
      "step": 10957
    },
    {
      "epoch": 42.47286821705426,
      "grad_norm": 0.0016089590499177575,
      "learning_rate": 7.5271317829457375e-06,
      "loss": 0.0001,
      "step": 10958
    },
    {
      "epoch": 42.47674418604651,
      "grad_norm": 2.737567186355591,
      "learning_rate": 7.523255813953489e-06,
      "loss": 0.2305,
      "step": 10959
    },
    {
      "epoch": 42.48062015503876,
      "grad_norm": 0.0008419526275247335,
      "learning_rate": 7.5193798449612415e-06,
      "loss": 0.0001,
      "step": 10960
    },
    {
      "epoch": 42.48449612403101,
      "grad_norm": 0.0007186827133409679,
      "learning_rate": 7.515503875968993e-06,
      "loss": 0.0001,
      "step": 10961
    },
    {
      "epoch": 42.48837209302326,
      "grad_norm": 0.0010108276037499309,
      "learning_rate": 7.511627906976744e-06,
      "loss": 0.0001,
      "step": 10962
    },
    {
      "epoch": 42.492248062015506,
      "grad_norm": 0.0018647016258910298,
      "learning_rate": 7.507751937984496e-06,
      "loss": 0.0002,
      "step": 10963
    },
    {
      "epoch": 42.49612403100775,
      "grad_norm": 0.0012629408156499267,
      "learning_rate": 7.503875968992248e-06,
      "loss": 0.0001,
      "step": 10964
    },
    {
      "epoch": 42.5,
      "grad_norm": 0.0020820610225200653,
      "learning_rate": 7.5e-06,
      "loss": 0.0001,
      "step": 10965
    },
    {
      "epoch": 42.50387596899225,
      "grad_norm": 0.0012284355470910668,
      "learning_rate": 7.496124031007752e-06,
      "loss": 0.0001,
      "step": 10966
    },
    {
      "epoch": 42.507751937984494,
      "grad_norm": 0.0015663931844756007,
      "learning_rate": 7.492248062015504e-06,
      "loss": 0.0001,
      "step": 10967
    },
    {
      "epoch": 42.51162790697674,
      "grad_norm": 0.0008190168300643563,
      "learning_rate": 7.488372093023257e-06,
      "loss": 0.0001,
      "step": 10968
    },
    {
      "epoch": 42.51550387596899,
      "grad_norm": 0.001002923003397882,
      "learning_rate": 7.484496124031008e-06,
      "loss": 0.0001,
      "step": 10969
    },
    {
      "epoch": 42.51937984496124,
      "grad_norm": 0.0008497879607602954,
      "learning_rate": 7.480620155038761e-06,
      "loss": 0.0001,
      "step": 10970
    },
    {
      "epoch": 42.52325581395349,
      "grad_norm": 1.1087149381637573,
      "learning_rate": 7.476744186046512e-06,
      "loss": 0.0805,
      "step": 10971
    },
    {
      "epoch": 42.52713178294574,
      "grad_norm": 0.0023678450379520655,
      "learning_rate": 7.472868217054265e-06,
      "loss": 0.0002,
      "step": 10972
    },
    {
      "epoch": 42.531007751937985,
      "grad_norm": 0.0008453045738860965,
      "learning_rate": 7.468992248062016e-06,
      "loss": 0.0001,
      "step": 10973
    },
    {
      "epoch": 42.53488372093023,
      "grad_norm": 0.0017641640733927488,
      "learning_rate": 7.465116279069769e-06,
      "loss": 0.0001,
      "step": 10974
    },
    {
      "epoch": 42.53875968992248,
      "grad_norm": 0.00217042095027864,
      "learning_rate": 7.461240310077519e-06,
      "loss": 0.0002,
      "step": 10975
    },
    {
      "epoch": 42.542635658914726,
      "grad_norm": 0.002318908926099539,
      "learning_rate": 7.457364341085271e-06,
      "loss": 0.0002,
      "step": 10976
    },
    {
      "epoch": 42.54651162790697,
      "grad_norm": 0.0038383814971894026,
      "learning_rate": 7.453488372093023e-06,
      "loss": 0.0002,
      "step": 10977
    },
    {
      "epoch": 42.55038759689923,
      "grad_norm": 0.0009474408579990268,
      "learning_rate": 7.449612403100775e-06,
      "loss": 0.0001,
      "step": 10978
    },
    {
      "epoch": 42.554263565891475,
      "grad_norm": 0.0007441893103532493,
      "learning_rate": 7.445736434108527e-06,
      "loss": 0.0001,
      "step": 10979
    },
    {
      "epoch": 42.55813953488372,
      "grad_norm": 0.00129750557243824,
      "learning_rate": 7.44186046511628e-06,
      "loss": 0.0001,
      "step": 10980
    },
    {
      "epoch": 42.56201550387597,
      "grad_norm": 2.6460819244384766,
      "learning_rate": 7.437984496124031e-06,
      "loss": 0.0131,
      "step": 10981
    },
    {
      "epoch": 42.565891472868216,
      "grad_norm": 0.0009634554153308272,
      "learning_rate": 7.434108527131784e-06,
      "loss": 0.0001,
      "step": 10982
    },
    {
      "epoch": 42.56976744186046,
      "grad_norm": 0.0010746647603809834,
      "learning_rate": 7.430232558139535e-06,
      "loss": 0.0001,
      "step": 10983
    },
    {
      "epoch": 42.57364341085271,
      "grad_norm": 0.002346387365832925,
      "learning_rate": 7.426356589147288e-06,
      "loss": 0.0002,
      "step": 10984
    },
    {
      "epoch": 42.57751937984496,
      "grad_norm": 0.0009235446923412383,
      "learning_rate": 7.422480620155039e-06,
      "loss": 0.0001,
      "step": 10985
    },
    {
      "epoch": 42.58139534883721,
      "grad_norm": 0.0007657163077965379,
      "learning_rate": 7.418604651162792e-06,
      "loss": 0.0001,
      "step": 10986
    },
    {
      "epoch": 42.58527131782946,
      "grad_norm": 0.0007979009533300996,
      "learning_rate": 7.414728682170543e-06,
      "loss": 0.0001,
      "step": 10987
    },
    {
      "epoch": 42.58914728682171,
      "grad_norm": 0.0011322868522256613,
      "learning_rate": 7.410852713178294e-06,
      "loss": 0.0001,
      "step": 10988
    },
    {
      "epoch": 42.593023255813954,
      "grad_norm": 0.000864094530697912,
      "learning_rate": 7.4069767441860464e-06,
      "loss": 0.0001,
      "step": 10989
    },
    {
      "epoch": 42.5968992248062,
      "grad_norm": 0.4849238693714142,
      "learning_rate": 7.403100775193798e-06,
      "loss": 0.0195,
      "step": 10990
    },
    {
      "epoch": 42.60077519379845,
      "grad_norm": 0.0019692343194037676,
      "learning_rate": 7.3992248062015504e-06,
      "loss": 0.0001,
      "step": 10991
    },
    {
      "epoch": 42.604651162790695,
      "grad_norm": 0.0011526880552992225,
      "learning_rate": 7.395348837209302e-06,
      "loss": 0.0001,
      "step": 10992
    },
    {
      "epoch": 42.60852713178294,
      "grad_norm": 0.002887764712795615,
      "learning_rate": 7.3914728682170544e-06,
      "loss": 0.0001,
      "step": 10993
    },
    {
      "epoch": 42.6124031007752,
      "grad_norm": 0.0030012282077223063,
      "learning_rate": 7.387596899224807e-06,
      "loss": 0.0002,
      "step": 10994
    },
    {
      "epoch": 42.616279069767444,
      "grad_norm": 0.0007782107568345964,
      "learning_rate": 7.3837209302325584e-06,
      "loss": 0.0001,
      "step": 10995
    },
    {
      "epoch": 42.62015503875969,
      "grad_norm": 1.161005973815918,
      "learning_rate": 7.379844961240311e-06,
      "loss": 0.0475,
      "step": 10996
    },
    {
      "epoch": 42.62403100775194,
      "grad_norm": 0.0007151542231440544,
      "learning_rate": 7.3759689922480624e-06,
      "loss": 0.0001,
      "step": 10997
    },
    {
      "epoch": 42.627906976744185,
      "grad_norm": 0.5951981544494629,
      "learning_rate": 7.372093023255815e-06,
      "loss": 0.0243,
      "step": 10998
    },
    {
      "epoch": 42.63178294573643,
      "grad_norm": 0.0016699887346476316,
      "learning_rate": 7.3682170542635664e-06,
      "loss": 0.0002,
      "step": 10999
    },
    {
      "epoch": 42.63565891472868,
      "grad_norm": 0.0008482917328365147,
      "learning_rate": 7.364341085271319e-06,
      "loss": 0.0001,
      "step": 11000
    },
    {
      "epoch": 42.63953488372093,
      "grad_norm": 0.0028328648768365383,
      "learning_rate": 7.36046511627907e-06,
      "loss": 0.0001,
      "step": 11001
    },
    {
      "epoch": 42.64341085271318,
      "grad_norm": 0.002696279902011156,
      "learning_rate": 7.356589147286821e-06,
      "loss": 0.0002,
      "step": 11002
    },
    {
      "epoch": 42.64728682170543,
      "grad_norm": 0.0006592769641429186,
      "learning_rate": 7.3527131782945736e-06,
      "loss": 0.0001,
      "step": 11003
    },
    {
      "epoch": 42.651162790697676,
      "grad_norm": 1.2657426595687866,
      "learning_rate": 7.348837209302325e-06,
      "loss": 0.0782,
      "step": 11004
    },
    {
      "epoch": 42.65503875968992,
      "grad_norm": 0.0013500797795131803,
      "learning_rate": 7.3449612403100776e-06,
      "loss": 0.0001,
      "step": 11005
    },
    {
      "epoch": 42.65891472868217,
      "grad_norm": 0.0011851381277665496,
      "learning_rate": 7.34108527131783e-06,
      "loss": 0.0001,
      "step": 11006
    },
    {
      "epoch": 42.66279069767442,
      "grad_norm": 0.0020173429511487484,
      "learning_rate": 7.3372093023255816e-06,
      "loss": 0.0002,
      "step": 11007
    },
    {
      "epoch": 42.666666666666664,
      "grad_norm": 1.302916169166565,
      "learning_rate": 7.333333333333334e-06,
      "loss": 0.0777,
      "step": 11008
    },
    {
      "epoch": 42.67054263565891,
      "grad_norm": 0.0006393297808244824,
      "learning_rate": 7.3294573643410856e-06,
      "loss": 0.0001,
      "step": 11009
    },
    {
      "epoch": 42.674418604651166,
      "grad_norm": 0.05539354309439659,
      "learning_rate": 7.325581395348838e-06,
      "loss": 0.0007,
      "step": 11010
    },
    {
      "epoch": 42.67829457364341,
      "grad_norm": 0.0007307720952667296,
      "learning_rate": 7.3217054263565896e-06,
      "loss": 0.0001,
      "step": 11011
    },
    {
      "epoch": 42.68217054263566,
      "grad_norm": 0.0008542274590581656,
      "learning_rate": 7.317829457364342e-06,
      "loss": 0.0001,
      "step": 11012
    },
    {
      "epoch": 42.68604651162791,
      "grad_norm": 0.0009185087983496487,
      "learning_rate": 7.3139534883720936e-06,
      "loss": 0.0001,
      "step": 11013
    },
    {
      "epoch": 42.689922480620154,
      "grad_norm": 0.0007559718796983361,
      "learning_rate": 7.310077519379846e-06,
      "loss": 0.0001,
      "step": 11014
    },
    {
      "epoch": 42.6937984496124,
      "grad_norm": 0.0021730344742536545,
      "learning_rate": 7.306201550387597e-06,
      "loss": 0.0002,
      "step": 11015
    },
    {
      "epoch": 42.69767441860465,
      "grad_norm": 0.0007524621905758977,
      "learning_rate": 7.302325581395348e-06,
      "loss": 0.0001,
      "step": 11016
    },
    {
      "epoch": 42.701550387596896,
      "grad_norm": 0.00242661708034575,
      "learning_rate": 7.298449612403101e-06,
      "loss": 0.0002,
      "step": 11017
    },
    {
      "epoch": 42.70542635658915,
      "grad_norm": 0.0017369957640767097,
      "learning_rate": 7.294573643410853e-06,
      "loss": 0.0002,
      "step": 11018
    },
    {
      "epoch": 42.7093023255814,
      "grad_norm": 0.0014273121487349272,
      "learning_rate": 7.290697674418605e-06,
      "loss": 0.0001,
      "step": 11019
    },
    {
      "epoch": 42.713178294573645,
      "grad_norm": 0.0008361726650036871,
      "learning_rate": 7.286821705426357e-06,
      "loss": 0.0001,
      "step": 11020
    },
    {
      "epoch": 42.71705426356589,
      "grad_norm": 0.0013855531578883529,
      "learning_rate": 7.282945736434109e-06,
      "loss": 0.0001,
      "step": 11021
    },
    {
      "epoch": 42.72093023255814,
      "grad_norm": 0.0022048328537493944,
      "learning_rate": 7.279069767441861e-06,
      "loss": 0.0002,
      "step": 11022
    },
    {
      "epoch": 42.724806201550386,
      "grad_norm": 0.0008031492470763624,
      "learning_rate": 7.275193798449613e-06,
      "loss": 0.0001,
      "step": 11023
    },
    {
      "epoch": 42.72868217054263,
      "grad_norm": 0.0015829625772312284,
      "learning_rate": 7.271317829457365e-06,
      "loss": 0.0001,
      "step": 11024
    },
    {
      "epoch": 42.73255813953488,
      "grad_norm": 0.004250624682754278,
      "learning_rate": 7.267441860465117e-06,
      "loss": 0.0003,
      "step": 11025
    },
    {
      "epoch": 42.736434108527135,
      "grad_norm": 0.0013503116788342595,
      "learning_rate": 7.263565891472869e-06,
      "loss": 0.0001,
      "step": 11026
    },
    {
      "epoch": 42.74031007751938,
      "grad_norm": 0.0007081021904014051,
      "learning_rate": 7.2596899224806215e-06,
      "loss": 0.0001,
      "step": 11027
    },
    {
      "epoch": 42.74418604651163,
      "grad_norm": 0.0014567595208063722,
      "learning_rate": 7.255813953488371e-06,
      "loss": 0.0001,
      "step": 11028
    },
    {
      "epoch": 42.748062015503876,
      "grad_norm": 0.0010791677050292492,
      "learning_rate": 7.251937984496124e-06,
      "loss": 0.0001,
      "step": 11029
    },
    {
      "epoch": 42.751937984496124,
      "grad_norm": 0.7227042317390442,
      "learning_rate": 7.248062015503876e-06,
      "loss": 0.0316,
      "step": 11030
    },
    {
      "epoch": 42.75581395348837,
      "grad_norm": 0.0019344259053468704,
      "learning_rate": 7.244186046511628e-06,
      "loss": 0.0002,
      "step": 11031
    },
    {
      "epoch": 42.75968992248062,
      "grad_norm": 0.0010675255907699466,
      "learning_rate": 7.24031007751938e-06,
      "loss": 0.0001,
      "step": 11032
    },
    {
      "epoch": 42.763565891472865,
      "grad_norm": 0.0007351214881055057,
      "learning_rate": 7.236434108527132e-06,
      "loss": 0.0001,
      "step": 11033
    },
    {
      "epoch": 42.76744186046512,
      "grad_norm": 0.000995917129330337,
      "learning_rate": 7.232558139534884e-06,
      "loss": 0.0001,
      "step": 11034
    },
    {
      "epoch": 42.77131782945737,
      "grad_norm": 0.0013989834114909172,
      "learning_rate": 7.228682170542636e-06,
      "loss": 0.0001,
      "step": 11035
    },
    {
      "epoch": 42.775193798449614,
      "grad_norm": 0.00118052470497787,
      "learning_rate": 7.224806201550388e-06,
      "loss": 0.0001,
      "step": 11036
    },
    {
      "epoch": 42.77906976744186,
      "grad_norm": 0.003177895210683346,
      "learning_rate": 7.22093023255814e-06,
      "loss": 0.0002,
      "step": 11037
    },
    {
      "epoch": 42.78294573643411,
      "grad_norm": 0.0023523273412138224,
      "learning_rate": 7.217054263565892e-06,
      "loss": 0.0002,
      "step": 11038
    },
    {
      "epoch": 42.786821705426355,
      "grad_norm": 0.0007672885549254715,
      "learning_rate": 7.213178294573645e-06,
      "loss": 0.0001,
      "step": 11039
    },
    {
      "epoch": 42.7906976744186,
      "grad_norm": 0.0007164134876802564,
      "learning_rate": 7.209302325581396e-06,
      "loss": 0.0001,
      "step": 11040
    },
    {
      "epoch": 42.79457364341085,
      "grad_norm": 0.0025921412743628025,
      "learning_rate": 7.205426356589147e-06,
      "loss": 0.0002,
      "step": 11041
    },
    {
      "epoch": 42.798449612403104,
      "grad_norm": 0.0007525105029344559,
      "learning_rate": 7.201550387596899e-06,
      "loss": 0.0001,
      "step": 11042
    },
    {
      "epoch": 42.80232558139535,
      "grad_norm": 0.005744366906583309,
      "learning_rate": 7.197674418604651e-06,
      "loss": 0.0002,
      "step": 11043
    },
    {
      "epoch": 42.8062015503876,
      "grad_norm": 0.0009478733991272748,
      "learning_rate": 7.193798449612403e-06,
      "loss": 0.0001,
      "step": 11044
    },
    {
      "epoch": 42.810077519379846,
      "grad_norm": 0.000594124139752239,
      "learning_rate": 7.189922480620155e-06,
      "loss": 0.0001,
      "step": 11045
    },
    {
      "epoch": 42.81395348837209,
      "grad_norm": 0.236898273229599,
      "learning_rate": 7.186046511627907e-06,
      "loss": 0.0097,
      "step": 11046
    },
    {
      "epoch": 42.81782945736434,
      "grad_norm": 0.0011602387530729175,
      "learning_rate": 7.182170542635659e-06,
      "loss": 0.0001,
      "step": 11047
    },
    {
      "epoch": 42.82170542635659,
      "grad_norm": 0.0007558299112133682,
      "learning_rate": 7.178294573643411e-06,
      "loss": 0.0001,
      "step": 11048
    },
    {
      "epoch": 42.825581395348834,
      "grad_norm": 0.0007884276565164328,
      "learning_rate": 7.174418604651163e-06,
      "loss": 0.0001,
      "step": 11049
    },
    {
      "epoch": 42.82945736434109,
      "grad_norm": 0.001031005522236228,
      "learning_rate": 7.170542635658915e-06,
      "loss": 0.0001,
      "step": 11050
    },
    {
      "epoch": 42.833333333333336,
      "grad_norm": 0.0007865847437642515,
      "learning_rate": 7.166666666666667e-06,
      "loss": 0.0001,
      "step": 11051
    },
    {
      "epoch": 42.83720930232558,
      "grad_norm": 0.10482028126716614,
      "learning_rate": 7.162790697674419e-06,
      "loss": 0.0037,
      "step": 11052
    },
    {
      "epoch": 42.84108527131783,
      "grad_norm": 0.0015889209462329745,
      "learning_rate": 7.158914728682172e-06,
      "loss": 0.0001,
      "step": 11053
    },
    {
      "epoch": 42.84496124031008,
      "grad_norm": 0.0015196074964478612,
      "learning_rate": 7.155038759689923e-06,
      "loss": 0.0001,
      "step": 11054
    },
    {
      "epoch": 42.848837209302324,
      "grad_norm": 0.0012081640306860209,
      "learning_rate": 7.151162790697674e-06,
      "loss": 0.0001,
      "step": 11055
    },
    {
      "epoch": 42.85271317829457,
      "grad_norm": 0.003183216555044055,
      "learning_rate": 7.1472868217054265e-06,
      "loss": 0.0002,
      "step": 11056
    },
    {
      "epoch": 42.85658914728682,
      "grad_norm": 0.0016192588955163956,
      "learning_rate": 7.143410852713178e-06,
      "loss": 0.0001,
      "step": 11057
    },
    {
      "epoch": 42.86046511627907,
      "grad_norm": 0.2863907217979431,
      "learning_rate": 7.1395348837209305e-06,
      "loss": 0.0091,
      "step": 11058
    },
    {
      "epoch": 42.86434108527132,
      "grad_norm": 0.0009637420298531651,
      "learning_rate": 7.135658914728682e-06,
      "loss": 0.0001,
      "step": 11059
    },
    {
      "epoch": 42.86821705426357,
      "grad_norm": 0.0007402945193462074,
      "learning_rate": 7.1317829457364345e-06,
      "loss": 0.0001,
      "step": 11060
    },
    {
      "epoch": 42.872093023255815,
      "grad_norm": 0.0007682284340262413,
      "learning_rate": 7.127906976744186e-06,
      "loss": 0.0001,
      "step": 11061
    },
    {
      "epoch": 42.87596899224806,
      "grad_norm": 0.0006847282638773322,
      "learning_rate": 7.1240310077519385e-06,
      "loss": 0.0001,
      "step": 11062
    },
    {
      "epoch": 42.87984496124031,
      "grad_norm": 0.0007484049419872463,
      "learning_rate": 7.12015503875969e-06,
      "loss": 0.0001,
      "step": 11063
    },
    {
      "epoch": 42.883720930232556,
      "grad_norm": 0.0007921138312667608,
      "learning_rate": 7.1162790697674425e-06,
      "loss": 0.0001,
      "step": 11064
    },
    {
      "epoch": 42.8875968992248,
      "grad_norm": 0.001548743573948741,
      "learning_rate": 7.112403100775195e-06,
      "loss": 0.0002,
      "step": 11065
    },
    {
      "epoch": 42.89147286821706,
      "grad_norm": 0.0006841329741291702,
      "learning_rate": 7.1085271317829465e-06,
      "loss": 0.0001,
      "step": 11066
    },
    {
      "epoch": 42.895348837209305,
      "grad_norm": 0.000807909294962883,
      "learning_rate": 7.104651162790699e-06,
      "loss": 0.0001,
      "step": 11067
    },
    {
      "epoch": 42.89922480620155,
      "grad_norm": 0.9412556886672974,
      "learning_rate": 7.10077519379845e-06,
      "loss": 0.054,
      "step": 11068
    },
    {
      "epoch": 42.9031007751938,
      "grad_norm": 0.0012093513505533338,
      "learning_rate": 7.096899224806201e-06,
      "loss": 0.0001,
      "step": 11069
    },
    {
      "epoch": 42.906976744186046,
      "grad_norm": 0.0016205465653911233,
      "learning_rate": 7.093023255813954e-06,
      "loss": 0.0001,
      "step": 11070
    },
    {
      "epoch": 42.91085271317829,
      "grad_norm": 0.0009930478408932686,
      "learning_rate": 7.089147286821705e-06,
      "loss": 0.0001,
      "step": 11071
    },
    {
      "epoch": 42.91472868217054,
      "grad_norm": 0.0018023084849119186,
      "learning_rate": 7.085271317829458e-06,
      "loss": 0.0001,
      "step": 11072
    },
    {
      "epoch": 42.91860465116279,
      "grad_norm": 0.000694239919539541,
      "learning_rate": 7.081395348837209e-06,
      "loss": 0.0001,
      "step": 11073
    },
    {
      "epoch": 42.92248062015504,
      "grad_norm": 0.0017950724577531219,
      "learning_rate": 7.077519379844962e-06,
      "loss": 0.0001,
      "step": 11074
    },
    {
      "epoch": 42.92635658914729,
      "grad_norm": 0.001125216018408537,
      "learning_rate": 7.073643410852713e-06,
      "loss": 0.0001,
      "step": 11075
    },
    {
      "epoch": 42.93023255813954,
      "grad_norm": 0.001073695719242096,
      "learning_rate": 7.069767441860466e-06,
      "loss": 0.0001,
      "step": 11076
    },
    {
      "epoch": 42.934108527131784,
      "grad_norm": 0.0011742901988327503,
      "learning_rate": 7.065891472868218e-06,
      "loss": 0.0001,
      "step": 11077
    },
    {
      "epoch": 42.93798449612403,
      "grad_norm": 0.0014913888880982995,
      "learning_rate": 7.06201550387597e-06,
      "loss": 0.0001,
      "step": 11078
    },
    {
      "epoch": 42.94186046511628,
      "grad_norm": 0.0008155865943990648,
      "learning_rate": 7.058139534883722e-06,
      "loss": 0.0001,
      "step": 11079
    },
    {
      "epoch": 42.945736434108525,
      "grad_norm": 0.0025821710005402565,
      "learning_rate": 7.054263565891474e-06,
      "loss": 0.0001,
      "step": 11080
    },
    {
      "epoch": 42.94961240310077,
      "grad_norm": 0.12640289962291718,
      "learning_rate": 7.050387596899224e-06,
      "loss": 0.0032,
      "step": 11081
    },
    {
      "epoch": 42.95348837209303,
      "grad_norm": 0.0013740772847086191,
      "learning_rate": 7.046511627906977e-06,
      "loss": 0.0001,
      "step": 11082
    },
    {
      "epoch": 42.957364341085274,
      "grad_norm": 0.0008149248315021396,
      "learning_rate": 7.042635658914728e-06,
      "loss": 0.0001,
      "step": 11083
    },
    {
      "epoch": 42.96124031007752,
      "grad_norm": 0.01779220439493656,
      "learning_rate": 7.038759689922481e-06,
      "loss": 0.0002,
      "step": 11084
    },
    {
      "epoch": 42.96511627906977,
      "grad_norm": 0.045326974242925644,
      "learning_rate": 7.034883720930232e-06,
      "loss": 0.0002,
      "step": 11085
    },
    {
      "epoch": 42.968992248062015,
      "grad_norm": 0.0008880503010004759,
      "learning_rate": 7.031007751937985e-06,
      "loss": 0.0001,
      "step": 11086
    },
    {
      "epoch": 42.97286821705426,
      "grad_norm": 0.004594299476593733,
      "learning_rate": 7.027131782945736e-06,
      "loss": 0.0003,
      "step": 11087
    },
    {
      "epoch": 42.97674418604651,
      "grad_norm": 0.0007740852888673544,
      "learning_rate": 7.023255813953489e-06,
      "loss": 0.0001,
      "step": 11088
    },
    {
      "epoch": 42.98062015503876,
      "grad_norm": 0.0008488896419294178,
      "learning_rate": 7.019379844961241e-06,
      "loss": 0.0001,
      "step": 11089
    },
    {
      "epoch": 42.98449612403101,
      "grad_norm": 0.0007217300008051097,
      "learning_rate": 7.015503875968993e-06,
      "loss": 0.0001,
      "step": 11090
    },
    {
      "epoch": 42.98837209302326,
      "grad_norm": 0.00334596773609519,
      "learning_rate": 7.011627906976745e-06,
      "loss": 0.0002,
      "step": 11091
    },
    {
      "epoch": 42.992248062015506,
      "grad_norm": 0.0007563307881355286,
      "learning_rate": 7.007751937984497e-06,
      "loss": 0.0001,
      "step": 11092
    },
    {
      "epoch": 42.99612403100775,
      "grad_norm": 0.0007546722772531211,
      "learning_rate": 7.003875968992249e-06,
      "loss": 0.0001,
      "step": 11093
    },
    {
      "epoch": 43.0,
      "grad_norm": 0.0008263891795650125,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.0001,
      "step": 11094
    },
    {
      "epoch": 43.00387596899225,
      "grad_norm": 0.000984026351943612,
      "learning_rate": 6.9961240310077515e-06,
      "loss": 0.0001,
      "step": 11095
    },
    {
      "epoch": 43.007751937984494,
      "grad_norm": 0.013193265534937382,
      "learning_rate": 6.992248062015504e-06,
      "loss": 0.0003,
      "step": 11096
    },
    {
      "epoch": 43.01162790697674,
      "grad_norm": 0.0006697995122522116,
      "learning_rate": 6.9883720930232555e-06,
      "loss": 0.0001,
      "step": 11097
    },
    {
      "epoch": 43.01550387596899,
      "grad_norm": 0.0007795481360517442,
      "learning_rate": 6.984496124031008e-06,
      "loss": 0.0001,
      "step": 11098
    },
    {
      "epoch": 43.01937984496124,
      "grad_norm": 0.000858709157910198,
      "learning_rate": 6.9806201550387595e-06,
      "loss": 0.0001,
      "step": 11099
    },
    {
      "epoch": 43.02325581395349,
      "grad_norm": 0.0011267490917816758,
      "learning_rate": 6.976744186046512e-06,
      "loss": 0.0001,
      "step": 11100
    },
    {
      "epoch": 43.02713178294574,
      "grad_norm": 0.006673475261777639,
      "learning_rate": 6.972868217054264e-06,
      "loss": 0.0003,
      "step": 11101
    },
    {
      "epoch": 43.031007751937985,
      "grad_norm": 0.0029369324911385775,
      "learning_rate": 6.968992248062016e-06,
      "loss": 0.0002,
      "step": 11102
    },
    {
      "epoch": 43.03488372093023,
      "grad_norm": 0.0006863765884190798,
      "learning_rate": 6.965116279069768e-06,
      "loss": 0.0001,
      "step": 11103
    },
    {
      "epoch": 43.03875968992248,
      "grad_norm": 0.0008531059720553458,
      "learning_rate": 6.96124031007752e-06,
      "loss": 0.0001,
      "step": 11104
    },
    {
      "epoch": 43.042635658914726,
      "grad_norm": 0.0007949764258228242,
      "learning_rate": 6.957364341085272e-06,
      "loss": 0.0001,
      "step": 11105
    },
    {
      "epoch": 43.04651162790697,
      "grad_norm": 0.0007930435240268707,
      "learning_rate": 6.953488372093024e-06,
      "loss": 0.0001,
      "step": 11106
    },
    {
      "epoch": 43.05038759689923,
      "grad_norm": 0.004210837185382843,
      "learning_rate": 6.949612403100776e-06,
      "loss": 0.0002,
      "step": 11107
    },
    {
      "epoch": 43.054263565891475,
      "grad_norm": 0.0009550859103910625,
      "learning_rate": 6.945736434108527e-06,
      "loss": 0.0001,
      "step": 11108
    },
    {
      "epoch": 43.05813953488372,
      "grad_norm": 0.0012444976018741727,
      "learning_rate": 6.941860465116279e-06,
      "loss": 0.0001,
      "step": 11109
    },
    {
      "epoch": 43.06201550387597,
      "grad_norm": 0.0007889124099165201,
      "learning_rate": 6.937984496124031e-06,
      "loss": 0.0001,
      "step": 11110
    },
    {
      "epoch": 43.065891472868216,
      "grad_norm": 0.0012188650434836745,
      "learning_rate": 6.934108527131783e-06,
      "loss": 0.0001,
      "step": 11111
    },
    {
      "epoch": 43.06976744186046,
      "grad_norm": 0.004449343308806419,
      "learning_rate": 6.930232558139535e-06,
      "loss": 0.0002,
      "step": 11112
    },
    {
      "epoch": 43.07364341085271,
      "grad_norm": 0.05537683516740799,
      "learning_rate": 6.9263565891472874e-06,
      "loss": 0.0024,
      "step": 11113
    },
    {
      "epoch": 43.07751937984496,
      "grad_norm": 0.0009817668469622731,
      "learning_rate": 6.922480620155039e-06,
      "loss": 0.0001,
      "step": 11114
    },
    {
      "epoch": 43.08139534883721,
      "grad_norm": 0.004021091852337122,
      "learning_rate": 6.9186046511627914e-06,
      "loss": 0.0002,
      "step": 11115
    },
    {
      "epoch": 43.08527131782946,
      "grad_norm": 0.0007903026416897774,
      "learning_rate": 6.914728682170543e-06,
      "loss": 0.0001,
      "step": 11116
    },
    {
      "epoch": 43.08914728682171,
      "grad_norm": 0.0007073126616887748,
      "learning_rate": 6.9108527131782954e-06,
      "loss": 0.0001,
      "step": 11117
    },
    {
      "epoch": 43.093023255813954,
      "grad_norm": 0.0012721772072836757,
      "learning_rate": 6.906976744186047e-06,
      "loss": 0.0001,
      "step": 11118
    },
    {
      "epoch": 43.0968992248062,
      "grad_norm": 0.002006551716476679,
      "learning_rate": 6.903100775193799e-06,
      "loss": 0.0002,
      "step": 11119
    },
    {
      "epoch": 43.10077519379845,
      "grad_norm": 0.003031823318451643,
      "learning_rate": 6.899224806201551e-06,
      "loss": 0.0002,
      "step": 11120
    },
    {
      "epoch": 43.104651162790695,
      "grad_norm": 0.000810052384622395,
      "learning_rate": 6.895348837209302e-06,
      "loss": 0.0001,
      "step": 11121
    },
    {
      "epoch": 43.10852713178294,
      "grad_norm": 0.2313491553068161,
      "learning_rate": 6.891472868217054e-06,
      "loss": 0.0092,
      "step": 11122
    },
    {
      "epoch": 43.1124031007752,
      "grad_norm": 0.0008758067851886153,
      "learning_rate": 6.887596899224806e-06,
      "loss": 0.0001,
      "step": 11123
    },
    {
      "epoch": 43.116279069767444,
      "grad_norm": 0.0007614847854711115,
      "learning_rate": 6.883720930232558e-06,
      "loss": 0.0001,
      "step": 11124
    },
    {
      "epoch": 43.12015503875969,
      "grad_norm": 0.0007466370589099824,
      "learning_rate": 6.87984496124031e-06,
      "loss": 0.0001,
      "step": 11125
    },
    {
      "epoch": 43.12403100775194,
      "grad_norm": 0.0017249741358682513,
      "learning_rate": 6.875968992248062e-06,
      "loss": 0.0001,
      "step": 11126
    },
    {
      "epoch": 43.127906976744185,
      "grad_norm": 0.0008417575154453516,
      "learning_rate": 6.8720930232558146e-06,
      "loss": 0.0001,
      "step": 11127
    },
    {
      "epoch": 43.13178294573643,
      "grad_norm": 0.0016561629017814994,
      "learning_rate": 6.868217054263566e-06,
      "loss": 0.0001,
      "step": 11128
    },
    {
      "epoch": 43.13565891472868,
      "grad_norm": 0.010013226419687271,
      "learning_rate": 6.8643410852713186e-06,
      "loss": 0.0003,
      "step": 11129
    },
    {
      "epoch": 43.13953488372093,
      "grad_norm": 0.0017138284165412188,
      "learning_rate": 6.86046511627907e-06,
      "loss": 0.0002,
      "step": 11130
    },
    {
      "epoch": 43.14341085271318,
      "grad_norm": 0.001200457802042365,
      "learning_rate": 6.8565891472868226e-06,
      "loss": 0.0001,
      "step": 11131
    },
    {
      "epoch": 43.14728682170543,
      "grad_norm": 0.0007304751197807491,
      "learning_rate": 6.852713178294574e-06,
      "loss": 0.0001,
      "step": 11132
    },
    {
      "epoch": 43.151162790697676,
      "grad_norm": 0.000896151177585125,
      "learning_rate": 6.8488372093023265e-06,
      "loss": 0.0001,
      "step": 11133
    },
    {
      "epoch": 43.15503875968992,
      "grad_norm": 0.0007596123032271862,
      "learning_rate": 6.844961240310078e-06,
      "loss": 0.0001,
      "step": 11134
    },
    {
      "epoch": 43.15891472868217,
      "grad_norm": 0.0007140763918869197,
      "learning_rate": 6.841085271317829e-06,
      "loss": 0.0001,
      "step": 11135
    },
    {
      "epoch": 43.16279069767442,
      "grad_norm": 0.020642682909965515,
      "learning_rate": 6.837209302325581e-06,
      "loss": 0.0003,
      "step": 11136
    },
    {
      "epoch": 43.166666666666664,
      "grad_norm": 1.60774564743042,
      "learning_rate": 6.833333333333333e-06,
      "loss": 0.1659,
      "step": 11137
    },
    {
      "epoch": 43.17054263565891,
      "grad_norm": 0.0027787708677351475,
      "learning_rate": 6.829457364341085e-06,
      "loss": 0.0002,
      "step": 11138
    },
    {
      "epoch": 43.174418604651166,
      "grad_norm": 0.0011165825417265296,
      "learning_rate": 6.825581395348838e-06,
      "loss": 0.0001,
      "step": 11139
    },
    {
      "epoch": 43.17829457364341,
      "grad_norm": 0.00392393721267581,
      "learning_rate": 6.821705426356589e-06,
      "loss": 0.0002,
      "step": 11140
    },
    {
      "epoch": 43.18217054263566,
      "grad_norm": 0.0010551521554589272,
      "learning_rate": 6.817829457364342e-06,
      "loss": 0.0001,
      "step": 11141
    },
    {
      "epoch": 43.18604651162791,
      "grad_norm": 0.0007358287111856043,
      "learning_rate": 6.813953488372093e-06,
      "loss": 0.0001,
      "step": 11142
    },
    {
      "epoch": 43.189922480620154,
      "grad_norm": 0.0007160575478337705,
      "learning_rate": 6.810077519379846e-06,
      "loss": 0.0001,
      "step": 11143
    },
    {
      "epoch": 43.1937984496124,
      "grad_norm": 0.0008255318971350789,
      "learning_rate": 6.806201550387597e-06,
      "loss": 0.0001,
      "step": 11144
    },
    {
      "epoch": 43.19767441860465,
      "grad_norm": 0.0009463172173127532,
      "learning_rate": 6.80232558139535e-06,
      "loss": 0.0001,
      "step": 11145
    },
    {
      "epoch": 43.201550387596896,
      "grad_norm": 0.0008300476474687457,
      "learning_rate": 6.798449612403101e-06,
      "loss": 0.0001,
      "step": 11146
    },
    {
      "epoch": 43.20542635658915,
      "grad_norm": 0.0006469172658398747,
      "learning_rate": 6.794573643410854e-06,
      "loss": 0.0001,
      "step": 11147
    },
    {
      "epoch": 43.2093023255814,
      "grad_norm": 0.001401678891852498,
      "learning_rate": 6.790697674418604e-06,
      "loss": 0.0001,
      "step": 11148
    },
    {
      "epoch": 43.213178294573645,
      "grad_norm": 0.691663920879364,
      "learning_rate": 6.786821705426356e-06,
      "loss": 0.0387,
      "step": 11149
    },
    {
      "epoch": 43.21705426356589,
      "grad_norm": 0.0006677427445538342,
      "learning_rate": 6.782945736434108e-06,
      "loss": 0.0001,
      "step": 11150
    },
    {
      "epoch": 43.22093023255814,
      "grad_norm": 0.0006740311509929597,
      "learning_rate": 6.779069767441861e-06,
      "loss": 0.0001,
      "step": 11151
    },
    {
      "epoch": 43.224806201550386,
      "grad_norm": 0.0008445277344435453,
      "learning_rate": 6.775193798449612e-06,
      "loss": 0.0001,
      "step": 11152
    },
    {
      "epoch": 43.22868217054263,
      "grad_norm": 0.0010820067254826427,
      "learning_rate": 6.771317829457365e-06,
      "loss": 0.0001,
      "step": 11153
    },
    {
      "epoch": 43.23255813953488,
      "grad_norm": 0.007019387558102608,
      "learning_rate": 6.767441860465116e-06,
      "loss": 0.0001,
      "step": 11154
    },
    {
      "epoch": 43.236434108527135,
      "grad_norm": 3.382983446121216,
      "learning_rate": 6.763565891472869e-06,
      "loss": 0.3411,
      "step": 11155
    },
    {
      "epoch": 43.24031007751938,
      "grad_norm": 0.0034904435742646456,
      "learning_rate": 6.75968992248062e-06,
      "loss": 0.0002,
      "step": 11156
    },
    {
      "epoch": 43.24418604651163,
      "grad_norm": 0.0008534239022992551,
      "learning_rate": 6.755813953488373e-06,
      "loss": 0.0001,
      "step": 11157
    },
    {
      "epoch": 43.248062015503876,
      "grad_norm": 0.001244360231794417,
      "learning_rate": 6.751937984496124e-06,
      "loss": 0.0001,
      "step": 11158
    },
    {
      "epoch": 43.251937984496124,
      "grad_norm": 0.0007939637871459126,
      "learning_rate": 6.748062015503877e-06,
      "loss": 0.0001,
      "step": 11159
    },
    {
      "epoch": 43.25581395348837,
      "grad_norm": 0.0036399581003934145,
      "learning_rate": 6.744186046511629e-06,
      "loss": 0.0003,
      "step": 11160
    },
    {
      "epoch": 43.25968992248062,
      "grad_norm": 0.0011840626830235124,
      "learning_rate": 6.740310077519379e-06,
      "loss": 0.0001,
      "step": 11161
    },
    {
      "epoch": 43.263565891472865,
      "grad_norm": 0.0011716244043782353,
      "learning_rate": 6.7364341085271315e-06,
      "loss": 0.0001,
      "step": 11162
    },
    {
      "epoch": 43.26744186046512,
      "grad_norm": 0.0007930833962745965,
      "learning_rate": 6.732558139534884e-06,
      "loss": 0.0001,
      "step": 11163
    },
    {
      "epoch": 43.27131782945737,
      "grad_norm": 0.0011021706741303205,
      "learning_rate": 6.7286821705426355e-06,
      "loss": 0.0001,
      "step": 11164
    },
    {
      "epoch": 43.275193798449614,
      "grad_norm": 0.0013778368011116982,
      "learning_rate": 6.724806201550388e-06,
      "loss": 0.0001,
      "step": 11165
    },
    {
      "epoch": 43.27906976744186,
      "grad_norm": 0.0015279456274583936,
      "learning_rate": 6.7209302325581395e-06,
      "loss": 0.0001,
      "step": 11166
    },
    {
      "epoch": 43.28294573643411,
      "grad_norm": 0.0020023812539875507,
      "learning_rate": 6.717054263565892e-06,
      "loss": 0.0001,
      "step": 11167
    },
    {
      "epoch": 43.286821705426355,
      "grad_norm": 0.0007166308350861073,
      "learning_rate": 6.7131782945736435e-06,
      "loss": 0.0001,
      "step": 11168
    },
    {
      "epoch": 43.2906976744186,
      "grad_norm": 0.0009872117079794407,
      "learning_rate": 6.709302325581396e-06,
      "loss": 0.0001,
      "step": 11169
    },
    {
      "epoch": 43.29457364341085,
      "grad_norm": 0.001478303805924952,
      "learning_rate": 6.7054263565891475e-06,
      "loss": 0.0001,
      "step": 11170
    },
    {
      "epoch": 43.298449612403104,
      "grad_norm": 0.0008170746150426567,
      "learning_rate": 6.7015503875969e-06,
      "loss": 0.0001,
      "step": 11171
    },
    {
      "epoch": 43.30232558139535,
      "grad_norm": 0.0007665000157430768,
      "learning_rate": 6.697674418604652e-06,
      "loss": 0.0001,
      "step": 11172
    },
    {
      "epoch": 43.3062015503876,
      "grad_norm": 0.0006396619137376547,
      "learning_rate": 6.693798449612404e-06,
      "loss": 0.0001,
      "step": 11173
    },
    {
      "epoch": 43.310077519379846,
      "grad_norm": 0.0015971205430105329,
      "learning_rate": 6.689922480620156e-06,
      "loss": 0.0001,
      "step": 11174
    },
    {
      "epoch": 43.31395348837209,
      "grad_norm": 0.0008398094214498997,
      "learning_rate": 6.686046511627907e-06,
      "loss": 0.0001,
      "step": 11175
    },
    {
      "epoch": 43.31782945736434,
      "grad_norm": 0.0031572661828249693,
      "learning_rate": 6.682170542635659e-06,
      "loss": 0.0002,
      "step": 11176
    },
    {
      "epoch": 43.32170542635659,
      "grad_norm": 0.0007058755727484822,
      "learning_rate": 6.678294573643411e-06,
      "loss": 0.0001,
      "step": 11177
    },
    {
      "epoch": 43.325581395348834,
      "grad_norm": 0.0010584640549495816,
      "learning_rate": 6.674418604651163e-06,
      "loss": 0.0001,
      "step": 11178
    },
    {
      "epoch": 43.32945736434109,
      "grad_norm": 0.0008105108863674104,
      "learning_rate": 6.670542635658915e-06,
      "loss": 0.0001,
      "step": 11179
    },
    {
      "epoch": 43.333333333333336,
      "grad_norm": 0.0007868690299801528,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0001,
      "step": 11180
    },
    {
      "epoch": 43.33720930232558,
      "grad_norm": 0.0007433478021994233,
      "learning_rate": 6.662790697674419e-06,
      "loss": 0.0001,
      "step": 11181
    },
    {
      "epoch": 43.34108527131783,
      "grad_norm": 0.0007147990399971604,
      "learning_rate": 6.658914728682171e-06,
      "loss": 0.0001,
      "step": 11182
    },
    {
      "epoch": 43.34496124031008,
      "grad_norm": 0.001082217670045793,
      "learning_rate": 6.655038759689923e-06,
      "loss": 0.0001,
      "step": 11183
    },
    {
      "epoch": 43.348837209302324,
      "grad_norm": 0.0023080501705408096,
      "learning_rate": 6.651162790697675e-06,
      "loss": 0.0001,
      "step": 11184
    },
    {
      "epoch": 43.35271317829457,
      "grad_norm": 0.0007680040434934199,
      "learning_rate": 6.647286821705427e-06,
      "loss": 0.0001,
      "step": 11185
    },
    {
      "epoch": 43.35658914728682,
      "grad_norm": 0.004515725187957287,
      "learning_rate": 6.6434108527131795e-06,
      "loss": 0.0001,
      "step": 11186
    },
    {
      "epoch": 43.36046511627907,
      "grad_norm": 0.000760328839533031,
      "learning_rate": 6.639534883720931e-06,
      "loss": 0.0001,
      "step": 11187
    },
    {
      "epoch": 43.36434108527132,
      "grad_norm": 0.0008106084424071014,
      "learning_rate": 6.635658914728682e-06,
      "loss": 0.0001,
      "step": 11188
    },
    {
      "epoch": 43.36821705426357,
      "grad_norm": 0.0007034160080365837,
      "learning_rate": 6.631782945736434e-06,
      "loss": 0.0001,
      "step": 11189
    },
    {
      "epoch": 43.372093023255815,
      "grad_norm": 0.0007076459005475044,
      "learning_rate": 6.627906976744186e-06,
      "loss": 0.0001,
      "step": 11190
    },
    {
      "epoch": 43.37596899224806,
      "grad_norm": 0.0009708933648653328,
      "learning_rate": 6.624031007751938e-06,
      "loss": 0.0001,
      "step": 11191
    },
    {
      "epoch": 43.37984496124031,
      "grad_norm": 0.0008494656067341566,
      "learning_rate": 6.62015503875969e-06,
      "loss": 0.0001,
      "step": 11192
    },
    {
      "epoch": 43.383720930232556,
      "grad_norm": 0.0007209269097074866,
      "learning_rate": 6.616279069767442e-06,
      "loss": 0.0001,
      "step": 11193
    },
    {
      "epoch": 43.3875968992248,
      "grad_norm": 0.0012264683609828353,
      "learning_rate": 6.612403100775194e-06,
      "loss": 0.0001,
      "step": 11194
    },
    {
      "epoch": 43.39147286821706,
      "grad_norm": 0.00291815516538918,
      "learning_rate": 6.608527131782946e-06,
      "loss": 0.0002,
      "step": 11195
    },
    {
      "epoch": 43.395348837209305,
      "grad_norm": 0.0007193186320364475,
      "learning_rate": 6.604651162790698e-06,
      "loss": 0.0001,
      "step": 11196
    },
    {
      "epoch": 43.39922480620155,
      "grad_norm": 0.0007551448652520776,
      "learning_rate": 6.60077519379845e-06,
      "loss": 0.0001,
      "step": 11197
    },
    {
      "epoch": 43.4031007751938,
      "grad_norm": 0.0007408036035485566,
      "learning_rate": 6.596899224806203e-06,
      "loss": 0.0001,
      "step": 11198
    },
    {
      "epoch": 43.406976744186046,
      "grad_norm": 0.35414984822273254,
      "learning_rate": 6.593023255813954e-06,
      "loss": 0.0151,
      "step": 11199
    },
    {
      "epoch": 43.41085271317829,
      "grad_norm": 0.0011112961219623685,
      "learning_rate": 6.589147286821707e-06,
      "loss": 0.0001,
      "step": 11200
    },
    {
      "epoch": 43.41472868217054,
      "grad_norm": 0.0009371820488013327,
      "learning_rate": 6.585271317829457e-06,
      "loss": 0.0001,
      "step": 11201
    },
    {
      "epoch": 43.41860465116279,
      "grad_norm": 0.0008966271998360753,
      "learning_rate": 6.581395348837209e-06,
      "loss": 0.0001,
      "step": 11202
    },
    {
      "epoch": 43.42248062015504,
      "grad_norm": 0.00982017070055008,
      "learning_rate": 6.577519379844961e-06,
      "loss": 0.0003,
      "step": 11203
    },
    {
      "epoch": 43.42635658914729,
      "grad_norm": 0.00115098780952394,
      "learning_rate": 6.573643410852713e-06,
      "loss": 0.0001,
      "step": 11204
    },
    {
      "epoch": 43.43023255813954,
      "grad_norm": 0.0011393631575629115,
      "learning_rate": 6.569767441860465e-06,
      "loss": 0.0001,
      "step": 11205
    },
    {
      "epoch": 43.434108527131784,
      "grad_norm": 0.000748435384593904,
      "learning_rate": 6.565891472868217e-06,
      "loss": 0.0001,
      "step": 11206
    },
    {
      "epoch": 43.43798449612403,
      "grad_norm": 0.6368727684020996,
      "learning_rate": 6.562015503875969e-06,
      "loss": 0.0267,
      "step": 11207
    },
    {
      "epoch": 43.44186046511628,
      "grad_norm": 0.004324929788708687,
      "learning_rate": 6.558139534883721e-06,
      "loss": 0.0002,
      "step": 11208
    },
    {
      "epoch": 43.445736434108525,
      "grad_norm": 0.11129012703895569,
      "learning_rate": 6.554263565891473e-06,
      "loss": 0.0046,
      "step": 11209
    },
    {
      "epoch": 43.44961240310077,
      "grad_norm": 0.0008151112706400454,
      "learning_rate": 6.550387596899226e-06,
      "loss": 0.0001,
      "step": 11210
    },
    {
      "epoch": 43.45348837209303,
      "grad_norm": 0.001904459553770721,
      "learning_rate": 6.546511627906977e-06,
      "loss": 0.0002,
      "step": 11211
    },
    {
      "epoch": 43.457364341085274,
      "grad_norm": 0.0011503425193950534,
      "learning_rate": 6.54263565891473e-06,
      "loss": 0.0001,
      "step": 11212
    },
    {
      "epoch": 43.46124031007752,
      "grad_norm": 0.0008500175317749381,
      "learning_rate": 6.538759689922481e-06,
      "loss": 0.0001,
      "step": 11213
    },
    {
      "epoch": 43.46511627906977,
      "grad_norm": 0.0008991700015030801,
      "learning_rate": 6.534883720930234e-06,
      "loss": 0.0001,
      "step": 11214
    },
    {
      "epoch": 43.468992248062015,
      "grad_norm": 0.0008024832350201905,
      "learning_rate": 6.5310077519379845e-06,
      "loss": 0.0001,
      "step": 11215
    },
    {
      "epoch": 43.47286821705426,
      "grad_norm": 0.0009364280267618597,
      "learning_rate": 6.527131782945736e-06,
      "loss": 0.0001,
      "step": 11216
    },
    {
      "epoch": 43.47674418604651,
      "grad_norm": 0.0007708026096224785,
      "learning_rate": 6.5232558139534885e-06,
      "loss": 0.0001,
      "step": 11217
    },
    {
      "epoch": 43.48062015503876,
      "grad_norm": 0.0007576356292702258,
      "learning_rate": 6.51937984496124e-06,
      "loss": 0.0001,
      "step": 11218
    },
    {
      "epoch": 43.48449612403101,
      "grad_norm": 0.406277060508728,
      "learning_rate": 6.5155038759689925e-06,
      "loss": 0.0199,
      "step": 11219
    },
    {
      "epoch": 43.48837209302326,
      "grad_norm": 0.0007275904063135386,
      "learning_rate": 6.511627906976744e-06,
      "loss": 0.0001,
      "step": 11220
    },
    {
      "epoch": 43.492248062015506,
      "grad_norm": 46.42551803588867,
      "learning_rate": 6.5077519379844965e-06,
      "loss": 0.0231,
      "step": 11221
    },
    {
      "epoch": 43.49612403100775,
      "grad_norm": 0.0009603113867342472,
      "learning_rate": 6.503875968992249e-06,
      "loss": 0.0001,
      "step": 11222
    },
    {
      "epoch": 43.5,
      "grad_norm": 0.0023266850039362907,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0002,
      "step": 11223
    },
    {
      "epoch": 43.50387596899225,
      "grad_norm": 0.0007150985184125602,
      "learning_rate": 6.496124031007753e-06,
      "loss": 0.0001,
      "step": 11224
    },
    {
      "epoch": 43.507751937984494,
      "grad_norm": 0.5416243672370911,
      "learning_rate": 6.4922480620155044e-06,
      "loss": 0.0289,
      "step": 11225
    },
    {
      "epoch": 43.51162790697674,
      "grad_norm": 0.0024938296992331743,
      "learning_rate": 6.488372093023257e-06,
      "loss": 0.0001,
      "step": 11226
    },
    {
      "epoch": 43.51550387596899,
      "grad_norm": 0.0008265719516202807,
      "learning_rate": 6.4844961240310084e-06,
      "loss": 0.0001,
      "step": 11227
    },
    {
      "epoch": 43.51937984496124,
      "grad_norm": 0.0006615904858335853,
      "learning_rate": 6.480620155038759e-06,
      "loss": 0.0001,
      "step": 11228
    },
    {
      "epoch": 43.52325581395349,
      "grad_norm": 0.0009299070807173848,
      "learning_rate": 6.476744186046512e-06,
      "loss": 0.0001,
      "step": 11229
    },
    {
      "epoch": 43.52713178294574,
      "grad_norm": 0.0007246224558912218,
      "learning_rate": 6.472868217054263e-06,
      "loss": 0.0001,
      "step": 11230
    },
    {
      "epoch": 43.531007751937985,
      "grad_norm": 0.0007470079581253231,
      "learning_rate": 6.468992248062016e-06,
      "loss": 0.0001,
      "step": 11231
    },
    {
      "epoch": 43.53488372093023,
      "grad_norm": 0.000715780071914196,
      "learning_rate": 6.465116279069767e-06,
      "loss": 0.0001,
      "step": 11232
    },
    {
      "epoch": 43.53875968992248,
      "grad_norm": 0.0009763035923242569,
      "learning_rate": 6.46124031007752e-06,
      "loss": 0.0001,
      "step": 11233
    },
    {
      "epoch": 43.542635658914726,
      "grad_norm": 0.000749595055822283,
      "learning_rate": 6.457364341085272e-06,
      "loss": 0.0001,
      "step": 11234
    },
    {
      "epoch": 43.54651162790697,
      "grad_norm": 0.0009301482350565493,
      "learning_rate": 6.453488372093024e-06,
      "loss": 0.0001,
      "step": 11235
    },
    {
      "epoch": 43.55038759689923,
      "grad_norm": 0.001564070233143866,
      "learning_rate": 6.449612403100776e-06,
      "loss": 0.0001,
      "step": 11236
    },
    {
      "epoch": 43.554263565891475,
      "grad_norm": 0.0008404965046793222,
      "learning_rate": 6.4457364341085276e-06,
      "loss": 0.0001,
      "step": 11237
    },
    {
      "epoch": 43.55813953488372,
      "grad_norm": 0.0006621130160056055,
      "learning_rate": 6.44186046511628e-06,
      "loss": 0.0001,
      "step": 11238
    },
    {
      "epoch": 43.56201550387597,
      "grad_norm": 0.0007262891158461571,
      "learning_rate": 6.4379844961240316e-06,
      "loss": 0.0001,
      "step": 11239
    },
    {
      "epoch": 43.565891472868216,
      "grad_norm": 0.0010933836456388235,
      "learning_rate": 6.434108527131784e-06,
      "loss": 0.0001,
      "step": 11240
    },
    {
      "epoch": 43.56976744186046,
      "grad_norm": 5.987463474273682,
      "learning_rate": 6.430232558139535e-06,
      "loss": 0.0151,
      "step": 11241
    },
    {
      "epoch": 43.57364341085271,
      "grad_norm": 0.0006395233212970197,
      "learning_rate": 6.426356589147286e-06,
      "loss": 0.0001,
      "step": 11242
    },
    {
      "epoch": 43.57751937984496,
      "grad_norm": 0.052252527326345444,
      "learning_rate": 6.422480620155039e-06,
      "loss": 0.0003,
      "step": 11243
    },
    {
      "epoch": 43.58139534883721,
      "grad_norm": 0.0009905569022521377,
      "learning_rate": 6.41860465116279e-06,
      "loss": 0.0001,
      "step": 11244
    },
    {
      "epoch": 43.58527131782946,
      "grad_norm": 0.0008557902765460312,
      "learning_rate": 6.414728682170543e-06,
      "loss": 0.0001,
      "step": 11245
    },
    {
      "epoch": 43.58914728682171,
      "grad_norm": 0.0011113638756796718,
      "learning_rate": 6.410852713178295e-06,
      "loss": 0.0001,
      "step": 11246
    },
    {
      "epoch": 43.593023255813954,
      "grad_norm": 0.0010816158028319478,
      "learning_rate": 6.406976744186047e-06,
      "loss": 0.0001,
      "step": 11247
    },
    {
      "epoch": 43.5968992248062,
      "grad_norm": 0.001074781408533454,
      "learning_rate": 6.403100775193799e-06,
      "loss": 0.0001,
      "step": 11248
    },
    {
      "epoch": 43.60077519379845,
      "grad_norm": 0.0016517878975719213,
      "learning_rate": 6.399224806201551e-06,
      "loss": 0.0001,
      "step": 11249
    },
    {
      "epoch": 43.604651162790695,
      "grad_norm": 0.0006949740345589817,
      "learning_rate": 6.395348837209303e-06,
      "loss": 0.0001,
      "step": 11250
    },
    {
      "epoch": 43.60852713178294,
      "grad_norm": 0.0010153773473575711,
      "learning_rate": 6.391472868217055e-06,
      "loss": 0.0001,
      "step": 11251
    },
    {
      "epoch": 43.6124031007752,
      "grad_norm": 0.001201425795443356,
      "learning_rate": 6.387596899224807e-06,
      "loss": 0.0001,
      "step": 11252
    },
    {
      "epoch": 43.616279069767444,
      "grad_norm": 0.0008182364981621504,
      "learning_rate": 6.383720930232559e-06,
      "loss": 0.0001,
      "step": 11253
    },
    {
      "epoch": 43.62015503875969,
      "grad_norm": 0.0011640232987701893,
      "learning_rate": 6.379844961240311e-06,
      "loss": 0.0001,
      "step": 11254
    },
    {
      "epoch": 43.62403100775194,
      "grad_norm": 0.0009080235613510013,
      "learning_rate": 6.375968992248062e-06,
      "loss": 0.0001,
      "step": 11255
    },
    {
      "epoch": 43.627906976744185,
      "grad_norm": 0.0016343449242413044,
      "learning_rate": 6.372093023255813e-06,
      "loss": 0.0001,
      "step": 11256
    },
    {
      "epoch": 43.63178294573643,
      "grad_norm": 0.0013221504632383585,
      "learning_rate": 6.368217054263566e-06,
      "loss": 0.0001,
      "step": 11257
    },
    {
      "epoch": 43.63565891472868,
      "grad_norm": 0.0024054686073213816,
      "learning_rate": 6.364341085271317e-06,
      "loss": 0.0001,
      "step": 11258
    },
    {
      "epoch": 43.63953488372093,
      "grad_norm": 0.001860491232946515,
      "learning_rate": 6.36046511627907e-06,
      "loss": 0.0002,
      "step": 11259
    },
    {
      "epoch": 43.64341085271318,
      "grad_norm": 0.0011377709452062845,
      "learning_rate": 6.356589147286822e-06,
      "loss": 0.0001,
      "step": 11260
    },
    {
      "epoch": 43.64728682170543,
      "grad_norm": 0.000747459358535707,
      "learning_rate": 6.352713178294574e-06,
      "loss": 0.0001,
      "step": 11261
    },
    {
      "epoch": 43.651162790697676,
      "grad_norm": 0.0008145852480083704,
      "learning_rate": 6.348837209302326e-06,
      "loss": 0.0001,
      "step": 11262
    },
    {
      "epoch": 43.65503875968992,
      "grad_norm": 0.0008187637431547046,
      "learning_rate": 6.344961240310078e-06,
      "loss": 0.0001,
      "step": 11263
    },
    {
      "epoch": 43.65891472868217,
      "grad_norm": 3.57854962348938,
      "learning_rate": 6.34108527131783e-06,
      "loss": 0.3599,
      "step": 11264
    },
    {
      "epoch": 43.66279069767442,
      "grad_norm": 0.0008383046369999647,
      "learning_rate": 6.337209302325582e-06,
      "loss": 0.0001,
      "step": 11265
    },
    {
      "epoch": 43.666666666666664,
      "grad_norm": 0.0010293842060491443,
      "learning_rate": 6.333333333333334e-06,
      "loss": 0.0001,
      "step": 11266
    },
    {
      "epoch": 43.67054263565891,
      "grad_norm": 0.0035332238767296076,
      "learning_rate": 6.329457364341086e-06,
      "loss": 0.0002,
      "step": 11267
    },
    {
      "epoch": 43.674418604651166,
      "grad_norm": 0.0016653824131935835,
      "learning_rate": 6.3255813953488365e-06,
      "loss": 0.0002,
      "step": 11268
    },
    {
      "epoch": 43.67829457364341,
      "grad_norm": 0.001336249290034175,
      "learning_rate": 6.321705426356589e-06,
      "loss": 0.0001,
      "step": 11269
    },
    {
      "epoch": 43.68217054263566,
      "grad_norm": 0.000811565900221467,
      "learning_rate": 6.3178294573643405e-06,
      "loss": 0.0001,
      "step": 11270
    },
    {
      "epoch": 43.68604651162791,
      "grad_norm": 0.001039952039718628,
      "learning_rate": 6.313953488372093e-06,
      "loss": 0.0001,
      "step": 11271
    },
    {
      "epoch": 43.689922480620154,
      "grad_norm": 0.0007606602157466114,
      "learning_rate": 6.310077519379845e-06,
      "loss": 0.0001,
      "step": 11272
    },
    {
      "epoch": 43.6937984496124,
      "grad_norm": 0.001998692750930786,
      "learning_rate": 6.306201550387597e-06,
      "loss": 0.0001,
      "step": 11273
    },
    {
      "epoch": 43.69767441860465,
      "grad_norm": 0.053519852459430695,
      "learning_rate": 6.302325581395349e-06,
      "loss": 0.0011,
      "step": 11274
    },
    {
      "epoch": 43.701550387596896,
      "grad_norm": 0.0010767942294478416,
      "learning_rate": 6.298449612403101e-06,
      "loss": 0.0001,
      "step": 11275
    },
    {
      "epoch": 43.70542635658915,
      "grad_norm": 0.001289794105105102,
      "learning_rate": 6.294573643410853e-06,
      "loss": 0.0001,
      "step": 11276
    },
    {
      "epoch": 43.7093023255814,
      "grad_norm": 0.0008566745091229677,
      "learning_rate": 6.290697674418605e-06,
      "loss": 0.0001,
      "step": 11277
    },
    {
      "epoch": 43.713178294573645,
      "grad_norm": 0.0007672057254239917,
      "learning_rate": 6.286821705426357e-06,
      "loss": 0.0001,
      "step": 11278
    },
    {
      "epoch": 43.71705426356589,
      "grad_norm": 0.0018953474937006831,
      "learning_rate": 6.282945736434109e-06,
      "loss": 0.0001,
      "step": 11279
    },
    {
      "epoch": 43.72093023255814,
      "grad_norm": 0.0008905887370929122,
      "learning_rate": 6.279069767441861e-06,
      "loss": 0.0001,
      "step": 11280
    },
    {
      "epoch": 43.724806201550386,
      "grad_norm": 0.0018655398162081838,
      "learning_rate": 6.275193798449612e-06,
      "loss": 0.0002,
      "step": 11281
    },
    {
      "epoch": 43.72868217054263,
      "grad_norm": 0.8548767566680908,
      "learning_rate": 6.271317829457364e-06,
      "loss": 0.0667,
      "step": 11282
    },
    {
      "epoch": 43.73255813953488,
      "grad_norm": 0.0027922673616558313,
      "learning_rate": 6.267441860465116e-06,
      "loss": 0.0002,
      "step": 11283
    },
    {
      "epoch": 43.736434108527135,
      "grad_norm": 0.0012485792394727468,
      "learning_rate": 6.2635658914728685e-06,
      "loss": 0.0001,
      "step": 11284
    },
    {
      "epoch": 43.74031007751938,
      "grad_norm": 0.0010936919134110212,
      "learning_rate": 6.25968992248062e-06,
      "loss": 0.0001,
      "step": 11285
    },
    {
      "epoch": 43.74418604651163,
      "grad_norm": 0.0016860202886164188,
      "learning_rate": 6.2558139534883725e-06,
      "loss": 0.0002,
      "step": 11286
    },
    {
      "epoch": 43.748062015503876,
      "grad_norm": 0.004729743115603924,
      "learning_rate": 6.251937984496124e-06,
      "loss": 0.0001,
      "step": 11287
    },
    {
      "epoch": 43.751937984496124,
      "grad_norm": 0.001149267191067338,
      "learning_rate": 6.2480620155038765e-06,
      "loss": 0.0001,
      "step": 11288
    },
    {
      "epoch": 43.75581395348837,
      "grad_norm": 0.0008857937064021826,
      "learning_rate": 6.244186046511628e-06,
      "loss": 0.0001,
      "step": 11289
    },
    {
      "epoch": 43.75968992248062,
      "grad_norm": 0.0007381996838375926,
      "learning_rate": 6.2403100775193805e-06,
      "loss": 0.0001,
      "step": 11290
    },
    {
      "epoch": 43.763565891472865,
      "grad_norm": 0.0008173374808393419,
      "learning_rate": 6.236434108527132e-06,
      "loss": 0.0001,
      "step": 11291
    },
    {
      "epoch": 43.76744186046512,
      "grad_norm": 0.002403568709269166,
      "learning_rate": 6.232558139534884e-06,
      "loss": 0.0002,
      "step": 11292
    },
    {
      "epoch": 43.77131782945737,
      "grad_norm": 0.0020977759268134832,
      "learning_rate": 6.228682170542636e-06,
      "loss": 0.0002,
      "step": 11293
    },
    {
      "epoch": 43.775193798449614,
      "grad_norm": 0.0015618880279362202,
      "learning_rate": 6.224806201550388e-06,
      "loss": 0.0001,
      "step": 11294
    },
    {
      "epoch": 43.77906976744186,
      "grad_norm": 0.0013870266266167164,
      "learning_rate": 6.22093023255814e-06,
      "loss": 0.0001,
      "step": 11295
    },
    {
      "epoch": 43.78294573643411,
      "grad_norm": 0.10343703627586365,
      "learning_rate": 6.217054263565892e-06,
      "loss": 0.0033,
      "step": 11296
    },
    {
      "epoch": 43.786821705426355,
      "grad_norm": 0.0009800620609894395,
      "learning_rate": 6.213178294573644e-06,
      "loss": 0.0001,
      "step": 11297
    },
    {
      "epoch": 43.7906976744186,
      "grad_norm": 0.0006853570230305195,
      "learning_rate": 6.209302325581396e-06,
      "loss": 0.0001,
      "step": 11298
    },
    {
      "epoch": 43.79457364341085,
      "grad_norm": 0.0013073690934106708,
      "learning_rate": 6.205426356589147e-06,
      "loss": 0.0001,
      "step": 11299
    },
    {
      "epoch": 43.798449612403104,
      "grad_norm": 0.060056738555431366,
      "learning_rate": 6.2015503875969e-06,
      "loss": 0.0002,
      "step": 11300
    },
    {
      "epoch": 43.80232558139535,
      "grad_norm": 0.0008532252977602184,
      "learning_rate": 6.197674418604651e-06,
      "loss": 0.0001,
      "step": 11301
    },
    {
      "epoch": 43.8062015503876,
      "grad_norm": 0.0007184252608567476,
      "learning_rate": 6.193798449612404e-06,
      "loss": 0.0001,
      "step": 11302
    },
    {
      "epoch": 43.810077519379846,
      "grad_norm": 0.47787630558013916,
      "learning_rate": 6.189922480620155e-06,
      "loss": 0.0202,
      "step": 11303
    },
    {
      "epoch": 43.81395348837209,
      "grad_norm": 0.001300176721997559,
      "learning_rate": 6.186046511627908e-06,
      "loss": 0.0001,
      "step": 11304
    },
    {
      "epoch": 43.81782945736434,
      "grad_norm": 0.0008741616038605571,
      "learning_rate": 6.182170542635659e-06,
      "loss": 0.0001,
      "step": 11305
    },
    {
      "epoch": 43.82170542635659,
      "grad_norm": 0.0010704492451623082,
      "learning_rate": 6.178294573643411e-06,
      "loss": 0.0001,
      "step": 11306
    },
    {
      "epoch": 43.825581395348834,
      "grad_norm": 0.001080864924006164,
      "learning_rate": 6.174418604651163e-06,
      "loss": 0.0001,
      "step": 11307
    },
    {
      "epoch": 43.82945736434109,
      "grad_norm": 0.0017866498092189431,
      "learning_rate": 6.170542635658915e-06,
      "loss": 0.0001,
      "step": 11308
    },
    {
      "epoch": 43.833333333333336,
      "grad_norm": 0.0007904454250819981,
      "learning_rate": 6.166666666666667e-06,
      "loss": 0.0001,
      "step": 11309
    },
    {
      "epoch": 43.83720930232558,
      "grad_norm": 0.0007853104616515338,
      "learning_rate": 6.162790697674419e-06,
      "loss": 0.0001,
      "step": 11310
    },
    {
      "epoch": 43.84108527131783,
      "grad_norm": 0.14627870917320251,
      "learning_rate": 6.15891472868217e-06,
      "loss": 0.006,
      "step": 11311
    },
    {
      "epoch": 43.84496124031008,
      "grad_norm": 0.0010695888195186853,
      "learning_rate": 6.155038759689923e-06,
      "loss": 0.0001,
      "step": 11312
    },
    {
      "epoch": 43.848837209302324,
      "grad_norm": 0.00562911294400692,
      "learning_rate": 6.151162790697674e-06,
      "loss": 0.0002,
      "step": 11313
    },
    {
      "epoch": 43.85271317829457,
      "grad_norm": 0.0006546467775478959,
      "learning_rate": 6.147286821705427e-06,
      "loss": 0.0001,
      "step": 11314
    },
    {
      "epoch": 43.85658914728682,
      "grad_norm": 0.0006897342391312122,
      "learning_rate": 6.143410852713178e-06,
      "loss": 0.0001,
      "step": 11315
    },
    {
      "epoch": 43.86046511627907,
      "grad_norm": 0.0007414357387460768,
      "learning_rate": 6.139534883720931e-06,
      "loss": 0.0001,
      "step": 11316
    },
    {
      "epoch": 43.86434108527132,
      "grad_norm": 0.001130625489167869,
      "learning_rate": 6.135658914728683e-06,
      "loss": 0.0001,
      "step": 11317
    },
    {
      "epoch": 43.86821705426357,
      "grad_norm": 26.39736557006836,
      "learning_rate": 6.131782945736434e-06,
      "loss": 0.0254,
      "step": 11318
    },
    {
      "epoch": 43.872093023255815,
      "grad_norm": 0.45581403374671936,
      "learning_rate": 6.127906976744186e-06,
      "loss": 0.0182,
      "step": 11319
    },
    {
      "epoch": 43.87596899224806,
      "grad_norm": 0.5582306385040283,
      "learning_rate": 6.124031007751938e-06,
      "loss": 0.0256,
      "step": 11320
    },
    {
      "epoch": 43.87984496124031,
      "grad_norm": 0.00081225874600932,
      "learning_rate": 6.12015503875969e-06,
      "loss": 0.0001,
      "step": 11321
    },
    {
      "epoch": 43.883720930232556,
      "grad_norm": 0.0012863896554335952,
      "learning_rate": 6.116279069767442e-06,
      "loss": 0.0001,
      "step": 11322
    },
    {
      "epoch": 43.8875968992248,
      "grad_norm": 0.0020646650809794664,
      "learning_rate": 6.112403100775194e-06,
      "loss": 0.0002,
      "step": 11323
    },
    {
      "epoch": 43.89147286821706,
      "grad_norm": 0.0007858783937990665,
      "learning_rate": 6.108527131782947e-06,
      "loss": 0.0001,
      "step": 11324
    },
    {
      "epoch": 43.895348837209305,
      "grad_norm": 0.0009189737611450255,
      "learning_rate": 6.1046511627906975e-06,
      "loss": 0.0001,
      "step": 11325
    },
    {
      "epoch": 43.89922480620155,
      "grad_norm": 0.0009515492129139602,
      "learning_rate": 6.10077519379845e-06,
      "loss": 0.0001,
      "step": 11326
    },
    {
      "epoch": 43.9031007751938,
      "grad_norm": 0.0017503902781754732,
      "learning_rate": 6.0968992248062015e-06,
      "loss": 0.0001,
      "step": 11327
    },
    {
      "epoch": 43.906976744186046,
      "grad_norm": 0.0008541702991351485,
      "learning_rate": 6.093023255813954e-06,
      "loss": 0.0001,
      "step": 11328
    },
    {
      "epoch": 43.91085271317829,
      "grad_norm": 0.001212956034578383,
      "learning_rate": 6.0891472868217055e-06,
      "loss": 0.0001,
      "step": 11329
    },
    {
      "epoch": 43.91472868217054,
      "grad_norm": 0.0007513497839681804,
      "learning_rate": 6.085271317829458e-06,
      "loss": 0.0001,
      "step": 11330
    },
    {
      "epoch": 43.91860465116279,
      "grad_norm": 0.001475834520533681,
      "learning_rate": 6.0813953488372095e-06,
      "loss": 0.0001,
      "step": 11331
    },
    {
      "epoch": 43.92248062015504,
      "grad_norm": 0.0014039685484021902,
      "learning_rate": 6.077519379844961e-06,
      "loss": 0.0001,
      "step": 11332
    },
    {
      "epoch": 43.92635658914729,
      "grad_norm": 0.05375043675303459,
      "learning_rate": 6.0736434108527135e-06,
      "loss": 0.0017,
      "step": 11333
    },
    {
      "epoch": 43.93023255813954,
      "grad_norm": 0.0007144729606807232,
      "learning_rate": 6.069767441860465e-06,
      "loss": 0.0001,
      "step": 11334
    },
    {
      "epoch": 43.934108527131784,
      "grad_norm": 4.834964752197266,
      "learning_rate": 6.0658914728682175e-06,
      "loss": 0.6562,
      "step": 11335
    },
    {
      "epoch": 43.93798449612403,
      "grad_norm": 0.0036227607633918524,
      "learning_rate": 6.06201550387597e-06,
      "loss": 0.0003,
      "step": 11336
    },
    {
      "epoch": 43.94186046511628,
      "grad_norm": 0.0011682072654366493,
      "learning_rate": 6.0581395348837215e-06,
      "loss": 0.0001,
      "step": 11337
    },
    {
      "epoch": 43.945736434108525,
      "grad_norm": 0.003602360375225544,
      "learning_rate": 6.054263565891473e-06,
      "loss": 0.0002,
      "step": 11338
    },
    {
      "epoch": 43.94961240310077,
      "grad_norm": 0.001294473884627223,
      "learning_rate": 6.050387596899225e-06,
      "loss": 0.0001,
      "step": 11339
    },
    {
      "epoch": 43.95348837209303,
      "grad_norm": 0.0010481210192665458,
      "learning_rate": 6.046511627906977e-06,
      "loss": 0.0001,
      "step": 11340
    },
    {
      "epoch": 43.957364341085274,
      "grad_norm": 0.0010998555226251483,
      "learning_rate": 6.042635658914729e-06,
      "loss": 0.0001,
      "step": 11341
    },
    {
      "epoch": 43.96124031007752,
      "grad_norm": 0.0022397791035473347,
      "learning_rate": 6.038759689922481e-06,
      "loss": 0.0002,
      "step": 11342
    },
    {
      "epoch": 43.96511627906977,
      "grad_norm": 0.0008589226054027677,
      "learning_rate": 6.0348837209302334e-06,
      "loss": 0.0001,
      "step": 11343
    },
    {
      "epoch": 43.968992248062015,
      "grad_norm": 0.0006201195647008717,
      "learning_rate": 6.031007751937985e-06,
      "loss": 0.0001,
      "step": 11344
    },
    {
      "epoch": 43.97286821705426,
      "grad_norm": 0.0007794555858708918,
      "learning_rate": 6.027131782945737e-06,
      "loss": 0.0001,
      "step": 11345
    },
    {
      "epoch": 43.97674418604651,
      "grad_norm": 0.0009532251860946417,
      "learning_rate": 6.023255813953488e-06,
      "loss": 0.0001,
      "step": 11346
    },
    {
      "epoch": 43.98062015503876,
      "grad_norm": 0.0006143918144516647,
      "learning_rate": 6.019379844961241e-06,
      "loss": 0.0001,
      "step": 11347
    },
    {
      "epoch": 43.98449612403101,
      "grad_norm": 0.0007952331798151135,
      "learning_rate": 6.015503875968993e-06,
      "loss": 0.0001,
      "step": 11348
    },
    {
      "epoch": 43.98837209302326,
      "grad_norm": 0.0018280375516042113,
      "learning_rate": 6.011627906976745e-06,
      "loss": 0.0002,
      "step": 11349
    },
    {
      "epoch": 43.992248062015506,
      "grad_norm": 0.0009004320600070059,
      "learning_rate": 6.007751937984497e-06,
      "loss": 0.0001,
      "step": 11350
    },
    {
      "epoch": 43.99612403100775,
      "grad_norm": 0.0027965500485152006,
      "learning_rate": 6.003875968992248e-06,
      "loss": 0.0002,
      "step": 11351
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.00075502012623474,
      "learning_rate": 6e-06,
      "loss": 0.0001,
      "step": 11352
    },
    {
      "epoch": 44.00387596899225,
      "grad_norm": 0.0033212981652468443,
      "learning_rate": 5.996124031007752e-06,
      "loss": 0.0002,
      "step": 11353
    },
    {
      "epoch": 44.007751937984494,
      "grad_norm": 0.0007731900550425053,
      "learning_rate": 5.992248062015504e-06,
      "loss": 0.0001,
      "step": 11354
    },
    {
      "epoch": 44.01162790697674,
      "grad_norm": 2.1840174198150635,
      "learning_rate": 5.9883720930232566e-06,
      "loss": 0.211,
      "step": 11355
    },
    {
      "epoch": 44.01550387596899,
      "grad_norm": 0.0019270689226686954,
      "learning_rate": 5.984496124031008e-06,
      "loss": 0.0002,
      "step": 11356
    },
    {
      "epoch": 44.01937984496124,
      "grad_norm": 0.014143033884465694,
      "learning_rate": 5.9806201550387606e-06,
      "loss": 0.0003,
      "step": 11357
    },
    {
      "epoch": 44.02325581395349,
      "grad_norm": 0.0006677031051367521,
      "learning_rate": 5.976744186046511e-06,
      "loss": 0.0001,
      "step": 11358
    },
    {
      "epoch": 44.02713178294574,
      "grad_norm": 0.0009369179024361074,
      "learning_rate": 5.972868217054264e-06,
      "loss": 0.0001,
      "step": 11359
    },
    {
      "epoch": 44.031007751937985,
      "grad_norm": 0.0007530281436629593,
      "learning_rate": 5.968992248062015e-06,
      "loss": 0.0001,
      "step": 11360
    },
    {
      "epoch": 44.03488372093023,
      "grad_norm": 0.0007120780064724386,
      "learning_rate": 5.965116279069768e-06,
      "loss": 0.0001,
      "step": 11361
    },
    {
      "epoch": 44.03875968992248,
      "grad_norm": 0.001289062318392098,
      "learning_rate": 5.96124031007752e-06,
      "loss": 0.0001,
      "step": 11362
    },
    {
      "epoch": 44.042635658914726,
      "grad_norm": 0.0015656660543754697,
      "learning_rate": 5.957364341085272e-06,
      "loss": 0.0001,
      "step": 11363
    },
    {
      "epoch": 44.04651162790697,
      "grad_norm": 0.0014665719354525208,
      "learning_rate": 5.953488372093024e-06,
      "loss": 0.0001,
      "step": 11364
    },
    {
      "epoch": 44.05038759689923,
      "grad_norm": 0.0009065804770216346,
      "learning_rate": 5.949612403100775e-06,
      "loss": 0.0001,
      "step": 11365
    },
    {
      "epoch": 44.054263565891475,
      "grad_norm": 0.002316361526027322,
      "learning_rate": 5.945736434108527e-06,
      "loss": 0.0002,
      "step": 11366
    },
    {
      "epoch": 44.05813953488372,
      "grad_norm": 0.28460246324539185,
      "learning_rate": 5.94186046511628e-06,
      "loss": 0.0114,
      "step": 11367
    },
    {
      "epoch": 44.06201550387597,
      "grad_norm": 0.0013434425927698612,
      "learning_rate": 5.937984496124031e-06,
      "loss": 0.0001,
      "step": 11368
    },
    {
      "epoch": 44.065891472868216,
      "grad_norm": 0.0007839986938051879,
      "learning_rate": 5.934108527131784e-06,
      "loss": 0.0001,
      "step": 11369
    },
    {
      "epoch": 44.06976744186046,
      "grad_norm": 0.0038325549103319645,
      "learning_rate": 5.930232558139535e-06,
      "loss": 0.0002,
      "step": 11370
    },
    {
      "epoch": 44.07364341085271,
      "grad_norm": 0.012281721457839012,
      "learning_rate": 5.926356589147287e-06,
      "loss": 0.0001,
      "step": 11371
    },
    {
      "epoch": 44.07751937984496,
      "grad_norm": 0.0006728674052283168,
      "learning_rate": 5.922480620155038e-06,
      "loss": 0.0001,
      "step": 11372
    },
    {
      "epoch": 44.08139534883721,
      "grad_norm": 0.0009756828076206148,
      "learning_rate": 5.918604651162791e-06,
      "loss": 0.0001,
      "step": 11373
    },
    {
      "epoch": 44.08527131782946,
      "grad_norm": 0.0011040209792554379,
      "learning_rate": 5.914728682170543e-06,
      "loss": 0.0001,
      "step": 11374
    },
    {
      "epoch": 44.08914728682171,
      "grad_norm": 0.0006908515933901072,
      "learning_rate": 5.910852713178295e-06,
      "loss": 0.0001,
      "step": 11375
    },
    {
      "epoch": 44.093023255813954,
      "grad_norm": 0.0012770043686032295,
      "learning_rate": 5.906976744186047e-06,
      "loss": 0.0001,
      "step": 11376
    },
    {
      "epoch": 44.0968992248062,
      "grad_norm": 1.665314793586731,
      "learning_rate": 5.903100775193799e-06,
      "loss": 0.1683,
      "step": 11377
    },
    {
      "epoch": 44.10077519379845,
      "grad_norm": 0.0008019913220778108,
      "learning_rate": 5.89922480620155e-06,
      "loss": 0.0001,
      "step": 11378
    },
    {
      "epoch": 44.104651162790695,
      "grad_norm": 0.001106649055145681,
      "learning_rate": 5.895348837209303e-06,
      "loss": 0.0001,
      "step": 11379
    },
    {
      "epoch": 44.10852713178294,
      "grad_norm": 0.0007320083677768707,
      "learning_rate": 5.891472868217054e-06,
      "loss": 0.0001,
      "step": 11380
    },
    {
      "epoch": 44.1124031007752,
      "grad_norm": 0.0007013154681771994,
      "learning_rate": 5.887596899224807e-06,
      "loss": 0.0001,
      "step": 11381
    },
    {
      "epoch": 44.116279069767444,
      "grad_norm": 0.0009713483159430325,
      "learning_rate": 5.883720930232558e-06,
      "loss": 0.0001,
      "step": 11382
    },
    {
      "epoch": 44.12015503875969,
      "grad_norm": 0.001380943227559328,
      "learning_rate": 5.879844961240311e-06,
      "loss": 0.0001,
      "step": 11383
    },
    {
      "epoch": 44.12403100775194,
      "grad_norm": 0.000785737473051995,
      "learning_rate": 5.875968992248062e-06,
      "loss": 0.0001,
      "step": 11384
    },
    {
      "epoch": 44.127906976744185,
      "grad_norm": 0.0006639374187216163,
      "learning_rate": 5.872093023255814e-06,
      "loss": 0.0001,
      "step": 11385
    },
    {
      "epoch": 44.13178294573643,
      "grad_norm": 0.0008320776396431029,
      "learning_rate": 5.868217054263566e-06,
      "loss": 0.0001,
      "step": 11386
    },
    {
      "epoch": 44.13565891472868,
      "grad_norm": 0.0007986780256032944,
      "learning_rate": 5.864341085271318e-06,
      "loss": 0.0001,
      "step": 11387
    },
    {
      "epoch": 44.13953488372093,
      "grad_norm": 0.0008003986440598965,
      "learning_rate": 5.86046511627907e-06,
      "loss": 0.0001,
      "step": 11388
    },
    {
      "epoch": 44.14341085271318,
      "grad_norm": 0.0008860343368723989,
      "learning_rate": 5.856589147286822e-06,
      "loss": 0.0001,
      "step": 11389
    },
    {
      "epoch": 44.14728682170543,
      "grad_norm": 0.001089027151465416,
      "learning_rate": 5.852713178294574e-06,
      "loss": 0.0001,
      "step": 11390
    },
    {
      "epoch": 44.151162790697676,
      "grad_norm": 0.0007657495443709195,
      "learning_rate": 5.848837209302326e-06,
      "loss": 0.0001,
      "step": 11391
    },
    {
      "epoch": 44.15503875968992,
      "grad_norm": 0.0014230933738872409,
      "learning_rate": 5.8449612403100775e-06,
      "loss": 0.0001,
      "step": 11392
    },
    {
      "epoch": 44.15891472868217,
      "grad_norm": 0.0013384344056248665,
      "learning_rate": 5.84108527131783e-06,
      "loss": 0.0001,
      "step": 11393
    },
    {
      "epoch": 44.16279069767442,
      "grad_norm": 0.0014703894266858697,
      "learning_rate": 5.8372093023255815e-06,
      "loss": 0.0001,
      "step": 11394
    },
    {
      "epoch": 44.166666666666664,
      "grad_norm": 0.0013696512905880809,
      "learning_rate": 5.833333333333334e-06,
      "loss": 0.0001,
      "step": 11395
    },
    {
      "epoch": 44.17054263565891,
      "grad_norm": 0.4986346364021301,
      "learning_rate": 5.8294573643410855e-06,
      "loss": 0.0284,
      "step": 11396
    },
    {
      "epoch": 44.174418604651166,
      "grad_norm": 0.005625053774565458,
      "learning_rate": 5.825581395348838e-06,
      "loss": 0.0002,
      "step": 11397
    },
    {
      "epoch": 44.17829457364341,
      "grad_norm": 0.0007436155574396253,
      "learning_rate": 5.8217054263565895e-06,
      "loss": 0.0001,
      "step": 11398
    },
    {
      "epoch": 44.18217054263566,
      "grad_norm": 0.0008855600608512759,
      "learning_rate": 5.817829457364341e-06,
      "loss": 0.0001,
      "step": 11399
    },
    {
      "epoch": 44.18604651162791,
      "grad_norm": 0.0007509218994528055,
      "learning_rate": 5.8139534883720935e-06,
      "loss": 0.0001,
      "step": 11400
    },
    {
      "epoch": 44.189922480620154,
      "grad_norm": 0.0023181044962257147,
      "learning_rate": 5.810077519379845e-06,
      "loss": 0.0002,
      "step": 11401
    },
    {
      "epoch": 44.1937984496124,
      "grad_norm": 0.002791601698845625,
      "learning_rate": 5.8062015503875975e-06,
      "loss": 0.0002,
      "step": 11402
    },
    {
      "epoch": 44.19767441860465,
      "grad_norm": 0.0008133300580084324,
      "learning_rate": 5.802325581395349e-06,
      "loss": 0.0001,
      "step": 11403
    },
    {
      "epoch": 44.201550387596896,
      "grad_norm": 0.0009988433448597789,
      "learning_rate": 5.7984496124031015e-06,
      "loss": 0.0001,
      "step": 11404
    },
    {
      "epoch": 44.20542635658915,
      "grad_norm": 0.000686267449054867,
      "learning_rate": 5.794573643410853e-06,
      "loss": 0.0001,
      "step": 11405
    },
    {
      "epoch": 44.2093023255814,
      "grad_norm": 0.0017042908584699035,
      "learning_rate": 5.790697674418605e-06,
      "loss": 0.0001,
      "step": 11406
    },
    {
      "epoch": 44.213178294573645,
      "grad_norm": 0.0006856539403088391,
      "learning_rate": 5.786821705426357e-06,
      "loss": 0.0001,
      "step": 11407
    },
    {
      "epoch": 44.21705426356589,
      "grad_norm": 0.0008585899486206472,
      "learning_rate": 5.782945736434109e-06,
      "loss": 0.0001,
      "step": 11408
    },
    {
      "epoch": 44.22093023255814,
      "grad_norm": 0.0006338683888316154,
      "learning_rate": 5.779069767441861e-06,
      "loss": 0.0001,
      "step": 11409
    },
    {
      "epoch": 44.224806201550386,
      "grad_norm": 0.0007137537468224764,
      "learning_rate": 5.775193798449613e-06,
      "loss": 0.0001,
      "step": 11410
    },
    {
      "epoch": 44.22868217054263,
      "grad_norm": 0.0008875326602719724,
      "learning_rate": 5.771317829457364e-06,
      "loss": 0.0001,
      "step": 11411
    },
    {
      "epoch": 44.23255813953488,
      "grad_norm": 0.0009283560793846846,
      "learning_rate": 5.767441860465117e-06,
      "loss": 0.0001,
      "step": 11412
    },
    {
      "epoch": 44.236434108527135,
      "grad_norm": 0.0009554395801387727,
      "learning_rate": 5.763565891472868e-06,
      "loss": 0.0001,
      "step": 11413
    },
    {
      "epoch": 44.24031007751938,
      "grad_norm": 0.0006788133759982884,
      "learning_rate": 5.759689922480621e-06,
      "loss": 0.0001,
      "step": 11414
    },
    {
      "epoch": 44.24418604651163,
      "grad_norm": 0.0006954691489227116,
      "learning_rate": 5.755813953488372e-06,
      "loss": 0.0001,
      "step": 11415
    },
    {
      "epoch": 44.248062015503876,
      "grad_norm": 0.0008902708650566638,
      "learning_rate": 5.751937984496125e-06,
      "loss": 0.0001,
      "step": 11416
    },
    {
      "epoch": 44.251937984496124,
      "grad_norm": 0.0007298474665731192,
      "learning_rate": 5.748062015503876e-06,
      "loss": 0.0001,
      "step": 11417
    },
    {
      "epoch": 44.25581395348837,
      "grad_norm": 0.001309197978116572,
      "learning_rate": 5.744186046511628e-06,
      "loss": 0.0001,
      "step": 11418
    },
    {
      "epoch": 44.25968992248062,
      "grad_norm": 0.0010370234958827496,
      "learning_rate": 5.74031007751938e-06,
      "loss": 0.0001,
      "step": 11419
    },
    {
      "epoch": 44.263565891472865,
      "grad_norm": 0.41717106103897095,
      "learning_rate": 5.736434108527132e-06,
      "loss": 0.0171,
      "step": 11420
    },
    {
      "epoch": 44.26744186046512,
      "grad_norm": 0.0007638923125341535,
      "learning_rate": 5.732558139534884e-06,
      "loss": 0.0001,
      "step": 11421
    },
    {
      "epoch": 44.27131782945737,
      "grad_norm": 0.0008750988636165857,
      "learning_rate": 5.728682170542636e-06,
      "loss": 0.0001,
      "step": 11422
    },
    {
      "epoch": 44.275193798449614,
      "grad_norm": 0.0012869122438132763,
      "learning_rate": 5.724806201550388e-06,
      "loss": 0.0001,
      "step": 11423
    },
    {
      "epoch": 44.27906976744186,
      "grad_norm": 0.0007714892271906137,
      "learning_rate": 5.72093023255814e-06,
      "loss": 0.0001,
      "step": 11424
    },
    {
      "epoch": 44.28294573643411,
      "grad_norm": 0.0013689612969756126,
      "learning_rate": 5.717054263565891e-06,
      "loss": 0.0001,
      "step": 11425
    },
    {
      "epoch": 44.286821705426355,
      "grad_norm": 0.001900809002108872,
      "learning_rate": 5.713178294573644e-06,
      "loss": 0.0001,
      "step": 11426
    },
    {
      "epoch": 44.2906976744186,
      "grad_norm": 0.000921902246773243,
      "learning_rate": 5.709302325581395e-06,
      "loss": 0.0001,
      "step": 11427
    },
    {
      "epoch": 44.29457364341085,
      "grad_norm": 0.0007238848484121263,
      "learning_rate": 5.705426356589148e-06,
      "loss": 0.0001,
      "step": 11428
    },
    {
      "epoch": 44.298449612403104,
      "grad_norm": 0.0009273720788769424,
      "learning_rate": 5.701550387596899e-06,
      "loss": 0.0001,
      "step": 11429
    },
    {
      "epoch": 44.30232558139535,
      "grad_norm": 0.0010930816642940044,
      "learning_rate": 5.697674418604652e-06,
      "loss": 0.0001,
      "step": 11430
    },
    {
      "epoch": 44.3062015503876,
      "grad_norm": 0.0008878459921106696,
      "learning_rate": 5.693798449612403e-06,
      "loss": 0.0001,
      "step": 11431
    },
    {
      "epoch": 44.310077519379846,
      "grad_norm": 0.27301326394081116,
      "learning_rate": 5.689922480620155e-06,
      "loss": 0.0109,
      "step": 11432
    },
    {
      "epoch": 44.31395348837209,
      "grad_norm": 0.0006077899597585201,
      "learning_rate": 5.686046511627907e-06,
      "loss": 0.0001,
      "step": 11433
    },
    {
      "epoch": 44.31782945736434,
      "grad_norm": 0.0006931526586413383,
      "learning_rate": 5.682170542635659e-06,
      "loss": 0.0001,
      "step": 11434
    },
    {
      "epoch": 44.32170542635659,
      "grad_norm": 0.2909509837627411,
      "learning_rate": 5.678294573643411e-06,
      "loss": 0.0117,
      "step": 11435
    },
    {
      "epoch": 44.325581395348834,
      "grad_norm": 0.0007534826290793717,
      "learning_rate": 5.674418604651163e-06,
      "loss": 0.0001,
      "step": 11436
    },
    {
      "epoch": 44.32945736434109,
      "grad_norm": 0.0006826705648563802,
      "learning_rate": 5.670542635658915e-06,
      "loss": 0.0001,
      "step": 11437
    },
    {
      "epoch": 44.333333333333336,
      "grad_norm": 0.0010083464439958334,
      "learning_rate": 5.666666666666667e-06,
      "loss": 0.0001,
      "step": 11438
    },
    {
      "epoch": 44.33720930232558,
      "grad_norm": 0.0008201586315408349,
      "learning_rate": 5.6627906976744185e-06,
      "loss": 0.0001,
      "step": 11439
    },
    {
      "epoch": 44.34108527131783,
      "grad_norm": 0.003980961628258228,
      "learning_rate": 5.658914728682171e-06,
      "loss": 0.0002,
      "step": 11440
    },
    {
      "epoch": 44.34496124031008,
      "grad_norm": 0.0008857977227307856,
      "learning_rate": 5.6550387596899225e-06,
      "loss": 0.0001,
      "step": 11441
    },
    {
      "epoch": 44.348837209302324,
      "grad_norm": 0.0011152318911626935,
      "learning_rate": 5.651162790697675e-06,
      "loss": 0.0001,
      "step": 11442
    },
    {
      "epoch": 44.35271317829457,
      "grad_norm": 0.0014330890262499452,
      "learning_rate": 5.6472868217054265e-06,
      "loss": 0.0001,
      "step": 11443
    },
    {
      "epoch": 44.35658914728682,
      "grad_norm": 0.0006948997615836561,
      "learning_rate": 5.643410852713179e-06,
      "loss": 0.0001,
      "step": 11444
    },
    {
      "epoch": 44.36046511627907,
      "grad_norm": 0.001030476181767881,
      "learning_rate": 5.6395348837209305e-06,
      "loss": 0.0001,
      "step": 11445
    },
    {
      "epoch": 44.36434108527132,
      "grad_norm": 0.0013640625402331352,
      "learning_rate": 5.635658914728682e-06,
      "loss": 0.0001,
      "step": 11446
    },
    {
      "epoch": 44.36821705426357,
      "grad_norm": 0.0012426828034222126,
      "learning_rate": 5.6317829457364345e-06,
      "loss": 0.0001,
      "step": 11447
    },
    {
      "epoch": 44.372093023255815,
      "grad_norm": 0.000786861521191895,
      "learning_rate": 5.627906976744186e-06,
      "loss": 0.0001,
      "step": 11448
    },
    {
      "epoch": 44.37596899224806,
      "grad_norm": 0.0007646171725355089,
      "learning_rate": 5.6240310077519385e-06,
      "loss": 0.0001,
      "step": 11449
    },
    {
      "epoch": 44.37984496124031,
      "grad_norm": 0.0006805572775192559,
      "learning_rate": 5.620155038759691e-06,
      "loss": 0.0001,
      "step": 11450
    },
    {
      "epoch": 44.383720930232556,
      "grad_norm": 0.0019810404628515244,
      "learning_rate": 5.616279069767442e-06,
      "loss": 0.0002,
      "step": 11451
    },
    {
      "epoch": 44.3875968992248,
      "grad_norm": 0.0007526875124312937,
      "learning_rate": 5.612403100775194e-06,
      "loss": 0.0001,
      "step": 11452
    },
    {
      "epoch": 44.39147286821706,
      "grad_norm": 0.27134910225868225,
      "learning_rate": 5.608527131782946e-06,
      "loss": 0.011,
      "step": 11453
    },
    {
      "epoch": 44.395348837209305,
      "grad_norm": 0.0009249867871403694,
      "learning_rate": 5.604651162790698e-06,
      "loss": 0.0001,
      "step": 11454
    },
    {
      "epoch": 44.39922480620155,
      "grad_norm": 0.06091711297631264,
      "learning_rate": 5.60077519379845e-06,
      "loss": 0.0004,
      "step": 11455
    },
    {
      "epoch": 44.4031007751938,
      "grad_norm": 0.002291054232046008,
      "learning_rate": 5.596899224806202e-06,
      "loss": 0.0002,
      "step": 11456
    },
    {
      "epoch": 44.406976744186046,
      "grad_norm": 0.0007526936242356896,
      "learning_rate": 5.5930232558139544e-06,
      "loss": 0.0001,
      "step": 11457
    },
    {
      "epoch": 44.41085271317829,
      "grad_norm": 0.0020472120959311724,
      "learning_rate": 5.589147286821705e-06,
      "loss": 0.0002,
      "step": 11458
    },
    {
      "epoch": 44.41472868217054,
      "grad_norm": 0.0010718726553022861,
      "learning_rate": 5.585271317829458e-06,
      "loss": 0.0001,
      "step": 11459
    },
    {
      "epoch": 44.41860465116279,
      "grad_norm": 0.0006789288017898798,
      "learning_rate": 5.581395348837209e-06,
      "loss": 0.0001,
      "step": 11460
    },
    {
      "epoch": 44.42248062015504,
      "grad_norm": 0.0012288589496165514,
      "learning_rate": 5.577519379844962e-06,
      "loss": 0.0001,
      "step": 11461
    },
    {
      "epoch": 44.42635658914729,
      "grad_norm": 0.0011512304190546274,
      "learning_rate": 5.573643410852713e-06,
      "loss": 0.0001,
      "step": 11462
    },
    {
      "epoch": 44.43023255813954,
      "grad_norm": 5.577001094818115,
      "learning_rate": 5.569767441860466e-06,
      "loss": 0.5575,
      "step": 11463
    },
    {
      "epoch": 44.434108527131784,
      "grad_norm": 0.0008323568617925048,
      "learning_rate": 5.565891472868218e-06,
      "loss": 0.0001,
      "step": 11464
    },
    {
      "epoch": 44.43798449612403,
      "grad_norm": 0.0021996391005814075,
      "learning_rate": 5.562015503875969e-06,
      "loss": 0.0001,
      "step": 11465
    },
    {
      "epoch": 44.44186046511628,
      "grad_norm": 0.0007136045023798943,
      "learning_rate": 5.558139534883721e-06,
      "loss": 0.0001,
      "step": 11466
    },
    {
      "epoch": 44.445736434108525,
      "grad_norm": 0.0014686636859551072,
      "learning_rate": 5.554263565891473e-06,
      "loss": 0.0001,
      "step": 11467
    },
    {
      "epoch": 44.44961240310077,
      "grad_norm": 0.0007633083732798696,
      "learning_rate": 5.550387596899225e-06,
      "loss": 0.0001,
      "step": 11468
    },
    {
      "epoch": 44.45348837209303,
      "grad_norm": 0.0008236435241997242,
      "learning_rate": 5.5465116279069776e-06,
      "loss": 0.0001,
      "step": 11469
    },
    {
      "epoch": 44.457364341085274,
      "grad_norm": 0.0021914641838520765,
      "learning_rate": 5.542635658914729e-06,
      "loss": 0.0001,
      "step": 11470
    },
    {
      "epoch": 44.46124031007752,
      "grad_norm": 0.3011922538280487,
      "learning_rate": 5.538759689922481e-06,
      "loss": 0.0126,
      "step": 11471
    },
    {
      "epoch": 44.46511627906977,
      "grad_norm": 0.42183977365493774,
      "learning_rate": 5.534883720930232e-06,
      "loss": 0.0179,
      "step": 11472
    },
    {
      "epoch": 44.468992248062015,
      "grad_norm": 0.0024856519885361195,
      "learning_rate": 5.531007751937985e-06,
      "loss": 0.0001,
      "step": 11473
    },
    {
      "epoch": 44.47286821705426,
      "grad_norm": 0.04653036221861839,
      "learning_rate": 5.527131782945736e-06,
      "loss": 0.0004,
      "step": 11474
    },
    {
      "epoch": 44.47674418604651,
      "grad_norm": 0.0009843787411227822,
      "learning_rate": 5.523255813953489e-06,
      "loss": 0.0001,
      "step": 11475
    },
    {
      "epoch": 44.48062015503876,
      "grad_norm": 0.003011132590472698,
      "learning_rate": 5.519379844961241e-06,
      "loss": 0.0002,
      "step": 11476
    },
    {
      "epoch": 44.48449612403101,
      "grad_norm": 0.0007237799582071602,
      "learning_rate": 5.515503875968993e-06,
      "loss": 0.0001,
      "step": 11477
    },
    {
      "epoch": 44.48837209302326,
      "grad_norm": 0.0007843221537768841,
      "learning_rate": 5.511627906976744e-06,
      "loss": 0.0001,
      "step": 11478
    },
    {
      "epoch": 44.492248062015506,
      "grad_norm": 0.0014706836082041264,
      "learning_rate": 5.507751937984496e-06,
      "loss": 0.0001,
      "step": 11479
    },
    {
      "epoch": 44.49612403100775,
      "grad_norm": 0.000620971666648984,
      "learning_rate": 5.503875968992248e-06,
      "loss": 0.0001,
      "step": 11480
    },
    {
      "epoch": 44.5,
      "grad_norm": 0.0008227889193221927,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.0001,
      "step": 11481
    },
    {
      "epoch": 44.50387596899225,
      "grad_norm": 0.0007711597136221826,
      "learning_rate": 5.496124031007752e-06,
      "loss": 0.0001,
      "step": 11482
    },
    {
      "epoch": 44.507751937984494,
      "grad_norm": 0.003478679805994034,
      "learning_rate": 5.492248062015505e-06,
      "loss": 0.0001,
      "step": 11483
    },
    {
      "epoch": 44.51162790697674,
      "grad_norm": 0.00294403824955225,
      "learning_rate": 5.488372093023256e-06,
      "loss": 0.0002,
      "step": 11484
    },
    {
      "epoch": 44.51550387596899,
      "grad_norm": 0.0007854178547859192,
      "learning_rate": 5.484496124031008e-06,
      "loss": 0.0001,
      "step": 11485
    },
    {
      "epoch": 44.51937984496124,
      "grad_norm": 0.002324384870007634,
      "learning_rate": 5.4806201550387594e-06,
      "loss": 0.0002,
      "step": 11486
    },
    {
      "epoch": 44.52325581395349,
      "grad_norm": 0.0012017962289974093,
      "learning_rate": 5.476744186046512e-06,
      "loss": 0.0001,
      "step": 11487
    },
    {
      "epoch": 44.52713178294574,
      "grad_norm": 0.0009875184623524547,
      "learning_rate": 5.472868217054264e-06,
      "loss": 0.0001,
      "step": 11488
    },
    {
      "epoch": 44.531007751937985,
      "grad_norm": 0.0008648135117255151,
      "learning_rate": 5.468992248062016e-06,
      "loss": 0.0001,
      "step": 11489
    },
    {
      "epoch": 44.53488372093023,
      "grad_norm": 0.065048947930336,
      "learning_rate": 5.465116279069768e-06,
      "loss": 0.001,
      "step": 11490
    },
    {
      "epoch": 44.53875968992248,
      "grad_norm": 0.6811297535896301,
      "learning_rate": 5.461240310077519e-06,
      "loss": 0.0007,
      "step": 11491
    },
    {
      "epoch": 44.542635658914726,
      "grad_norm": 0.0007989924633875489,
      "learning_rate": 5.457364341085271e-06,
      "loss": 0.0001,
      "step": 11492
    },
    {
      "epoch": 44.54651162790697,
      "grad_norm": 0.0006887726485729218,
      "learning_rate": 5.453488372093023e-06,
      "loss": 0.0001,
      "step": 11493
    },
    {
      "epoch": 44.55038759689923,
      "grad_norm": 0.0017661760793998837,
      "learning_rate": 5.449612403100775e-06,
      "loss": 0.0001,
      "step": 11494
    },
    {
      "epoch": 44.554263565891475,
      "grad_norm": 0.000758722482714802,
      "learning_rate": 5.445736434108528e-06,
      "loss": 0.0001,
      "step": 11495
    },
    {
      "epoch": 44.55813953488372,
      "grad_norm": 0.001199777820147574,
      "learning_rate": 5.441860465116279e-06,
      "loss": 0.0001,
      "step": 11496
    },
    {
      "epoch": 44.56201550387597,
      "grad_norm": 0.001127237337641418,
      "learning_rate": 5.437984496124032e-06,
      "loss": 0.0001,
      "step": 11497
    },
    {
      "epoch": 44.565891472868216,
      "grad_norm": 0.0012541509931907058,
      "learning_rate": 5.4341085271317826e-06,
      "loss": 0.0001,
      "step": 11498
    },
    {
      "epoch": 44.56976744186046,
      "grad_norm": 0.0006865362520329654,
      "learning_rate": 5.430232558139535e-06,
      "loss": 0.0001,
      "step": 11499
    },
    {
      "epoch": 44.57364341085271,
      "grad_norm": 0.0008623306057415903,
      "learning_rate": 5.426356589147287e-06,
      "loss": 0.0001,
      "step": 11500
    },
    {
      "epoch": 44.57751937984496,
      "grad_norm": 0.002084083389490843,
      "learning_rate": 5.422480620155039e-06,
      "loss": 0.0002,
      "step": 11501
    },
    {
      "epoch": 44.58139534883721,
      "grad_norm": 3.7448861598968506,
      "learning_rate": 5.418604651162791e-06,
      "loss": 0.0045,
      "step": 11502
    },
    {
      "epoch": 44.58527131782946,
      "grad_norm": 0.0011023980332538486,
      "learning_rate": 5.414728682170543e-06,
      "loss": 0.0001,
      "step": 11503
    },
    {
      "epoch": 44.58914728682171,
      "grad_norm": 0.0006899722502566874,
      "learning_rate": 5.410852713178295e-06,
      "loss": 0.0001,
      "step": 11504
    },
    {
      "epoch": 44.593023255813954,
      "grad_norm": 0.0007300330325961113,
      "learning_rate": 5.406976744186046e-06,
      "loss": 0.0001,
      "step": 11505
    },
    {
      "epoch": 44.5968992248062,
      "grad_norm": 0.0006505243945866823,
      "learning_rate": 5.4031007751937985e-06,
      "loss": 0.0001,
      "step": 11506
    },
    {
      "epoch": 44.60077519379845,
      "grad_norm": 0.0015162626514211297,
      "learning_rate": 5.399224806201551e-06,
      "loss": 0.0001,
      "step": 11507
    },
    {
      "epoch": 44.604651162790695,
      "grad_norm": 0.0008517201640643179,
      "learning_rate": 5.3953488372093025e-06,
      "loss": 0.0001,
      "step": 11508
    },
    {
      "epoch": 44.60852713178294,
      "grad_norm": 0.0012445759493857622,
      "learning_rate": 5.391472868217055e-06,
      "loss": 0.0001,
      "step": 11509
    },
    {
      "epoch": 44.6124031007752,
      "grad_norm": 0.0007154135382734239,
      "learning_rate": 5.3875968992248065e-06,
      "loss": 0.0001,
      "step": 11510
    },
    {
      "epoch": 44.616279069767444,
      "grad_norm": 0.000787737313657999,
      "learning_rate": 5.383720930232558e-06,
      "loss": 0.0001,
      "step": 11511
    },
    {
      "epoch": 44.62015503875969,
      "grad_norm": 0.0008511810447089374,
      "learning_rate": 5.3798449612403105e-06,
      "loss": 0.0001,
      "step": 11512
    },
    {
      "epoch": 44.62403100775194,
      "grad_norm": 0.0006674012984149158,
      "learning_rate": 5.375968992248062e-06,
      "loss": 0.0001,
      "step": 11513
    },
    {
      "epoch": 44.627906976744185,
      "grad_norm": 5.783082962036133,
      "learning_rate": 5.3720930232558145e-06,
      "loss": 0.7241,
      "step": 11514
    },
    {
      "epoch": 44.63178294573643,
      "grad_norm": 0.0009309665765613317,
      "learning_rate": 5.368217054263566e-06,
      "loss": 0.0001,
      "step": 11515
    },
    {
      "epoch": 44.63565891472868,
      "grad_norm": 0.0023593890946358442,
      "learning_rate": 5.3643410852713185e-06,
      "loss": 0.0001,
      "step": 11516
    },
    {
      "epoch": 44.63953488372093,
      "grad_norm": 0.0009492463432252407,
      "learning_rate": 5.36046511627907e-06,
      "loss": 0.0001,
      "step": 11517
    },
    {
      "epoch": 44.64341085271318,
      "grad_norm": 0.0007427451200783253,
      "learning_rate": 5.356589147286822e-06,
      "loss": 0.0001,
      "step": 11518
    },
    {
      "epoch": 44.64728682170543,
      "grad_norm": 0.0015143407508730888,
      "learning_rate": 5.352713178294574e-06,
      "loss": 0.0001,
      "step": 11519
    },
    {
      "epoch": 44.651162790697676,
      "grad_norm": 0.0007021109922789037,
      "learning_rate": 5.348837209302326e-06,
      "loss": 0.0001,
      "step": 11520
    },
    {
      "epoch": 44.65503875968992,
      "grad_norm": 0.0017217735294252634,
      "learning_rate": 5.344961240310078e-06,
      "loss": 0.0001,
      "step": 11521
    },
    {
      "epoch": 44.65891472868217,
      "grad_norm": 0.0012996741570532322,
      "learning_rate": 5.34108527131783e-06,
      "loss": 0.0001,
      "step": 11522
    },
    {
      "epoch": 44.66279069767442,
      "grad_norm": 0.0007196925580501556,
      "learning_rate": 5.337209302325582e-06,
      "loss": 0.0001,
      "step": 11523
    },
    {
      "epoch": 44.666666666666664,
      "grad_norm": 0.0020402290392667055,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.0002,
      "step": 11524
    },
    {
      "epoch": 44.67054263565891,
      "grad_norm": 0.000763322866987437,
      "learning_rate": 5.329457364341085e-06,
      "loss": 0.0001,
      "step": 11525
    },
    {
      "epoch": 44.674418604651166,
      "grad_norm": 0.0009930350352078676,
      "learning_rate": 5.325581395348838e-06,
      "loss": 0.0001,
      "step": 11526
    },
    {
      "epoch": 44.67829457364341,
      "grad_norm": 0.0006784996367059648,
      "learning_rate": 5.321705426356589e-06,
      "loss": 0.0001,
      "step": 11527
    },
    {
      "epoch": 44.68217054263566,
      "grad_norm": 0.0007911322172731161,
      "learning_rate": 5.317829457364342e-06,
      "loss": 0.0001,
      "step": 11528
    },
    {
      "epoch": 44.68604651162791,
      "grad_norm": 4.168899059295654,
      "learning_rate": 5.313953488372093e-06,
      "loss": 0.0067,
      "step": 11529
    },
    {
      "epoch": 44.689922480620154,
      "grad_norm": 0.0006647465052083135,
      "learning_rate": 5.310077519379846e-06,
      "loss": 0.0001,
      "step": 11530
    },
    {
      "epoch": 44.6937984496124,
      "grad_norm": 0.001285190344788134,
      "learning_rate": 5.306201550387597e-06,
      "loss": 0.0001,
      "step": 11531
    },
    {
      "epoch": 44.69767441860465,
      "grad_norm": 0.001125034410506487,
      "learning_rate": 5.302325581395349e-06,
      "loss": 0.0001,
      "step": 11532
    },
    {
      "epoch": 44.701550387596896,
      "grad_norm": 0.0010132876923307776,
      "learning_rate": 5.298449612403101e-06,
      "loss": 0.0001,
      "step": 11533
    },
    {
      "epoch": 44.70542635658915,
      "grad_norm": 0.0011256060097366571,
      "learning_rate": 5.294573643410853e-06,
      "loss": 0.0001,
      "step": 11534
    },
    {
      "epoch": 44.7093023255814,
      "grad_norm": 0.0009012892260216177,
      "learning_rate": 5.290697674418605e-06,
      "loss": 0.0001,
      "step": 11535
    },
    {
      "epoch": 44.713178294573645,
      "grad_norm": 0.0010609307792037725,
      "learning_rate": 5.286821705426357e-06,
      "loss": 0.0001,
      "step": 11536
    },
    {
      "epoch": 44.71705426356589,
      "grad_norm": 0.0007283181184902787,
      "learning_rate": 5.282945736434109e-06,
      "loss": 0.0001,
      "step": 11537
    },
    {
      "epoch": 44.72093023255814,
      "grad_norm": 0.0007658996619284153,
      "learning_rate": 5.279069767441861e-06,
      "loss": 0.0001,
      "step": 11538
    },
    {
      "epoch": 44.724806201550386,
      "grad_norm": 0.0007904914091341197,
      "learning_rate": 5.275193798449612e-06,
      "loss": 0.0001,
      "step": 11539
    },
    {
      "epoch": 44.72868217054263,
      "grad_norm": 0.0007017300231382251,
      "learning_rate": 5.271317829457365e-06,
      "loss": 0.0001,
      "step": 11540
    },
    {
      "epoch": 44.73255813953488,
      "grad_norm": 0.0008488951134495437,
      "learning_rate": 5.267441860465116e-06,
      "loss": 0.0001,
      "step": 11541
    },
    {
      "epoch": 44.736434108527135,
      "grad_norm": 0.0008735123556107283,
      "learning_rate": 5.263565891472869e-06,
      "loss": 0.0001,
      "step": 11542
    },
    {
      "epoch": 44.74031007751938,
      "grad_norm": 0.037450503557920456,
      "learning_rate": 5.25968992248062e-06,
      "loss": 0.0012,
      "step": 11543
    },
    {
      "epoch": 44.74418604651163,
      "grad_norm": 0.0008866226999089122,
      "learning_rate": 5.255813953488373e-06,
      "loss": 0.0001,
      "step": 11544
    },
    {
      "epoch": 44.748062015503876,
      "grad_norm": 0.000711378117557615,
      "learning_rate": 5.251937984496124e-06,
      "loss": 0.0001,
      "step": 11545
    },
    {
      "epoch": 44.751937984496124,
      "grad_norm": 0.0011684137862175703,
      "learning_rate": 5.248062015503876e-06,
      "loss": 0.0001,
      "step": 11546
    },
    {
      "epoch": 44.75581395348837,
      "grad_norm": 41.035675048828125,
      "learning_rate": 5.244186046511628e-06,
      "loss": 0.0348,
      "step": 11547
    },
    {
      "epoch": 44.75968992248062,
      "grad_norm": 0.000785504758823663,
      "learning_rate": 5.24031007751938e-06,
      "loss": 0.0001,
      "step": 11548
    },
    {
      "epoch": 44.763565891472865,
      "grad_norm": 0.038613881915807724,
      "learning_rate": 5.236434108527132e-06,
      "loss": 0.0005,
      "step": 11549
    },
    {
      "epoch": 44.76744186046512,
      "grad_norm": 0.0007072512526065111,
      "learning_rate": 5.232558139534884e-06,
      "loss": 0.0001,
      "step": 11550
    },
    {
      "epoch": 44.77131782945737,
      "grad_norm": 0.0026561457198113203,
      "learning_rate": 5.2286821705426355e-06,
      "loss": 0.0002,
      "step": 11551
    },
    {
      "epoch": 44.775193798449614,
      "grad_norm": 0.0017881118692457676,
      "learning_rate": 5.224806201550388e-06,
      "loss": 0.0001,
      "step": 11552
    },
    {
      "epoch": 44.77906976744186,
      "grad_norm": 0.0015257674967870116,
      "learning_rate": 5.2209302325581395e-06,
      "loss": 0.0001,
      "step": 11553
    },
    {
      "epoch": 44.78294573643411,
      "grad_norm": 0.0008318033069372177,
      "learning_rate": 5.217054263565892e-06,
      "loss": 0.0001,
      "step": 11554
    },
    {
      "epoch": 44.786821705426355,
      "grad_norm": 0.0008596925181336701,
      "learning_rate": 5.2131782945736435e-06,
      "loss": 0.0001,
      "step": 11555
    },
    {
      "epoch": 44.7906976744186,
      "grad_norm": 0.0018993469420820475,
      "learning_rate": 5.209302325581396e-06,
      "loss": 0.0001,
      "step": 11556
    },
    {
      "epoch": 44.79457364341085,
      "grad_norm": 0.002414123620837927,
      "learning_rate": 5.2054263565891475e-06,
      "loss": 0.0002,
      "step": 11557
    },
    {
      "epoch": 44.798449612403104,
      "grad_norm": 0.3074650466442108,
      "learning_rate": 5.201550387596899e-06,
      "loss": 0.0039,
      "step": 11558
    },
    {
      "epoch": 44.80232558139535,
      "grad_norm": 0.6060121655464172,
      "learning_rate": 5.1976744186046515e-06,
      "loss": 0.0372,
      "step": 11559
    },
    {
      "epoch": 44.8062015503876,
      "grad_norm": 0.0005867468426004052,
      "learning_rate": 5.193798449612403e-06,
      "loss": 0.0001,
      "step": 11560
    },
    {
      "epoch": 44.810077519379846,
      "grad_norm": 0.0006593508296646178,
      "learning_rate": 5.1899224806201555e-06,
      "loss": 0.0001,
      "step": 11561
    },
    {
      "epoch": 44.81395348837209,
      "grad_norm": 0.002460934454575181,
      "learning_rate": 5.186046511627907e-06,
      "loss": 0.0002,
      "step": 11562
    },
    {
      "epoch": 44.81782945736434,
      "grad_norm": 0.0007433447754010558,
      "learning_rate": 5.1821705426356595e-06,
      "loss": 0.0001,
      "step": 11563
    },
    {
      "epoch": 44.82170542635659,
      "grad_norm": 0.000756759662181139,
      "learning_rate": 5.178294573643411e-06,
      "loss": 0.0001,
      "step": 11564
    },
    {
      "epoch": 44.825581395348834,
      "grad_norm": 0.0008200361044146121,
      "learning_rate": 5.174418604651163e-06,
      "loss": 0.0001,
      "step": 11565
    },
    {
      "epoch": 44.82945736434109,
      "grad_norm": 0.0007759442087262869,
      "learning_rate": 5.170542635658915e-06,
      "loss": 0.0001,
      "step": 11566
    },
    {
      "epoch": 44.833333333333336,
      "grad_norm": 0.0007484165253117681,
      "learning_rate": 5.166666666666667e-06,
      "loss": 0.0001,
      "step": 11567
    },
    {
      "epoch": 44.83720930232558,
      "grad_norm": 0.0013469626428559422,
      "learning_rate": 5.162790697674419e-06,
      "loss": 0.0001,
      "step": 11568
    },
    {
      "epoch": 44.84108527131783,
      "grad_norm": 0.0007248274050652981,
      "learning_rate": 5.158914728682171e-06,
      "loss": 0.0001,
      "step": 11569
    },
    {
      "epoch": 44.84496124031008,
      "grad_norm": 0.0013880253536626697,
      "learning_rate": 5.155038759689923e-06,
      "loss": 0.0001,
      "step": 11570
    },
    {
      "epoch": 44.848837209302324,
      "grad_norm": 0.001666115946136415,
      "learning_rate": 5.151162790697675e-06,
      "loss": 0.0001,
      "step": 11571
    },
    {
      "epoch": 44.85271317829457,
      "grad_norm": 0.000746462435927242,
      "learning_rate": 5.147286821705426e-06,
      "loss": 0.0001,
      "step": 11572
    },
    {
      "epoch": 44.85658914728682,
      "grad_norm": 0.0014341259375214577,
      "learning_rate": 5.143410852713179e-06,
      "loss": 0.0001,
      "step": 11573
    },
    {
      "epoch": 44.86046511627907,
      "grad_norm": 0.0013984235702082515,
      "learning_rate": 5.13953488372093e-06,
      "loss": 0.0001,
      "step": 11574
    },
    {
      "epoch": 44.86434108527132,
      "grad_norm": 0.001159479608759284,
      "learning_rate": 5.135658914728683e-06,
      "loss": 0.0001,
      "step": 11575
    },
    {
      "epoch": 44.86821705426357,
      "grad_norm": 0.0012522474862635136,
      "learning_rate": 5.131782945736434e-06,
      "loss": 0.0001,
      "step": 11576
    },
    {
      "epoch": 44.872093023255815,
      "grad_norm": 0.0016426056390628219,
      "learning_rate": 5.127906976744187e-06,
      "loss": 0.0001,
      "step": 11577
    },
    {
      "epoch": 44.87596899224806,
      "grad_norm": 0.8761239051818848,
      "learning_rate": 5.124031007751938e-06,
      "loss": 0.0503,
      "step": 11578
    },
    {
      "epoch": 44.87984496124031,
      "grad_norm": 0.0017788331024348736,
      "learning_rate": 5.12015503875969e-06,
      "loss": 0.0001,
      "step": 11579
    },
    {
      "epoch": 44.883720930232556,
      "grad_norm": 0.03210374340415001,
      "learning_rate": 5.116279069767442e-06,
      "loss": 0.0008,
      "step": 11580
    },
    {
      "epoch": 44.8875968992248,
      "grad_norm": 0.0005836422205902636,
      "learning_rate": 5.112403100775194e-06,
      "loss": 0.0001,
      "step": 11581
    },
    {
      "epoch": 44.89147286821706,
      "grad_norm": 0.0007204239373095334,
      "learning_rate": 5.108527131782946e-06,
      "loss": 0.0001,
      "step": 11582
    },
    {
      "epoch": 44.895348837209305,
      "grad_norm": 0.0006564531358890235,
      "learning_rate": 5.104651162790699e-06,
      "loss": 0.0001,
      "step": 11583
    },
    {
      "epoch": 44.89922480620155,
      "grad_norm": 0.0009100288734771311,
      "learning_rate": 5.10077519379845e-06,
      "loss": 0.0001,
      "step": 11584
    },
    {
      "epoch": 44.9031007751938,
      "grad_norm": 0.002968141809105873,
      "learning_rate": 5.096899224806202e-06,
      "loss": 0.0002,
      "step": 11585
    },
    {
      "epoch": 44.906976744186046,
      "grad_norm": 0.0017590952338650823,
      "learning_rate": 5.093023255813953e-06,
      "loss": 0.0001,
      "step": 11586
    },
    {
      "epoch": 44.91085271317829,
      "grad_norm": 0.0009436379768885672,
      "learning_rate": 5.089147286821706e-06,
      "loss": 0.0001,
      "step": 11587
    },
    {
      "epoch": 44.91472868217054,
      "grad_norm": 0.10790622979402542,
      "learning_rate": 5.085271317829457e-06,
      "loss": 0.004,
      "step": 11588
    },
    {
      "epoch": 44.91860465116279,
      "grad_norm": 0.0007641994743607938,
      "learning_rate": 5.08139534883721e-06,
      "loss": 0.0001,
      "step": 11589
    },
    {
      "epoch": 44.92248062015504,
      "grad_norm": 0.0012654177844524384,
      "learning_rate": 5.077519379844962e-06,
      "loss": 0.0001,
      "step": 11590
    },
    {
      "epoch": 44.92635658914729,
      "grad_norm": 0.0016734179807826877,
      "learning_rate": 5.073643410852713e-06,
      "loss": 0.0001,
      "step": 11591
    },
    {
      "epoch": 44.93023255813954,
      "grad_norm": 0.0007814006530679762,
      "learning_rate": 5.069767441860465e-06,
      "loss": 0.0001,
      "step": 11592
    },
    {
      "epoch": 44.934108527131784,
      "grad_norm": 0.043498195707798004,
      "learning_rate": 5.065891472868217e-06,
      "loss": 0.0017,
      "step": 11593
    },
    {
      "epoch": 44.93798449612403,
      "grad_norm": 0.000667316373437643,
      "learning_rate": 5.062015503875969e-06,
      "loss": 0.0001,
      "step": 11594
    },
    {
      "epoch": 44.94186046511628,
      "grad_norm": 0.0006208861595951021,
      "learning_rate": 5.058139534883721e-06,
      "loss": 0.0001,
      "step": 11595
    },
    {
      "epoch": 44.945736434108525,
      "grad_norm": 0.0007379042217507958,
      "learning_rate": 5.054263565891473e-06,
      "loss": 0.0001,
      "step": 11596
    },
    {
      "epoch": 44.94961240310077,
      "grad_norm": 0.43741121888160706,
      "learning_rate": 5.050387596899226e-06,
      "loss": 0.011,
      "step": 11597
    },
    {
      "epoch": 44.95348837209303,
      "grad_norm": 0.0008327649557031691,
      "learning_rate": 5.0465116279069764e-06,
      "loss": 0.0001,
      "step": 11598
    },
    {
      "epoch": 44.957364341085274,
      "grad_norm": 0.002655678428709507,
      "learning_rate": 5.042635658914729e-06,
      "loss": 0.0001,
      "step": 11599
    },
    {
      "epoch": 44.96124031007752,
      "grad_norm": 0.0020673591643571854,
      "learning_rate": 5.0387596899224804e-06,
      "loss": 0.0002,
      "step": 11600
    },
    {
      "epoch": 44.96511627906977,
      "grad_norm": 0.0007401630864478648,
      "learning_rate": 5.034883720930233e-06,
      "loss": 0.0001,
      "step": 11601
    },
    {
      "epoch": 44.968992248062015,
      "grad_norm": 0.0015031422954052687,
      "learning_rate": 5.031007751937985e-06,
      "loss": 0.0001,
      "step": 11602
    },
    {
      "epoch": 44.97286821705426,
      "grad_norm": 0.0006008469499647617,
      "learning_rate": 5.027131782945737e-06,
      "loss": 0.0001,
      "step": 11603
    },
    {
      "epoch": 44.97674418604651,
      "grad_norm": 0.012302380055189133,
      "learning_rate": 5.023255813953489e-06,
      "loss": 0.0003,
      "step": 11604
    },
    {
      "epoch": 44.98062015503876,
      "grad_norm": 0.0007699453854002059,
      "learning_rate": 5.01937984496124e-06,
      "loss": 0.0001,
      "step": 11605
    },
    {
      "epoch": 44.98449612403101,
      "grad_norm": 0.0007765216869302094,
      "learning_rate": 5.015503875968992e-06,
      "loss": 0.0001,
      "step": 11606
    },
    {
      "epoch": 44.98837209302326,
      "grad_norm": 0.0032994127832353115,
      "learning_rate": 5.011627906976744e-06,
      "loss": 0.0002,
      "step": 11607
    },
    {
      "epoch": 44.992248062015506,
      "grad_norm": 0.0007024580263532698,
      "learning_rate": 5.007751937984496e-06,
      "loss": 0.0001,
      "step": 11608
    },
    {
      "epoch": 44.99612403100775,
      "grad_norm": 1.5073647499084473,
      "learning_rate": 5.003875968992249e-06,
      "loss": 0.1163,
      "step": 11609
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.0023621676955372095,
      "learning_rate": 5e-06,
      "loss": 0.0001,
      "step": 11610
    },
    {
      "epoch": 45.00387596899225,
      "grad_norm": 0.000936737924348563,
      "learning_rate": 4.996124031007752e-06,
      "loss": 0.0001,
      "step": 11611
    },
    {
      "epoch": 45.007751937984494,
      "grad_norm": 0.0008539130794815719,
      "learning_rate": 4.9922480620155036e-06,
      "loss": 0.0001,
      "step": 11612
    },
    {
      "epoch": 45.01162790697674,
      "grad_norm": 0.0018253694288432598,
      "learning_rate": 4.988372093023256e-06,
      "loss": 0.0002,
      "step": 11613
    },
    {
      "epoch": 45.01550387596899,
      "grad_norm": 0.0007055858732201159,
      "learning_rate": 4.984496124031008e-06,
      "loss": 0.0001,
      "step": 11614
    },
    {
      "epoch": 45.01937984496124,
      "grad_norm": 0.0006980567122809589,
      "learning_rate": 4.98062015503876e-06,
      "loss": 0.0001,
      "step": 11615
    },
    {
      "epoch": 45.02325581395349,
      "grad_norm": 0.0009232209995388985,
      "learning_rate": 4.976744186046512e-06,
      "loss": 0.0001,
      "step": 11616
    },
    {
      "epoch": 45.02713178294574,
      "grad_norm": 2.6657044887542725,
      "learning_rate": 4.972868217054264e-06,
      "loss": 0.2545,
      "step": 11617
    },
    {
      "epoch": 45.031007751937985,
      "grad_norm": 0.0015642133075743914,
      "learning_rate": 4.9689922480620155e-06,
      "loss": 0.0001,
      "step": 11618
    },
    {
      "epoch": 45.03488372093023,
      "grad_norm": 0.0011099940165877342,
      "learning_rate": 4.965116279069767e-06,
      "loss": 0.0001,
      "step": 11619
    },
    {
      "epoch": 45.03875968992248,
      "grad_norm": 0.0017700258176773787,
      "learning_rate": 4.9612403100775195e-06,
      "loss": 0.0001,
      "step": 11620
    },
    {
      "epoch": 45.042635658914726,
      "grad_norm": 0.0011873191688209772,
      "learning_rate": 4.957364341085272e-06,
      "loss": 0.0001,
      "step": 11621
    },
    {
      "epoch": 45.04651162790697,
      "grad_norm": 0.004078870173543692,
      "learning_rate": 4.9534883720930235e-06,
      "loss": 0.0002,
      "step": 11622
    },
    {
      "epoch": 45.05038759689923,
      "grad_norm": 0.515067458152771,
      "learning_rate": 4.949612403100776e-06,
      "loss": 0.0214,
      "step": 11623
    },
    {
      "epoch": 45.054263565891475,
      "grad_norm": 0.0007023023208603263,
      "learning_rate": 4.945736434108527e-06,
      "loss": 0.0001,
      "step": 11624
    },
    {
      "epoch": 45.05813953488372,
      "grad_norm": 0.000737566442694515,
      "learning_rate": 4.941860465116279e-06,
      "loss": 0.0001,
      "step": 11625
    },
    {
      "epoch": 45.06201550387597,
      "grad_norm": 0.0009594595176167786,
      "learning_rate": 4.937984496124031e-06,
      "loss": 0.0001,
      "step": 11626
    },
    {
      "epoch": 45.065891472868216,
      "grad_norm": 0.0006660899380221963,
      "learning_rate": 4.934108527131783e-06,
      "loss": 0.0001,
      "step": 11627
    },
    {
      "epoch": 45.06976744186046,
      "grad_norm": 0.0007304087048396468,
      "learning_rate": 4.9302325581395355e-06,
      "loss": 0.0001,
      "step": 11628
    },
    {
      "epoch": 45.07364341085271,
      "grad_norm": 0.0025794124230742455,
      "learning_rate": 4.926356589147287e-06,
      "loss": 0.0002,
      "step": 11629
    },
    {
      "epoch": 45.07751937984496,
      "grad_norm": 0.0011535646626725793,
      "learning_rate": 4.9224806201550395e-06,
      "loss": 0.0001,
      "step": 11630
    },
    {
      "epoch": 45.08139534883721,
      "grad_norm": 0.0030747447162866592,
      "learning_rate": 4.91860465116279e-06,
      "loss": 0.0002,
      "step": 11631
    },
    {
      "epoch": 45.08527131782946,
      "grad_norm": 0.0011740386253222823,
      "learning_rate": 4.914728682170543e-06,
      "loss": 0.0001,
      "step": 11632
    },
    {
      "epoch": 45.08914728682171,
      "grad_norm": 0.0007824611384421587,
      "learning_rate": 4.910852713178295e-06,
      "loss": 0.0001,
      "step": 11633
    },
    {
      "epoch": 45.093023255813954,
      "grad_norm": 0.0010142268147319555,
      "learning_rate": 4.906976744186047e-06,
      "loss": 0.0001,
      "step": 11634
    },
    {
      "epoch": 45.0968992248062,
      "grad_norm": 0.0007249877671711147,
      "learning_rate": 4.903100775193799e-06,
      "loss": 0.0001,
      "step": 11635
    },
    {
      "epoch": 45.10077519379845,
      "grad_norm": 0.0008710910915397108,
      "learning_rate": 4.899224806201551e-06,
      "loss": 0.0001,
      "step": 11636
    },
    {
      "epoch": 45.104651162790695,
      "grad_norm": 0.0007297415286302567,
      "learning_rate": 4.895348837209303e-06,
      "loss": 0.0001,
      "step": 11637
    },
    {
      "epoch": 45.10852713178294,
      "grad_norm": 0.0007113805622793734,
      "learning_rate": 4.891472868217054e-06,
      "loss": 0.0001,
      "step": 11638
    },
    {
      "epoch": 45.1124031007752,
      "grad_norm": 0.0016988023417070508,
      "learning_rate": 4.887596899224806e-06,
      "loss": 0.0001,
      "step": 11639
    },
    {
      "epoch": 45.116279069767444,
      "grad_norm": 5.25689172744751,
      "learning_rate": 4.883720930232559e-06,
      "loss": 0.6304,
      "step": 11640
    },
    {
      "epoch": 45.12015503875969,
      "grad_norm": 0.0007173360791057348,
      "learning_rate": 4.87984496124031e-06,
      "loss": 0.0001,
      "step": 11641
    },
    {
      "epoch": 45.12403100775194,
      "grad_norm": 0.5275790691375732,
      "learning_rate": 4.875968992248063e-06,
      "loss": 0.0264,
      "step": 11642
    },
    {
      "epoch": 45.127906976744185,
      "grad_norm": 0.0023411137517541647,
      "learning_rate": 4.872093023255814e-06,
      "loss": 0.0002,
      "step": 11643
    },
    {
      "epoch": 45.13178294573643,
      "grad_norm": 0.0006724393460899591,
      "learning_rate": 4.868217054263566e-06,
      "loss": 0.0001,
      "step": 11644
    },
    {
      "epoch": 45.13565891472868,
      "grad_norm": 0.0014087026938796043,
      "learning_rate": 4.864341085271318e-06,
      "loss": 0.0001,
      "step": 11645
    },
    {
      "epoch": 45.13953488372093,
      "grad_norm": 0.0008794120512902737,
      "learning_rate": 4.86046511627907e-06,
      "loss": 0.0001,
      "step": 11646
    },
    {
      "epoch": 45.14341085271318,
      "grad_norm": 0.0007707028998993337,
      "learning_rate": 4.856589147286822e-06,
      "loss": 0.0001,
      "step": 11647
    },
    {
      "epoch": 45.14728682170543,
      "grad_norm": 0.0006861940491944551,
      "learning_rate": 4.852713178294574e-06,
      "loss": 0.0001,
      "step": 11648
    },
    {
      "epoch": 45.151162790697676,
      "grad_norm": 0.002322196029126644,
      "learning_rate": 4.848837209302326e-06,
      "loss": 0.0002,
      "step": 11649
    },
    {
      "epoch": 45.15503875968992,
      "grad_norm": 0.0009150091209448874,
      "learning_rate": 4.844961240310078e-06,
      "loss": 0.0001,
      "step": 11650
    },
    {
      "epoch": 45.15891472868217,
      "grad_norm": 0.0006888918578624725,
      "learning_rate": 4.841085271317829e-06,
      "loss": 0.0001,
      "step": 11651
    },
    {
      "epoch": 45.16279069767442,
      "grad_norm": 0.0007771137170493603,
      "learning_rate": 4.837209302325582e-06,
      "loss": 0.0001,
      "step": 11652
    },
    {
      "epoch": 45.166666666666664,
      "grad_norm": 0.0007157986983656883,
      "learning_rate": 4.833333333333333e-06,
      "loss": 0.0001,
      "step": 11653
    },
    {
      "epoch": 45.17054263565891,
      "grad_norm": 0.00087216985411942,
      "learning_rate": 4.829457364341086e-06,
      "loss": 0.0001,
      "step": 11654
    },
    {
      "epoch": 45.174418604651166,
      "grad_norm": 0.000774079468101263,
      "learning_rate": 4.825581395348837e-06,
      "loss": 0.0001,
      "step": 11655
    },
    {
      "epoch": 45.17829457364341,
      "grad_norm": 0.0008450754103250802,
      "learning_rate": 4.82170542635659e-06,
      "loss": 0.0001,
      "step": 11656
    },
    {
      "epoch": 45.18217054263566,
      "grad_norm": 0.0014090909389778972,
      "learning_rate": 4.817829457364341e-06,
      "loss": 0.0001,
      "step": 11657
    },
    {
      "epoch": 45.18604651162791,
      "grad_norm": 0.0013406454818323255,
      "learning_rate": 4.813953488372093e-06,
      "loss": 0.0001,
      "step": 11658
    },
    {
      "epoch": 45.189922480620154,
      "grad_norm": 0.001718151499517262,
      "learning_rate": 4.810077519379845e-06,
      "loss": 0.0002,
      "step": 11659
    },
    {
      "epoch": 45.1937984496124,
      "grad_norm": 0.0008605652255937457,
      "learning_rate": 4.806201550387597e-06,
      "loss": 0.0001,
      "step": 11660
    },
    {
      "epoch": 45.19767441860465,
      "grad_norm": 0.021867660805583,
      "learning_rate": 4.802325581395349e-06,
      "loss": 0.0003,
      "step": 11661
    },
    {
      "epoch": 45.201550387596896,
      "grad_norm": 0.010931582190096378,
      "learning_rate": 4.798449612403101e-06,
      "loss": 0.0004,
      "step": 11662
    },
    {
      "epoch": 45.20542635658915,
      "grad_norm": 0.0022249643225222826,
      "learning_rate": 4.794573643410853e-06,
      "loss": 0.0002,
      "step": 11663
    },
    {
      "epoch": 45.2093023255814,
      "grad_norm": 0.0011426664423197508,
      "learning_rate": 4.790697674418605e-06,
      "loss": 0.0001,
      "step": 11664
    },
    {
      "epoch": 45.213178294573645,
      "grad_norm": 0.0008318924228660762,
      "learning_rate": 4.7868217054263565e-06,
      "loss": 0.0001,
      "step": 11665
    },
    {
      "epoch": 45.21705426356589,
      "grad_norm": 0.0007048870320431888,
      "learning_rate": 4.782945736434109e-06,
      "loss": 0.0001,
      "step": 11666
    },
    {
      "epoch": 45.22093023255814,
      "grad_norm": 0.0006890250951983035,
      "learning_rate": 4.7790697674418605e-06,
      "loss": 0.0001,
      "step": 11667
    },
    {
      "epoch": 45.224806201550386,
      "grad_norm": 0.0010930993594229221,
      "learning_rate": 4.775193798449613e-06,
      "loss": 0.0001,
      "step": 11668
    },
    {
      "epoch": 45.22868217054263,
      "grad_norm": 0.0011407817946746945,
      "learning_rate": 4.7713178294573645e-06,
      "loss": 0.0001,
      "step": 11669
    },
    {
      "epoch": 45.23255813953488,
      "grad_norm": 0.0009163401555269957,
      "learning_rate": 4.767441860465117e-06,
      "loss": 0.0001,
      "step": 11670
    },
    {
      "epoch": 45.236434108527135,
      "grad_norm": 0.014498459175229073,
      "learning_rate": 4.7635658914728685e-06,
      "loss": 0.0003,
      "step": 11671
    },
    {
      "epoch": 45.24031007751938,
      "grad_norm": 0.0007374626002274454,
      "learning_rate": 4.75968992248062e-06,
      "loss": 0.0001,
      "step": 11672
    },
    {
      "epoch": 45.24418604651163,
      "grad_norm": 0.0023046506103128195,
      "learning_rate": 4.7558139534883725e-06,
      "loss": 0.0002,
      "step": 11673
    },
    {
      "epoch": 45.248062015503876,
      "grad_norm": 0.0005321892094798386,
      "learning_rate": 4.751937984496124e-06,
      "loss": 0.0001,
      "step": 11674
    },
    {
      "epoch": 45.251937984496124,
      "grad_norm": 0.0012755003990605474,
      "learning_rate": 4.7480620155038765e-06,
      "loss": 0.0001,
      "step": 11675
    },
    {
      "epoch": 45.25581395348837,
      "grad_norm": 0.0009942130418494344,
      "learning_rate": 4.744186046511628e-06,
      "loss": 0.0001,
      "step": 11676
    },
    {
      "epoch": 45.25968992248062,
      "grad_norm": 0.0008120097336359322,
      "learning_rate": 4.7403100775193805e-06,
      "loss": 0.0001,
      "step": 11677
    },
    {
      "epoch": 45.263565891472865,
      "grad_norm": 0.0013463788200169802,
      "learning_rate": 4.736434108527132e-06,
      "loss": 0.0001,
      "step": 11678
    },
    {
      "epoch": 45.26744186046512,
      "grad_norm": 0.16182878613471985,
      "learning_rate": 4.732558139534884e-06,
      "loss": 0.0049,
      "step": 11679
    },
    {
      "epoch": 45.27131782945737,
      "grad_norm": 0.0013578240759670734,
      "learning_rate": 4.728682170542636e-06,
      "loss": 0.0001,
      "step": 11680
    },
    {
      "epoch": 45.275193798449614,
      "grad_norm": 0.0006950171082280576,
      "learning_rate": 4.724806201550388e-06,
      "loss": 0.0001,
      "step": 11681
    },
    {
      "epoch": 45.27906976744186,
      "grad_norm": 0.0025935345329344273,
      "learning_rate": 4.72093023255814e-06,
      "loss": 0.0001,
      "step": 11682
    },
    {
      "epoch": 45.28294573643411,
      "grad_norm": 0.0013122218661010265,
      "learning_rate": 4.717054263565892e-06,
      "loss": 0.0001,
      "step": 11683
    },
    {
      "epoch": 45.286821705426355,
      "grad_norm": 0.001222079386934638,
      "learning_rate": 4.713178294573643e-06,
      "loss": 0.0001,
      "step": 11684
    },
    {
      "epoch": 45.2906976744186,
      "grad_norm": 1.716630220413208,
      "learning_rate": 4.709302325581396e-06,
      "loss": 0.1053,
      "step": 11685
    },
    {
      "epoch": 45.29457364341085,
      "grad_norm": 0.0020854396279901266,
      "learning_rate": 4.705426356589147e-06,
      "loss": 0.0002,
      "step": 11686
    },
    {
      "epoch": 45.298449612403104,
      "grad_norm": 0.0007733603124506772,
      "learning_rate": 4.7015503875969e-06,
      "loss": 0.0001,
      "step": 11687
    },
    {
      "epoch": 45.30232558139535,
      "grad_norm": 0.0011322159552946687,
      "learning_rate": 4.697674418604651e-06,
      "loss": 0.0001,
      "step": 11688
    },
    {
      "epoch": 45.3062015503876,
      "grad_norm": 0.0015330881578847766,
      "learning_rate": 4.693798449612404e-06,
      "loss": 0.0001,
      "step": 11689
    },
    {
      "epoch": 45.310077519379846,
      "grad_norm": 0.0008935602381825447,
      "learning_rate": 4.689922480620155e-06,
      "loss": 0.0001,
      "step": 11690
    },
    {
      "epoch": 45.31395348837209,
      "grad_norm": 0.040124524384737015,
      "learning_rate": 4.686046511627907e-06,
      "loss": 0.0008,
      "step": 11691
    },
    {
      "epoch": 45.31782945736434,
      "grad_norm": 0.0008427251013927162,
      "learning_rate": 4.682170542635659e-06,
      "loss": 0.0001,
      "step": 11692
    },
    {
      "epoch": 45.32170542635659,
      "grad_norm": 0.0008463231497444212,
      "learning_rate": 4.678294573643411e-06,
      "loss": 0.0001,
      "step": 11693
    },
    {
      "epoch": 45.325581395348834,
      "grad_norm": 0.000676135066896677,
      "learning_rate": 4.674418604651163e-06,
      "loss": 0.0001,
      "step": 11694
    },
    {
      "epoch": 45.32945736434109,
      "grad_norm": 0.000791289028711617,
      "learning_rate": 4.670542635658915e-06,
      "loss": 0.0001,
      "step": 11695
    },
    {
      "epoch": 45.333333333333336,
      "grad_norm": 0.0007542187231592834,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.0001,
      "step": 11696
    },
    {
      "epoch": 45.33720930232558,
      "grad_norm": 0.0011601459700614214,
      "learning_rate": 4.662790697674419e-06,
      "loss": 0.0001,
      "step": 11697
    },
    {
      "epoch": 45.34108527131783,
      "grad_norm": 0.004040650092065334,
      "learning_rate": 4.65891472868217e-06,
      "loss": 0.0002,
      "step": 11698
    },
    {
      "epoch": 45.34496124031008,
      "grad_norm": 0.0007858029566705227,
      "learning_rate": 4.655038759689923e-06,
      "loss": 0.0001,
      "step": 11699
    },
    {
      "epoch": 45.348837209302324,
      "grad_norm": 0.0007381860632449389,
      "learning_rate": 4.651162790697674e-06,
      "loss": 0.0001,
      "step": 11700
    },
    {
      "epoch": 45.35271317829457,
      "grad_norm": 0.4690231680870056,
      "learning_rate": 4.647286821705427e-06,
      "loss": 0.0193,
      "step": 11701
    },
    {
      "epoch": 45.35658914728682,
      "grad_norm": 0.0007132994360290468,
      "learning_rate": 4.643410852713178e-06,
      "loss": 0.0001,
      "step": 11702
    },
    {
      "epoch": 45.36046511627907,
      "grad_norm": 0.0007599611417390406,
      "learning_rate": 4.639534883720931e-06,
      "loss": 0.0001,
      "step": 11703
    },
    {
      "epoch": 45.36434108527132,
      "grad_norm": 0.07232606410980225,
      "learning_rate": 4.635658914728682e-06,
      "loss": 0.0018,
      "step": 11704
    },
    {
      "epoch": 45.36821705426357,
      "grad_norm": 0.0005979915731586516,
      "learning_rate": 4.631782945736434e-06,
      "loss": 0.0001,
      "step": 11705
    },
    {
      "epoch": 45.372093023255815,
      "grad_norm": 0.0023656729608774185,
      "learning_rate": 4.627906976744186e-06,
      "loss": 0.0002,
      "step": 11706
    },
    {
      "epoch": 45.37596899224806,
      "grad_norm": 0.0006377407116815448,
      "learning_rate": 4.624031007751938e-06,
      "loss": 0.0001,
      "step": 11707
    },
    {
      "epoch": 45.37984496124031,
      "grad_norm": 0.005447704344987869,
      "learning_rate": 4.62015503875969e-06,
      "loss": 0.0001,
      "step": 11708
    },
    {
      "epoch": 45.383720930232556,
      "grad_norm": 0.0008000579546205699,
      "learning_rate": 4.616279069767442e-06,
      "loss": 0.0001,
      "step": 11709
    },
    {
      "epoch": 45.3875968992248,
      "grad_norm": 0.000783480063546449,
      "learning_rate": 4.612403100775194e-06,
      "loss": 0.0001,
      "step": 11710
    },
    {
      "epoch": 45.39147286821706,
      "grad_norm": 0.0008442990947514772,
      "learning_rate": 4.608527131782946e-06,
      "loss": 0.0001,
      "step": 11711
    },
    {
      "epoch": 45.395348837209305,
      "grad_norm": 0.0013023850042372942,
      "learning_rate": 4.6046511627906974e-06,
      "loss": 0.0001,
      "step": 11712
    },
    {
      "epoch": 45.39922480620155,
      "grad_norm": 0.0007995111518539488,
      "learning_rate": 4.60077519379845e-06,
      "loss": 0.0001,
      "step": 11713
    },
    {
      "epoch": 45.4031007751938,
      "grad_norm": 0.0006237748311832547,
      "learning_rate": 4.5968992248062014e-06,
      "loss": 0.0001,
      "step": 11714
    },
    {
      "epoch": 45.406976744186046,
      "grad_norm": 0.642789900302887,
      "learning_rate": 4.593023255813954e-06,
      "loss": 0.0303,
      "step": 11715
    },
    {
      "epoch": 45.41085271317829,
      "grad_norm": 0.0008245086646638811,
      "learning_rate": 4.589147286821706e-06,
      "loss": 0.0001,
      "step": 11716
    },
    {
      "epoch": 45.41472868217054,
      "grad_norm": 0.39580202102661133,
      "learning_rate": 4.585271317829458e-06,
      "loss": 0.0158,
      "step": 11717
    },
    {
      "epoch": 45.41860465116279,
      "grad_norm": 0.0006699843797832727,
      "learning_rate": 4.5813953488372094e-06,
      "loss": 0.0001,
      "step": 11718
    },
    {
      "epoch": 45.42248062015504,
      "grad_norm": 0.0014636616688221693,
      "learning_rate": 4.577519379844961e-06,
      "loss": 0.0001,
      "step": 11719
    },
    {
      "epoch": 45.42635658914729,
      "grad_norm": 0.0007885429076850414,
      "learning_rate": 4.573643410852713e-06,
      "loss": 0.0001,
      "step": 11720
    },
    {
      "epoch": 45.43023255813954,
      "grad_norm": 0.04190582409501076,
      "learning_rate": 4.569767441860465e-06,
      "loss": 0.0016,
      "step": 11721
    },
    {
      "epoch": 45.434108527131784,
      "grad_norm": 0.0025659725069999695,
      "learning_rate": 4.565891472868217e-06,
      "loss": 0.0002,
      "step": 11722
    },
    {
      "epoch": 45.43798449612403,
      "grad_norm": 0.0026329660322517157,
      "learning_rate": 4.56201550387597e-06,
      "loss": 0.0001,
      "step": 11723
    },
    {
      "epoch": 45.44186046511628,
      "grad_norm": 0.0007226393790915608,
      "learning_rate": 4.5581395348837206e-06,
      "loss": 0.0001,
      "step": 11724
    },
    {
      "epoch": 45.445736434108525,
      "grad_norm": 0.0007568274741061032,
      "learning_rate": 4.554263565891473e-06,
      "loss": 0.0001,
      "step": 11725
    },
    {
      "epoch": 45.44961240310077,
      "grad_norm": 0.0011914673959836364,
      "learning_rate": 4.5503875968992246e-06,
      "loss": 0.0001,
      "step": 11726
    },
    {
      "epoch": 45.45348837209303,
      "grad_norm": 0.0013378547737374902,
      "learning_rate": 4.546511627906977e-06,
      "loss": 0.0001,
      "step": 11727
    },
    {
      "epoch": 45.457364341085274,
      "grad_norm": 0.00092753377975896,
      "learning_rate": 4.5426356589147286e-06,
      "loss": 0.0001,
      "step": 11728
    },
    {
      "epoch": 45.46124031007752,
      "grad_norm": 0.0007975392509251833,
      "learning_rate": 4.538759689922481e-06,
      "loss": 0.0001,
      "step": 11729
    },
    {
      "epoch": 45.46511627906977,
      "grad_norm": 0.0021203358191996813,
      "learning_rate": 4.534883720930233e-06,
      "loss": 0.0002,
      "step": 11730
    },
    {
      "epoch": 45.468992248062015,
      "grad_norm": 0.0007534490432590246,
      "learning_rate": 4.531007751937984e-06,
      "loss": 0.0001,
      "step": 11731
    },
    {
      "epoch": 45.47286821705426,
      "grad_norm": 0.002856412436813116,
      "learning_rate": 4.5271317829457366e-06,
      "loss": 0.0002,
      "step": 11732
    },
    {
      "epoch": 45.47674418604651,
      "grad_norm": 1.8760677576065063,
      "learning_rate": 4.523255813953488e-06,
      "loss": 0.1883,
      "step": 11733
    },
    {
      "epoch": 45.48062015503876,
      "grad_norm": 0.8765577077865601,
      "learning_rate": 4.5193798449612405e-06,
      "loss": 0.0495,
      "step": 11734
    },
    {
      "epoch": 45.48449612403101,
      "grad_norm": 0.0008480186224915087,
      "learning_rate": 4.515503875968993e-06,
      "loss": 0.0001,
      "step": 11735
    },
    {
      "epoch": 45.48837209302326,
      "grad_norm": 0.0012152394047006965,
      "learning_rate": 4.5116279069767445e-06,
      "loss": 0.0001,
      "step": 11736
    },
    {
      "epoch": 45.492248062015506,
      "grad_norm": 0.0010385136120021343,
      "learning_rate": 4.507751937984497e-06,
      "loss": 0.0001,
      "step": 11737
    },
    {
      "epoch": 45.49612403100775,
      "grad_norm": 0.0007611646433360875,
      "learning_rate": 4.503875968992248e-06,
      "loss": 0.0001,
      "step": 11738
    },
    {
      "epoch": 45.5,
      "grad_norm": 0.00850114319473505,
      "learning_rate": 4.5e-06,
      "loss": 0.0002,
      "step": 11739
    },
    {
      "epoch": 45.50387596899225,
      "grad_norm": 0.0054625775665044785,
      "learning_rate": 4.496124031007752e-06,
      "loss": 0.0002,
      "step": 11740
    },
    {
      "epoch": 45.507751937984494,
      "grad_norm": 0.0006976664299145341,
      "learning_rate": 4.492248062015504e-06,
      "loss": 0.0001,
      "step": 11741
    },
    {
      "epoch": 45.51162790697674,
      "grad_norm": 0.005214733071625233,
      "learning_rate": 4.4883720930232565e-06,
      "loss": 0.0003,
      "step": 11742
    },
    {
      "epoch": 45.51550387596899,
      "grad_norm": 0.0009451337973587215,
      "learning_rate": 4.484496124031008e-06,
      "loss": 0.0001,
      "step": 11743
    },
    {
      "epoch": 45.51937984496124,
      "grad_norm": 0.0009860715363174677,
      "learning_rate": 4.48062015503876e-06,
      "loss": 0.0001,
      "step": 11744
    },
    {
      "epoch": 45.52325581395349,
      "grad_norm": 0.0007077098707668483,
      "learning_rate": 4.476744186046511e-06,
      "loss": 0.0001,
      "step": 11745
    },
    {
      "epoch": 45.52713178294574,
      "grad_norm": 0.0006279793451540172,
      "learning_rate": 4.472868217054264e-06,
      "loss": 0.0001,
      "step": 11746
    },
    {
      "epoch": 45.531007751937985,
      "grad_norm": 0.0010853298008441925,
      "learning_rate": 4.468992248062016e-06,
      "loss": 0.0001,
      "step": 11747
    },
    {
      "epoch": 45.53488372093023,
      "grad_norm": 0.0008202558383345604,
      "learning_rate": 4.465116279069768e-06,
      "loss": 0.0001,
      "step": 11748
    },
    {
      "epoch": 45.53875968992248,
      "grad_norm": 0.0009317884687334299,
      "learning_rate": 4.46124031007752e-06,
      "loss": 0.0001,
      "step": 11749
    },
    {
      "epoch": 45.542635658914726,
      "grad_norm": 0.0006797910900786519,
      "learning_rate": 4.457364341085272e-06,
      "loss": 0.0001,
      "step": 11750
    },
    {
      "epoch": 45.54651162790697,
      "grad_norm": 0.4303211271762848,
      "learning_rate": 4.453488372093023e-06,
      "loss": 0.0044,
      "step": 11751
    },
    {
      "epoch": 45.55038759689923,
      "grad_norm": 0.6446062326431274,
      "learning_rate": 4.449612403100775e-06,
      "loss": 0.0346,
      "step": 11752
    },
    {
      "epoch": 45.554263565891475,
      "grad_norm": 0.0019189462764188647,
      "learning_rate": 4.445736434108527e-06,
      "loss": 0.0002,
      "step": 11753
    },
    {
      "epoch": 45.55813953488372,
      "grad_norm": 0.0007121673552319407,
      "learning_rate": 4.44186046511628e-06,
      "loss": 0.0001,
      "step": 11754
    },
    {
      "epoch": 45.56201550387597,
      "grad_norm": 0.0007571732858195901,
      "learning_rate": 4.437984496124031e-06,
      "loss": 0.0001,
      "step": 11755
    },
    {
      "epoch": 45.565891472868216,
      "grad_norm": 0.013875546865165234,
      "learning_rate": 4.434108527131784e-06,
      "loss": 0.0002,
      "step": 11756
    },
    {
      "epoch": 45.56976744186046,
      "grad_norm": 0.0009306966094300151,
      "learning_rate": 4.430232558139535e-06,
      "loss": 0.0001,
      "step": 11757
    },
    {
      "epoch": 45.57364341085271,
      "grad_norm": 0.000767405319493264,
      "learning_rate": 4.426356589147287e-06,
      "loss": 0.0001,
      "step": 11758
    },
    {
      "epoch": 45.57751937984496,
      "grad_norm": 0.0033982691820710897,
      "learning_rate": 4.422480620155039e-06,
      "loss": 0.0001,
      "step": 11759
    },
    {
      "epoch": 45.58139534883721,
      "grad_norm": 0.005836665164679289,
      "learning_rate": 4.418604651162791e-06,
      "loss": 0.0002,
      "step": 11760
    },
    {
      "epoch": 45.58527131782946,
      "grad_norm": 0.0008645034395158291,
      "learning_rate": 4.414728682170543e-06,
      "loss": 0.0001,
      "step": 11761
    },
    {
      "epoch": 45.58914728682171,
      "grad_norm": 0.0008337816107086837,
      "learning_rate": 4.410852713178295e-06,
      "loss": 0.0001,
      "step": 11762
    },
    {
      "epoch": 45.593023255813954,
      "grad_norm": 0.0014127790927886963,
      "learning_rate": 4.406976744186047e-06,
      "loss": 0.0001,
      "step": 11763
    },
    {
      "epoch": 45.5968992248062,
      "grad_norm": 0.0009890561923384666,
      "learning_rate": 4.403100775193798e-06,
      "loss": 0.0001,
      "step": 11764
    },
    {
      "epoch": 45.60077519379845,
      "grad_norm": 0.0007831669063307345,
      "learning_rate": 4.39922480620155e-06,
      "loss": 0.0001,
      "step": 11765
    },
    {
      "epoch": 45.604651162790695,
      "grad_norm": 0.0018247171537950635,
      "learning_rate": 4.395348837209303e-06,
      "loss": 0.0001,
      "step": 11766
    },
    {
      "epoch": 45.60852713178294,
      "grad_norm": 0.0006432238151319325,
      "learning_rate": 4.391472868217054e-06,
      "loss": 0.0001,
      "step": 11767
    },
    {
      "epoch": 45.6124031007752,
      "grad_norm": 0.0008495177607983351,
      "learning_rate": 4.387596899224807e-06,
      "loss": 0.0001,
      "step": 11768
    },
    {
      "epoch": 45.616279069767444,
      "grad_norm": 0.0009105768986046314,
      "learning_rate": 4.383720930232558e-06,
      "loss": 0.0001,
      "step": 11769
    },
    {
      "epoch": 45.62015503875969,
      "grad_norm": 0.0015005051391199231,
      "learning_rate": 4.379844961240311e-06,
      "loss": 0.0001,
      "step": 11770
    },
    {
      "epoch": 45.62403100775194,
      "grad_norm": 0.0009002170991152525,
      "learning_rate": 4.3759689922480615e-06,
      "loss": 0.0001,
      "step": 11771
    },
    {
      "epoch": 45.627906976744185,
      "grad_norm": 0.0012068424839526415,
      "learning_rate": 4.372093023255814e-06,
      "loss": 0.0001,
      "step": 11772
    },
    {
      "epoch": 45.63178294573643,
      "grad_norm": 0.0012888713972643018,
      "learning_rate": 4.368217054263566e-06,
      "loss": 0.0001,
      "step": 11773
    },
    {
      "epoch": 45.63565891472868,
      "grad_norm": 0.0011541246203705668,
      "learning_rate": 4.364341085271318e-06,
      "loss": 0.0001,
      "step": 11774
    },
    {
      "epoch": 45.63953488372093,
      "grad_norm": 0.0006414116942323744,
      "learning_rate": 4.36046511627907e-06,
      "loss": 0.0001,
      "step": 11775
    },
    {
      "epoch": 45.64341085271318,
      "grad_norm": 0.0010186543222516775,
      "learning_rate": 4.356589147286822e-06,
      "loss": 0.0001,
      "step": 11776
    },
    {
      "epoch": 45.64728682170543,
      "grad_norm": 0.0010357728460803628,
      "learning_rate": 4.352713178294574e-06,
      "loss": 0.0001,
      "step": 11777
    },
    {
      "epoch": 45.651162790697676,
      "grad_norm": 0.0011161401635035872,
      "learning_rate": 4.348837209302326e-06,
      "loss": 0.0001,
      "step": 11778
    },
    {
      "epoch": 45.65503875968992,
      "grad_norm": 0.0028911593835800886,
      "learning_rate": 4.3449612403100775e-06,
      "loss": 0.0002,
      "step": 11779
    },
    {
      "epoch": 45.65891472868217,
      "grad_norm": 3.030513048171997,
      "learning_rate": 4.34108527131783e-06,
      "loss": 0.2962,
      "step": 11780
    },
    {
      "epoch": 45.66279069767442,
      "grad_norm": 0.0007495128666050732,
      "learning_rate": 4.3372093023255815e-06,
      "loss": 0.0001,
      "step": 11781
    },
    {
      "epoch": 45.666666666666664,
      "grad_norm": 0.001663066097535193,
      "learning_rate": 4.333333333333334e-06,
      "loss": 0.0001,
      "step": 11782
    },
    {
      "epoch": 45.67054263565891,
      "grad_norm": 0.0017153610242530704,
      "learning_rate": 4.3294573643410855e-06,
      "loss": 0.0001,
      "step": 11783
    },
    {
      "epoch": 45.674418604651166,
      "grad_norm": 0.002321908948943019,
      "learning_rate": 4.325581395348837e-06,
      "loss": 0.0002,
      "step": 11784
    },
    {
      "epoch": 45.67829457364341,
      "grad_norm": 0.0008630338707007468,
      "learning_rate": 4.3217054263565895e-06,
      "loss": 0.0001,
      "step": 11785
    },
    {
      "epoch": 45.68217054263566,
      "grad_norm": 0.3344133496284485,
      "learning_rate": 4.317829457364341e-06,
      "loss": 0.0139,
      "step": 11786
    },
    {
      "epoch": 45.68604651162791,
      "grad_norm": 0.0007290479261428118,
      "learning_rate": 4.3139534883720935e-06,
      "loss": 0.0001,
      "step": 11787
    },
    {
      "epoch": 45.689922480620154,
      "grad_norm": 0.000990736880339682,
      "learning_rate": 4.310077519379845e-06,
      "loss": 0.0001,
      "step": 11788
    },
    {
      "epoch": 45.6937984496124,
      "grad_norm": 0.0012693020980805159,
      "learning_rate": 4.3062015503875975e-06,
      "loss": 0.0001,
      "step": 11789
    },
    {
      "epoch": 45.69767441860465,
      "grad_norm": 0.0007155756466090679,
      "learning_rate": 4.302325581395349e-06,
      "loss": 0.0001,
      "step": 11790
    },
    {
      "epoch": 45.701550387596896,
      "grad_norm": 0.0006816374370828271,
      "learning_rate": 4.298449612403101e-06,
      "loss": 0.0001,
      "step": 11791
    },
    {
      "epoch": 45.70542635658915,
      "grad_norm": 0.0005866425344720483,
      "learning_rate": 4.294573643410853e-06,
      "loss": 0.0001,
      "step": 11792
    },
    {
      "epoch": 45.7093023255814,
      "grad_norm": 0.0015462483279407024,
      "learning_rate": 4.290697674418605e-06,
      "loss": 0.0001,
      "step": 11793
    },
    {
      "epoch": 45.713178294573645,
      "grad_norm": 0.0007379510789178312,
      "learning_rate": 4.286821705426357e-06,
      "loss": 0.0001,
      "step": 11794
    },
    {
      "epoch": 45.71705426356589,
      "grad_norm": 0.0011751819401979446,
      "learning_rate": 4.282945736434109e-06,
      "loss": 0.0001,
      "step": 11795
    },
    {
      "epoch": 45.72093023255814,
      "grad_norm": 0.18799766898155212,
      "learning_rate": 4.279069767441861e-06,
      "loss": 0.0001,
      "step": 11796
    },
    {
      "epoch": 45.724806201550386,
      "grad_norm": 0.00078581616980955,
      "learning_rate": 4.275193798449613e-06,
      "loss": 0.0001,
      "step": 11797
    },
    {
      "epoch": 45.72868217054263,
      "grad_norm": 0.0007730784709565341,
      "learning_rate": 4.271317829457364e-06,
      "loss": 0.0001,
      "step": 11798
    },
    {
      "epoch": 45.73255813953488,
      "grad_norm": 0.0013854221906512976,
      "learning_rate": 4.267441860465117e-06,
      "loss": 0.0001,
      "step": 11799
    },
    {
      "epoch": 45.736434108527135,
      "grad_norm": 0.0009000797290354967,
      "learning_rate": 4.263565891472868e-06,
      "loss": 0.0001,
      "step": 11800
    },
    {
      "epoch": 45.74031007751938,
      "grad_norm": 0.0006622094660997391,
      "learning_rate": 4.259689922480621e-06,
      "loss": 0.0001,
      "step": 11801
    },
    {
      "epoch": 45.74418604651163,
      "grad_norm": 0.0009229565039277077,
      "learning_rate": 4.255813953488372e-06,
      "loss": 0.0001,
      "step": 11802
    },
    {
      "epoch": 45.748062015503876,
      "grad_norm": 0.0006995552685111761,
      "learning_rate": 4.251937984496125e-06,
      "loss": 0.0001,
      "step": 11803
    },
    {
      "epoch": 45.751937984496124,
      "grad_norm": 0.0012492710957303643,
      "learning_rate": 4.248062015503876e-06,
      "loss": 0.0001,
      "step": 11804
    },
    {
      "epoch": 45.75581395348837,
      "grad_norm": 0.0006596185266971588,
      "learning_rate": 4.244186046511628e-06,
      "loss": 0.0001,
      "step": 11805
    },
    {
      "epoch": 45.75968992248062,
      "grad_norm": 0.0008257745648734272,
      "learning_rate": 4.24031007751938e-06,
      "loss": 0.0001,
      "step": 11806
    },
    {
      "epoch": 45.763565891472865,
      "grad_norm": 0.0006581604829989374,
      "learning_rate": 4.236434108527132e-06,
      "loss": 0.0001,
      "step": 11807
    },
    {
      "epoch": 45.76744186046512,
      "grad_norm": 0.0006501317257061601,
      "learning_rate": 4.232558139534884e-06,
      "loss": 0.0001,
      "step": 11808
    },
    {
      "epoch": 45.77131782945737,
      "grad_norm": 0.0008016578503884375,
      "learning_rate": 4.228682170542636e-06,
      "loss": 0.0001,
      "step": 11809
    },
    {
      "epoch": 45.775193798449614,
      "grad_norm": 0.0006658759084530175,
      "learning_rate": 4.224806201550388e-06,
      "loss": 0.0001,
      "step": 11810
    },
    {
      "epoch": 45.77906976744186,
      "grad_norm": 0.0014002133393660188,
      "learning_rate": 4.22093023255814e-06,
      "loss": 0.0001,
      "step": 11811
    },
    {
      "epoch": 45.78294573643411,
      "grad_norm": 0.002798772417008877,
      "learning_rate": 4.217054263565891e-06,
      "loss": 0.0002,
      "step": 11812
    },
    {
      "epoch": 45.786821705426355,
      "grad_norm": 0.0011883272090926766,
      "learning_rate": 4.213178294573644e-06,
      "loss": 0.0001,
      "step": 11813
    },
    {
      "epoch": 45.7906976744186,
      "grad_norm": 0.0037570269778370857,
      "learning_rate": 4.209302325581395e-06,
      "loss": 0.0001,
      "step": 11814
    },
    {
      "epoch": 45.79457364341085,
      "grad_norm": 0.002057974226772785,
      "learning_rate": 4.205426356589148e-06,
      "loss": 0.0002,
      "step": 11815
    },
    {
      "epoch": 45.798449612403104,
      "grad_norm": 0.0007075980538502336,
      "learning_rate": 4.201550387596899e-06,
      "loss": 0.0001,
      "step": 11816
    },
    {
      "epoch": 45.80232558139535,
      "grad_norm": 0.25188377499580383,
      "learning_rate": 4.197674418604652e-06,
      "loss": 0.0101,
      "step": 11817
    },
    {
      "epoch": 45.8062015503876,
      "grad_norm": 0.0008944458677433431,
      "learning_rate": 4.193798449612403e-06,
      "loss": 0.0001,
      "step": 11818
    },
    {
      "epoch": 45.810077519379846,
      "grad_norm": 0.0007625086582265794,
      "learning_rate": 4.189922480620155e-06,
      "loss": 0.0001,
      "step": 11819
    },
    {
      "epoch": 45.81395348837209,
      "grad_norm": 0.0006831726641394198,
      "learning_rate": 4.186046511627907e-06,
      "loss": 0.0001,
      "step": 11820
    },
    {
      "epoch": 45.81782945736434,
      "grad_norm": 0.0006720488308928907,
      "learning_rate": 4.182170542635659e-06,
      "loss": 0.0001,
      "step": 11821
    },
    {
      "epoch": 45.82170542635659,
      "grad_norm": 0.0006416385294869542,
      "learning_rate": 4.178294573643411e-06,
      "loss": 0.0001,
      "step": 11822
    },
    {
      "epoch": 45.825581395348834,
      "grad_norm": 0.0006740671233274043,
      "learning_rate": 4.174418604651163e-06,
      "loss": 0.0001,
      "step": 11823
    },
    {
      "epoch": 45.82945736434109,
      "grad_norm": 0.0006619870546273887,
      "learning_rate": 4.1705426356589144e-06,
      "loss": 0.0001,
      "step": 11824
    },
    {
      "epoch": 45.833333333333336,
      "grad_norm": 0.0011118906550109386,
      "learning_rate": 4.166666666666667e-06,
      "loss": 0.0001,
      "step": 11825
    },
    {
      "epoch": 45.83720930232558,
      "grad_norm": 0.0008253236301243305,
      "learning_rate": 4.1627906976744184e-06,
      "loss": 0.0001,
      "step": 11826
    },
    {
      "epoch": 45.84108527131783,
      "grad_norm": 0.001543541788123548,
      "learning_rate": 4.158914728682171e-06,
      "loss": 0.0001,
      "step": 11827
    },
    {
      "epoch": 45.84496124031008,
      "grad_norm": 0.0007939368369989097,
      "learning_rate": 4.1550387596899224e-06,
      "loss": 0.0001,
      "step": 11828
    },
    {
      "epoch": 45.848837209302324,
      "grad_norm": 0.0007775122066959739,
      "learning_rate": 4.151162790697675e-06,
      "loss": 0.0001,
      "step": 11829
    },
    {
      "epoch": 45.85271317829457,
      "grad_norm": 0.0007965679396875203,
      "learning_rate": 4.1472868217054264e-06,
      "loss": 0.0001,
      "step": 11830
    },
    {
      "epoch": 45.85658914728682,
      "grad_norm": 0.0011396539630368352,
      "learning_rate": 4.143410852713178e-06,
      "loss": 0.0001,
      "step": 11831
    },
    {
      "epoch": 45.86046511627907,
      "grad_norm": 0.0006522210314869881,
      "learning_rate": 4.1395348837209304e-06,
      "loss": 0.0001,
      "step": 11832
    },
    {
      "epoch": 45.86434108527132,
      "grad_norm": 0.0011131647042930126,
      "learning_rate": 4.135658914728682e-06,
      "loss": 0.0001,
      "step": 11833
    },
    {
      "epoch": 45.86821705426357,
      "grad_norm": 0.000693794630933553,
      "learning_rate": 4.1317829457364344e-06,
      "loss": 0.0001,
      "step": 11834
    },
    {
      "epoch": 45.872093023255815,
      "grad_norm": 0.00631001265719533,
      "learning_rate": 4.127906976744186e-06,
      "loss": 0.0002,
      "step": 11835
    },
    {
      "epoch": 45.87596899224806,
      "grad_norm": 0.0007292748778127134,
      "learning_rate": 4.124031007751938e-06,
      "loss": 0.0001,
      "step": 11836
    },
    {
      "epoch": 45.87984496124031,
      "grad_norm": 0.0008768705301918089,
      "learning_rate": 4.120155038759691e-06,
      "loss": 0.0001,
      "step": 11837
    },
    {
      "epoch": 45.883720930232556,
      "grad_norm": 0.0006505319615826011,
      "learning_rate": 4.1162790697674416e-06,
      "loss": 0.0001,
      "step": 11838
    },
    {
      "epoch": 45.8875968992248,
      "grad_norm": 0.0015726096462458372,
      "learning_rate": 4.112403100775194e-06,
      "loss": 0.0001,
      "step": 11839
    },
    {
      "epoch": 45.89147286821706,
      "grad_norm": 0.0009652642183937132,
      "learning_rate": 4.1085271317829456e-06,
      "loss": 0.0001,
      "step": 11840
    },
    {
      "epoch": 45.895348837209305,
      "grad_norm": 0.0010701791616156697,
      "learning_rate": 4.104651162790698e-06,
      "loss": 0.0001,
      "step": 11841
    },
    {
      "epoch": 45.89922480620155,
      "grad_norm": 0.0007160906679928303,
      "learning_rate": 4.1007751937984496e-06,
      "loss": 0.0001,
      "step": 11842
    },
    {
      "epoch": 45.9031007751938,
      "grad_norm": 0.35597407817840576,
      "learning_rate": 4.096899224806202e-06,
      "loss": 0.0154,
      "step": 11843
    },
    {
      "epoch": 45.906976744186046,
      "grad_norm": 0.7328051328659058,
      "learning_rate": 4.0930232558139536e-06,
      "loss": 0.0321,
      "step": 11844
    },
    {
      "epoch": 45.91085271317829,
      "grad_norm": 0.0033697409089654684,
      "learning_rate": 4.089147286821705e-06,
      "loss": 0.0003,
      "step": 11845
    },
    {
      "epoch": 45.91472868217054,
      "grad_norm": 0.0006755935028195381,
      "learning_rate": 4.0852713178294576e-06,
      "loss": 0.0001,
      "step": 11846
    },
    {
      "epoch": 45.91860465116279,
      "grad_norm": 0.0013271268690004945,
      "learning_rate": 4.081395348837209e-06,
      "loss": 0.0001,
      "step": 11847
    },
    {
      "epoch": 45.92248062015504,
      "grad_norm": 0.0008231765241362154,
      "learning_rate": 4.0775193798449616e-06,
      "loss": 0.0001,
      "step": 11848
    },
    {
      "epoch": 45.92635658914729,
      "grad_norm": 0.0016117349732667208,
      "learning_rate": 4.073643410852714e-06,
      "loss": 0.0001,
      "step": 11849
    },
    {
      "epoch": 45.93023255813954,
      "grad_norm": 0.0008228903752751648,
      "learning_rate": 4.0697674418604655e-06,
      "loss": 0.0001,
      "step": 11850
    },
    {
      "epoch": 45.934108527131784,
      "grad_norm": 0.0006673977477476001,
      "learning_rate": 4.065891472868217e-06,
      "loss": 0.0001,
      "step": 11851
    },
    {
      "epoch": 45.93798449612403,
      "grad_norm": 0.011086439713835716,
      "learning_rate": 4.062015503875969e-06,
      "loss": 0.0002,
      "step": 11852
    },
    {
      "epoch": 45.94186046511628,
      "grad_norm": 0.0008156640105880797,
      "learning_rate": 4.058139534883721e-06,
      "loss": 0.0001,
      "step": 11853
    },
    {
      "epoch": 45.945736434108525,
      "grad_norm": 0.0029868651181459427,
      "learning_rate": 4.054263565891473e-06,
      "loss": 0.0002,
      "step": 11854
    },
    {
      "epoch": 45.94961240310077,
      "grad_norm": 0.0008610193617641926,
      "learning_rate": 4.050387596899225e-06,
      "loss": 0.0001,
      "step": 11855
    },
    {
      "epoch": 45.95348837209303,
      "grad_norm": 0.000855811929795891,
      "learning_rate": 4.0465116279069775e-06,
      "loss": 0.0001,
      "step": 11856
    },
    {
      "epoch": 45.957364341085274,
      "grad_norm": 0.0007534167962148786,
      "learning_rate": 4.042635658914729e-06,
      "loss": 0.0001,
      "step": 11857
    },
    {
      "epoch": 45.96124031007752,
      "grad_norm": 0.0013285480672493577,
      "learning_rate": 4.038759689922481e-06,
      "loss": 0.0001,
      "step": 11858
    },
    {
      "epoch": 45.96511627906977,
      "grad_norm": 0.0006471042288467288,
      "learning_rate": 4.034883720930232e-06,
      "loss": 0.0001,
      "step": 11859
    },
    {
      "epoch": 45.968992248062015,
      "grad_norm": 0.0007280444842763245,
      "learning_rate": 4.031007751937985e-06,
      "loss": 0.0001,
      "step": 11860
    },
    {
      "epoch": 45.97286821705426,
      "grad_norm": 0.0006167598767206073,
      "learning_rate": 4.027131782945736e-06,
      "loss": 0.0001,
      "step": 11861
    },
    {
      "epoch": 45.97674418604651,
      "grad_norm": 0.0006858949782326818,
      "learning_rate": 4.023255813953489e-06,
      "loss": 0.0001,
      "step": 11862
    },
    {
      "epoch": 45.98062015503876,
      "grad_norm": 0.0018518076976761222,
      "learning_rate": 4.019379844961241e-06,
      "loss": 0.0002,
      "step": 11863
    },
    {
      "epoch": 45.98449612403101,
      "grad_norm": 0.0008189523359760642,
      "learning_rate": 4.015503875968992e-06,
      "loss": 0.0001,
      "step": 11864
    },
    {
      "epoch": 45.98837209302326,
      "grad_norm": 0.0008554478990845382,
      "learning_rate": 4.011627906976744e-06,
      "loss": 0.0001,
      "step": 11865
    },
    {
      "epoch": 45.992248062015506,
      "grad_norm": 1.616990327835083,
      "learning_rate": 4.007751937984496e-06,
      "loss": 0.0014,
      "step": 11866
    },
    {
      "epoch": 45.99612403100775,
      "grad_norm": 0.0006559530738741159,
      "learning_rate": 4.003875968992248e-06,
      "loss": 0.0001,
      "step": 11867
    },
    {
      "epoch": 46.0,
      "grad_norm": 0.001434789621271193,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0001,
      "step": 11868
    },
    {
      "epoch": 46.00387596899225,
      "grad_norm": 0.6917608380317688,
      "learning_rate": 3.996124031007752e-06,
      "loss": 0.0341,
      "step": 11869
    },
    {
      "epoch": 46.007751937984494,
      "grad_norm": 0.4109325110912323,
      "learning_rate": 3.992248062015505e-06,
      "loss": 0.0169,
      "step": 11870
    },
    {
      "epoch": 46.01162790697674,
      "grad_norm": 0.000694268208462745,
      "learning_rate": 3.988372093023255e-06,
      "loss": 0.0001,
      "step": 11871
    },
    {
      "epoch": 46.01550387596899,
      "grad_norm": 0.002586589427664876,
      "learning_rate": 3.984496124031008e-06,
      "loss": 0.0001,
      "step": 11872
    },
    {
      "epoch": 46.01937984496124,
      "grad_norm": 0.0017419584328308702,
      "learning_rate": 3.980620155038759e-06,
      "loss": 0.0001,
      "step": 11873
    },
    {
      "epoch": 46.02325581395349,
      "grad_norm": 0.20165616273880005,
      "learning_rate": 3.976744186046512e-06,
      "loss": 0.008,
      "step": 11874
    },
    {
      "epoch": 46.02713178294574,
      "grad_norm": 0.002736777998507023,
      "learning_rate": 3.972868217054264e-06,
      "loss": 0.0002,
      "step": 11875
    },
    {
      "epoch": 46.031007751937985,
      "grad_norm": 0.0011017004726454616,
      "learning_rate": 3.968992248062016e-06,
      "loss": 0.0001,
      "step": 11876
    },
    {
      "epoch": 46.03488372093023,
      "grad_norm": 0.000794516468886286,
      "learning_rate": 3.965116279069768e-06,
      "loss": 0.0001,
      "step": 11877
    },
    {
      "epoch": 46.03875968992248,
      "grad_norm": 0.001176712685264647,
      "learning_rate": 3.961240310077519e-06,
      "loss": 0.0001,
      "step": 11878
    },
    {
      "epoch": 46.042635658914726,
      "grad_norm": 0.0005930413026362658,
      "learning_rate": 3.957364341085271e-06,
      "loss": 0.0001,
      "step": 11879
    },
    {
      "epoch": 46.04651162790697,
      "grad_norm": 0.0008733691647648811,
      "learning_rate": 3.953488372093024e-06,
      "loss": 0.0001,
      "step": 11880
    },
    {
      "epoch": 46.05038759689923,
      "grad_norm": 0.0018321670359000564,
      "learning_rate": 3.949612403100775e-06,
      "loss": 0.0001,
      "step": 11881
    },
    {
      "epoch": 46.054263565891475,
      "grad_norm": 0.0007747248164378107,
      "learning_rate": 3.945736434108528e-06,
      "loss": 0.0001,
      "step": 11882
    },
    {
      "epoch": 46.05813953488372,
      "grad_norm": 0.0007779544102959335,
      "learning_rate": 3.941860465116279e-06,
      "loss": 0.0001,
      "step": 11883
    },
    {
      "epoch": 46.06201550387597,
      "grad_norm": 0.0007137200445868075,
      "learning_rate": 3.937984496124031e-06,
      "loss": 0.0001,
      "step": 11884
    },
    {
      "epoch": 46.065891472868216,
      "grad_norm": 0.0007114018662832677,
      "learning_rate": 3.9341085271317825e-06,
      "loss": 0.0001,
      "step": 11885
    },
    {
      "epoch": 46.06976744186046,
      "grad_norm": 0.0005913695204071701,
      "learning_rate": 3.930232558139535e-06,
      "loss": 0.0001,
      "step": 11886
    },
    {
      "epoch": 46.07364341085271,
      "grad_norm": 0.0012952865799888968,
      "learning_rate": 3.926356589147287e-06,
      "loss": 0.0001,
      "step": 11887
    },
    {
      "epoch": 46.07751937984496,
      "grad_norm": 0.0015382050769403577,
      "learning_rate": 3.922480620155039e-06,
      "loss": 0.0001,
      "step": 11888
    },
    {
      "epoch": 46.08139534883721,
      "grad_norm": 0.0006631336873397231,
      "learning_rate": 3.918604651162791e-06,
      "loss": 0.0001,
      "step": 11889
    },
    {
      "epoch": 46.08527131782946,
      "grad_norm": 0.0007250343915075064,
      "learning_rate": 3.914728682170543e-06,
      "loss": 0.0001,
      "step": 11890
    },
    {
      "epoch": 46.08914728682171,
      "grad_norm": 0.0013850264949724078,
      "learning_rate": 3.9108527131782945e-06,
      "loss": 0.0001,
      "step": 11891
    },
    {
      "epoch": 46.093023255813954,
      "grad_norm": 0.0018101715249940753,
      "learning_rate": 3.906976744186047e-06,
      "loss": 0.0001,
      "step": 11892
    },
    {
      "epoch": 46.0968992248062,
      "grad_norm": 0.0007260595448315144,
      "learning_rate": 3.9031007751937985e-06,
      "loss": 0.0001,
      "step": 11893
    },
    {
      "epoch": 46.10077519379845,
      "grad_norm": 0.0007206996669992805,
      "learning_rate": 3.899224806201551e-06,
      "loss": 0.0001,
      "step": 11894
    },
    {
      "epoch": 46.104651162790695,
      "grad_norm": 0.0007506749243475497,
      "learning_rate": 3.8953488372093025e-06,
      "loss": 0.0001,
      "step": 11895
    },
    {
      "epoch": 46.10852713178294,
      "grad_norm": 0.0007753490353934467,
      "learning_rate": 3.891472868217055e-06,
      "loss": 0.0001,
      "step": 11896
    },
    {
      "epoch": 46.1124031007752,
      "grad_norm": 0.0008785170502960682,
      "learning_rate": 3.8875968992248065e-06,
      "loss": 0.0001,
      "step": 11897
    },
    {
      "epoch": 46.116279069767444,
      "grad_norm": 0.0009182344656437635,
      "learning_rate": 3.883720930232558e-06,
      "loss": 0.0001,
      "step": 11898
    },
    {
      "epoch": 46.12015503875969,
      "grad_norm": 0.0006814077496528625,
      "learning_rate": 3.8798449612403105e-06,
      "loss": 0.0001,
      "step": 11899
    },
    {
      "epoch": 46.12403100775194,
      "grad_norm": 0.0012964359484612942,
      "learning_rate": 3.875968992248062e-06,
      "loss": 0.0001,
      "step": 11900
    },
    {
      "epoch": 46.127906976744185,
      "grad_norm": 0.003409824799746275,
      "learning_rate": 3.8720930232558145e-06,
      "loss": 0.0002,
      "step": 11901
    },
    {
      "epoch": 46.13178294573643,
      "grad_norm": 0.0010708076879382133,
      "learning_rate": 3.868217054263566e-06,
      "loss": 0.0001,
      "step": 11902
    },
    {
      "epoch": 46.13565891472868,
      "grad_norm": 0.0007189690368250012,
      "learning_rate": 3.8643410852713185e-06,
      "loss": 0.0001,
      "step": 11903
    },
    {
      "epoch": 46.13953488372093,
      "grad_norm": 2.191020965576172,
      "learning_rate": 3.860465116279069e-06,
      "loss": 0.1522,
      "step": 11904
    },
    {
      "epoch": 46.14341085271318,
      "grad_norm": 0.0006982188788242638,
      "learning_rate": 3.856589147286822e-06,
      "loss": 0.0001,
      "step": 11905
    },
    {
      "epoch": 46.14728682170543,
      "grad_norm": 0.0007774304831400514,
      "learning_rate": 3.852713178294574e-06,
      "loss": 0.0001,
      "step": 11906
    },
    {
      "epoch": 46.151162790697676,
      "grad_norm": 0.001021391013637185,
      "learning_rate": 3.848837209302326e-06,
      "loss": 0.0001,
      "step": 11907
    },
    {
      "epoch": 46.15503875968992,
      "grad_norm": 0.004006972070783377,
      "learning_rate": 3.844961240310078e-06,
      "loss": 0.0002,
      "step": 11908
    },
    {
      "epoch": 46.15891472868217,
      "grad_norm": 0.0013624917482957244,
      "learning_rate": 3.84108527131783e-06,
      "loss": 0.0001,
      "step": 11909
    },
    {
      "epoch": 46.16279069767442,
      "grad_norm": 0.0007285953033715487,
      "learning_rate": 3.837209302325582e-06,
      "loss": 0.0001,
      "step": 11910
    },
    {
      "epoch": 46.166666666666664,
      "grad_norm": 0.0008114023949019611,
      "learning_rate": 3.833333333333334e-06,
      "loss": 0.0001,
      "step": 11911
    },
    {
      "epoch": 46.17054263565891,
      "grad_norm": 0.0006835442618466914,
      "learning_rate": 3.829457364341085e-06,
      "loss": 0.0001,
      "step": 11912
    },
    {
      "epoch": 46.174418604651166,
      "grad_norm": 0.002711768262088299,
      "learning_rate": 3.825581395348838e-06,
      "loss": 0.0002,
      "step": 11913
    },
    {
      "epoch": 46.17829457364341,
      "grad_norm": 0.0007606834406033158,
      "learning_rate": 3.821705426356589e-06,
      "loss": 0.0001,
      "step": 11914
    },
    {
      "epoch": 46.18217054263566,
      "grad_norm": 0.0010159903904423118,
      "learning_rate": 3.817829457364342e-06,
      "loss": 0.0001,
      "step": 11915
    },
    {
      "epoch": 46.18604651162791,
      "grad_norm": 0.001466683461330831,
      "learning_rate": 3.8139534883720936e-06,
      "loss": 0.0001,
      "step": 11916
    },
    {
      "epoch": 46.189922480620154,
      "grad_norm": 2.659454822540283,
      "learning_rate": 3.8100775193798456e-06,
      "loss": 0.2467,
      "step": 11917
    },
    {
      "epoch": 46.1937984496124,
      "grad_norm": 0.0014816396869719028,
      "learning_rate": 3.8062015503875968e-06,
      "loss": 0.0001,
      "step": 11918
    },
    {
      "epoch": 46.19767441860465,
      "grad_norm": 0.0007265752647072077,
      "learning_rate": 3.8023255813953488e-06,
      "loss": 0.0001,
      "step": 11919
    },
    {
      "epoch": 46.201550387596896,
      "grad_norm": 0.001803255290724337,
      "learning_rate": 3.7984496124031008e-06,
      "loss": 0.0002,
      "step": 11920
    },
    {
      "epoch": 46.20542635658915,
      "grad_norm": 0.0010354055557399988,
      "learning_rate": 3.7945736434108528e-06,
      "loss": 0.0001,
      "step": 11921
    },
    {
      "epoch": 46.2093023255814,
      "grad_norm": 0.0013223355636000633,
      "learning_rate": 3.790697674418605e-06,
      "loss": 0.0001,
      "step": 11922
    },
    {
      "epoch": 46.213178294573645,
      "grad_norm": 0.0006992902490310371,
      "learning_rate": 3.786821705426357e-06,
      "loss": 0.0001,
      "step": 11923
    },
    {
      "epoch": 46.21705426356589,
      "grad_norm": 0.0007286412874236703,
      "learning_rate": 3.7829457364341083e-06,
      "loss": 0.0001,
      "step": 11924
    },
    {
      "epoch": 46.22093023255814,
      "grad_norm": 0.0007084496319293976,
      "learning_rate": 3.7790697674418603e-06,
      "loss": 0.0001,
      "step": 11925
    },
    {
      "epoch": 46.224806201550386,
      "grad_norm": 0.0007112163002602756,
      "learning_rate": 3.7751937984496123e-06,
      "loss": 0.0001,
      "step": 11926
    },
    {
      "epoch": 46.22868217054263,
      "grad_norm": 0.0006787899765186012,
      "learning_rate": 3.7713178294573643e-06,
      "loss": 0.0001,
      "step": 11927
    },
    {
      "epoch": 46.23255813953488,
      "grad_norm": 0.0011443404946476221,
      "learning_rate": 3.7674418604651167e-06,
      "loss": 0.0001,
      "step": 11928
    },
    {
      "epoch": 46.236434108527135,
      "grad_norm": 0.0008064078283496201,
      "learning_rate": 3.7635658914728687e-06,
      "loss": 0.0001,
      "step": 11929
    },
    {
      "epoch": 46.24031007751938,
      "grad_norm": 0.0006245620897971094,
      "learning_rate": 3.7596899224806207e-06,
      "loss": 0.0001,
      "step": 11930
    },
    {
      "epoch": 46.24418604651163,
      "grad_norm": 0.0008371989824809134,
      "learning_rate": 3.755813953488372e-06,
      "loss": 0.0001,
      "step": 11931
    },
    {
      "epoch": 46.248062015503876,
      "grad_norm": 0.0007483086083084345,
      "learning_rate": 3.751937984496124e-06,
      "loss": 0.0001,
      "step": 11932
    },
    {
      "epoch": 46.251937984496124,
      "grad_norm": 0.0007789283990859985,
      "learning_rate": 3.748062015503876e-06,
      "loss": 0.0001,
      "step": 11933
    },
    {
      "epoch": 46.25581395348837,
      "grad_norm": 0.002585345646366477,
      "learning_rate": 3.7441860465116283e-06,
      "loss": 0.0002,
      "step": 11934
    },
    {
      "epoch": 46.25968992248062,
      "grad_norm": 60.590511322021484,
      "learning_rate": 3.7403100775193803e-06,
      "loss": 0.0058,
      "step": 11935
    },
    {
      "epoch": 46.263565891472865,
      "grad_norm": 0.0011046315776184201,
      "learning_rate": 3.7364341085271323e-06,
      "loss": 0.0001,
      "step": 11936
    },
    {
      "epoch": 46.26744186046512,
      "grad_norm": 0.0006657615886069834,
      "learning_rate": 3.7325581395348843e-06,
      "loss": 0.0001,
      "step": 11937
    },
    {
      "epoch": 46.27131782945737,
      "grad_norm": 0.0007864792132750154,
      "learning_rate": 3.7286821705426354e-06,
      "loss": 0.0001,
      "step": 11938
    },
    {
      "epoch": 46.275193798449614,
      "grad_norm": 0.0006718082586303353,
      "learning_rate": 3.7248062015503874e-06,
      "loss": 0.0001,
      "step": 11939
    },
    {
      "epoch": 46.27906976744186,
      "grad_norm": 0.000714384310413152,
      "learning_rate": 3.72093023255814e-06,
      "loss": 0.0001,
      "step": 11940
    },
    {
      "epoch": 46.28294573643411,
      "grad_norm": 0.0010805778438225389,
      "learning_rate": 3.717054263565892e-06,
      "loss": 0.0001,
      "step": 11941
    },
    {
      "epoch": 46.286821705426355,
      "grad_norm": 0.0010227513266727328,
      "learning_rate": 3.713178294573644e-06,
      "loss": 0.0001,
      "step": 11942
    },
    {
      "epoch": 46.2906976744186,
      "grad_norm": 0.000696430157404393,
      "learning_rate": 3.709302325581396e-06,
      "loss": 0.0001,
      "step": 11943
    },
    {
      "epoch": 46.29457364341085,
      "grad_norm": 0.6818550229072571,
      "learning_rate": 3.705426356589147e-06,
      "loss": 0.0375,
      "step": 11944
    },
    {
      "epoch": 46.298449612403104,
      "grad_norm": 0.0006981771439313889,
      "learning_rate": 3.701550387596899e-06,
      "loss": 0.0001,
      "step": 11945
    },
    {
      "epoch": 46.30232558139535,
      "grad_norm": 0.03914470225572586,
      "learning_rate": 3.697674418604651e-06,
      "loss": 0.0009,
      "step": 11946
    },
    {
      "epoch": 46.3062015503876,
      "grad_norm": 0.0007832198753021657,
      "learning_rate": 3.6937984496124034e-06,
      "loss": 0.0001,
      "step": 11947
    },
    {
      "epoch": 46.310077519379846,
      "grad_norm": 0.0064324974082410336,
      "learning_rate": 3.6899224806201554e-06,
      "loss": 0.0001,
      "step": 11948
    },
    {
      "epoch": 46.31395348837209,
      "grad_norm": 0.000647758599370718,
      "learning_rate": 3.6860465116279074e-06,
      "loss": 0.0001,
      "step": 11949
    },
    {
      "epoch": 46.31782945736434,
      "grad_norm": 0.02967132069170475,
      "learning_rate": 3.6821705426356594e-06,
      "loss": 0.0003,
      "step": 11950
    },
    {
      "epoch": 46.32170542635659,
      "grad_norm": 0.0009818568360060453,
      "learning_rate": 3.6782945736434106e-06,
      "loss": 0.0001,
      "step": 11951
    },
    {
      "epoch": 46.325581395348834,
      "grad_norm": 0.0012743144761770964,
      "learning_rate": 3.6744186046511626e-06,
      "loss": 0.0001,
      "step": 11952
    },
    {
      "epoch": 46.32945736434109,
      "grad_norm": 0.0014448213623836637,
      "learning_rate": 3.670542635658915e-06,
      "loss": 0.0001,
      "step": 11953
    },
    {
      "epoch": 46.333333333333336,
      "grad_norm": 0.0019157867645844817,
      "learning_rate": 3.666666666666667e-06,
      "loss": 0.0001,
      "step": 11954
    },
    {
      "epoch": 46.33720930232558,
      "grad_norm": 0.00075615692185238,
      "learning_rate": 3.662790697674419e-06,
      "loss": 0.0001,
      "step": 11955
    },
    {
      "epoch": 46.34108527131783,
      "grad_norm": 0.001547935069538653,
      "learning_rate": 3.658914728682171e-06,
      "loss": 0.0001,
      "step": 11956
    },
    {
      "epoch": 46.34496124031008,
      "grad_norm": 0.0010375407291576266,
      "learning_rate": 3.655038759689923e-06,
      "loss": 0.0001,
      "step": 11957
    },
    {
      "epoch": 46.348837209302324,
      "grad_norm": 0.0014922716654837132,
      "learning_rate": 3.651162790697674e-06,
      "loss": 0.0001,
      "step": 11958
    },
    {
      "epoch": 46.35271317829457,
      "grad_norm": 0.0006305213901214302,
      "learning_rate": 3.6472868217054266e-06,
      "loss": 0.0001,
      "step": 11959
    },
    {
      "epoch": 46.35658914728682,
      "grad_norm": 0.0021115229465067387,
      "learning_rate": 3.6434108527131786e-06,
      "loss": 0.0002,
      "step": 11960
    },
    {
      "epoch": 46.36046511627907,
      "grad_norm": 0.0013284466695040464,
      "learning_rate": 3.6395348837209306e-06,
      "loss": 0.0001,
      "step": 11961
    },
    {
      "epoch": 46.36434108527132,
      "grad_norm": 0.0006971392431296408,
      "learning_rate": 3.6356589147286826e-06,
      "loss": 0.0001,
      "step": 11962
    },
    {
      "epoch": 46.36821705426357,
      "grad_norm": 0.004129850305616856,
      "learning_rate": 3.6317829457364346e-06,
      "loss": 0.0002,
      "step": 11963
    },
    {
      "epoch": 46.372093023255815,
      "grad_norm": 0.01978548988699913,
      "learning_rate": 3.6279069767441857e-06,
      "loss": 0.0006,
      "step": 11964
    },
    {
      "epoch": 46.37596899224806,
      "grad_norm": 0.0007380038732662797,
      "learning_rate": 3.624031007751938e-06,
      "loss": 0.0001,
      "step": 11965
    },
    {
      "epoch": 46.37984496124031,
      "grad_norm": 0.0012760063400492072,
      "learning_rate": 3.62015503875969e-06,
      "loss": 0.0001,
      "step": 11966
    },
    {
      "epoch": 46.383720930232556,
      "grad_norm": 0.0006555254803970456,
      "learning_rate": 3.616279069767442e-06,
      "loss": 0.0001,
      "step": 11967
    },
    {
      "epoch": 46.3875968992248,
      "grad_norm": 0.0009601523051969707,
      "learning_rate": 3.612403100775194e-06,
      "loss": 0.0001,
      "step": 11968
    },
    {
      "epoch": 46.39147286821706,
      "grad_norm": 0.0009482568711973727,
      "learning_rate": 3.608527131782946e-06,
      "loss": 0.0001,
      "step": 11969
    },
    {
      "epoch": 46.395348837209305,
      "grad_norm": 0.0006155204027891159,
      "learning_rate": 3.604651162790698e-06,
      "loss": 0.0001,
      "step": 11970
    },
    {
      "epoch": 46.39922480620155,
      "grad_norm": 0.000846767274197191,
      "learning_rate": 3.6007751937984497e-06,
      "loss": 0.0001,
      "step": 11971
    },
    {
      "epoch": 46.4031007751938,
      "grad_norm": 0.0008796483161859214,
      "learning_rate": 3.5968992248062017e-06,
      "loss": 0.0001,
      "step": 11972
    },
    {
      "epoch": 46.406976744186046,
      "grad_norm": 0.0009621538920328021,
      "learning_rate": 3.5930232558139537e-06,
      "loss": 0.0001,
      "step": 11973
    },
    {
      "epoch": 46.41085271317829,
      "grad_norm": 0.0053979502990841866,
      "learning_rate": 3.5891472868217057e-06,
      "loss": 0.0002,
      "step": 11974
    },
    {
      "epoch": 46.41472868217054,
      "grad_norm": 0.0008795528556220233,
      "learning_rate": 3.5852713178294577e-06,
      "loss": 0.0001,
      "step": 11975
    },
    {
      "epoch": 46.41860465116279,
      "grad_norm": 0.0006121813785284758,
      "learning_rate": 3.5813953488372097e-06,
      "loss": 0.0001,
      "step": 11976
    },
    {
      "epoch": 46.42248062015504,
      "grad_norm": 0.0007630676846019924,
      "learning_rate": 3.5775193798449617e-06,
      "loss": 0.0001,
      "step": 11977
    },
    {
      "epoch": 46.42635658914729,
      "grad_norm": 0.0007998667424544692,
      "learning_rate": 3.5736434108527133e-06,
      "loss": 0.0001,
      "step": 11978
    },
    {
      "epoch": 46.43023255813954,
      "grad_norm": 0.0006376327364705503,
      "learning_rate": 3.5697674418604653e-06,
      "loss": 0.0001,
      "step": 11979
    },
    {
      "epoch": 46.434108527131784,
      "grad_norm": 0.0006565892254002392,
      "learning_rate": 3.5658914728682173e-06,
      "loss": 0.0001,
      "step": 11980
    },
    {
      "epoch": 46.43798449612403,
      "grad_norm": 0.5021308064460754,
      "learning_rate": 3.5620155038759692e-06,
      "loss": 0.0229,
      "step": 11981
    },
    {
      "epoch": 46.44186046511628,
      "grad_norm": 0.000703857745975256,
      "learning_rate": 3.5581395348837212e-06,
      "loss": 0.0001,
      "step": 11982
    },
    {
      "epoch": 46.445736434108525,
      "grad_norm": 0.7870453596115112,
      "learning_rate": 3.5542635658914732e-06,
      "loss": 0.0427,
      "step": 11983
    },
    {
      "epoch": 46.44961240310077,
      "grad_norm": 0.0017304380889981985,
      "learning_rate": 3.550387596899225e-06,
      "loss": 0.0001,
      "step": 11984
    },
    {
      "epoch": 46.45348837209303,
      "grad_norm": 0.0010410267859697342,
      "learning_rate": 3.546511627906977e-06,
      "loss": 0.0001,
      "step": 11985
    },
    {
      "epoch": 46.457364341085274,
      "grad_norm": 0.0033229785040020943,
      "learning_rate": 3.542635658914729e-06,
      "loss": 0.0002,
      "step": 11986
    },
    {
      "epoch": 46.46124031007752,
      "grad_norm": 0.0010265758028253913,
      "learning_rate": 3.538759689922481e-06,
      "loss": 0.0001,
      "step": 11987
    },
    {
      "epoch": 46.46511627906977,
      "grad_norm": 0.0008913771598599851,
      "learning_rate": 3.534883720930233e-06,
      "loss": 0.0001,
      "step": 11988
    },
    {
      "epoch": 46.468992248062015,
      "grad_norm": 0.0008929498144425452,
      "learning_rate": 3.531007751937985e-06,
      "loss": 0.0001,
      "step": 11989
    },
    {
      "epoch": 46.47286821705426,
      "grad_norm": 0.002226141281425953,
      "learning_rate": 3.527131782945737e-06,
      "loss": 0.0002,
      "step": 11990
    },
    {
      "epoch": 46.47674418604651,
      "grad_norm": 0.0007173495832830667,
      "learning_rate": 3.5232558139534884e-06,
      "loss": 0.0001,
      "step": 11991
    },
    {
      "epoch": 46.48062015503876,
      "grad_norm": 0.005818716250360012,
      "learning_rate": 3.5193798449612404e-06,
      "loss": 0.0002,
      "step": 11992
    },
    {
      "epoch": 46.48449612403101,
      "grad_norm": 0.0006907675415277481,
      "learning_rate": 3.5155038759689924e-06,
      "loss": 0.0001,
      "step": 11993
    },
    {
      "epoch": 46.48837209302326,
      "grad_norm": 0.0008251431863754988,
      "learning_rate": 3.5116279069767444e-06,
      "loss": 0.0001,
      "step": 11994
    },
    {
      "epoch": 46.492248062015506,
      "grad_norm": 0.0005762469954788685,
      "learning_rate": 3.5077519379844964e-06,
      "loss": 0.0001,
      "step": 11995
    },
    {
      "epoch": 46.49612403100775,
      "grad_norm": 0.0008159030112437904,
      "learning_rate": 3.5038759689922484e-06,
      "loss": 0.0001,
      "step": 11996
    },
    {
      "epoch": 46.5,
      "grad_norm": 0.002575080841779709,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.0002,
      "step": 11997
    },
    {
      "epoch": 46.50387596899225,
      "grad_norm": 0.0009165393421426415,
      "learning_rate": 3.496124031007752e-06,
      "loss": 0.0001,
      "step": 11998
    },
    {
      "epoch": 46.507751937984494,
      "grad_norm": 0.0008712282869964838,
      "learning_rate": 3.492248062015504e-06,
      "loss": 0.0001,
      "step": 11999
    },
    {
      "epoch": 46.51162790697674,
      "grad_norm": 0.0006562443450093269,
      "learning_rate": 3.488372093023256e-06,
      "loss": 0.0001,
      "step": 12000
    },
    {
      "epoch": 46.51550387596899,
      "grad_norm": 0.000665020605083555,
      "learning_rate": 3.484496124031008e-06,
      "loss": 0.0001,
      "step": 12001
    },
    {
      "epoch": 46.51937984496124,
      "grad_norm": 0.0017067663138732314,
      "learning_rate": 3.48062015503876e-06,
      "loss": 0.0001,
      "step": 12002
    },
    {
      "epoch": 46.52325581395349,
      "grad_norm": 0.0017382220830768347,
      "learning_rate": 3.476744186046512e-06,
      "loss": 0.0001,
      "step": 12003
    },
    {
      "epoch": 46.52713178294574,
      "grad_norm": 0.0008775514434091747,
      "learning_rate": 3.4728682170542635e-06,
      "loss": 0.0001,
      "step": 12004
    },
    {
      "epoch": 46.531007751937985,
      "grad_norm": 0.0008364939712919295,
      "learning_rate": 3.4689922480620155e-06,
      "loss": 0.0001,
      "step": 12005
    },
    {
      "epoch": 46.53488372093023,
      "grad_norm": 0.0007110601873137057,
      "learning_rate": 3.4651162790697675e-06,
      "loss": 0.0001,
      "step": 12006
    },
    {
      "epoch": 46.53875968992248,
      "grad_norm": 0.0007273005321621895,
      "learning_rate": 3.4612403100775195e-06,
      "loss": 0.0001,
      "step": 12007
    },
    {
      "epoch": 46.542635658914726,
      "grad_norm": 0.0005999009008519351,
      "learning_rate": 3.4573643410852715e-06,
      "loss": 0.0001,
      "step": 12008
    },
    {
      "epoch": 46.54651162790697,
      "grad_norm": 0.0007264922605827451,
      "learning_rate": 3.4534883720930235e-06,
      "loss": 0.0001,
      "step": 12009
    },
    {
      "epoch": 46.55038759689923,
      "grad_norm": 0.21024766564369202,
      "learning_rate": 3.4496124031007755e-06,
      "loss": 0.0083,
      "step": 12010
    },
    {
      "epoch": 46.554263565891475,
      "grad_norm": 0.0007089504506438971,
      "learning_rate": 3.445736434108527e-06,
      "loss": 0.0001,
      "step": 12011
    },
    {
      "epoch": 46.55813953488372,
      "grad_norm": 0.00136176950763911,
      "learning_rate": 3.441860465116279e-06,
      "loss": 0.0001,
      "step": 12012
    },
    {
      "epoch": 46.56201550387597,
      "grad_norm": 0.0008421040838584304,
      "learning_rate": 3.437984496124031e-06,
      "loss": 0.0001,
      "step": 12013
    },
    {
      "epoch": 46.565891472868216,
      "grad_norm": 0.00156764208804816,
      "learning_rate": 3.434108527131783e-06,
      "loss": 0.0001,
      "step": 12014
    },
    {
      "epoch": 46.56976744186046,
      "grad_norm": 0.0006755620124749839,
      "learning_rate": 3.430232558139535e-06,
      "loss": 0.0001,
      "step": 12015
    },
    {
      "epoch": 46.57364341085271,
      "grad_norm": 0.001339947571977973,
      "learning_rate": 3.426356589147287e-06,
      "loss": 0.0001,
      "step": 12016
    },
    {
      "epoch": 46.57751937984496,
      "grad_norm": 0.0006585723604075611,
      "learning_rate": 3.422480620155039e-06,
      "loss": 0.0001,
      "step": 12017
    },
    {
      "epoch": 46.58139534883721,
      "grad_norm": 0.000648499873932451,
      "learning_rate": 3.4186046511627906e-06,
      "loss": 0.0001,
      "step": 12018
    },
    {
      "epoch": 46.58527131782946,
      "grad_norm": 0.0018053032690659165,
      "learning_rate": 3.4147286821705426e-06,
      "loss": 0.0001,
      "step": 12019
    },
    {
      "epoch": 46.58914728682171,
      "grad_norm": 0.0012832245556637645,
      "learning_rate": 3.4108527131782946e-06,
      "loss": 0.0001,
      "step": 12020
    },
    {
      "epoch": 46.593023255813954,
      "grad_norm": 0.0011547483736649156,
      "learning_rate": 3.4069767441860466e-06,
      "loss": 0.0001,
      "step": 12021
    },
    {
      "epoch": 46.5968992248062,
      "grad_norm": 0.001706305774860084,
      "learning_rate": 3.4031007751937986e-06,
      "loss": 0.0002,
      "step": 12022
    },
    {
      "epoch": 46.60077519379845,
      "grad_norm": 0.001620397437363863,
      "learning_rate": 3.3992248062015506e-06,
      "loss": 0.0002,
      "step": 12023
    },
    {
      "epoch": 46.604651162790695,
      "grad_norm": 7.528524875640869,
      "learning_rate": 3.395348837209302e-06,
      "loss": 0.9735,
      "step": 12024
    },
    {
      "epoch": 46.60852713178294,
      "grad_norm": 0.00137708627153188,
      "learning_rate": 3.391472868217054e-06,
      "loss": 0.0001,
      "step": 12025
    },
    {
      "epoch": 46.6124031007752,
      "grad_norm": 0.26474595069885254,
      "learning_rate": 3.387596899224806e-06,
      "loss": 0.0105,
      "step": 12026
    },
    {
      "epoch": 46.616279069767444,
      "grad_norm": 0.008367998525500298,
      "learning_rate": 3.383720930232558e-06,
      "loss": 0.0002,
      "step": 12027
    },
    {
      "epoch": 46.62015503875969,
      "grad_norm": 0.000898970291018486,
      "learning_rate": 3.37984496124031e-06,
      "loss": 0.0001,
      "step": 12028
    },
    {
      "epoch": 46.62403100775194,
      "grad_norm": 0.0017025403212755919,
      "learning_rate": 3.375968992248062e-06,
      "loss": 0.0001,
      "step": 12029
    },
    {
      "epoch": 46.627906976744185,
      "grad_norm": 0.0011039149248972535,
      "learning_rate": 3.3720930232558146e-06,
      "loss": 0.0001,
      "step": 12030
    },
    {
      "epoch": 46.63178294573643,
      "grad_norm": 0.0011814855970442295,
      "learning_rate": 3.3682170542635658e-06,
      "loss": 0.0001,
      "step": 12031
    },
    {
      "epoch": 46.63565891472868,
      "grad_norm": 0.0006117623415775597,
      "learning_rate": 3.3643410852713178e-06,
      "loss": 0.0001,
      "step": 12032
    },
    {
      "epoch": 46.63953488372093,
      "grad_norm": 0.001207419903948903,
      "learning_rate": 3.3604651162790698e-06,
      "loss": 0.0001,
      "step": 12033
    },
    {
      "epoch": 46.64341085271318,
      "grad_norm": 0.0021204573567956686,
      "learning_rate": 3.3565891472868218e-06,
      "loss": 0.0002,
      "step": 12034
    },
    {
      "epoch": 46.64728682170543,
      "grad_norm": 0.0007098194910213351,
      "learning_rate": 3.3527131782945738e-06,
      "loss": 0.0001,
      "step": 12035
    },
    {
      "epoch": 46.651162790697676,
      "grad_norm": 0.0009286314598284662,
      "learning_rate": 3.348837209302326e-06,
      "loss": 0.0001,
      "step": 12036
    },
    {
      "epoch": 46.65503875968992,
      "grad_norm": 0.0008622067398391664,
      "learning_rate": 3.344961240310078e-06,
      "loss": 0.0001,
      "step": 12037
    },
    {
      "epoch": 46.65891472868217,
      "grad_norm": 0.0013540913350880146,
      "learning_rate": 3.3410852713178293e-06,
      "loss": 0.0001,
      "step": 12038
    },
    {
      "epoch": 46.66279069767442,
      "grad_norm": 0.0006306766299530864,
      "learning_rate": 3.3372093023255813e-06,
      "loss": 0.0001,
      "step": 12039
    },
    {
      "epoch": 46.666666666666664,
      "grad_norm": 0.001064796233549714,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.0001,
      "step": 12040
    },
    {
      "epoch": 46.67054263565891,
      "grad_norm": 0.0012466388288885355,
      "learning_rate": 3.3294573643410853e-06,
      "loss": 0.0001,
      "step": 12041
    },
    {
      "epoch": 46.674418604651166,
      "grad_norm": 0.0007473159348592162,
      "learning_rate": 3.3255813953488373e-06,
      "loss": 0.0001,
      "step": 12042
    },
    {
      "epoch": 46.67829457364341,
      "grad_norm": 0.0006916699931025505,
      "learning_rate": 3.3217054263565897e-06,
      "loss": 0.0001,
      "step": 12043
    },
    {
      "epoch": 46.68217054263566,
      "grad_norm": 0.0018445748137310147,
      "learning_rate": 3.317829457364341e-06,
      "loss": 0.0002,
      "step": 12044
    },
    {
      "epoch": 46.68604651162791,
      "grad_norm": 0.0007881109486334026,
      "learning_rate": 3.313953488372093e-06,
      "loss": 0.0001,
      "step": 12045
    },
    {
      "epoch": 46.689922480620154,
      "grad_norm": 0.0006811550701968372,
      "learning_rate": 3.310077519379845e-06,
      "loss": 0.0001,
      "step": 12046
    },
    {
      "epoch": 46.6937984496124,
      "grad_norm": 0.0006565123912878335,
      "learning_rate": 3.306201550387597e-06,
      "loss": 0.0001,
      "step": 12047
    },
    {
      "epoch": 46.69767441860465,
      "grad_norm": 0.0010673142969608307,
      "learning_rate": 3.302325581395349e-06,
      "loss": 0.0001,
      "step": 12048
    },
    {
      "epoch": 46.701550387596896,
      "grad_norm": 0.0006465944461524487,
      "learning_rate": 3.2984496124031013e-06,
      "loss": 0.0001,
      "step": 12049
    },
    {
      "epoch": 46.70542635658915,
      "grad_norm": 0.0007279911660589278,
      "learning_rate": 3.2945736434108533e-06,
      "loss": 0.0001,
      "step": 12050
    },
    {
      "epoch": 46.7093023255814,
      "grad_norm": 0.001423100009560585,
      "learning_rate": 3.2906976744186045e-06,
      "loss": 0.0001,
      "step": 12051
    },
    {
      "epoch": 46.713178294573645,
      "grad_norm": 0.0007473843870684505,
      "learning_rate": 3.2868217054263565e-06,
      "loss": 0.0001,
      "step": 12052
    },
    {
      "epoch": 46.71705426356589,
      "grad_norm": 0.0007963215466588736,
      "learning_rate": 3.2829457364341085e-06,
      "loss": 0.0001,
      "step": 12053
    },
    {
      "epoch": 46.72093023255814,
      "grad_norm": 0.0007488087867386639,
      "learning_rate": 3.2790697674418604e-06,
      "loss": 0.0001,
      "step": 12054
    },
    {
      "epoch": 46.724806201550386,
      "grad_norm": 0.020320968702435493,
      "learning_rate": 3.275193798449613e-06,
      "loss": 0.0002,
      "step": 12055
    },
    {
      "epoch": 46.72868217054263,
      "grad_norm": 0.0012225592508912086,
      "learning_rate": 3.271317829457365e-06,
      "loss": 0.0001,
      "step": 12056
    },
    {
      "epoch": 46.73255813953488,
      "grad_norm": 0.03025073930621147,
      "learning_rate": 3.267441860465117e-06,
      "loss": 0.0012,
      "step": 12057
    },
    {
      "epoch": 46.736434108527135,
      "grad_norm": 0.06379420310258865,
      "learning_rate": 3.263565891472868e-06,
      "loss": 0.0002,
      "step": 12058
    },
    {
      "epoch": 46.74031007751938,
      "grad_norm": 5.826396942138672,
      "learning_rate": 3.25968992248062e-06,
      "loss": 0.5637,
      "step": 12059
    },
    {
      "epoch": 46.74418604651163,
      "grad_norm": 0.00147989671677351,
      "learning_rate": 3.255813953488372e-06,
      "loss": 0.0001,
      "step": 12060
    },
    {
      "epoch": 46.748062015503876,
      "grad_norm": 0.0009883481543511152,
      "learning_rate": 3.2519379844961244e-06,
      "loss": 0.0001,
      "step": 12061
    },
    {
      "epoch": 46.751937984496124,
      "grad_norm": 0.006186539772897959,
      "learning_rate": 3.2480620155038764e-06,
      "loss": 0.0001,
      "step": 12062
    },
    {
      "epoch": 46.75581395348837,
      "grad_norm": 0.0010143673280254006,
      "learning_rate": 3.2441860465116284e-06,
      "loss": 0.0001,
      "step": 12063
    },
    {
      "epoch": 46.75968992248062,
      "grad_norm": 0.0015264243120327592,
      "learning_rate": 3.2403100775193796e-06,
      "loss": 0.0001,
      "step": 12064
    },
    {
      "epoch": 46.763565891472865,
      "grad_norm": 0.3370387554168701,
      "learning_rate": 3.2364341085271316e-06,
      "loss": 0.0141,
      "step": 12065
    },
    {
      "epoch": 46.76744186046512,
      "grad_norm": 0.0007894728914834559,
      "learning_rate": 3.2325581395348836e-06,
      "loss": 0.0001,
      "step": 12066
    },
    {
      "epoch": 46.77131782945737,
      "grad_norm": 0.0007472365396097302,
      "learning_rate": 3.228682170542636e-06,
      "loss": 0.0001,
      "step": 12067
    },
    {
      "epoch": 46.775193798449614,
      "grad_norm": 0.0007517001358792186,
      "learning_rate": 3.224806201550388e-06,
      "loss": 0.0001,
      "step": 12068
    },
    {
      "epoch": 46.77906976744186,
      "grad_norm": 0.004483475815504789,
      "learning_rate": 3.22093023255814e-06,
      "loss": 0.0002,
      "step": 12069
    },
    {
      "epoch": 46.78294573643411,
      "grad_norm": 0.0007571743335574865,
      "learning_rate": 3.217054263565892e-06,
      "loss": 0.0001,
      "step": 12070
    },
    {
      "epoch": 46.786821705426355,
      "grad_norm": 0.0006419260753318667,
      "learning_rate": 3.213178294573643e-06,
      "loss": 0.0001,
      "step": 12071
    },
    {
      "epoch": 46.7906976744186,
      "grad_norm": 0.0032578834798187017,
      "learning_rate": 3.209302325581395e-06,
      "loss": 0.0001,
      "step": 12072
    },
    {
      "epoch": 46.79457364341085,
      "grad_norm": 0.001274983282200992,
      "learning_rate": 3.2054263565891476e-06,
      "loss": 0.0001,
      "step": 12073
    },
    {
      "epoch": 46.798449612403104,
      "grad_norm": 0.0006462994497269392,
      "learning_rate": 3.2015503875968996e-06,
      "loss": 0.0001,
      "step": 12074
    },
    {
      "epoch": 46.80232558139535,
      "grad_norm": 0.0010306198382750154,
      "learning_rate": 3.1976744186046516e-06,
      "loss": 0.0001,
      "step": 12075
    },
    {
      "epoch": 46.8062015503876,
      "grad_norm": 0.0007469314150512218,
      "learning_rate": 3.1937984496124036e-06,
      "loss": 0.0001,
      "step": 12076
    },
    {
      "epoch": 46.810077519379846,
      "grad_norm": 0.0006932606920599937,
      "learning_rate": 3.1899224806201556e-06,
      "loss": 0.0001,
      "step": 12077
    },
    {
      "epoch": 46.81395348837209,
      "grad_norm": 0.0009077969589270651,
      "learning_rate": 3.1860465116279067e-06,
      "loss": 0.0001,
      "step": 12078
    },
    {
      "epoch": 46.81782945736434,
      "grad_norm": 0.0008753432193771005,
      "learning_rate": 3.1821705426356587e-06,
      "loss": 0.0001,
      "step": 12079
    },
    {
      "epoch": 46.82170542635659,
      "grad_norm": 0.0009832704672589898,
      "learning_rate": 3.178294573643411e-06,
      "loss": 0.0001,
      "step": 12080
    },
    {
      "epoch": 46.825581395348834,
      "grad_norm": 0.0008700759499333799,
      "learning_rate": 3.174418604651163e-06,
      "loss": 0.0001,
      "step": 12081
    },
    {
      "epoch": 46.82945736434109,
      "grad_norm": 0.0006800073315389454,
      "learning_rate": 3.170542635658915e-06,
      "loss": 0.0001,
      "step": 12082
    },
    {
      "epoch": 46.833333333333336,
      "grad_norm": 0.000666873762384057,
      "learning_rate": 3.166666666666667e-06,
      "loss": 0.0001,
      "step": 12083
    },
    {
      "epoch": 46.83720930232558,
      "grad_norm": 0.0013116848422214389,
      "learning_rate": 3.1627906976744183e-06,
      "loss": 0.0001,
      "step": 12084
    },
    {
      "epoch": 46.84108527131783,
      "grad_norm": 0.850841760635376,
      "learning_rate": 3.1589147286821703e-06,
      "loss": 0.0364,
      "step": 12085
    },
    {
      "epoch": 46.84496124031008,
      "grad_norm": 0.003716388251632452,
      "learning_rate": 3.1550387596899227e-06,
      "loss": 0.0003,
      "step": 12086
    },
    {
      "epoch": 46.848837209302324,
      "grad_norm": 0.001055326545611024,
      "learning_rate": 3.1511627906976747e-06,
      "loss": 0.0001,
      "step": 12087
    },
    {
      "epoch": 46.85271317829457,
      "grad_norm": 0.0011376808397471905,
      "learning_rate": 3.1472868217054267e-06,
      "loss": 0.0001,
      "step": 12088
    },
    {
      "epoch": 46.85658914728682,
      "grad_norm": 0.0008848338038660586,
      "learning_rate": 3.1434108527131787e-06,
      "loss": 0.0001,
      "step": 12089
    },
    {
      "epoch": 46.86046511627907,
      "grad_norm": 0.0005939867696724832,
      "learning_rate": 3.1395348837209307e-06,
      "loss": 0.0001,
      "step": 12090
    },
    {
      "epoch": 46.86434108527132,
      "grad_norm": 0.0020373438019305468,
      "learning_rate": 3.135658914728682e-06,
      "loss": 0.0002,
      "step": 12091
    },
    {
      "epoch": 46.86821705426357,
      "grad_norm": 0.0007343052420765162,
      "learning_rate": 3.1317829457364343e-06,
      "loss": 0.0001,
      "step": 12092
    },
    {
      "epoch": 46.872093023255815,
      "grad_norm": 0.002748947823420167,
      "learning_rate": 3.1279069767441863e-06,
      "loss": 0.0002,
      "step": 12093
    },
    {
      "epoch": 46.87596899224806,
      "grad_norm": 0.002939072670415044,
      "learning_rate": 3.1240310077519383e-06,
      "loss": 0.0001,
      "step": 12094
    },
    {
      "epoch": 46.87984496124031,
      "grad_norm": 0.005403854884207249,
      "learning_rate": 3.1201550387596903e-06,
      "loss": 0.0002,
      "step": 12095
    },
    {
      "epoch": 46.883720930232556,
      "grad_norm": 0.000759954855311662,
      "learning_rate": 3.116279069767442e-06,
      "loss": 0.0001,
      "step": 12096
    },
    {
      "epoch": 46.8875968992248,
      "grad_norm": 0.001282145967707038,
      "learning_rate": 3.112403100775194e-06,
      "loss": 0.0001,
      "step": 12097
    },
    {
      "epoch": 46.89147286821706,
      "grad_norm": 0.0012220926582813263,
      "learning_rate": 3.108527131782946e-06,
      "loss": 0.0001,
      "step": 12098
    },
    {
      "epoch": 46.895348837209305,
      "grad_norm": 0.0013122233795002103,
      "learning_rate": 3.104651162790698e-06,
      "loss": 0.0001,
      "step": 12099
    },
    {
      "epoch": 46.89922480620155,
      "grad_norm": 0.0012200173223391175,
      "learning_rate": 3.10077519379845e-06,
      "loss": 0.0001,
      "step": 12100
    },
    {
      "epoch": 46.9031007751938,
      "grad_norm": 0.0007063632947392762,
      "learning_rate": 3.096899224806202e-06,
      "loss": 0.0001,
      "step": 12101
    },
    {
      "epoch": 46.906976744186046,
      "grad_norm": 2.3900959491729736,
      "learning_rate": 3.093023255813954e-06,
      "loss": 0.2426,
      "step": 12102
    },
    {
      "epoch": 46.91085271317829,
      "grad_norm": 0.0007156669162213802,
      "learning_rate": 3.0891472868217054e-06,
      "loss": 0.0001,
      "step": 12103
    },
    {
      "epoch": 46.91472868217054,
      "grad_norm": 0.0008085803710855544,
      "learning_rate": 3.0852713178294574e-06,
      "loss": 0.0001,
      "step": 12104
    },
    {
      "epoch": 46.91860465116279,
      "grad_norm": 0.0007049805717542768,
      "learning_rate": 3.0813953488372094e-06,
      "loss": 0.0001,
      "step": 12105
    },
    {
      "epoch": 46.92248062015504,
      "grad_norm": 0.0008074518409557641,
      "learning_rate": 3.0775193798449614e-06,
      "loss": 0.0001,
      "step": 12106
    },
    {
      "epoch": 46.92635658914729,
      "grad_norm": 0.002004089532420039,
      "learning_rate": 3.0736434108527134e-06,
      "loss": 0.0001,
      "step": 12107
    },
    {
      "epoch": 46.93023255813954,
      "grad_norm": 1.1926134824752808,
      "learning_rate": 3.0697674418604654e-06,
      "loss": 0.0056,
      "step": 12108
    },
    {
      "epoch": 46.934108527131784,
      "grad_norm": 0.000653832103125751,
      "learning_rate": 3.065891472868217e-06,
      "loss": 0.0001,
      "step": 12109
    },
    {
      "epoch": 46.93798449612403,
      "grad_norm": 0.0007026474922895432,
      "learning_rate": 3.062015503875969e-06,
      "loss": 0.0001,
      "step": 12110
    },
    {
      "epoch": 46.94186046511628,
      "grad_norm": 0.0008026740397326648,
      "learning_rate": 3.058139534883721e-06,
      "loss": 0.0001,
      "step": 12111
    },
    {
      "epoch": 46.945736434108525,
      "grad_norm": 0.000981757533736527,
      "learning_rate": 3.0542635658914734e-06,
      "loss": 0.0001,
      "step": 12112
    },
    {
      "epoch": 46.94961240310077,
      "grad_norm": 0.0009389855549670756,
      "learning_rate": 3.050387596899225e-06,
      "loss": 0.0001,
      "step": 12113
    },
    {
      "epoch": 46.95348837209303,
      "grad_norm": 0.00107617920730263,
      "learning_rate": 3.046511627906977e-06,
      "loss": 0.0001,
      "step": 12114
    },
    {
      "epoch": 46.957364341085274,
      "grad_norm": 0.0017788277473300695,
      "learning_rate": 3.042635658914729e-06,
      "loss": 0.0001,
      "step": 12115
    },
    {
      "epoch": 46.96124031007752,
      "grad_norm": 0.405516654253006,
      "learning_rate": 3.0387596899224805e-06,
      "loss": 0.0175,
      "step": 12116
    },
    {
      "epoch": 46.96511627906977,
      "grad_norm": 0.0007709654746577144,
      "learning_rate": 3.0348837209302325e-06,
      "loss": 0.0001,
      "step": 12117
    },
    {
      "epoch": 46.968992248062015,
      "grad_norm": 0.010084270499646664,
      "learning_rate": 3.031007751937985e-06,
      "loss": 0.0003,
      "step": 12118
    },
    {
      "epoch": 46.97286821705426,
      "grad_norm": 0.0010395105928182602,
      "learning_rate": 3.0271317829457365e-06,
      "loss": 0.0001,
      "step": 12119
    },
    {
      "epoch": 46.97674418604651,
      "grad_norm": 0.019364938139915466,
      "learning_rate": 3.0232558139534885e-06,
      "loss": 0.0007,
      "step": 12120
    },
    {
      "epoch": 46.98062015503876,
      "grad_norm": 0.000888378475792706,
      "learning_rate": 3.0193798449612405e-06,
      "loss": 0.0001,
      "step": 12121
    },
    {
      "epoch": 46.98449612403101,
      "grad_norm": 0.0007256110548041761,
      "learning_rate": 3.0155038759689925e-06,
      "loss": 0.0001,
      "step": 12122
    },
    {
      "epoch": 46.98837209302326,
      "grad_norm": 0.0014014175394549966,
      "learning_rate": 3.011627906976744e-06,
      "loss": 0.0001,
      "step": 12123
    },
    {
      "epoch": 46.992248062015506,
      "grad_norm": 0.000645650434307754,
      "learning_rate": 3.0077519379844965e-06,
      "loss": 0.0001,
      "step": 12124
    },
    {
      "epoch": 46.99612403100775,
      "grad_norm": 0.0013551611918956041,
      "learning_rate": 3.0038759689922485e-06,
      "loss": 0.0001,
      "step": 12125
    },
    {
      "epoch": 47.0,
      "grad_norm": 0.0010765173938125372,
      "learning_rate": 3e-06,
      "loss": 0.0001,
      "step": 12126
    },
    {
      "epoch": 47.00387596899225,
      "grad_norm": 0.000834499194752425,
      "learning_rate": 2.996124031007752e-06,
      "loss": 0.0001,
      "step": 12127
    },
    {
      "epoch": 47.007751937984494,
      "grad_norm": 0.3957644999027252,
      "learning_rate": 2.992248062015504e-06,
      "loss": 0.0219,
      "step": 12128
    },
    {
      "epoch": 47.01162790697674,
      "grad_norm": 0.0018730707233771682,
      "learning_rate": 2.9883720930232556e-06,
      "loss": 0.0001,
      "step": 12129
    },
    {
      "epoch": 47.01550387596899,
      "grad_norm": 0.0006053867400623858,
      "learning_rate": 2.9844961240310076e-06,
      "loss": 0.0001,
      "step": 12130
    },
    {
      "epoch": 47.01937984496124,
      "grad_norm": 0.0009504754561930895,
      "learning_rate": 2.98062015503876e-06,
      "loss": 0.0001,
      "step": 12131
    },
    {
      "epoch": 47.02325581395349,
      "grad_norm": 0.0008151417132467031,
      "learning_rate": 2.976744186046512e-06,
      "loss": 0.0001,
      "step": 12132
    },
    {
      "epoch": 47.02713178294574,
      "grad_norm": 0.0015108317602425814,
      "learning_rate": 2.9728682170542636e-06,
      "loss": 0.0001,
      "step": 12133
    },
    {
      "epoch": 47.031007751937985,
      "grad_norm": 0.0021620490588247776,
      "learning_rate": 2.9689922480620156e-06,
      "loss": 0.0002,
      "step": 12134
    },
    {
      "epoch": 47.03488372093023,
      "grad_norm": 0.001891707070171833,
      "learning_rate": 2.9651162790697676e-06,
      "loss": 0.0002,
      "step": 12135
    },
    {
      "epoch": 47.03875968992248,
      "grad_norm": 0.0008143329177983105,
      "learning_rate": 2.961240310077519e-06,
      "loss": 0.0001,
      "step": 12136
    },
    {
      "epoch": 47.042635658914726,
      "grad_norm": 0.0011275779688730836,
      "learning_rate": 2.9573643410852716e-06,
      "loss": 0.0001,
      "step": 12137
    },
    {
      "epoch": 47.04651162790697,
      "grad_norm": 0.0006897169514559209,
      "learning_rate": 2.9534883720930236e-06,
      "loss": 0.0001,
      "step": 12138
    },
    {
      "epoch": 47.05038759689923,
      "grad_norm": 0.595521867275238,
      "learning_rate": 2.949612403100775e-06,
      "loss": 0.0247,
      "step": 12139
    },
    {
      "epoch": 47.054263565891475,
      "grad_norm": 0.0007336202543228865,
      "learning_rate": 2.945736434108527e-06,
      "loss": 0.0001,
      "step": 12140
    },
    {
      "epoch": 47.05813953488372,
      "grad_norm": 0.0006679213838651776,
      "learning_rate": 2.941860465116279e-06,
      "loss": 0.0001,
      "step": 12141
    },
    {
      "epoch": 47.06201550387597,
      "grad_norm": 0.0017094031209126115,
      "learning_rate": 2.937984496124031e-06,
      "loss": 0.0001,
      "step": 12142
    },
    {
      "epoch": 47.065891472868216,
      "grad_norm": 0.001003253972157836,
      "learning_rate": 2.934108527131783e-06,
      "loss": 0.0001,
      "step": 12143
    },
    {
      "epoch": 47.06976744186046,
      "grad_norm": 0.0010118442587554455,
      "learning_rate": 2.930232558139535e-06,
      "loss": 0.0001,
      "step": 12144
    },
    {
      "epoch": 47.07364341085271,
      "grad_norm": 0.0006379240076057613,
      "learning_rate": 2.926356589147287e-06,
      "loss": 0.0001,
      "step": 12145
    },
    {
      "epoch": 47.07751937984496,
      "grad_norm": 0.0007183157140389085,
      "learning_rate": 2.9224806201550388e-06,
      "loss": 0.0001,
      "step": 12146
    },
    {
      "epoch": 47.08139534883721,
      "grad_norm": 0.0006523127085529268,
      "learning_rate": 2.9186046511627908e-06,
      "loss": 0.0001,
      "step": 12147
    },
    {
      "epoch": 47.08527131782946,
      "grad_norm": 0.0006621673237532377,
      "learning_rate": 2.9147286821705428e-06,
      "loss": 0.0001,
      "step": 12148
    },
    {
      "epoch": 47.08914728682171,
      "grad_norm": 0.0006790994666516781,
      "learning_rate": 2.9108527131782948e-06,
      "loss": 0.0001,
      "step": 12149
    },
    {
      "epoch": 47.093023255813954,
      "grad_norm": 0.0010223088320344687,
      "learning_rate": 2.9069767441860468e-06,
      "loss": 0.0001,
      "step": 12150
    },
    {
      "epoch": 47.0968992248062,
      "grad_norm": 0.0013700827257707715,
      "learning_rate": 2.9031007751937988e-06,
      "loss": 0.0001,
      "step": 12151
    },
    {
      "epoch": 47.10077519379845,
      "grad_norm": 0.0009713316685520113,
      "learning_rate": 2.8992248062015508e-06,
      "loss": 0.0001,
      "step": 12152
    },
    {
      "epoch": 47.104651162790695,
      "grad_norm": 0.002620426006615162,
      "learning_rate": 2.8953488372093023e-06,
      "loss": 0.0001,
      "step": 12153
    },
    {
      "epoch": 47.10852713178294,
      "grad_norm": 0.001623026910237968,
      "learning_rate": 2.8914728682170543e-06,
      "loss": 0.0001,
      "step": 12154
    },
    {
      "epoch": 47.1124031007752,
      "grad_norm": 0.0010671233758330345,
      "learning_rate": 2.8875968992248063e-06,
      "loss": 0.0001,
      "step": 12155
    },
    {
      "epoch": 47.116279069767444,
      "grad_norm": 0.000752406136598438,
      "learning_rate": 2.8837209302325583e-06,
      "loss": 0.0001,
      "step": 12156
    },
    {
      "epoch": 47.12015503875969,
      "grad_norm": 0.0012324962299317122,
      "learning_rate": 2.8798449612403103e-06,
      "loss": 0.0001,
      "step": 12157
    },
    {
      "epoch": 47.12403100775194,
      "grad_norm": 0.0007403932395391166,
      "learning_rate": 2.8759689922480623e-06,
      "loss": 0.0001,
      "step": 12158
    },
    {
      "epoch": 47.127906976744185,
      "grad_norm": 2.26283860206604,
      "learning_rate": 2.872093023255814e-06,
      "loss": 0.2388,
      "step": 12159
    },
    {
      "epoch": 47.13178294573643,
      "grad_norm": 0.0007519749342463911,
      "learning_rate": 2.868217054263566e-06,
      "loss": 0.0001,
      "step": 12160
    },
    {
      "epoch": 47.13565891472868,
      "grad_norm": 0.0006994628347456455,
      "learning_rate": 2.864341085271318e-06,
      "loss": 0.0001,
      "step": 12161
    },
    {
      "epoch": 47.13953488372093,
      "grad_norm": 0.000747759360820055,
      "learning_rate": 2.86046511627907e-06,
      "loss": 0.0001,
      "step": 12162
    },
    {
      "epoch": 47.14341085271318,
      "grad_norm": 0.0007128193392418325,
      "learning_rate": 2.856589147286822e-06,
      "loss": 0.0001,
      "step": 12163
    },
    {
      "epoch": 47.14728682170543,
      "grad_norm": 0.0006180682685226202,
      "learning_rate": 2.852713178294574e-06,
      "loss": 0.0001,
      "step": 12164
    },
    {
      "epoch": 47.151162790697676,
      "grad_norm": 0.00661021564155817,
      "learning_rate": 2.848837209302326e-06,
      "loss": 0.0002,
      "step": 12165
    },
    {
      "epoch": 47.15503875968992,
      "grad_norm": 0.0011217097053304315,
      "learning_rate": 2.8449612403100775e-06,
      "loss": 0.0001,
      "step": 12166
    },
    {
      "epoch": 47.15891472868217,
      "grad_norm": 0.0011282415362074971,
      "learning_rate": 2.8410852713178295e-06,
      "loss": 0.0001,
      "step": 12167
    },
    {
      "epoch": 47.16279069767442,
      "grad_norm": 0.0008953622309491038,
      "learning_rate": 2.8372093023255815e-06,
      "loss": 0.0001,
      "step": 12168
    },
    {
      "epoch": 47.166666666666664,
      "grad_norm": 0.0007329419604502618,
      "learning_rate": 2.8333333333333335e-06,
      "loss": 0.0001,
      "step": 12169
    },
    {
      "epoch": 47.17054263565891,
      "grad_norm": 0.001816773321479559,
      "learning_rate": 2.8294573643410855e-06,
      "loss": 0.0001,
      "step": 12170
    },
    {
      "epoch": 47.174418604651166,
      "grad_norm": 0.0007117678178474307,
      "learning_rate": 2.8255813953488374e-06,
      "loss": 0.0001,
      "step": 12171
    },
    {
      "epoch": 47.17829457364341,
      "grad_norm": 0.9069234132766724,
      "learning_rate": 2.8217054263565894e-06,
      "loss": 0.0475,
      "step": 12172
    },
    {
      "epoch": 47.18217054263566,
      "grad_norm": 0.0006941487081348896,
      "learning_rate": 2.817829457364341e-06,
      "loss": 0.0001,
      "step": 12173
    },
    {
      "epoch": 47.18604651162791,
      "grad_norm": 0.003585687605664134,
      "learning_rate": 2.813953488372093e-06,
      "loss": 0.0002,
      "step": 12174
    },
    {
      "epoch": 47.189922480620154,
      "grad_norm": 0.0008344689849764109,
      "learning_rate": 2.8100775193798454e-06,
      "loss": 0.0001,
      "step": 12175
    },
    {
      "epoch": 47.1937984496124,
      "grad_norm": 0.0006677489727735519,
      "learning_rate": 2.806201550387597e-06,
      "loss": 0.0001,
      "step": 12176
    },
    {
      "epoch": 47.19767441860465,
      "grad_norm": 0.0006601633504033089,
      "learning_rate": 2.802325581395349e-06,
      "loss": 0.0001,
      "step": 12177
    },
    {
      "epoch": 47.201550387596896,
      "grad_norm": 0.0011784929083660245,
      "learning_rate": 2.798449612403101e-06,
      "loss": 0.0001,
      "step": 12178
    },
    {
      "epoch": 47.20542635658915,
      "grad_norm": 0.0008343369117937982,
      "learning_rate": 2.7945736434108526e-06,
      "loss": 0.0001,
      "step": 12179
    },
    {
      "epoch": 47.2093023255814,
      "grad_norm": 0.007332717999815941,
      "learning_rate": 2.7906976744186046e-06,
      "loss": 0.0002,
      "step": 12180
    },
    {
      "epoch": 47.213178294573645,
      "grad_norm": 0.0007954761385917664,
      "learning_rate": 2.7868217054263566e-06,
      "loss": 0.0001,
      "step": 12181
    },
    {
      "epoch": 47.21705426356589,
      "grad_norm": 0.0008254427229985595,
      "learning_rate": 2.782945736434109e-06,
      "loss": 0.0001,
      "step": 12182
    },
    {
      "epoch": 47.22093023255814,
      "grad_norm": 0.0006214875029399991,
      "learning_rate": 2.7790697674418606e-06,
      "loss": 0.0001,
      "step": 12183
    },
    {
      "epoch": 47.224806201550386,
      "grad_norm": 1.2394044399261475,
      "learning_rate": 2.7751937984496126e-06,
      "loss": 0.0881,
      "step": 12184
    },
    {
      "epoch": 47.22868217054263,
      "grad_norm": 0.0011972958454862237,
      "learning_rate": 2.7713178294573646e-06,
      "loss": 0.0001,
      "step": 12185
    },
    {
      "epoch": 47.23255813953488,
      "grad_norm": 0.0008643111796118319,
      "learning_rate": 2.767441860465116e-06,
      "loss": 0.0001,
      "step": 12186
    },
    {
      "epoch": 47.236434108527135,
      "grad_norm": 0.000699352181982249,
      "learning_rate": 2.763565891472868e-06,
      "loss": 0.0001,
      "step": 12187
    },
    {
      "epoch": 47.24031007751938,
      "grad_norm": 0.0006203036173246801,
      "learning_rate": 2.7596899224806206e-06,
      "loss": 0.0001,
      "step": 12188
    },
    {
      "epoch": 47.24418604651163,
      "grad_norm": 2.233287811279297,
      "learning_rate": 2.755813953488372e-06,
      "loss": 0.208,
      "step": 12189
    },
    {
      "epoch": 47.248062015503876,
      "grad_norm": 0.0006625343230552971,
      "learning_rate": 2.751937984496124e-06,
      "loss": 0.0001,
      "step": 12190
    },
    {
      "epoch": 47.251937984496124,
      "grad_norm": 0.000730450265109539,
      "learning_rate": 2.748062015503876e-06,
      "loss": 0.0001,
      "step": 12191
    },
    {
      "epoch": 47.25581395348837,
      "grad_norm": 0.0012420249404385686,
      "learning_rate": 2.744186046511628e-06,
      "loss": 0.0001,
      "step": 12192
    },
    {
      "epoch": 47.25968992248062,
      "grad_norm": 0.0007488182745873928,
      "learning_rate": 2.7403100775193797e-06,
      "loss": 0.0001,
      "step": 12193
    },
    {
      "epoch": 47.263565891472865,
      "grad_norm": 0.0007383805932477117,
      "learning_rate": 2.736434108527132e-06,
      "loss": 0.0001,
      "step": 12194
    },
    {
      "epoch": 47.26744186046512,
      "grad_norm": 0.0008412558818235993,
      "learning_rate": 2.732558139534884e-06,
      "loss": 0.0001,
      "step": 12195
    },
    {
      "epoch": 47.27131782945737,
      "grad_norm": 0.0006489563384093344,
      "learning_rate": 2.7286821705426357e-06,
      "loss": 0.0001,
      "step": 12196
    },
    {
      "epoch": 47.275193798449614,
      "grad_norm": 0.0006445274921134114,
      "learning_rate": 2.7248062015503877e-06,
      "loss": 0.0001,
      "step": 12197
    },
    {
      "epoch": 47.27906976744186,
      "grad_norm": 0.001295405556447804,
      "learning_rate": 2.7209302325581397e-06,
      "loss": 0.0001,
      "step": 12198
    },
    {
      "epoch": 47.28294573643411,
      "grad_norm": 0.001246105064637959,
      "learning_rate": 2.7170542635658913e-06,
      "loss": 0.0001,
      "step": 12199
    },
    {
      "epoch": 47.286821705426355,
      "grad_norm": 0.007268559653311968,
      "learning_rate": 2.7131782945736437e-06,
      "loss": 0.0003,
      "step": 12200
    },
    {
      "epoch": 47.2906976744186,
      "grad_norm": 0.0007434417493641376,
      "learning_rate": 2.7093023255813957e-06,
      "loss": 0.0001,
      "step": 12201
    },
    {
      "epoch": 47.29457364341085,
      "grad_norm": 0.0008289185934700072,
      "learning_rate": 2.7054263565891477e-06,
      "loss": 0.0001,
      "step": 12202
    },
    {
      "epoch": 47.298449612403104,
      "grad_norm": 0.06496118754148483,
      "learning_rate": 2.7015503875968993e-06,
      "loss": 0.0016,
      "step": 12203
    },
    {
      "epoch": 47.30232558139535,
      "grad_norm": 0.0005800951621495187,
      "learning_rate": 2.6976744186046513e-06,
      "loss": 0.0001,
      "step": 12204
    },
    {
      "epoch": 47.3062015503876,
      "grad_norm": 0.0006944509805180132,
      "learning_rate": 2.6937984496124033e-06,
      "loss": 0.0001,
      "step": 12205
    },
    {
      "epoch": 47.310077519379846,
      "grad_norm": 0.7990103363990784,
      "learning_rate": 2.6899224806201553e-06,
      "loss": 0.0433,
      "step": 12206
    },
    {
      "epoch": 47.31395348837209,
      "grad_norm": 0.09179326146841049,
      "learning_rate": 2.6860465116279073e-06,
      "loss": 0.0029,
      "step": 12207
    },
    {
      "epoch": 47.31782945736434,
      "grad_norm": 0.0007238694233819842,
      "learning_rate": 2.6821705426356593e-06,
      "loss": 0.0001,
      "step": 12208
    },
    {
      "epoch": 47.32170542635659,
      "grad_norm": 0.0010773803805932403,
      "learning_rate": 2.678294573643411e-06,
      "loss": 0.0001,
      "step": 12209
    },
    {
      "epoch": 47.325581395348834,
      "grad_norm": 0.002104352228343487,
      "learning_rate": 2.674418604651163e-06,
      "loss": 0.0001,
      "step": 12210
    },
    {
      "epoch": 47.32945736434109,
      "grad_norm": 0.0010615356732159853,
      "learning_rate": 2.670542635658915e-06,
      "loss": 0.0001,
      "step": 12211
    },
    {
      "epoch": 47.333333333333336,
      "grad_norm": 0.0008102094288915396,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.0001,
      "step": 12212
    },
    {
      "epoch": 47.33720930232558,
      "grad_norm": 0.0006276117637753487,
      "learning_rate": 2.662790697674419e-06,
      "loss": 0.0001,
      "step": 12213
    },
    {
      "epoch": 47.34108527131783,
      "grad_norm": 0.0005944642471149564,
      "learning_rate": 2.658914728682171e-06,
      "loss": 0.0001,
      "step": 12214
    },
    {
      "epoch": 47.34496124031008,
      "grad_norm": 0.0006253947503864765,
      "learning_rate": 2.655038759689923e-06,
      "loss": 0.0001,
      "step": 12215
    },
    {
      "epoch": 47.348837209302324,
      "grad_norm": 0.0009370541083626449,
      "learning_rate": 2.6511627906976744e-06,
      "loss": 0.0001,
      "step": 12216
    },
    {
      "epoch": 47.35271317829457,
      "grad_norm": 0.0007291068322956562,
      "learning_rate": 2.6472868217054264e-06,
      "loss": 0.0001,
      "step": 12217
    },
    {
      "epoch": 47.35658914728682,
      "grad_norm": 0.0016318355919793248,
      "learning_rate": 2.6434108527131784e-06,
      "loss": 0.0001,
      "step": 12218
    },
    {
      "epoch": 47.36046511627907,
      "grad_norm": 0.0011645166669040918,
      "learning_rate": 2.6395348837209304e-06,
      "loss": 0.0001,
      "step": 12219
    },
    {
      "epoch": 47.36434108527132,
      "grad_norm": 0.001124361646361649,
      "learning_rate": 2.6356589147286824e-06,
      "loss": 0.0001,
      "step": 12220
    },
    {
      "epoch": 47.36821705426357,
      "grad_norm": 0.0006301438552327454,
      "learning_rate": 2.6317829457364344e-06,
      "loss": 0.0001,
      "step": 12221
    },
    {
      "epoch": 47.372093023255815,
      "grad_norm": 0.0006736853392794728,
      "learning_rate": 2.6279069767441864e-06,
      "loss": 0.0001,
      "step": 12222
    },
    {
      "epoch": 47.37596899224806,
      "grad_norm": 0.0008635957492515445,
      "learning_rate": 2.624031007751938e-06,
      "loss": 0.0001,
      "step": 12223
    },
    {
      "epoch": 47.37984496124031,
      "grad_norm": 0.001022093347273767,
      "learning_rate": 2.62015503875969e-06,
      "loss": 0.0001,
      "step": 12224
    },
    {
      "epoch": 47.383720930232556,
      "grad_norm": 0.011685228906571865,
      "learning_rate": 2.616279069767442e-06,
      "loss": 0.0002,
      "step": 12225
    },
    {
      "epoch": 47.3875968992248,
      "grad_norm": 0.0013454711297526956,
      "learning_rate": 2.612403100775194e-06,
      "loss": 0.0001,
      "step": 12226
    },
    {
      "epoch": 47.39147286821706,
      "grad_norm": 0.0015006305184215307,
      "learning_rate": 2.608527131782946e-06,
      "loss": 0.0001,
      "step": 12227
    },
    {
      "epoch": 47.395348837209305,
      "grad_norm": 0.006649999879300594,
      "learning_rate": 2.604651162790698e-06,
      "loss": 0.0002,
      "step": 12228
    },
    {
      "epoch": 47.39922480620155,
      "grad_norm": 0.0012800369877368212,
      "learning_rate": 2.6007751937984495e-06,
      "loss": 0.0001,
      "step": 12229
    },
    {
      "epoch": 47.4031007751938,
      "grad_norm": 0.0007850489346310496,
      "learning_rate": 2.5968992248062015e-06,
      "loss": 0.0001,
      "step": 12230
    },
    {
      "epoch": 47.406976744186046,
      "grad_norm": 0.0009652259759604931,
      "learning_rate": 2.5930232558139535e-06,
      "loss": 0.0001,
      "step": 12231
    },
    {
      "epoch": 47.41085271317829,
      "grad_norm": 0.0008220202871598303,
      "learning_rate": 2.5891472868217055e-06,
      "loss": 0.0001,
      "step": 12232
    },
    {
      "epoch": 47.41472868217054,
      "grad_norm": 0.0008731349371373653,
      "learning_rate": 2.5852713178294575e-06,
      "loss": 0.0001,
      "step": 12233
    },
    {
      "epoch": 47.41860465116279,
      "grad_norm": 0.0007547318236902356,
      "learning_rate": 2.5813953488372095e-06,
      "loss": 0.0001,
      "step": 12234
    },
    {
      "epoch": 47.42248062015504,
      "grad_norm": 0.0006232167943380773,
      "learning_rate": 2.5775193798449615e-06,
      "loss": 0.0001,
      "step": 12235
    },
    {
      "epoch": 47.42635658914729,
      "grad_norm": 0.0011491177137941122,
      "learning_rate": 2.573643410852713e-06,
      "loss": 0.0001,
      "step": 12236
    },
    {
      "epoch": 47.43023255813954,
      "grad_norm": 0.002932567149400711,
      "learning_rate": 2.569767441860465e-06,
      "loss": 0.0002,
      "step": 12237
    },
    {
      "epoch": 47.434108527131784,
      "grad_norm": 0.0014168303459882736,
      "learning_rate": 2.565891472868217e-06,
      "loss": 0.0001,
      "step": 12238
    },
    {
      "epoch": 47.43798449612403,
      "grad_norm": 0.0008331789867952466,
      "learning_rate": 2.562015503875969e-06,
      "loss": 0.0001,
      "step": 12239
    },
    {
      "epoch": 47.44186046511628,
      "grad_norm": 0.0008675867575220764,
      "learning_rate": 2.558139534883721e-06,
      "loss": 0.0001,
      "step": 12240
    },
    {
      "epoch": 47.445736434108525,
      "grad_norm": 0.0040328181348741055,
      "learning_rate": 2.554263565891473e-06,
      "loss": 0.0001,
      "step": 12241
    },
    {
      "epoch": 47.44961240310077,
      "grad_norm": 0.0006009977660141885,
      "learning_rate": 2.550387596899225e-06,
      "loss": 0.0001,
      "step": 12242
    },
    {
      "epoch": 47.45348837209303,
      "grad_norm": 0.0006391672068275511,
      "learning_rate": 2.5465116279069767e-06,
      "loss": 0.0001,
      "step": 12243
    },
    {
      "epoch": 47.457364341085274,
      "grad_norm": 0.0008453563204966486,
      "learning_rate": 2.5426356589147286e-06,
      "loss": 0.0001,
      "step": 12244
    },
    {
      "epoch": 47.46124031007752,
      "grad_norm": 0.6992151141166687,
      "learning_rate": 2.538759689922481e-06,
      "loss": 0.0281,
      "step": 12245
    },
    {
      "epoch": 47.46511627906977,
      "grad_norm": 0.00132942630443722,
      "learning_rate": 2.5348837209302326e-06,
      "loss": 0.0001,
      "step": 12246
    },
    {
      "epoch": 47.468992248062015,
      "grad_norm": 0.001062045688740909,
      "learning_rate": 2.5310077519379846e-06,
      "loss": 0.0001,
      "step": 12247
    },
    {
      "epoch": 47.47286821705426,
      "grad_norm": 0.0005967403412796557,
      "learning_rate": 2.5271317829457366e-06,
      "loss": 0.0001,
      "step": 12248
    },
    {
      "epoch": 47.47674418604651,
      "grad_norm": 0.0006815564702264965,
      "learning_rate": 2.5232558139534882e-06,
      "loss": 0.0001,
      "step": 12249
    },
    {
      "epoch": 47.48062015503876,
      "grad_norm": 0.005815723445266485,
      "learning_rate": 2.5193798449612402e-06,
      "loss": 0.0002,
      "step": 12250
    },
    {
      "epoch": 47.48449612403101,
      "grad_norm": 0.0012961267493665218,
      "learning_rate": 2.5155038759689926e-06,
      "loss": 0.0001,
      "step": 12251
    },
    {
      "epoch": 47.48837209302326,
      "grad_norm": 0.0010443178471177816,
      "learning_rate": 2.5116279069767446e-06,
      "loss": 0.0001,
      "step": 12252
    },
    {
      "epoch": 47.492248062015506,
      "grad_norm": 0.35306501388549805,
      "learning_rate": 2.507751937984496e-06,
      "loss": 0.0143,
      "step": 12253
    },
    {
      "epoch": 47.49612403100775,
      "grad_norm": 0.0006827716715633869,
      "learning_rate": 2.503875968992248e-06,
      "loss": 0.0001,
      "step": 12254
    },
    {
      "epoch": 47.5,
      "grad_norm": 0.0006194674642756581,
      "learning_rate": 2.5e-06,
      "loss": 0.0001,
      "step": 12255
    },
    {
      "epoch": 47.50387596899225,
      "grad_norm": 0.0007545571424998343,
      "learning_rate": 2.4961240310077518e-06,
      "loss": 0.0001,
      "step": 12256
    },
    {
      "epoch": 47.507751937984494,
      "grad_norm": 0.0007846389198675752,
      "learning_rate": 2.492248062015504e-06,
      "loss": 0.0001,
      "step": 12257
    },
    {
      "epoch": 47.51162790697674,
      "grad_norm": 0.0006438405835069716,
      "learning_rate": 2.488372093023256e-06,
      "loss": 0.0001,
      "step": 12258
    },
    {
      "epoch": 47.51550387596899,
      "grad_norm": 1.0244410037994385,
      "learning_rate": 2.4844961240310078e-06,
      "loss": 0.041,
      "step": 12259
    },
    {
      "epoch": 47.51937984496124,
      "grad_norm": 0.0006517095607705414,
      "learning_rate": 2.4806201550387598e-06,
      "loss": 0.0001,
      "step": 12260
    },
    {
      "epoch": 47.52325581395349,
      "grad_norm": 0.0008438345976173878,
      "learning_rate": 2.4767441860465118e-06,
      "loss": 0.0001,
      "step": 12261
    },
    {
      "epoch": 47.52713178294574,
      "grad_norm": 0.0006184617523103952,
      "learning_rate": 2.4728682170542633e-06,
      "loss": 0.0001,
      "step": 12262
    },
    {
      "epoch": 47.531007751937985,
      "grad_norm": 0.003872258821502328,
      "learning_rate": 2.4689922480620153e-06,
      "loss": 0.0003,
      "step": 12263
    },
    {
      "epoch": 47.53488372093023,
      "grad_norm": 0.7269989252090454,
      "learning_rate": 2.4651162790697678e-06,
      "loss": 0.0325,
      "step": 12264
    },
    {
      "epoch": 47.53875968992248,
      "grad_norm": 0.002305214758962393,
      "learning_rate": 2.4612403100775198e-06,
      "loss": 0.0002,
      "step": 12265
    },
    {
      "epoch": 47.542635658914726,
      "grad_norm": 3.7402148246765137,
      "learning_rate": 2.4573643410852713e-06,
      "loss": 0.3441,
      "step": 12266
    },
    {
      "epoch": 47.54651162790697,
      "grad_norm": 0.0007171831675805151,
      "learning_rate": 2.4534883720930233e-06,
      "loss": 0.0001,
      "step": 12267
    },
    {
      "epoch": 47.55038759689923,
      "grad_norm": 0.000714657420758158,
      "learning_rate": 2.4496124031007753e-06,
      "loss": 0.0001,
      "step": 12268
    },
    {
      "epoch": 47.554263565891475,
      "grad_norm": 0.0008020753157325089,
      "learning_rate": 2.445736434108527e-06,
      "loss": 0.0001,
      "step": 12269
    },
    {
      "epoch": 47.55813953488372,
      "grad_norm": 0.0006072726682759821,
      "learning_rate": 2.4418604651162793e-06,
      "loss": 0.0001,
      "step": 12270
    },
    {
      "epoch": 47.56201550387597,
      "grad_norm": 0.04585598409175873,
      "learning_rate": 2.4379844961240313e-06,
      "loss": 0.0007,
      "step": 12271
    },
    {
      "epoch": 47.565891472868216,
      "grad_norm": 0.0008650724194012582,
      "learning_rate": 2.434108527131783e-06,
      "loss": 0.0001,
      "step": 12272
    },
    {
      "epoch": 47.56976744186046,
      "grad_norm": 0.0010337940184399486,
      "learning_rate": 2.430232558139535e-06,
      "loss": 0.0001,
      "step": 12273
    },
    {
      "epoch": 47.57364341085271,
      "grad_norm": 0.000875380530487746,
      "learning_rate": 2.426356589147287e-06,
      "loss": 0.0001,
      "step": 12274
    },
    {
      "epoch": 47.57751937984496,
      "grad_norm": 0.0006675709155388176,
      "learning_rate": 2.422480620155039e-06,
      "loss": 0.0001,
      "step": 12275
    },
    {
      "epoch": 47.58139534883721,
      "grad_norm": 0.001157325692474842,
      "learning_rate": 2.418604651162791e-06,
      "loss": 0.0001,
      "step": 12276
    },
    {
      "epoch": 47.58527131782946,
      "grad_norm": 0.0005867405561730266,
      "learning_rate": 2.414728682170543e-06,
      "loss": 0.0001,
      "step": 12277
    },
    {
      "epoch": 47.58914728682171,
      "grad_norm": 0.0008421741658821702,
      "learning_rate": 2.410852713178295e-06,
      "loss": 0.0001,
      "step": 12278
    },
    {
      "epoch": 47.593023255813954,
      "grad_norm": 0.0019192569889128208,
      "learning_rate": 2.4069767441860465e-06,
      "loss": 0.0002,
      "step": 12279
    },
    {
      "epoch": 47.5968992248062,
      "grad_norm": 0.0014505577273666859,
      "learning_rate": 2.4031007751937985e-06,
      "loss": 0.0001,
      "step": 12280
    },
    {
      "epoch": 47.60077519379845,
      "grad_norm": 0.0019040867919102311,
      "learning_rate": 2.3992248062015505e-06,
      "loss": 0.0001,
      "step": 12281
    },
    {
      "epoch": 47.604651162790695,
      "grad_norm": 0.0009477543062530458,
      "learning_rate": 2.3953488372093025e-06,
      "loss": 0.0001,
      "step": 12282
    },
    {
      "epoch": 47.60852713178294,
      "grad_norm": 0.0006713503389619291,
      "learning_rate": 2.3914728682170545e-06,
      "loss": 0.0001,
      "step": 12283
    },
    {
      "epoch": 47.6124031007752,
      "grad_norm": 0.0030850758776068687,
      "learning_rate": 2.3875968992248065e-06,
      "loss": 0.0002,
      "step": 12284
    },
    {
      "epoch": 47.616279069767444,
      "grad_norm": 0.0006353872013278306,
      "learning_rate": 2.3837209302325585e-06,
      "loss": 0.0001,
      "step": 12285
    },
    {
      "epoch": 47.62015503875969,
      "grad_norm": 0.0007976823835633695,
      "learning_rate": 2.37984496124031e-06,
      "loss": 0.0001,
      "step": 12286
    },
    {
      "epoch": 47.62403100775194,
      "grad_norm": 0.0007010981789790094,
      "learning_rate": 2.375968992248062e-06,
      "loss": 0.0001,
      "step": 12287
    },
    {
      "epoch": 47.627906976744185,
      "grad_norm": 0.0017264861380681396,
      "learning_rate": 2.372093023255814e-06,
      "loss": 0.0001,
      "step": 12288
    },
    {
      "epoch": 47.63178294573643,
      "grad_norm": 0.0010663887951523066,
      "learning_rate": 2.368217054263566e-06,
      "loss": 0.0001,
      "step": 12289
    },
    {
      "epoch": 47.63565891472868,
      "grad_norm": 0.0008347212569788098,
      "learning_rate": 2.364341085271318e-06,
      "loss": 0.0001,
      "step": 12290
    },
    {
      "epoch": 47.63953488372093,
      "grad_norm": 0.0006175454473122954,
      "learning_rate": 2.36046511627907e-06,
      "loss": 0.0001,
      "step": 12291
    },
    {
      "epoch": 47.64341085271318,
      "grad_norm": 0.0010908179683610797,
      "learning_rate": 2.3565891472868216e-06,
      "loss": 0.0001,
      "step": 12292
    },
    {
      "epoch": 47.64728682170543,
      "grad_norm": 0.00102243444416672,
      "learning_rate": 2.3527131782945736e-06,
      "loss": 0.0001,
      "step": 12293
    },
    {
      "epoch": 47.651162790697676,
      "grad_norm": 0.002345721237361431,
      "learning_rate": 2.3488372093023256e-06,
      "loss": 0.0001,
      "step": 12294
    },
    {
      "epoch": 47.65503875968992,
      "grad_norm": 0.0021961091551929712,
      "learning_rate": 2.3449612403100776e-06,
      "loss": 0.0002,
      "step": 12295
    },
    {
      "epoch": 47.65891472868217,
      "grad_norm": 0.0007772271637804806,
      "learning_rate": 2.3410852713178296e-06,
      "loss": 0.0001,
      "step": 12296
    },
    {
      "epoch": 47.66279069767442,
      "grad_norm": 0.8825161457061768,
      "learning_rate": 2.3372093023255816e-06,
      "loss": 0.0009,
      "step": 12297
    },
    {
      "epoch": 47.666666666666664,
      "grad_norm": 0.0017817965708673,
      "learning_rate": 2.3333333333333336e-06,
      "loss": 0.0001,
      "step": 12298
    },
    {
      "epoch": 47.67054263565891,
      "grad_norm": 0.001896203262731433,
      "learning_rate": 2.329457364341085e-06,
      "loss": 0.0002,
      "step": 12299
    },
    {
      "epoch": 47.674418604651166,
      "grad_norm": 0.0006567375385202467,
      "learning_rate": 2.325581395348837e-06,
      "loss": 0.0001,
      "step": 12300
    },
    {
      "epoch": 47.67829457364341,
      "grad_norm": 0.0008483543642796576,
      "learning_rate": 2.321705426356589e-06,
      "loss": 0.0001,
      "step": 12301
    },
    {
      "epoch": 47.68217054263566,
      "grad_norm": 0.0008892890764400363,
      "learning_rate": 2.317829457364341e-06,
      "loss": 0.0001,
      "step": 12302
    },
    {
      "epoch": 47.68604651162791,
      "grad_norm": 0.0007699725101701915,
      "learning_rate": 2.313953488372093e-06,
      "loss": 0.0001,
      "step": 12303
    },
    {
      "epoch": 47.689922480620154,
      "grad_norm": 0.0007203767308965325,
      "learning_rate": 2.310077519379845e-06,
      "loss": 0.0001,
      "step": 12304
    },
    {
      "epoch": 47.6937984496124,
      "grad_norm": 0.001975370803847909,
      "learning_rate": 2.306201550387597e-06,
      "loss": 0.0002,
      "step": 12305
    },
    {
      "epoch": 47.69767441860465,
      "grad_norm": 0.0011484057176858187,
      "learning_rate": 2.3023255813953487e-06,
      "loss": 0.0001,
      "step": 12306
    },
    {
      "epoch": 47.701550387596896,
      "grad_norm": 0.0006626214599236846,
      "learning_rate": 2.2984496124031007e-06,
      "loss": 0.0001,
      "step": 12307
    },
    {
      "epoch": 47.70542635658915,
      "grad_norm": 0.0010072781005874276,
      "learning_rate": 2.294573643410853e-06,
      "loss": 0.0001,
      "step": 12308
    },
    {
      "epoch": 47.7093023255814,
      "grad_norm": 0.0013043503277003765,
      "learning_rate": 2.2906976744186047e-06,
      "loss": 0.0001,
      "step": 12309
    },
    {
      "epoch": 47.713178294573645,
      "grad_norm": 0.0007143592811189592,
      "learning_rate": 2.2868217054263567e-06,
      "loss": 0.0001,
      "step": 12310
    },
    {
      "epoch": 47.71705426356589,
      "grad_norm": 0.0012172780698165298,
      "learning_rate": 2.2829457364341087e-06,
      "loss": 0.0001,
      "step": 12311
    },
    {
      "epoch": 47.72093023255814,
      "grad_norm": 0.0010516114998608828,
      "learning_rate": 2.2790697674418603e-06,
      "loss": 0.0001,
      "step": 12312
    },
    {
      "epoch": 47.724806201550386,
      "grad_norm": 0.0015009439084678888,
      "learning_rate": 2.2751937984496123e-06,
      "loss": 0.0001,
      "step": 12313
    },
    {
      "epoch": 47.72868217054263,
      "grad_norm": 0.0007740146247670054,
      "learning_rate": 2.2713178294573643e-06,
      "loss": 0.0001,
      "step": 12314
    },
    {
      "epoch": 47.73255813953488,
      "grad_norm": 0.008743813261389732,
      "learning_rate": 2.2674418604651167e-06,
      "loss": 0.0004,
      "step": 12315
    },
    {
      "epoch": 47.736434108527135,
      "grad_norm": 0.0007357208523899317,
      "learning_rate": 2.2635658914728683e-06,
      "loss": 0.0001,
      "step": 12316
    },
    {
      "epoch": 47.74031007751938,
      "grad_norm": 0.0006355291116051376,
      "learning_rate": 2.2596899224806203e-06,
      "loss": 0.0001,
      "step": 12317
    },
    {
      "epoch": 47.74418604651163,
      "grad_norm": 0.0015495606930926442,
      "learning_rate": 2.2558139534883723e-06,
      "loss": 0.0001,
      "step": 12318
    },
    {
      "epoch": 47.748062015503876,
      "grad_norm": 0.0006479991134256124,
      "learning_rate": 2.251937984496124e-06,
      "loss": 0.0001,
      "step": 12319
    },
    {
      "epoch": 47.751937984496124,
      "grad_norm": 0.0009250464499928057,
      "learning_rate": 2.248062015503876e-06,
      "loss": 0.0001,
      "step": 12320
    },
    {
      "epoch": 47.75581395348837,
      "grad_norm": 0.0007395835127681494,
      "learning_rate": 2.2441860465116283e-06,
      "loss": 0.0001,
      "step": 12321
    },
    {
      "epoch": 47.75968992248062,
      "grad_norm": 0.0008897939114831388,
      "learning_rate": 2.24031007751938e-06,
      "loss": 0.0001,
      "step": 12322
    },
    {
      "epoch": 47.763565891472865,
      "grad_norm": 0.00542431091889739,
      "learning_rate": 2.236434108527132e-06,
      "loss": 0.0001,
      "step": 12323
    },
    {
      "epoch": 47.76744186046512,
      "grad_norm": 0.0019385983468964696,
      "learning_rate": 2.232558139534884e-06,
      "loss": 0.0001,
      "step": 12324
    },
    {
      "epoch": 47.77131782945737,
      "grad_norm": 0.0006762690609320998,
      "learning_rate": 2.228682170542636e-06,
      "loss": 0.0001,
      "step": 12325
    },
    {
      "epoch": 47.775193798449614,
      "grad_norm": 0.4725199043750763,
      "learning_rate": 2.2248062015503874e-06,
      "loss": 0.0196,
      "step": 12326
    },
    {
      "epoch": 47.77906976744186,
      "grad_norm": 0.0006597714964300394,
      "learning_rate": 2.22093023255814e-06,
      "loss": 0.0001,
      "step": 12327
    },
    {
      "epoch": 47.78294573643411,
      "grad_norm": 0.0006337329978123307,
      "learning_rate": 2.217054263565892e-06,
      "loss": 0.0001,
      "step": 12328
    },
    {
      "epoch": 47.786821705426355,
      "grad_norm": 0.0007346287602558732,
      "learning_rate": 2.2131782945736434e-06,
      "loss": 0.0001,
      "step": 12329
    },
    {
      "epoch": 47.7906976744186,
      "grad_norm": 0.001329550752416253,
      "learning_rate": 2.2093023255813954e-06,
      "loss": 0.0001,
      "step": 12330
    },
    {
      "epoch": 47.79457364341085,
      "grad_norm": 8.294617652893066,
      "learning_rate": 2.2054263565891474e-06,
      "loss": 0.0056,
      "step": 12331
    },
    {
      "epoch": 47.798449612403104,
      "grad_norm": 0.0007597544463351369,
      "learning_rate": 2.201550387596899e-06,
      "loss": 0.0001,
      "step": 12332
    },
    {
      "epoch": 47.80232558139535,
      "grad_norm": 0.0014690769603475928,
      "learning_rate": 2.1976744186046514e-06,
      "loss": 0.0001,
      "step": 12333
    },
    {
      "epoch": 47.8062015503876,
      "grad_norm": 0.0029224224854260683,
      "learning_rate": 2.1937984496124034e-06,
      "loss": 0.0002,
      "step": 12334
    },
    {
      "epoch": 47.810077519379846,
      "grad_norm": 0.0014203810133039951,
      "learning_rate": 2.1899224806201554e-06,
      "loss": 0.0001,
      "step": 12335
    },
    {
      "epoch": 47.81395348837209,
      "grad_norm": 0.000996075919829309,
      "learning_rate": 2.186046511627907e-06,
      "loss": 0.0001,
      "step": 12336
    },
    {
      "epoch": 47.81782945736434,
      "grad_norm": 0.0006487788632512093,
      "learning_rate": 2.182170542635659e-06,
      "loss": 0.0001,
      "step": 12337
    },
    {
      "epoch": 47.82170542635659,
      "grad_norm": 0.0008146063191816211,
      "learning_rate": 2.178294573643411e-06,
      "loss": 0.0001,
      "step": 12338
    },
    {
      "epoch": 47.825581395348834,
      "grad_norm": 0.0007273776573128998,
      "learning_rate": 2.174418604651163e-06,
      "loss": 0.0001,
      "step": 12339
    },
    {
      "epoch": 47.82945736434109,
      "grad_norm": 0.001170269912108779,
      "learning_rate": 2.170542635658915e-06,
      "loss": 0.0001,
      "step": 12340
    },
    {
      "epoch": 47.833333333333336,
      "grad_norm": 0.0020044739358127117,
      "learning_rate": 2.166666666666667e-06,
      "loss": 0.0002,
      "step": 12341
    },
    {
      "epoch": 47.83720930232558,
      "grad_norm": 3.575051784515381,
      "learning_rate": 2.1627906976744185e-06,
      "loss": 0.4448,
      "step": 12342
    },
    {
      "epoch": 47.84108527131783,
      "grad_norm": 0.0014847300481051207,
      "learning_rate": 2.1589147286821705e-06,
      "loss": 0.0001,
      "step": 12343
    },
    {
      "epoch": 47.84496124031008,
      "grad_norm": 0.001041318872012198,
      "learning_rate": 2.1550387596899225e-06,
      "loss": 0.0001,
      "step": 12344
    },
    {
      "epoch": 47.848837209302324,
      "grad_norm": 0.0006689867586828768,
      "learning_rate": 2.1511627906976745e-06,
      "loss": 0.0001,
      "step": 12345
    },
    {
      "epoch": 47.85271317829457,
      "grad_norm": 0.0011873014736920595,
      "learning_rate": 2.1472868217054265e-06,
      "loss": 0.0001,
      "step": 12346
    },
    {
      "epoch": 47.85658914728682,
      "grad_norm": 0.0007408168748952448,
      "learning_rate": 2.1434108527131785e-06,
      "loss": 0.0001,
      "step": 12347
    },
    {
      "epoch": 47.86046511627907,
      "grad_norm": 0.0006332654156722128,
      "learning_rate": 2.1395348837209305e-06,
      "loss": 0.0001,
      "step": 12348
    },
    {
      "epoch": 47.86434108527132,
      "grad_norm": 0.002193919848650694,
      "learning_rate": 2.135658914728682e-06,
      "loss": 0.0001,
      "step": 12349
    },
    {
      "epoch": 47.86821705426357,
      "grad_norm": 0.0008787165861576796,
      "learning_rate": 2.131782945736434e-06,
      "loss": 0.0001,
      "step": 12350
    },
    {
      "epoch": 47.872093023255815,
      "grad_norm": 0.000858092273119837,
      "learning_rate": 2.127906976744186e-06,
      "loss": 0.0001,
      "step": 12351
    },
    {
      "epoch": 47.87596899224806,
      "grad_norm": 0.0018050161888822913,
      "learning_rate": 2.124031007751938e-06,
      "loss": 0.0001,
      "step": 12352
    },
    {
      "epoch": 47.87984496124031,
      "grad_norm": 0.0014062810223549604,
      "learning_rate": 2.12015503875969e-06,
      "loss": 0.0001,
      "step": 12353
    },
    {
      "epoch": 47.883720930232556,
      "grad_norm": 0.0011443000985309482,
      "learning_rate": 2.116279069767442e-06,
      "loss": 0.0001,
      "step": 12354
    },
    {
      "epoch": 47.8875968992248,
      "grad_norm": 0.0012014455860480666,
      "learning_rate": 2.112403100775194e-06,
      "loss": 0.0001,
      "step": 12355
    },
    {
      "epoch": 47.89147286821706,
      "grad_norm": 0.0008084077853709459,
      "learning_rate": 2.1085271317829457e-06,
      "loss": 0.0001,
      "step": 12356
    },
    {
      "epoch": 47.895348837209305,
      "grad_norm": 0.0007255207747220993,
      "learning_rate": 2.1046511627906977e-06,
      "loss": 0.0001,
      "step": 12357
    },
    {
      "epoch": 47.89922480620155,
      "grad_norm": 0.0007281408179551363,
      "learning_rate": 2.1007751937984497e-06,
      "loss": 0.0001,
      "step": 12358
    },
    {
      "epoch": 47.9031007751938,
      "grad_norm": 0.0007519173668697476,
      "learning_rate": 2.0968992248062017e-06,
      "loss": 0.0001,
      "step": 12359
    },
    {
      "epoch": 47.906976744186046,
      "grad_norm": 0.0006464425823651254,
      "learning_rate": 2.0930232558139536e-06,
      "loss": 0.0001,
      "step": 12360
    },
    {
      "epoch": 47.91085271317829,
      "grad_norm": 0.21586741507053375,
      "learning_rate": 2.0891472868217056e-06,
      "loss": 0.0089,
      "step": 12361
    },
    {
      "epoch": 47.91472868217054,
      "grad_norm": 0.0013338604476302862,
      "learning_rate": 2.0852713178294572e-06,
      "loss": 0.0001,
      "step": 12362
    },
    {
      "epoch": 47.91860465116279,
      "grad_norm": 0.0016067575197666883,
      "learning_rate": 2.0813953488372092e-06,
      "loss": 0.0001,
      "step": 12363
    },
    {
      "epoch": 47.92248062015504,
      "grad_norm": 0.0007026668172329664,
      "learning_rate": 2.0775193798449612e-06,
      "loss": 0.0001,
      "step": 12364
    },
    {
      "epoch": 47.92635658914729,
      "grad_norm": 0.0024605682119727135,
      "learning_rate": 2.0736434108527132e-06,
      "loss": 0.0002,
      "step": 12365
    },
    {
      "epoch": 47.93023255813954,
      "grad_norm": 0.01873600296676159,
      "learning_rate": 2.0697674418604652e-06,
      "loss": 0.0002,
      "step": 12366
    },
    {
      "epoch": 47.934108527131784,
      "grad_norm": 0.0012178621254861355,
      "learning_rate": 2.0658914728682172e-06,
      "loss": 0.0001,
      "step": 12367
    },
    {
      "epoch": 47.93798449612403,
      "grad_norm": 0.029181616380810738,
      "learning_rate": 2.062015503875969e-06,
      "loss": 0.0002,
      "step": 12368
    },
    {
      "epoch": 47.94186046511628,
      "grad_norm": 0.000733800872694701,
      "learning_rate": 2.0581395348837208e-06,
      "loss": 0.0001,
      "step": 12369
    },
    {
      "epoch": 47.945736434108525,
      "grad_norm": 0.001125417067669332,
      "learning_rate": 2.0542635658914728e-06,
      "loss": 0.0001,
      "step": 12370
    },
    {
      "epoch": 47.94961240310077,
      "grad_norm": 0.0005477439844980836,
      "learning_rate": 2.0503875968992248e-06,
      "loss": 0.0001,
      "step": 12371
    },
    {
      "epoch": 47.95348837209303,
      "grad_norm": 0.002184386597946286,
      "learning_rate": 2.0465116279069768e-06,
      "loss": 0.0002,
      "step": 12372
    },
    {
      "epoch": 47.957364341085274,
      "grad_norm": 0.0007076294277794659,
      "learning_rate": 2.0426356589147288e-06,
      "loss": 0.0001,
      "step": 12373
    },
    {
      "epoch": 47.96124031007752,
      "grad_norm": 0.0008331892895512283,
      "learning_rate": 2.0387596899224808e-06,
      "loss": 0.0001,
      "step": 12374
    },
    {
      "epoch": 47.96511627906977,
      "grad_norm": 0.001061270129866898,
      "learning_rate": 2.0348837209302328e-06,
      "loss": 0.0001,
      "step": 12375
    },
    {
      "epoch": 47.968992248062015,
      "grad_norm": 0.003047629725188017,
      "learning_rate": 2.0310077519379843e-06,
      "loss": 0.0002,
      "step": 12376
    },
    {
      "epoch": 47.97286821705426,
      "grad_norm": 0.0011231041280552745,
      "learning_rate": 2.0271317829457363e-06,
      "loss": 0.0001,
      "step": 12377
    },
    {
      "epoch": 47.97674418604651,
      "grad_norm": 0.0006096815341152251,
      "learning_rate": 2.0232558139534888e-06,
      "loss": 0.0001,
      "step": 12378
    },
    {
      "epoch": 47.98062015503876,
      "grad_norm": 0.2508012354373932,
      "learning_rate": 2.0193798449612403e-06,
      "loss": 0.0009,
      "step": 12379
    },
    {
      "epoch": 47.98449612403101,
      "grad_norm": 0.0010224730940535665,
      "learning_rate": 2.0155038759689923e-06,
      "loss": 0.0001,
      "step": 12380
    },
    {
      "epoch": 47.98837209302326,
      "grad_norm": 0.0376877635717392,
      "learning_rate": 2.0116279069767443e-06,
      "loss": 0.0009,
      "step": 12381
    },
    {
      "epoch": 47.992248062015506,
      "grad_norm": 0.0009649926796555519,
      "learning_rate": 2.007751937984496e-06,
      "loss": 0.0001,
      "step": 12382
    },
    {
      "epoch": 47.99612403100775,
      "grad_norm": 0.000657103315461427,
      "learning_rate": 2.003875968992248e-06,
      "loss": 0.0001,
      "step": 12383
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.0020130332559347153,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0001,
      "step": 12384
    },
    {
      "epoch": 48.00387596899225,
      "grad_norm": 0.0021332264877855778,
      "learning_rate": 1.9961240310077523e-06,
      "loss": 0.0002,
      "step": 12385
    },
    {
      "epoch": 48.007751937984494,
      "grad_norm": 0.0009633568697609007,
      "learning_rate": 1.992248062015504e-06,
      "loss": 0.0001,
      "step": 12386
    },
    {
      "epoch": 48.01162790697674,
      "grad_norm": 0.015273313038051128,
      "learning_rate": 1.988372093023256e-06,
      "loss": 0.0007,
      "step": 12387
    },
    {
      "epoch": 48.01550387596899,
      "grad_norm": 0.0007015375304035842,
      "learning_rate": 1.984496124031008e-06,
      "loss": 0.0001,
      "step": 12388
    },
    {
      "epoch": 48.01937984496124,
      "grad_norm": 0.0017760052578523755,
      "learning_rate": 1.9806201550387595e-06,
      "loss": 0.0001,
      "step": 12389
    },
    {
      "epoch": 48.02325581395349,
      "grad_norm": 0.00064019177807495,
      "learning_rate": 1.976744186046512e-06,
      "loss": 0.0001,
      "step": 12390
    },
    {
      "epoch": 48.02713178294574,
      "grad_norm": 0.000720644777175039,
      "learning_rate": 1.972868217054264e-06,
      "loss": 0.0001,
      "step": 12391
    },
    {
      "epoch": 48.031007751937985,
      "grad_norm": 0.0006323584238998592,
      "learning_rate": 1.9689922480620155e-06,
      "loss": 0.0001,
      "step": 12392
    },
    {
      "epoch": 48.03488372093023,
      "grad_norm": 0.0065852440893650055,
      "learning_rate": 1.9651162790697675e-06,
      "loss": 0.0001,
      "step": 12393
    },
    {
      "epoch": 48.03875968992248,
      "grad_norm": 0.0006382063147611916,
      "learning_rate": 1.9612403100775195e-06,
      "loss": 0.0001,
      "step": 12394
    },
    {
      "epoch": 48.042635658914726,
      "grad_norm": 0.0010290909558534622,
      "learning_rate": 1.9573643410852715e-06,
      "loss": 0.0001,
      "step": 12395
    },
    {
      "epoch": 48.04651162790697,
      "grad_norm": 0.0006640987121500075,
      "learning_rate": 1.9534883720930235e-06,
      "loss": 0.0001,
      "step": 12396
    },
    {
      "epoch": 48.05038759689923,
      "grad_norm": 0.0006521536270156503,
      "learning_rate": 1.9496124031007755e-06,
      "loss": 0.0001,
      "step": 12397
    },
    {
      "epoch": 48.054263565891475,
      "grad_norm": 0.0012421986320987344,
      "learning_rate": 1.9457364341085275e-06,
      "loss": 0.0001,
      "step": 12398
    },
    {
      "epoch": 48.05813953488372,
      "grad_norm": 0.0006022521993145347,
      "learning_rate": 1.941860465116279e-06,
      "loss": 0.0001,
      "step": 12399
    },
    {
      "epoch": 48.06201550387597,
      "grad_norm": 0.0007780516752973199,
      "learning_rate": 1.937984496124031e-06,
      "loss": 0.0001,
      "step": 12400
    },
    {
      "epoch": 48.065891472868216,
      "grad_norm": 0.0006268088473007083,
      "learning_rate": 1.934108527131783e-06,
      "loss": 0.0001,
      "step": 12401
    },
    {
      "epoch": 48.06976744186046,
      "grad_norm": 0.000898533093277365,
      "learning_rate": 1.9302325581395346e-06,
      "loss": 0.0001,
      "step": 12402
    },
    {
      "epoch": 48.07364341085271,
      "grad_norm": 0.007630595471709967,
      "learning_rate": 1.926356589147287e-06,
      "loss": 0.0002,
      "step": 12403
    },
    {
      "epoch": 48.07751937984496,
      "grad_norm": 0.002192598767578602,
      "learning_rate": 1.922480620155039e-06,
      "loss": 0.0001,
      "step": 12404
    },
    {
      "epoch": 48.08139534883721,
      "grad_norm": 0.0007292110822163522,
      "learning_rate": 1.918604651162791e-06,
      "loss": 0.0001,
      "step": 12405
    },
    {
      "epoch": 48.08527131782946,
      "grad_norm": 0.0006848031189292669,
      "learning_rate": 1.9147286821705426e-06,
      "loss": 0.0001,
      "step": 12406
    },
    {
      "epoch": 48.08914728682171,
      "grad_norm": 0.000573134864680469,
      "learning_rate": 1.9108527131782946e-06,
      "loss": 0.0001,
      "step": 12407
    },
    {
      "epoch": 48.093023255813954,
      "grad_norm": 0.014054855331778526,
      "learning_rate": 1.9069767441860468e-06,
      "loss": 0.0005,
      "step": 12408
    },
    {
      "epoch": 48.0968992248062,
      "grad_norm": 0.062350932508707047,
      "learning_rate": 1.9031007751937984e-06,
      "loss": 0.0014,
      "step": 12409
    },
    {
      "epoch": 48.10077519379845,
      "grad_norm": 0.0006957766017876565,
      "learning_rate": 1.8992248062015504e-06,
      "loss": 0.0001,
      "step": 12410
    },
    {
      "epoch": 48.104651162790695,
      "grad_norm": 0.0007861994090490043,
      "learning_rate": 1.8953488372093026e-06,
      "loss": 0.0001,
      "step": 12411
    },
    {
      "epoch": 48.10852713178294,
      "grad_norm": 0.0010528337443247437,
      "learning_rate": 1.8914728682170542e-06,
      "loss": 0.0001,
      "step": 12412
    },
    {
      "epoch": 48.1124031007752,
      "grad_norm": 0.001139554544351995,
      "learning_rate": 1.8875968992248062e-06,
      "loss": 0.0001,
      "step": 12413
    },
    {
      "epoch": 48.116279069767444,
      "grad_norm": 0.000627877947408706,
      "learning_rate": 1.8837209302325584e-06,
      "loss": 0.0001,
      "step": 12414
    },
    {
      "epoch": 48.12015503875969,
      "grad_norm": 0.0006611495045945048,
      "learning_rate": 1.8798449612403104e-06,
      "loss": 0.0001,
      "step": 12415
    },
    {
      "epoch": 48.12403100775194,
      "grad_norm": 0.0014607806224375963,
      "learning_rate": 1.875968992248062e-06,
      "loss": 0.0001,
      "step": 12416
    },
    {
      "epoch": 48.127906976744185,
      "grad_norm": 0.002490540500730276,
      "learning_rate": 1.8720930232558142e-06,
      "loss": 0.0002,
      "step": 12417
    },
    {
      "epoch": 48.13178294573643,
      "grad_norm": 0.0006229299469850957,
      "learning_rate": 1.8682170542635662e-06,
      "loss": 0.0001,
      "step": 12418
    },
    {
      "epoch": 48.13565891472868,
      "grad_norm": 0.0008631216478534043,
      "learning_rate": 1.8643410852713177e-06,
      "loss": 0.0001,
      "step": 12419
    },
    {
      "epoch": 48.13953488372093,
      "grad_norm": 0.0008881762623786926,
      "learning_rate": 1.86046511627907e-06,
      "loss": 0.0001,
      "step": 12420
    },
    {
      "epoch": 48.14341085271318,
      "grad_norm": 0.004935776814818382,
      "learning_rate": 1.856589147286822e-06,
      "loss": 0.0002,
      "step": 12421
    },
    {
      "epoch": 48.14728682170543,
      "grad_norm": 0.0016245661536231637,
      "learning_rate": 1.8527131782945735e-06,
      "loss": 0.0001,
      "step": 12422
    },
    {
      "epoch": 48.151162790697676,
      "grad_norm": 0.0007176136714406312,
      "learning_rate": 1.8488372093023255e-06,
      "loss": 0.0001,
      "step": 12423
    },
    {
      "epoch": 48.15503875968992,
      "grad_norm": 0.0013219808461144567,
      "learning_rate": 1.8449612403100777e-06,
      "loss": 0.0001,
      "step": 12424
    },
    {
      "epoch": 48.15891472868217,
      "grad_norm": 0.37964534759521484,
      "learning_rate": 1.8410852713178297e-06,
      "loss": 0.0154,
      "step": 12425
    },
    {
      "epoch": 48.16279069767442,
      "grad_norm": 0.0010239509865641594,
      "learning_rate": 1.8372093023255813e-06,
      "loss": 0.0001,
      "step": 12426
    },
    {
      "epoch": 48.166666666666664,
      "grad_norm": 0.0006742684636265039,
      "learning_rate": 1.8333333333333335e-06,
      "loss": 0.0001,
      "step": 12427
    },
    {
      "epoch": 48.17054263565891,
      "grad_norm": 0.0013215658254921436,
      "learning_rate": 1.8294573643410855e-06,
      "loss": 0.0001,
      "step": 12428
    },
    {
      "epoch": 48.174418604651166,
      "grad_norm": 0.0010025342926383018,
      "learning_rate": 1.825581395348837e-06,
      "loss": 0.0001,
      "step": 12429
    },
    {
      "epoch": 48.17829457364341,
      "grad_norm": 0.0006682660314254463,
      "learning_rate": 1.8217054263565893e-06,
      "loss": 0.0001,
      "step": 12430
    },
    {
      "epoch": 48.18217054263566,
      "grad_norm": 0.0010268492624163628,
      "learning_rate": 1.8178294573643413e-06,
      "loss": 0.0001,
      "step": 12431
    },
    {
      "epoch": 48.18604651162791,
      "grad_norm": 0.0007399213500320911,
      "learning_rate": 1.8139534883720929e-06,
      "loss": 0.0001,
      "step": 12432
    },
    {
      "epoch": 48.189922480620154,
      "grad_norm": 3.6319377422332764,
      "learning_rate": 1.810077519379845e-06,
      "loss": 0.3369,
      "step": 12433
    },
    {
      "epoch": 48.1937984496124,
      "grad_norm": 0.0017894998891279101,
      "learning_rate": 1.806201550387597e-06,
      "loss": 0.0001,
      "step": 12434
    },
    {
      "epoch": 48.19767441860465,
      "grad_norm": 0.0005815202603116632,
      "learning_rate": 1.802325581395349e-06,
      "loss": 0.0001,
      "step": 12435
    },
    {
      "epoch": 48.201550387596896,
      "grad_norm": 0.0023983814753592014,
      "learning_rate": 1.7984496124031008e-06,
      "loss": 0.0001,
      "step": 12436
    },
    {
      "epoch": 48.20542635658915,
      "grad_norm": 0.1598956286907196,
      "learning_rate": 1.7945736434108528e-06,
      "loss": 0.0003,
      "step": 12437
    },
    {
      "epoch": 48.2093023255814,
      "grad_norm": 0.0007269951747730374,
      "learning_rate": 1.7906976744186048e-06,
      "loss": 0.0001,
      "step": 12438
    },
    {
      "epoch": 48.213178294573645,
      "grad_norm": 0.0018532307585701346,
      "learning_rate": 1.7868217054263566e-06,
      "loss": 0.0001,
      "step": 12439
    },
    {
      "epoch": 48.21705426356589,
      "grad_norm": 0.0007316148839890957,
      "learning_rate": 1.7829457364341086e-06,
      "loss": 0.0001,
      "step": 12440
    },
    {
      "epoch": 48.22093023255814,
      "grad_norm": 0.0006625247187912464,
      "learning_rate": 1.7790697674418606e-06,
      "loss": 0.0001,
      "step": 12441
    },
    {
      "epoch": 48.224806201550386,
      "grad_norm": 0.0011230211239308119,
      "learning_rate": 1.7751937984496124e-06,
      "loss": 0.0001,
      "step": 12442
    },
    {
      "epoch": 48.22868217054263,
      "grad_norm": 0.3467002511024475,
      "learning_rate": 1.7713178294573644e-06,
      "loss": 0.0139,
      "step": 12443
    },
    {
      "epoch": 48.23255813953488,
      "grad_norm": 0.0007848023087717593,
      "learning_rate": 1.7674418604651164e-06,
      "loss": 0.0001,
      "step": 12444
    },
    {
      "epoch": 48.236434108527135,
      "grad_norm": 0.000801469199359417,
      "learning_rate": 1.7635658914728684e-06,
      "loss": 0.0001,
      "step": 12445
    },
    {
      "epoch": 48.24031007751938,
      "grad_norm": 0.0010713314404711127,
      "learning_rate": 1.7596899224806202e-06,
      "loss": 0.0001,
      "step": 12446
    },
    {
      "epoch": 48.24418604651163,
      "grad_norm": 0.002020128071308136,
      "learning_rate": 1.7558139534883722e-06,
      "loss": 0.0002,
      "step": 12447
    },
    {
      "epoch": 48.248062015503876,
      "grad_norm": 0.0010653083445504308,
      "learning_rate": 1.7519379844961242e-06,
      "loss": 0.0001,
      "step": 12448
    },
    {
      "epoch": 48.251937984496124,
      "grad_norm": 0.0007504664245061576,
      "learning_rate": 1.748062015503876e-06,
      "loss": 0.0001,
      "step": 12449
    },
    {
      "epoch": 48.25581395348837,
      "grad_norm": 0.003042822005227208,
      "learning_rate": 1.744186046511628e-06,
      "loss": 0.0002,
      "step": 12450
    },
    {
      "epoch": 48.25968992248062,
      "grad_norm": 0.000788858684245497,
      "learning_rate": 1.74031007751938e-06,
      "loss": 0.0001,
      "step": 12451
    },
    {
      "epoch": 48.263565891472865,
      "grad_norm": 0.0008763153455220163,
      "learning_rate": 1.7364341085271318e-06,
      "loss": 0.0001,
      "step": 12452
    },
    {
      "epoch": 48.26744186046512,
      "grad_norm": 0.0012930574594065547,
      "learning_rate": 1.7325581395348838e-06,
      "loss": 0.0001,
      "step": 12453
    },
    {
      "epoch": 48.27131782945737,
      "grad_norm": 1.5774805545806885,
      "learning_rate": 1.7286821705426358e-06,
      "loss": 0.1105,
      "step": 12454
    },
    {
      "epoch": 48.275193798449614,
      "grad_norm": 0.0012049643555656075,
      "learning_rate": 1.7248062015503877e-06,
      "loss": 0.0001,
      "step": 12455
    },
    {
      "epoch": 48.27906976744186,
      "grad_norm": 0.0006405296735465527,
      "learning_rate": 1.7209302325581395e-06,
      "loss": 0.0001,
      "step": 12456
    },
    {
      "epoch": 48.28294573643411,
      "grad_norm": 0.0016950452700257301,
      "learning_rate": 1.7170542635658915e-06,
      "loss": 0.0001,
      "step": 12457
    },
    {
      "epoch": 48.286821705426355,
      "grad_norm": 0.001166739733889699,
      "learning_rate": 1.7131782945736435e-06,
      "loss": 0.0001,
      "step": 12458
    },
    {
      "epoch": 48.2906976744186,
      "grad_norm": 0.0007057882030494511,
      "learning_rate": 1.7093023255813953e-06,
      "loss": 0.0001,
      "step": 12459
    },
    {
      "epoch": 48.29457364341085,
      "grad_norm": 0.0009916870621964335,
      "learning_rate": 1.7054263565891473e-06,
      "loss": 0.0001,
      "step": 12460
    },
    {
      "epoch": 48.298449612403104,
      "grad_norm": 0.0008275393047370017,
      "learning_rate": 1.7015503875968993e-06,
      "loss": 0.0001,
      "step": 12461
    },
    {
      "epoch": 48.30232558139535,
      "grad_norm": 0.0005682348855771124,
      "learning_rate": 1.697674418604651e-06,
      "loss": 0.0001,
      "step": 12462
    },
    {
      "epoch": 48.3062015503876,
      "grad_norm": 0.0010214012581855059,
      "learning_rate": 1.693798449612403e-06,
      "loss": 0.0001,
      "step": 12463
    },
    {
      "epoch": 48.310077519379846,
      "grad_norm": 0.000988457351922989,
      "learning_rate": 1.689922480620155e-06,
      "loss": 0.0001,
      "step": 12464
    },
    {
      "epoch": 48.31395348837209,
      "grad_norm": 0.0007487551192753017,
      "learning_rate": 1.6860465116279073e-06,
      "loss": 0.0001,
      "step": 12465
    },
    {
      "epoch": 48.31782945736434,
      "grad_norm": 0.0008054798818193376,
      "learning_rate": 1.6821705426356589e-06,
      "loss": 0.0001,
      "step": 12466
    },
    {
      "epoch": 48.32170542635659,
      "grad_norm": 0.008247985504567623,
      "learning_rate": 1.6782945736434109e-06,
      "loss": 0.0002,
      "step": 12467
    },
    {
      "epoch": 48.325581395348834,
      "grad_norm": 0.0014221316669136286,
      "learning_rate": 1.674418604651163e-06,
      "loss": 0.0001,
      "step": 12468
    },
    {
      "epoch": 48.32945736434109,
      "grad_norm": 0.0007206634036265314,
      "learning_rate": 1.6705426356589147e-06,
      "loss": 0.0001,
      "step": 12469
    },
    {
      "epoch": 48.333333333333336,
      "grad_norm": 0.0006379110855050385,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.0001,
      "step": 12470
    },
    {
      "epoch": 48.33720930232558,
      "grad_norm": 0.001299976371228695,
      "learning_rate": 1.6627906976744187e-06,
      "loss": 0.0001,
      "step": 12471
    },
    {
      "epoch": 48.34108527131783,
      "grad_norm": 0.0009255004115402699,
      "learning_rate": 1.6589147286821704e-06,
      "loss": 0.0001,
      "step": 12472
    },
    {
      "epoch": 48.34496124031008,
      "grad_norm": 0.0005820048972964287,
      "learning_rate": 1.6550387596899224e-06,
      "loss": 0.0001,
      "step": 12473
    },
    {
      "epoch": 48.348837209302324,
      "grad_norm": 0.0013095849426463246,
      "learning_rate": 1.6511627906976744e-06,
      "loss": 0.0001,
      "step": 12474
    },
    {
      "epoch": 48.35271317829457,
      "grad_norm": 0.0006424347520805895,
      "learning_rate": 1.6472868217054267e-06,
      "loss": 0.0001,
      "step": 12475
    },
    {
      "epoch": 48.35658914728682,
      "grad_norm": 0.0007006493397057056,
      "learning_rate": 1.6434108527131782e-06,
      "loss": 0.0001,
      "step": 12476
    },
    {
      "epoch": 48.36046511627907,
      "grad_norm": 0.0007576041389256716,
      "learning_rate": 1.6395348837209302e-06,
      "loss": 0.0001,
      "step": 12477
    },
    {
      "epoch": 48.36434108527132,
      "grad_norm": 0.0006922140019014478,
      "learning_rate": 1.6356589147286824e-06,
      "loss": 0.0001,
      "step": 12478
    },
    {
      "epoch": 48.36821705426357,
      "grad_norm": 0.0006518852896988392,
      "learning_rate": 1.631782945736434e-06,
      "loss": 0.0001,
      "step": 12479
    },
    {
      "epoch": 48.372093023255815,
      "grad_norm": 0.0008423855761066079,
      "learning_rate": 1.627906976744186e-06,
      "loss": 0.0001,
      "step": 12480
    },
    {
      "epoch": 48.37596899224806,
      "grad_norm": 0.0006526350625790656,
      "learning_rate": 1.6240310077519382e-06,
      "loss": 0.0001,
      "step": 12481
    },
    {
      "epoch": 48.37984496124031,
      "grad_norm": 0.0006005481700412929,
      "learning_rate": 1.6201550387596898e-06,
      "loss": 0.0001,
      "step": 12482
    },
    {
      "epoch": 48.383720930232556,
      "grad_norm": 0.0007798456936143339,
      "learning_rate": 1.6162790697674418e-06,
      "loss": 0.0001,
      "step": 12483
    },
    {
      "epoch": 48.3875968992248,
      "grad_norm": 0.0016119107604026794,
      "learning_rate": 1.612403100775194e-06,
      "loss": 0.0002,
      "step": 12484
    },
    {
      "epoch": 48.39147286821706,
      "grad_norm": 0.0006325390422716737,
      "learning_rate": 1.608527131782946e-06,
      "loss": 0.0001,
      "step": 12485
    },
    {
      "epoch": 48.395348837209305,
      "grad_norm": 0.0011446370044723153,
      "learning_rate": 1.6046511627906976e-06,
      "loss": 0.0001,
      "step": 12486
    },
    {
      "epoch": 48.39922480620155,
      "grad_norm": 0.0008346617687493563,
      "learning_rate": 1.6007751937984498e-06,
      "loss": 0.0001,
      "step": 12487
    },
    {
      "epoch": 48.4031007751938,
      "grad_norm": 0.0008576370310038328,
      "learning_rate": 1.5968992248062018e-06,
      "loss": 0.0001,
      "step": 12488
    },
    {
      "epoch": 48.406976744186046,
      "grad_norm": 0.0009851348586380482,
      "learning_rate": 1.5930232558139534e-06,
      "loss": 0.0001,
      "step": 12489
    },
    {
      "epoch": 48.41085271317829,
      "grad_norm": 0.0010271274950355291,
      "learning_rate": 1.5891472868217056e-06,
      "loss": 0.0001,
      "step": 12490
    },
    {
      "epoch": 48.41472868217054,
      "grad_norm": 0.0015098341973498464,
      "learning_rate": 1.5852713178294576e-06,
      "loss": 0.0001,
      "step": 12491
    },
    {
      "epoch": 48.41860465116279,
      "grad_norm": 0.0006509607774205506,
      "learning_rate": 1.5813953488372091e-06,
      "loss": 0.0001,
      "step": 12492
    },
    {
      "epoch": 48.42248062015504,
      "grad_norm": 0.0008361797081306577,
      "learning_rate": 1.5775193798449613e-06,
      "loss": 0.0001,
      "step": 12493
    },
    {
      "epoch": 48.42635658914729,
      "grad_norm": 0.0007380909519270062,
      "learning_rate": 1.5736434108527133e-06,
      "loss": 0.0001,
      "step": 12494
    },
    {
      "epoch": 48.43023255813954,
      "grad_norm": 0.0007611865294165909,
      "learning_rate": 1.5697674418604653e-06,
      "loss": 0.0001,
      "step": 12495
    },
    {
      "epoch": 48.434108527131784,
      "grad_norm": 0.001542149344459176,
      "learning_rate": 1.5658914728682171e-06,
      "loss": 0.0001,
      "step": 12496
    },
    {
      "epoch": 48.43798449612403,
      "grad_norm": 0.0006623920635320246,
      "learning_rate": 1.5620155038759691e-06,
      "loss": 0.0001,
      "step": 12497
    },
    {
      "epoch": 48.44186046511628,
      "grad_norm": 0.0007209738250821829,
      "learning_rate": 1.558139534883721e-06,
      "loss": 0.0001,
      "step": 12498
    },
    {
      "epoch": 48.445736434108525,
      "grad_norm": 0.0008310696575790644,
      "learning_rate": 1.554263565891473e-06,
      "loss": 0.0001,
      "step": 12499
    },
    {
      "epoch": 48.44961240310077,
      "grad_norm": 0.0008662825566716492,
      "learning_rate": 1.550387596899225e-06,
      "loss": 0.0001,
      "step": 12500
    },
    {
      "epoch": 48.45348837209303,
      "grad_norm": 0.0006125440704636276,
      "learning_rate": 1.546511627906977e-06,
      "loss": 0.0001,
      "step": 12501
    },
    {
      "epoch": 48.457364341085274,
      "grad_norm": 0.0007068240665830672,
      "learning_rate": 1.5426356589147287e-06,
      "loss": 0.0001,
      "step": 12502
    },
    {
      "epoch": 48.46124031007752,
      "grad_norm": 0.0008816572953946888,
      "learning_rate": 1.5387596899224807e-06,
      "loss": 0.0001,
      "step": 12503
    },
    {
      "epoch": 48.46511627906977,
      "grad_norm": 0.0008399276994168758,
      "learning_rate": 1.5348837209302327e-06,
      "loss": 0.0001,
      "step": 12504
    },
    {
      "epoch": 48.468992248062015,
      "grad_norm": 0.0008864228730089962,
      "learning_rate": 1.5310077519379845e-06,
      "loss": 0.0001,
      "step": 12505
    },
    {
      "epoch": 48.47286821705426,
      "grad_norm": 0.0006654749158769846,
      "learning_rate": 1.5271317829457367e-06,
      "loss": 0.0001,
      "step": 12506
    },
    {
      "epoch": 48.47674418604651,
      "grad_norm": 0.12845110893249512,
      "learning_rate": 1.5232558139534885e-06,
      "loss": 0.0022,
      "step": 12507
    },
    {
      "epoch": 48.48062015503876,
      "grad_norm": 0.002481222152709961,
      "learning_rate": 1.5193798449612403e-06,
      "loss": 0.0002,
      "step": 12508
    },
    {
      "epoch": 48.48449612403101,
      "grad_norm": 0.0007171537145040929,
      "learning_rate": 1.5155038759689925e-06,
      "loss": 0.0001,
      "step": 12509
    },
    {
      "epoch": 48.48837209302326,
      "grad_norm": 0.0014907491859048605,
      "learning_rate": 1.5116279069767443e-06,
      "loss": 0.0001,
      "step": 12510
    },
    {
      "epoch": 48.492248062015506,
      "grad_norm": 0.0032312865369021893,
      "learning_rate": 1.5077519379844963e-06,
      "loss": 0.0002,
      "step": 12511
    },
    {
      "epoch": 48.49612403100775,
      "grad_norm": 0.003055809997022152,
      "learning_rate": 1.5038759689922483e-06,
      "loss": 0.0001,
      "step": 12512
    },
    {
      "epoch": 48.5,
      "grad_norm": 0.0007822533370926976,
      "learning_rate": 1.5e-06,
      "loss": 0.0001,
      "step": 12513
    },
    {
      "epoch": 48.50387596899225,
      "grad_norm": 0.002508796053007245,
      "learning_rate": 1.496124031007752e-06,
      "loss": 0.0001,
      "step": 12514
    },
    {
      "epoch": 48.507751937984494,
      "grad_norm": 0.020400967448949814,
      "learning_rate": 1.4922480620155038e-06,
      "loss": 0.0004,
      "step": 12515
    },
    {
      "epoch": 48.51162790697674,
      "grad_norm": 0.0023107228334993124,
      "learning_rate": 1.488372093023256e-06,
      "loss": 0.0002,
      "step": 12516
    },
    {
      "epoch": 48.51550387596899,
      "grad_norm": 0.0008312479476444423,
      "learning_rate": 1.4844961240310078e-06,
      "loss": 0.0001,
      "step": 12517
    },
    {
      "epoch": 48.51937984496124,
      "grad_norm": 0.0009150855476036668,
      "learning_rate": 1.4806201550387596e-06,
      "loss": 0.0001,
      "step": 12518
    },
    {
      "epoch": 48.52325581395349,
      "grad_norm": 0.0008798972121439874,
      "learning_rate": 1.4767441860465118e-06,
      "loss": 0.0001,
      "step": 12519
    },
    {
      "epoch": 48.52713178294574,
      "grad_norm": 0.0008385608089156449,
      "learning_rate": 1.4728682170542636e-06,
      "loss": 0.0001,
      "step": 12520
    },
    {
      "epoch": 48.531007751937985,
      "grad_norm": 0.000677602190990001,
      "learning_rate": 1.4689922480620156e-06,
      "loss": 0.0001,
      "step": 12521
    },
    {
      "epoch": 48.53488372093023,
      "grad_norm": 0.0015688645653426647,
      "learning_rate": 1.4651162790697676e-06,
      "loss": 0.0001,
      "step": 12522
    },
    {
      "epoch": 48.53875968992248,
      "grad_norm": 0.0007987075950950384,
      "learning_rate": 1.4612403100775194e-06,
      "loss": 0.0001,
      "step": 12523
    },
    {
      "epoch": 48.542635658914726,
      "grad_norm": 0.0011001968523487449,
      "learning_rate": 1.4573643410852714e-06,
      "loss": 0.0001,
      "step": 12524
    },
    {
      "epoch": 48.54651162790697,
      "grad_norm": 0.0019184807315468788,
      "learning_rate": 1.4534883720930234e-06,
      "loss": 0.0002,
      "step": 12525
    },
    {
      "epoch": 48.55038759689923,
      "grad_norm": 0.0006920294254086912,
      "learning_rate": 1.4496124031007754e-06,
      "loss": 0.0001,
      "step": 12526
    },
    {
      "epoch": 48.554263565891475,
      "grad_norm": 0.0005970924394205213,
      "learning_rate": 1.4457364341085272e-06,
      "loss": 0.0001,
      "step": 12527
    },
    {
      "epoch": 48.55813953488372,
      "grad_norm": 0.0006416611722670496,
      "learning_rate": 1.4418604651162792e-06,
      "loss": 0.0001,
      "step": 12528
    },
    {
      "epoch": 48.56201550387597,
      "grad_norm": 0.0006696389173157513,
      "learning_rate": 1.4379844961240312e-06,
      "loss": 0.0001,
      "step": 12529
    },
    {
      "epoch": 48.565891472868216,
      "grad_norm": 0.000734224624466151,
      "learning_rate": 1.434108527131783e-06,
      "loss": 0.0001,
      "step": 12530
    },
    {
      "epoch": 48.56976744186046,
      "grad_norm": 0.0006620069616474211,
      "learning_rate": 1.430232558139535e-06,
      "loss": 0.0001,
      "step": 12531
    },
    {
      "epoch": 48.57364341085271,
      "grad_norm": 5.951051235198975,
      "learning_rate": 1.426356589147287e-06,
      "loss": 0.6832,
      "step": 12532
    },
    {
      "epoch": 48.57751937984496,
      "grad_norm": 0.17402972280979156,
      "learning_rate": 1.4224806201550387e-06,
      "loss": 0.007,
      "step": 12533
    },
    {
      "epoch": 48.58139534883721,
      "grad_norm": 0.0006175054586492479,
      "learning_rate": 1.4186046511627907e-06,
      "loss": 0.0001,
      "step": 12534
    },
    {
      "epoch": 48.58527131782946,
      "grad_norm": 0.0008953012875281274,
      "learning_rate": 1.4147286821705427e-06,
      "loss": 0.0001,
      "step": 12535
    },
    {
      "epoch": 48.58914728682171,
      "grad_norm": 0.0010117071215063334,
      "learning_rate": 1.4108527131782947e-06,
      "loss": 0.0001,
      "step": 12536
    },
    {
      "epoch": 48.593023255813954,
      "grad_norm": 0.0007986578857526183,
      "learning_rate": 1.4069767441860465e-06,
      "loss": 0.0001,
      "step": 12537
    },
    {
      "epoch": 48.5968992248062,
      "grad_norm": 0.6013033390045166,
      "learning_rate": 1.4031007751937985e-06,
      "loss": 0.0337,
      "step": 12538
    },
    {
      "epoch": 48.60077519379845,
      "grad_norm": 0.0008687322260811925,
      "learning_rate": 1.3992248062015505e-06,
      "loss": 0.0001,
      "step": 12539
    },
    {
      "epoch": 48.604651162790695,
      "grad_norm": 0.002402676735073328,
      "learning_rate": 1.3953488372093023e-06,
      "loss": 0.0002,
      "step": 12540
    },
    {
      "epoch": 48.60852713178294,
      "grad_norm": 0.000686823739670217,
      "learning_rate": 1.3914728682170545e-06,
      "loss": 0.0001,
      "step": 12541
    },
    {
      "epoch": 48.6124031007752,
      "grad_norm": 0.7751848697662354,
      "learning_rate": 1.3875968992248063e-06,
      "loss": 0.0361,
      "step": 12542
    },
    {
      "epoch": 48.616279069767444,
      "grad_norm": 0.0007008246029727161,
      "learning_rate": 1.383720930232558e-06,
      "loss": 0.0001,
      "step": 12543
    },
    {
      "epoch": 48.62015503875969,
      "grad_norm": 0.001209946465678513,
      "learning_rate": 1.3798449612403103e-06,
      "loss": 0.0001,
      "step": 12544
    },
    {
      "epoch": 48.62403100775194,
      "grad_norm": 0.005688853096216917,
      "learning_rate": 1.375968992248062e-06,
      "loss": 0.0001,
      "step": 12545
    },
    {
      "epoch": 48.627906976744185,
      "grad_norm": 0.0017667989013716578,
      "learning_rate": 1.372093023255814e-06,
      "loss": 0.0001,
      "step": 12546
    },
    {
      "epoch": 48.63178294573643,
      "grad_norm": 0.0007303463644348085,
      "learning_rate": 1.368217054263566e-06,
      "loss": 0.0001,
      "step": 12547
    },
    {
      "epoch": 48.63565891472868,
      "grad_norm": 0.0010585703421384096,
      "learning_rate": 1.3643410852713179e-06,
      "loss": 0.0001,
      "step": 12548
    },
    {
      "epoch": 48.63953488372093,
      "grad_norm": 0.0006861533038318157,
      "learning_rate": 1.3604651162790699e-06,
      "loss": 0.0001,
      "step": 12549
    },
    {
      "epoch": 48.64341085271318,
      "grad_norm": 0.0008920654654502869,
      "learning_rate": 1.3565891472868218e-06,
      "loss": 0.0001,
      "step": 12550
    },
    {
      "epoch": 48.64728682170543,
      "grad_norm": 0.0015870576025918126,
      "learning_rate": 1.3527131782945738e-06,
      "loss": 0.0001,
      "step": 12551
    },
    {
      "epoch": 48.651162790697676,
      "grad_norm": 0.39299729466438293,
      "learning_rate": 1.3488372093023256e-06,
      "loss": 0.0004,
      "step": 12552
    },
    {
      "epoch": 48.65503875968992,
      "grad_norm": 0.000760184891987592,
      "learning_rate": 1.3449612403100776e-06,
      "loss": 0.0001,
      "step": 12553
    },
    {
      "epoch": 48.65891472868217,
      "grad_norm": 0.0014366494724527001,
      "learning_rate": 1.3410852713178296e-06,
      "loss": 0.0001,
      "step": 12554
    },
    {
      "epoch": 48.66279069767442,
      "grad_norm": 0.0007698790286667645,
      "learning_rate": 1.3372093023255814e-06,
      "loss": 0.0001,
      "step": 12555
    },
    {
      "epoch": 48.666666666666664,
      "grad_norm": 0.0006665243417955935,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.0001,
      "step": 12556
    },
    {
      "epoch": 48.67054263565891,
      "grad_norm": 0.0006523329648189247,
      "learning_rate": 1.3294573643410854e-06,
      "loss": 0.0001,
      "step": 12557
    },
    {
      "epoch": 48.674418604651166,
      "grad_norm": 0.0016804718179628253,
      "learning_rate": 1.3255813953488372e-06,
      "loss": 0.0001,
      "step": 12558
    },
    {
      "epoch": 48.67829457364341,
      "grad_norm": 0.0010972736636176705,
      "learning_rate": 1.3217054263565892e-06,
      "loss": 0.0001,
      "step": 12559
    },
    {
      "epoch": 48.68217054263566,
      "grad_norm": 0.000702359015122056,
      "learning_rate": 1.3178294573643412e-06,
      "loss": 0.0001,
      "step": 12560
    },
    {
      "epoch": 48.68604651162791,
      "grad_norm": 0.0011716564185917377,
      "learning_rate": 1.3139534883720932e-06,
      "loss": 0.0001,
      "step": 12561
    },
    {
      "epoch": 48.689922480620154,
      "grad_norm": 1.807304859161377,
      "learning_rate": 1.310077519379845e-06,
      "loss": 0.1605,
      "step": 12562
    },
    {
      "epoch": 48.6937984496124,
      "grad_norm": 0.0017624039901420474,
      "learning_rate": 1.306201550387597e-06,
      "loss": 0.0001,
      "step": 12563
    },
    {
      "epoch": 48.69767441860465,
      "grad_norm": 0.0006591337732970715,
      "learning_rate": 1.302325581395349e-06,
      "loss": 0.0001,
      "step": 12564
    },
    {
      "epoch": 48.701550387596896,
      "grad_norm": 0.001351074781268835,
      "learning_rate": 1.2984496124031008e-06,
      "loss": 0.0001,
      "step": 12565
    },
    {
      "epoch": 48.70542635658915,
      "grad_norm": 0.0007851197733543813,
      "learning_rate": 1.2945736434108528e-06,
      "loss": 0.0001,
      "step": 12566
    },
    {
      "epoch": 48.7093023255814,
      "grad_norm": 0.0019665416330099106,
      "learning_rate": 1.2906976744186048e-06,
      "loss": 0.0002,
      "step": 12567
    },
    {
      "epoch": 48.713178294573645,
      "grad_norm": 0.0006374787189997733,
      "learning_rate": 1.2868217054263565e-06,
      "loss": 0.0001,
      "step": 12568
    },
    {
      "epoch": 48.71705426356589,
      "grad_norm": 0.006651749834418297,
      "learning_rate": 1.2829457364341085e-06,
      "loss": 0.0002,
      "step": 12569
    },
    {
      "epoch": 48.72093023255814,
      "grad_norm": 0.0011819517239928246,
      "learning_rate": 1.2790697674418605e-06,
      "loss": 0.0001,
      "step": 12570
    },
    {
      "epoch": 48.724806201550386,
      "grad_norm": 0.0014800800709053874,
      "learning_rate": 1.2751937984496125e-06,
      "loss": 0.0001,
      "step": 12571
    },
    {
      "epoch": 48.72868217054263,
      "grad_norm": 0.0006517816800624132,
      "learning_rate": 1.2713178294573643e-06,
      "loss": 0.0001,
      "step": 12572
    },
    {
      "epoch": 48.73255813953488,
      "grad_norm": 0.4335049092769623,
      "learning_rate": 1.2674418604651163e-06,
      "loss": 0.0189,
      "step": 12573
    },
    {
      "epoch": 48.736434108527135,
      "grad_norm": 0.0009745428105816245,
      "learning_rate": 1.2635658914728683e-06,
      "loss": 0.0001,
      "step": 12574
    },
    {
      "epoch": 48.74031007751938,
      "grad_norm": 0.0036688121035695076,
      "learning_rate": 1.2596899224806201e-06,
      "loss": 0.0002,
      "step": 12575
    },
    {
      "epoch": 48.74418604651163,
      "grad_norm": 0.0012534701963886619,
      "learning_rate": 1.2558139534883723e-06,
      "loss": 0.0001,
      "step": 12576
    },
    {
      "epoch": 48.748062015503876,
      "grad_norm": 0.0009134752326644957,
      "learning_rate": 1.251937984496124e-06,
      "loss": 0.0001,
      "step": 12577
    },
    {
      "epoch": 48.751937984496124,
      "grad_norm": 0.0019079040503129363,
      "learning_rate": 1.2480620155038759e-06,
      "loss": 0.0001,
      "step": 12578
    },
    {
      "epoch": 48.75581395348837,
      "grad_norm": 0.002880328567698598,
      "learning_rate": 1.244186046511628e-06,
      "loss": 0.0001,
      "step": 12579
    },
    {
      "epoch": 48.75968992248062,
      "grad_norm": 0.0006276521016843617,
      "learning_rate": 1.2403100775193799e-06,
      "loss": 0.0001,
      "step": 12580
    },
    {
      "epoch": 48.763565891472865,
      "grad_norm": 0.0010722109582275152,
      "learning_rate": 1.2364341085271317e-06,
      "loss": 0.0001,
      "step": 12581
    },
    {
      "epoch": 48.76744186046512,
      "grad_norm": 0.0008724274812266231,
      "learning_rate": 1.2325581395348839e-06,
      "loss": 0.0001,
      "step": 12582
    },
    {
      "epoch": 48.77131782945737,
      "grad_norm": 0.0007318108109757304,
      "learning_rate": 1.2286821705426357e-06,
      "loss": 0.0001,
      "step": 12583
    },
    {
      "epoch": 48.775193798449614,
      "grad_norm": 0.0013488983968272805,
      "learning_rate": 1.2248062015503877e-06,
      "loss": 0.0001,
      "step": 12584
    },
    {
      "epoch": 48.77906976744186,
      "grad_norm": 0.0006218344788067043,
      "learning_rate": 1.2209302325581397e-06,
      "loss": 0.0001,
      "step": 12585
    },
    {
      "epoch": 48.78294573643411,
      "grad_norm": 0.0014484729617834091,
      "learning_rate": 1.2170542635658915e-06,
      "loss": 0.0001,
      "step": 12586
    },
    {
      "epoch": 48.786821705426355,
      "grad_norm": 7.280357837677002,
      "learning_rate": 1.2131782945736434e-06,
      "loss": 0.0832,
      "step": 12587
    },
    {
      "epoch": 48.7906976744186,
      "grad_norm": 0.0054838163778185844,
      "learning_rate": 1.2093023255813954e-06,
      "loss": 0.0003,
      "step": 12588
    },
    {
      "epoch": 48.79457364341085,
      "grad_norm": 0.009873521514236927,
      "learning_rate": 1.2054263565891474e-06,
      "loss": 0.0002,
      "step": 12589
    },
    {
      "epoch": 48.798449612403104,
      "grad_norm": 0.0014178053243085742,
      "learning_rate": 1.2015503875968992e-06,
      "loss": 0.0001,
      "step": 12590
    },
    {
      "epoch": 48.80232558139535,
      "grad_norm": 0.34531766176223755,
      "learning_rate": 1.1976744186046512e-06,
      "loss": 0.0144,
      "step": 12591
    },
    {
      "epoch": 48.8062015503876,
      "grad_norm": 0.0020969207398593426,
      "learning_rate": 1.1937984496124032e-06,
      "loss": 0.0002,
      "step": 12592
    },
    {
      "epoch": 48.810077519379846,
      "grad_norm": 0.0008540544658899307,
      "learning_rate": 1.189922480620155e-06,
      "loss": 0.0001,
      "step": 12593
    },
    {
      "epoch": 48.81395348837209,
      "grad_norm": 0.005373778287321329,
      "learning_rate": 1.186046511627907e-06,
      "loss": 0.0002,
      "step": 12594
    },
    {
      "epoch": 48.81782945736434,
      "grad_norm": 0.0006204768433235586,
      "learning_rate": 1.182170542635659e-06,
      "loss": 0.0001,
      "step": 12595
    },
    {
      "epoch": 48.82170542635659,
      "grad_norm": 0.0006376575329340994,
      "learning_rate": 1.1782945736434108e-06,
      "loss": 0.0001,
      "step": 12596
    },
    {
      "epoch": 48.825581395348834,
      "grad_norm": 0.0006140528130345047,
      "learning_rate": 1.1744186046511628e-06,
      "loss": 0.0001,
      "step": 12597
    },
    {
      "epoch": 48.82945736434109,
      "grad_norm": 0.0009841506835073233,
      "learning_rate": 1.1705426356589148e-06,
      "loss": 0.0001,
      "step": 12598
    },
    {
      "epoch": 48.833333333333336,
      "grad_norm": 0.0012834930093958974,
      "learning_rate": 1.1666666666666668e-06,
      "loss": 0.0001,
      "step": 12599
    },
    {
      "epoch": 48.83720930232558,
      "grad_norm": 0.0006753318011760712,
      "learning_rate": 1.1627906976744186e-06,
      "loss": 0.0001,
      "step": 12600
    },
    {
      "epoch": 48.84108527131783,
      "grad_norm": 0.0007091012084856629,
      "learning_rate": 1.1589147286821706e-06,
      "loss": 0.0001,
      "step": 12601
    },
    {
      "epoch": 48.84496124031008,
      "grad_norm": 0.0008154874085448682,
      "learning_rate": 1.1550387596899226e-06,
      "loss": 0.0001,
      "step": 12602
    },
    {
      "epoch": 48.848837209302324,
      "grad_norm": 0.0006859641871415079,
      "learning_rate": 1.1511627906976744e-06,
      "loss": 0.0001,
      "step": 12603
    },
    {
      "epoch": 48.85271317829457,
      "grad_norm": 0.0006452222587540746,
      "learning_rate": 1.1472868217054266e-06,
      "loss": 0.0001,
      "step": 12604
    },
    {
      "epoch": 48.85658914728682,
      "grad_norm": 0.7835254669189453,
      "learning_rate": 1.1434108527131784e-06,
      "loss": 0.0432,
      "step": 12605
    },
    {
      "epoch": 48.86046511627907,
      "grad_norm": 0.0007282205624505877,
      "learning_rate": 1.1395348837209301e-06,
      "loss": 0.0001,
      "step": 12606
    },
    {
      "epoch": 48.86434108527132,
      "grad_norm": 0.0006668947171419859,
      "learning_rate": 1.1356589147286821e-06,
      "loss": 0.0001,
      "step": 12607
    },
    {
      "epoch": 48.86821705426357,
      "grad_norm": 0.0006964430795051157,
      "learning_rate": 1.1317829457364341e-06,
      "loss": 0.0001,
      "step": 12608
    },
    {
      "epoch": 48.872093023255815,
      "grad_norm": 0.0011467257281765342,
      "learning_rate": 1.1279069767441861e-06,
      "loss": 0.0001,
      "step": 12609
    },
    {
      "epoch": 48.87596899224806,
      "grad_norm": 1.4310119152069092,
      "learning_rate": 1.124031007751938e-06,
      "loss": 0.1385,
      "step": 12610
    },
    {
      "epoch": 48.87984496124031,
      "grad_norm": 0.0006050107185728848,
      "learning_rate": 1.12015503875969e-06,
      "loss": 0.0001,
      "step": 12611
    },
    {
      "epoch": 48.883720930232556,
      "grad_norm": 0.8100791573524475,
      "learning_rate": 1.116279069767442e-06,
      "loss": 0.0375,
      "step": 12612
    },
    {
      "epoch": 48.8875968992248,
      "grad_norm": 0.006168694701045752,
      "learning_rate": 1.1124031007751937e-06,
      "loss": 0.0002,
      "step": 12613
    },
    {
      "epoch": 48.89147286821706,
      "grad_norm": 0.0029583207797259092,
      "learning_rate": 1.108527131782946e-06,
      "loss": 0.0001,
      "step": 12614
    },
    {
      "epoch": 48.895348837209305,
      "grad_norm": 0.0005741653731092811,
      "learning_rate": 1.1046511627906977e-06,
      "loss": 0.0001,
      "step": 12615
    },
    {
      "epoch": 48.89922480620155,
      "grad_norm": 0.0007637067465111613,
      "learning_rate": 1.1007751937984495e-06,
      "loss": 0.0001,
      "step": 12616
    },
    {
      "epoch": 48.9031007751938,
      "grad_norm": 0.0006633487064391375,
      "learning_rate": 1.0968992248062017e-06,
      "loss": 0.0001,
      "step": 12617
    },
    {
      "epoch": 48.906976744186046,
      "grad_norm": 0.0022686151787638664,
      "learning_rate": 1.0930232558139535e-06,
      "loss": 0.0002,
      "step": 12618
    },
    {
      "epoch": 48.91085271317829,
      "grad_norm": 0.0005982434377074242,
      "learning_rate": 1.0891472868217055e-06,
      "loss": 0.0001,
      "step": 12619
    },
    {
      "epoch": 48.91472868217054,
      "grad_norm": 0.0009901388548314571,
      "learning_rate": 1.0852713178294575e-06,
      "loss": 0.0001,
      "step": 12620
    },
    {
      "epoch": 48.91860465116279,
      "grad_norm": 0.0008885942515917122,
      "learning_rate": 1.0813953488372093e-06,
      "loss": 0.0001,
      "step": 12621
    },
    {
      "epoch": 48.92248062015504,
      "grad_norm": 0.0010180965764448047,
      "learning_rate": 1.0775193798449613e-06,
      "loss": 0.0001,
      "step": 12622
    },
    {
      "epoch": 48.92635658914729,
      "grad_norm": 0.0007839028257876635,
      "learning_rate": 1.0736434108527133e-06,
      "loss": 0.0001,
      "step": 12623
    },
    {
      "epoch": 48.93023255813954,
      "grad_norm": 0.001476915436796844,
      "learning_rate": 1.0697674418604653e-06,
      "loss": 0.0001,
      "step": 12624
    },
    {
      "epoch": 48.934108527131784,
      "grad_norm": 0.0008271608967334032,
      "learning_rate": 1.065891472868217e-06,
      "loss": 0.0001,
      "step": 12625
    },
    {
      "epoch": 48.93798449612403,
      "grad_norm": 0.0008484279969707131,
      "learning_rate": 1.062015503875969e-06,
      "loss": 0.0001,
      "step": 12626
    },
    {
      "epoch": 48.94186046511628,
      "grad_norm": 0.0009785779984667897,
      "learning_rate": 1.058139534883721e-06,
      "loss": 0.0001,
      "step": 12627
    },
    {
      "epoch": 48.945736434108525,
      "grad_norm": 0.34647321701049805,
      "learning_rate": 1.0542635658914728e-06,
      "loss": 0.014,
      "step": 12628
    },
    {
      "epoch": 48.94961240310077,
      "grad_norm": 0.0006909589283168316,
      "learning_rate": 1.0503875968992248e-06,
      "loss": 0.0001,
      "step": 12629
    },
    {
      "epoch": 48.95348837209303,
      "grad_norm": 0.0013053016737103462,
      "learning_rate": 1.0465116279069768e-06,
      "loss": 0.0001,
      "step": 12630
    },
    {
      "epoch": 48.957364341085274,
      "grad_norm": 0.0010043871589004993,
      "learning_rate": 1.0426356589147286e-06,
      "loss": 0.0001,
      "step": 12631
    },
    {
      "epoch": 48.96124031007752,
      "grad_norm": 0.001015511923469603,
      "learning_rate": 1.0387596899224806e-06,
      "loss": 0.0001,
      "step": 12632
    },
    {
      "epoch": 48.96511627906977,
      "grad_norm": 0.002974429866299033,
      "learning_rate": 1.0348837209302326e-06,
      "loss": 0.0002,
      "step": 12633
    },
    {
      "epoch": 48.968992248062015,
      "grad_norm": 0.00119083805475384,
      "learning_rate": 1.0310077519379846e-06,
      "loss": 0.0001,
      "step": 12634
    },
    {
      "epoch": 48.97286821705426,
      "grad_norm": 0.0005931147024966776,
      "learning_rate": 1.0271317829457364e-06,
      "loss": 0.0001,
      "step": 12635
    },
    {
      "epoch": 48.97674418604651,
      "grad_norm": 0.0008273976854979992,
      "learning_rate": 1.0232558139534884e-06,
      "loss": 0.0001,
      "step": 12636
    },
    {
      "epoch": 48.98062015503876,
      "grad_norm": 0.3254600465297699,
      "learning_rate": 1.0193798449612404e-06,
      "loss": 0.0136,
      "step": 12637
    },
    {
      "epoch": 48.98449612403101,
      "grad_norm": 0.001030788174830377,
      "learning_rate": 1.0155038759689922e-06,
      "loss": 0.0001,
      "step": 12638
    },
    {
      "epoch": 48.98837209302326,
      "grad_norm": 0.0007970252772793174,
      "learning_rate": 1.0116279069767444e-06,
      "loss": 0.0001,
      "step": 12639
    },
    {
      "epoch": 48.992248062015506,
      "grad_norm": 0.0009499448933638632,
      "learning_rate": 1.0077519379844962e-06,
      "loss": 0.0001,
      "step": 12640
    },
    {
      "epoch": 48.99612403100775,
      "grad_norm": 0.0006070485105738044,
      "learning_rate": 1.003875968992248e-06,
      "loss": 0.0001,
      "step": 12641
    },
    {
      "epoch": 49.0,
      "grad_norm": 0.0011437616776674986,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0001,
      "step": 12642
    },
    {
      "epoch": 49.00387596899225,
      "grad_norm": 0.0007070000865496695,
      "learning_rate": 9.96124031007752e-07,
      "loss": 0.0001,
      "step": 12643
    },
    {
      "epoch": 49.007751937984494,
      "grad_norm": 0.0007617726805619895,
      "learning_rate": 9.92248062015504e-07,
      "loss": 0.0001,
      "step": 12644
    },
    {
      "epoch": 49.01162790697674,
      "grad_norm": 0.000738415343221277,
      "learning_rate": 9.88372093023256e-07,
      "loss": 0.0001,
      "step": 12645
    },
    {
      "epoch": 49.01550387596899,
      "grad_norm": 0.0010606502182781696,
      "learning_rate": 9.844961240310077e-07,
      "loss": 0.0001,
      "step": 12646
    },
    {
      "epoch": 49.01937984496124,
      "grad_norm": 0.0018281288212165236,
      "learning_rate": 9.806201550387597e-07,
      "loss": 0.0001,
      "step": 12647
    },
    {
      "epoch": 49.02325581395349,
      "grad_norm": 0.0029135814402252436,
      "learning_rate": 9.767441860465117e-07,
      "loss": 0.0001,
      "step": 12648
    },
    {
      "epoch": 49.02713178294574,
      "grad_norm": 0.0007007851381786168,
      "learning_rate": 9.728682170542637e-07,
      "loss": 0.0001,
      "step": 12649
    },
    {
      "epoch": 49.031007751937985,
      "grad_norm": 0.0006620052736252546,
      "learning_rate": 9.689922480620155e-07,
      "loss": 0.0001,
      "step": 12650
    },
    {
      "epoch": 49.03488372093023,
      "grad_norm": 0.006612346041947603,
      "learning_rate": 9.651162790697673e-07,
      "loss": 0.0003,
      "step": 12651
    },
    {
      "epoch": 49.03875968992248,
      "grad_norm": 0.0010636848164722323,
      "learning_rate": 9.612403100775195e-07,
      "loss": 0.0001,
      "step": 12652
    },
    {
      "epoch": 49.042635658914726,
      "grad_norm": 0.0010747791966423392,
      "learning_rate": 9.573643410852713e-07,
      "loss": 0.0001,
      "step": 12653
    },
    {
      "epoch": 49.04651162790697,
      "grad_norm": 0.005987246986478567,
      "learning_rate": 9.534883720930234e-07,
      "loss": 0.0001,
      "step": 12654
    },
    {
      "epoch": 49.05038759689923,
      "grad_norm": 0.0014277028385549784,
      "learning_rate": 9.496124031007752e-07,
      "loss": 0.0001,
      "step": 12655
    },
    {
      "epoch": 49.054263565891475,
      "grad_norm": 0.0007392905536107719,
      "learning_rate": 9.457364341085271e-07,
      "loss": 0.0001,
      "step": 12656
    },
    {
      "epoch": 49.05813953488372,
      "grad_norm": 0.0006611349526792765,
      "learning_rate": 9.418604651162792e-07,
      "loss": 0.0001,
      "step": 12657
    },
    {
      "epoch": 49.06201550387597,
      "grad_norm": 0.0018584050703793764,
      "learning_rate": 9.37984496124031e-07,
      "loss": 0.0001,
      "step": 12658
    },
    {
      "epoch": 49.065891472868216,
      "grad_norm": 0.0006550325197167695,
      "learning_rate": 9.341085271317831e-07,
      "loss": 0.0001,
      "step": 12659
    },
    {
      "epoch": 49.06976744186046,
      "grad_norm": 0.0008380223880521953,
      "learning_rate": 9.30232558139535e-07,
      "loss": 0.0001,
      "step": 12660
    },
    {
      "epoch": 49.07364341085271,
      "grad_norm": 0.000599839084316045,
      "learning_rate": 9.263565891472868e-07,
      "loss": 0.0001,
      "step": 12661
    },
    {
      "epoch": 49.07751937984496,
      "grad_norm": 0.00242055207490921,
      "learning_rate": 9.224806201550389e-07,
      "loss": 0.0002,
      "step": 12662
    },
    {
      "epoch": 49.08139534883721,
      "grad_norm": 0.0005874655907973647,
      "learning_rate": 9.186046511627906e-07,
      "loss": 0.0001,
      "step": 12663
    },
    {
      "epoch": 49.08527131782946,
      "grad_norm": 0.5806151032447815,
      "learning_rate": 9.147286821705427e-07,
      "loss": 0.0295,
      "step": 12664
    },
    {
      "epoch": 49.08914728682171,
      "grad_norm": 0.0009241505758836865,
      "learning_rate": 9.108527131782946e-07,
      "loss": 0.0001,
      "step": 12665
    },
    {
      "epoch": 49.093023255813954,
      "grad_norm": 0.0006070279632695019,
      "learning_rate": 9.069767441860464e-07,
      "loss": 0.0001,
      "step": 12666
    },
    {
      "epoch": 49.0968992248062,
      "grad_norm": 0.0009509062510915101,
      "learning_rate": 9.031007751937985e-07,
      "loss": 0.0001,
      "step": 12667
    },
    {
      "epoch": 49.10077519379845,
      "grad_norm": 0.0009140525362454355,
      "learning_rate": 8.992248062015504e-07,
      "loss": 0.0001,
      "step": 12668
    },
    {
      "epoch": 49.104651162790695,
      "grad_norm": 0.0006618362967856228,
      "learning_rate": 8.953488372093024e-07,
      "loss": 0.0001,
      "step": 12669
    },
    {
      "epoch": 49.10852713178294,
      "grad_norm": 0.0017436376074329019,
      "learning_rate": 8.914728682170543e-07,
      "loss": 0.0001,
      "step": 12670
    },
    {
      "epoch": 49.1124031007752,
      "grad_norm": 0.001279326737858355,
      "learning_rate": 8.875968992248062e-07,
      "loss": 0.0001,
      "step": 12671
    },
    {
      "epoch": 49.116279069767444,
      "grad_norm": 0.000981986871920526,
      "learning_rate": 8.837209302325582e-07,
      "loss": 0.0001,
      "step": 12672
    },
    {
      "epoch": 49.12015503875969,
      "grad_norm": 0.0006324084824882448,
      "learning_rate": 8.798449612403101e-07,
      "loss": 0.0001,
      "step": 12673
    },
    {
      "epoch": 49.12403100775194,
      "grad_norm": 0.0007021934725344181,
      "learning_rate": 8.759689922480621e-07,
      "loss": 0.0001,
      "step": 12674
    },
    {
      "epoch": 49.127906976744185,
      "grad_norm": 0.0009825468296185136,
      "learning_rate": 8.72093023255814e-07,
      "loss": 0.0001,
      "step": 12675
    },
    {
      "epoch": 49.13178294573643,
      "grad_norm": 0.00221058027818799,
      "learning_rate": 8.682170542635659e-07,
      "loss": 0.0001,
      "step": 12676
    },
    {
      "epoch": 49.13565891472868,
      "grad_norm": 0.027997639030218124,
      "learning_rate": 8.643410852713179e-07,
      "loss": 0.0002,
      "step": 12677
    },
    {
      "epoch": 49.13953488372093,
      "grad_norm": 0.0006591517012566328,
      "learning_rate": 8.604651162790698e-07,
      "loss": 0.0001,
      "step": 12678
    },
    {
      "epoch": 49.14341085271318,
      "grad_norm": 0.0011254478013142943,
      "learning_rate": 8.565891472868218e-07,
      "loss": 0.0001,
      "step": 12679
    },
    {
      "epoch": 49.14728682170543,
      "grad_norm": 0.0005456684739328921,
      "learning_rate": 8.527131782945737e-07,
      "loss": 0.0001,
      "step": 12680
    },
    {
      "epoch": 49.151162790697676,
      "grad_norm": 0.0010153448674827814,
      "learning_rate": 8.488372093023256e-07,
      "loss": 0.0001,
      "step": 12681
    },
    {
      "epoch": 49.15503875968992,
      "grad_norm": 0.0012278519570827484,
      "learning_rate": 8.449612403100775e-07,
      "loss": 0.0001,
      "step": 12682
    },
    {
      "epoch": 49.15891472868217,
      "grad_norm": 0.0008060045074671507,
      "learning_rate": 8.410852713178294e-07,
      "loss": 0.0001,
      "step": 12683
    },
    {
      "epoch": 49.16279069767442,
      "grad_norm": 0.0015323113184422255,
      "learning_rate": 8.372093023255815e-07,
      "loss": 0.0001,
      "step": 12684
    },
    {
      "epoch": 49.166666666666664,
      "grad_norm": 0.0005800053477287292,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.0001,
      "step": 12685
    },
    {
      "epoch": 49.17054263565891,
      "grad_norm": 0.0005936006200499833,
      "learning_rate": 8.294573643410852e-07,
      "loss": 0.0001,
      "step": 12686
    },
    {
      "epoch": 49.174418604651166,
      "grad_norm": 0.00234717084094882,
      "learning_rate": 8.255813953488372e-07,
      "loss": 0.0002,
      "step": 12687
    },
    {
      "epoch": 49.17829457364341,
      "grad_norm": 0.0007731837104074657,
      "learning_rate": 8.217054263565891e-07,
      "loss": 0.0001,
      "step": 12688
    },
    {
      "epoch": 49.18217054263566,
      "grad_norm": 0.000835807528346777,
      "learning_rate": 8.178294573643412e-07,
      "loss": 0.0001,
      "step": 12689
    },
    {
      "epoch": 49.18604651162791,
      "grad_norm": 24.93709945678711,
      "learning_rate": 8.13953488372093e-07,
      "loss": 0.1117,
      "step": 12690
    },
    {
      "epoch": 49.189922480620154,
      "grad_norm": 0.0010527463164180517,
      "learning_rate": 8.100775193798449e-07,
      "loss": 0.0001,
      "step": 12691
    },
    {
      "epoch": 49.1937984496124,
      "grad_norm": 1.6501038074493408,
      "learning_rate": 8.06201550387597e-07,
      "loss": 0.1031,
      "step": 12692
    },
    {
      "epoch": 49.19767441860465,
      "grad_norm": 0.0009416994289495051,
      "learning_rate": 8.023255813953488e-07,
      "loss": 0.0001,
      "step": 12693
    },
    {
      "epoch": 49.201550387596896,
      "grad_norm": 0.000978028983809054,
      "learning_rate": 7.984496124031009e-07,
      "loss": 0.0001,
      "step": 12694
    },
    {
      "epoch": 49.20542635658915,
      "grad_norm": 0.003080426249653101,
      "learning_rate": 7.945736434108528e-07,
      "loss": 0.0002,
      "step": 12695
    },
    {
      "epoch": 49.2093023255814,
      "grad_norm": 0.0008521578856743872,
      "learning_rate": 7.906976744186046e-07,
      "loss": 0.0001,
      "step": 12696
    },
    {
      "epoch": 49.213178294573645,
      "grad_norm": 0.3963581919670105,
      "learning_rate": 7.868217054263567e-07,
      "loss": 0.0167,
      "step": 12697
    },
    {
      "epoch": 49.21705426356589,
      "grad_norm": 0.0008983277366496623,
      "learning_rate": 7.829457364341086e-07,
      "loss": 0.0001,
      "step": 12698
    },
    {
      "epoch": 49.22093023255814,
      "grad_norm": 0.004212670493870974,
      "learning_rate": 7.790697674418605e-07,
      "loss": 0.0002,
      "step": 12699
    },
    {
      "epoch": 49.224806201550386,
      "grad_norm": 0.0008056311053223908,
      "learning_rate": 7.751937984496125e-07,
      "loss": 0.0001,
      "step": 12700
    },
    {
      "epoch": 49.22868217054263,
      "grad_norm": 0.005822088103741407,
      "learning_rate": 7.713178294573643e-07,
      "loss": 0.0002,
      "step": 12701
    },
    {
      "epoch": 49.23255813953488,
      "grad_norm": 0.0006420515710487962,
      "learning_rate": 7.674418604651163e-07,
      "loss": 0.0001,
      "step": 12702
    },
    {
      "epoch": 49.236434108527135,
      "grad_norm": 0.0009896601550281048,
      "learning_rate": 7.635658914728683e-07,
      "loss": 0.0001,
      "step": 12703
    },
    {
      "epoch": 49.24031007751938,
      "grad_norm": 0.0007191045442596078,
      "learning_rate": 7.596899224806201e-07,
      "loss": 0.0001,
      "step": 12704
    },
    {
      "epoch": 49.24418604651163,
      "grad_norm": 0.001734200050123036,
      "learning_rate": 7.558139534883721e-07,
      "loss": 0.0001,
      "step": 12705
    },
    {
      "epoch": 49.248062015503876,
      "grad_norm": 0.0006204024539329112,
      "learning_rate": 7.519379844961241e-07,
      "loss": 0.0001,
      "step": 12706
    },
    {
      "epoch": 49.251937984496124,
      "grad_norm": 0.0006990641122683883,
      "learning_rate": 7.48062015503876e-07,
      "loss": 0.0001,
      "step": 12707
    },
    {
      "epoch": 49.25581395348837,
      "grad_norm": 0.028626956045627594,
      "learning_rate": 7.44186046511628e-07,
      "loss": 0.0011,
      "step": 12708
    },
    {
      "epoch": 49.25968992248062,
      "grad_norm": 0.0005686654476448894,
      "learning_rate": 7.403100775193798e-07,
      "loss": 0.0001,
      "step": 12709
    },
    {
      "epoch": 49.263565891472865,
      "grad_norm": 0.0007578085642307997,
      "learning_rate": 7.364341085271318e-07,
      "loss": 0.0001,
      "step": 12710
    },
    {
      "epoch": 49.26744186046512,
      "grad_norm": 1.437096118927002,
      "learning_rate": 7.325581395348838e-07,
      "loss": 0.1479,
      "step": 12711
    },
    {
      "epoch": 49.27131782945737,
      "grad_norm": 0.0007810004171915352,
      "learning_rate": 7.286821705426357e-07,
      "loss": 0.0001,
      "step": 12712
    },
    {
      "epoch": 49.275193798449614,
      "grad_norm": 0.0031328569166362286,
      "learning_rate": 7.248062015503877e-07,
      "loss": 0.0003,
      "step": 12713
    },
    {
      "epoch": 49.27906976744186,
      "grad_norm": 0.0006307283765636384,
      "learning_rate": 7.209302325581396e-07,
      "loss": 0.0001,
      "step": 12714
    },
    {
      "epoch": 49.28294573643411,
      "grad_norm": 0.004707992076873779,
      "learning_rate": 7.170542635658915e-07,
      "loss": 0.0002,
      "step": 12715
    },
    {
      "epoch": 49.286821705426355,
      "grad_norm": 0.0015411432832479477,
      "learning_rate": 7.131782945736435e-07,
      "loss": 0.0001,
      "step": 12716
    },
    {
      "epoch": 49.2906976744186,
      "grad_norm": 0.0012901213485747576,
      "learning_rate": 7.093023255813954e-07,
      "loss": 0.0001,
      "step": 12717
    },
    {
      "epoch": 49.29457364341085,
      "grad_norm": 0.0006598366890102625,
      "learning_rate": 7.054263565891474e-07,
      "loss": 0.0001,
      "step": 12718
    },
    {
      "epoch": 49.298449612403104,
      "grad_norm": 0.0008755704620853066,
      "learning_rate": 7.015503875968993e-07,
      "loss": 0.0001,
      "step": 12719
    },
    {
      "epoch": 49.30232558139535,
      "grad_norm": 0.0006682896637357771,
      "learning_rate": 6.976744186046511e-07,
      "loss": 0.0001,
      "step": 12720
    },
    {
      "epoch": 49.3062015503876,
      "grad_norm": 0.649977445602417,
      "learning_rate": 6.937984496124031e-07,
      "loss": 0.0334,
      "step": 12721
    },
    {
      "epoch": 49.310077519379846,
      "grad_norm": 0.0007587385480292141,
      "learning_rate": 6.899224806201551e-07,
      "loss": 0.0001,
      "step": 12722
    },
    {
      "epoch": 49.31395348837209,
      "grad_norm": 0.0009227569098584354,
      "learning_rate": 6.86046511627907e-07,
      "loss": 0.0001,
      "step": 12723
    },
    {
      "epoch": 49.31782945736434,
      "grad_norm": 0.0009068323415704072,
      "learning_rate": 6.821705426356589e-07,
      "loss": 0.0001,
      "step": 12724
    },
    {
      "epoch": 49.32170542635659,
      "grad_norm": 0.0010013747960329056,
      "learning_rate": 6.782945736434109e-07,
      "loss": 0.0001,
      "step": 12725
    },
    {
      "epoch": 49.325581395348834,
      "grad_norm": 0.0007706331089138985,
      "learning_rate": 6.744186046511628e-07,
      "loss": 0.0001,
      "step": 12726
    },
    {
      "epoch": 49.32945736434109,
      "grad_norm": 0.0008181770681403577,
      "learning_rate": 6.705426356589148e-07,
      "loss": 0.0001,
      "step": 12727
    },
    {
      "epoch": 49.333333333333336,
      "grad_norm": 0.0007576157804578543,
      "learning_rate": 6.666666666666667e-07,
      "loss": 0.0001,
      "step": 12728
    },
    {
      "epoch": 49.33720930232558,
      "grad_norm": 0.0008758179028518498,
      "learning_rate": 6.627906976744186e-07,
      "loss": 0.0001,
      "step": 12729
    },
    {
      "epoch": 49.34108527131783,
      "grad_norm": 0.0017873109318315983,
      "learning_rate": 6.589147286821706e-07,
      "loss": 0.0002,
      "step": 12730
    },
    {
      "epoch": 49.34496124031008,
      "grad_norm": 0.4204959571361542,
      "learning_rate": 6.550387596899225e-07,
      "loss": 0.0183,
      "step": 12731
    },
    {
      "epoch": 49.348837209302324,
      "grad_norm": 0.0012741583632305264,
      "learning_rate": 6.511627906976745e-07,
      "loss": 0.0001,
      "step": 12732
    },
    {
      "epoch": 49.35271317829457,
      "grad_norm": 0.0006007219199091196,
      "learning_rate": 6.472868217054264e-07,
      "loss": 0.0001,
      "step": 12733
    },
    {
      "epoch": 49.35658914728682,
      "grad_norm": 0.039830803871154785,
      "learning_rate": 6.434108527131783e-07,
      "loss": 0.0007,
      "step": 12734
    },
    {
      "epoch": 49.36046511627907,
      "grad_norm": 0.0014128797920420766,
      "learning_rate": 6.395348837209303e-07,
      "loss": 0.0001,
      "step": 12735
    },
    {
      "epoch": 49.36434108527132,
      "grad_norm": 0.0014162848237901926,
      "learning_rate": 6.356589147286822e-07,
      "loss": 0.0001,
      "step": 12736
    },
    {
      "epoch": 49.36821705426357,
      "grad_norm": 0.0008731827838346362,
      "learning_rate": 6.317829457364342e-07,
      "loss": 0.0001,
      "step": 12737
    },
    {
      "epoch": 49.372093023255815,
      "grad_norm": 0.0006692310562357306,
      "learning_rate": 6.279069767441862e-07,
      "loss": 0.0001,
      "step": 12738
    },
    {
      "epoch": 49.37596899224806,
      "grad_norm": 0.0006900292937643826,
      "learning_rate": 6.240310077519379e-07,
      "loss": 0.0001,
      "step": 12739
    },
    {
      "epoch": 49.37984496124031,
      "grad_norm": 3.6960015296936035,
      "learning_rate": 6.201550387596899e-07,
      "loss": 0.3508,
      "step": 12740
    },
    {
      "epoch": 49.383720930232556,
      "grad_norm": 0.0007149683078750968,
      "learning_rate": 6.162790697674419e-07,
      "loss": 0.0001,
      "step": 12741
    },
    {
      "epoch": 49.3875968992248,
      "grad_norm": 0.001044953940436244,
      "learning_rate": 6.124031007751938e-07,
      "loss": 0.0001,
      "step": 12742
    },
    {
      "epoch": 49.39147286821706,
      "grad_norm": 0.0006661813240498304,
      "learning_rate": 6.085271317829457e-07,
      "loss": 0.0001,
      "step": 12743
    },
    {
      "epoch": 49.395348837209305,
      "grad_norm": 0.0007223461288958788,
      "learning_rate": 6.046511627906977e-07,
      "loss": 0.0001,
      "step": 12744
    },
    {
      "epoch": 49.39922480620155,
      "grad_norm": 0.0007498988416045904,
      "learning_rate": 6.007751937984496e-07,
      "loss": 0.0001,
      "step": 12745
    },
    {
      "epoch": 49.4031007751938,
      "grad_norm": 2.917717695236206,
      "learning_rate": 5.968992248062016e-07,
      "loss": 0.2798,
      "step": 12746
    },
    {
      "epoch": 49.406976744186046,
      "grad_norm": 0.0005807054694741964,
      "learning_rate": 5.930232558139535e-07,
      "loss": 0.0001,
      "step": 12747
    },
    {
      "epoch": 49.41085271317829,
      "grad_norm": 0.000746280828025192,
      "learning_rate": 5.891472868217054e-07,
      "loss": 0.0001,
      "step": 12748
    },
    {
      "epoch": 49.41472868217054,
      "grad_norm": 0.001662868307903409,
      "learning_rate": 5.852713178294574e-07,
      "loss": 0.0001,
      "step": 12749
    },
    {
      "epoch": 49.41860465116279,
      "grad_norm": 0.0010875455336645246,
      "learning_rate": 5.813953488372093e-07,
      "loss": 0.0001,
      "step": 12750
    },
    {
      "epoch": 49.42248062015504,
      "grad_norm": 0.0007364719640463591,
      "learning_rate": 5.775193798449613e-07,
      "loss": 0.0001,
      "step": 12751
    },
    {
      "epoch": 49.42635658914729,
      "grad_norm": 0.0007935038884170353,
      "learning_rate": 5.736434108527133e-07,
      "loss": 0.0001,
      "step": 12752
    },
    {
      "epoch": 49.43023255813954,
      "grad_norm": 0.0007064470555633307,
      "learning_rate": 5.697674418604651e-07,
      "loss": 0.0001,
      "step": 12753
    },
    {
      "epoch": 49.434108527131784,
      "grad_norm": 0.0014128522016108036,
      "learning_rate": 5.658914728682171e-07,
      "loss": 0.0001,
      "step": 12754
    },
    {
      "epoch": 49.43798449612403,
      "grad_norm": 0.0020626590121537447,
      "learning_rate": 5.62015503875969e-07,
      "loss": 0.0001,
      "step": 12755
    },
    {
      "epoch": 49.44186046511628,
      "grad_norm": 0.002391793765127659,
      "learning_rate": 5.58139534883721e-07,
      "loss": 0.0002,
      "step": 12756
    },
    {
      "epoch": 49.445736434108525,
      "grad_norm": 0.0008636023267172277,
      "learning_rate": 5.54263565891473e-07,
      "loss": 0.0001,
      "step": 12757
    },
    {
      "epoch": 49.44961240310077,
      "grad_norm": 0.0006512071704491973,
      "learning_rate": 5.503875968992247e-07,
      "loss": 0.0001,
      "step": 12758
    },
    {
      "epoch": 49.45348837209303,
      "grad_norm": 0.0007168435258790851,
      "learning_rate": 5.465116279069767e-07,
      "loss": 0.0001,
      "step": 12759
    },
    {
      "epoch": 49.457364341085274,
      "grad_norm": 0.000567452167160809,
      "learning_rate": 5.426356589147287e-07,
      "loss": 0.0001,
      "step": 12760
    },
    {
      "epoch": 49.46124031007752,
      "grad_norm": 0.0023299737367779016,
      "learning_rate": 5.387596899224806e-07,
      "loss": 0.0002,
      "step": 12761
    },
    {
      "epoch": 49.46511627906977,
      "grad_norm": 0.0007191027980297804,
      "learning_rate": 5.348837209302326e-07,
      "loss": 0.0001,
      "step": 12762
    },
    {
      "epoch": 49.468992248062015,
      "grad_norm": 0.0016966324765235186,
      "learning_rate": 5.310077519379845e-07,
      "loss": 0.0001,
      "step": 12763
    },
    {
      "epoch": 49.47286821705426,
      "grad_norm": 0.0008781334036029875,
      "learning_rate": 5.271317829457364e-07,
      "loss": 0.0001,
      "step": 12764
    },
    {
      "epoch": 49.47674418604651,
      "grad_norm": 0.0027394029311835766,
      "learning_rate": 5.232558139534884e-07,
      "loss": 0.0002,
      "step": 12765
    },
    {
      "epoch": 49.48062015503876,
      "grad_norm": 0.0008408955181948841,
      "learning_rate": 5.193798449612403e-07,
      "loss": 0.0001,
      "step": 12766
    },
    {
      "epoch": 49.48449612403101,
      "grad_norm": 0.001933404360897839,
      "learning_rate": 5.155038759689923e-07,
      "loss": 0.0001,
      "step": 12767
    },
    {
      "epoch": 49.48837209302326,
      "grad_norm": 0.0010914173908531666,
      "learning_rate": 5.116279069767442e-07,
      "loss": 0.0001,
      "step": 12768
    },
    {
      "epoch": 49.492248062015506,
      "grad_norm": 0.0007673033978790045,
      "learning_rate": 5.077519379844961e-07,
      "loss": 0.0001,
      "step": 12769
    },
    {
      "epoch": 49.49612403100775,
      "grad_norm": 0.0005872981855645776,
      "learning_rate": 5.038759689922481e-07,
      "loss": 0.0001,
      "step": 12770
    },
    {
      "epoch": 49.5,
      "grad_norm": 0.0007482139626517892,
      "learning_rate": 5.000000000000001e-07,
      "loss": 0.0001,
      "step": 12771
    },
    {
      "epoch": 49.50387596899225,
      "grad_norm": 0.00063172890804708,
      "learning_rate": 4.96124031007752e-07,
      "loss": 0.0001,
      "step": 12772
    },
    {
      "epoch": 49.507751937984494,
      "grad_norm": 0.0008756868774071336,
      "learning_rate": 4.922480620155039e-07,
      "loss": 0.0001,
      "step": 12773
    },
    {
      "epoch": 49.51162790697674,
      "grad_norm": 0.0009207570110447705,
      "learning_rate": 4.883720930232559e-07,
      "loss": 0.0001,
      "step": 12774
    },
    {
      "epoch": 49.51550387596899,
      "grad_norm": 0.0019891266711056232,
      "learning_rate": 4.844961240310078e-07,
      "loss": 0.0002,
      "step": 12775
    },
    {
      "epoch": 49.51937984496124,
      "grad_norm": 0.0010689342161640525,
      "learning_rate": 4.806201550387598e-07,
      "loss": 0.0001,
      "step": 12776
    },
    {
      "epoch": 49.52325581395349,
      "grad_norm": 0.0007941924850456417,
      "learning_rate": 4.767441860465117e-07,
      "loss": 0.0001,
      "step": 12777
    },
    {
      "epoch": 49.52713178294574,
      "grad_norm": 0.0006702583632431924,
      "learning_rate": 4.7286821705426354e-07,
      "loss": 0.0001,
      "step": 12778
    },
    {
      "epoch": 49.531007751937985,
      "grad_norm": 0.0006369985640048981,
      "learning_rate": 4.689922480620155e-07,
      "loss": 0.0001,
      "step": 12779
    },
    {
      "epoch": 49.53488372093023,
      "grad_norm": 0.0008918828680180013,
      "learning_rate": 4.651162790697675e-07,
      "loss": 0.0001,
      "step": 12780
    },
    {
      "epoch": 49.53875968992248,
      "grad_norm": 4.558185577392578,
      "learning_rate": 4.6124031007751943e-07,
      "loss": 0.5675,
      "step": 12781
    },
    {
      "epoch": 49.542635658914726,
      "grad_norm": 0.0006711088353767991,
      "learning_rate": 4.573643410852714e-07,
      "loss": 0.0001,
      "step": 12782
    },
    {
      "epoch": 49.54651162790697,
      "grad_norm": 0.0006982418708503246,
      "learning_rate": 4.534883720930232e-07,
      "loss": 0.0001,
      "step": 12783
    },
    {
      "epoch": 49.55038759689923,
      "grad_norm": 0.0006826999597251415,
      "learning_rate": 4.496124031007752e-07,
      "loss": 0.0001,
      "step": 12784
    },
    {
      "epoch": 49.554263565891475,
      "grad_norm": 0.0006736087379977107,
      "learning_rate": 4.4573643410852716e-07,
      "loss": 0.0001,
      "step": 12785
    },
    {
      "epoch": 49.55813953488372,
      "grad_norm": 0.0008261788170784712,
      "learning_rate": 4.418604651162791e-07,
      "loss": 0.0001,
      "step": 12786
    },
    {
      "epoch": 49.56201550387597,
      "grad_norm": 0.000747349695302546,
      "learning_rate": 4.3798449612403105e-07,
      "loss": 0.0001,
      "step": 12787
    },
    {
      "epoch": 49.565891472868216,
      "grad_norm": 0.0014841369120404124,
      "learning_rate": 4.3410852713178294e-07,
      "loss": 0.0001,
      "step": 12788
    },
    {
      "epoch": 49.56976744186046,
      "grad_norm": 0.002155504422262311,
      "learning_rate": 4.302325581395349e-07,
      "loss": 0.0002,
      "step": 12789
    },
    {
      "epoch": 49.57364341085271,
      "grad_norm": 0.0008636899292469025,
      "learning_rate": 4.2635658914728683e-07,
      "loss": 0.0001,
      "step": 12790
    },
    {
      "epoch": 49.57751937984496,
      "grad_norm": 0.0006835504900664091,
      "learning_rate": 4.224806201550388e-07,
      "loss": 0.0001,
      "step": 12791
    },
    {
      "epoch": 49.58139534883721,
      "grad_norm": 0.0005823199171572924,
      "learning_rate": 4.1860465116279077e-07,
      "loss": 0.0001,
      "step": 12792
    },
    {
      "epoch": 49.58527131782946,
      "grad_norm": 0.0010011850390583277,
      "learning_rate": 4.147286821705426e-07,
      "loss": 0.0001,
      "step": 12793
    },
    {
      "epoch": 49.58914728682171,
      "grad_norm": 0.001028604805469513,
      "learning_rate": 4.1085271317829456e-07,
      "loss": 0.0001,
      "step": 12794
    },
    {
      "epoch": 49.593023255813954,
      "grad_norm": 0.0016512322472408414,
      "learning_rate": 4.069767441860465e-07,
      "loss": 0.0001,
      "step": 12795
    },
    {
      "epoch": 49.5968992248062,
      "grad_norm": 0.0009844128508120775,
      "learning_rate": 4.031007751937985e-07,
      "loss": 0.0001,
      "step": 12796
    },
    {
      "epoch": 49.60077519379845,
      "grad_norm": 0.20324178040027618,
      "learning_rate": 3.9922480620155045e-07,
      "loss": 0.0087,
      "step": 12797
    },
    {
      "epoch": 49.604651162790695,
      "grad_norm": 0.0007649707840755582,
      "learning_rate": 3.953488372093023e-07,
      "loss": 0.0001,
      "step": 12798
    },
    {
      "epoch": 49.60852713178294,
      "grad_norm": 0.0007311048684641719,
      "learning_rate": 3.914728682170543e-07,
      "loss": 0.0001,
      "step": 12799
    },
    {
      "epoch": 49.6124031007752,
      "grad_norm": 0.5029581189155579,
      "learning_rate": 3.8759689922480623e-07,
      "loss": 0.0338,
      "step": 12800
    },
    {
      "epoch": 49.616279069767444,
      "grad_norm": 0.0007123729446902871,
      "learning_rate": 3.8372093023255817e-07,
      "loss": 0.0001,
      "step": 12801
    },
    {
      "epoch": 49.62015503875969,
      "grad_norm": 0.0011080021504312754,
      "learning_rate": 3.7984496124031006e-07,
      "loss": 0.0001,
      "step": 12802
    },
    {
      "epoch": 49.62403100775194,
      "grad_norm": 0.0010496883187443018,
      "learning_rate": 3.7596899224806206e-07,
      "loss": 0.0001,
      "step": 12803
    },
    {
      "epoch": 49.627906976744185,
      "grad_norm": 0.0006638013292104006,
      "learning_rate": 3.72093023255814e-07,
      "loss": 0.0001,
      "step": 12804
    },
    {
      "epoch": 49.63178294573643,
      "grad_norm": 0.0006027634954079986,
      "learning_rate": 3.682170542635659e-07,
      "loss": 0.0001,
      "step": 12805
    },
    {
      "epoch": 49.63565891472868,
      "grad_norm": 0.0006156893214210868,
      "learning_rate": 3.6434108527131785e-07,
      "loss": 0.0001,
      "step": 12806
    },
    {
      "epoch": 49.63953488372093,
      "grad_norm": 0.0014218835858628154,
      "learning_rate": 3.604651162790698e-07,
      "loss": 0.0001,
      "step": 12807
    },
    {
      "epoch": 49.64341085271318,
      "grad_norm": 0.0015538468724116683,
      "learning_rate": 3.5658914728682174e-07,
      "loss": 0.0001,
      "step": 12808
    },
    {
      "epoch": 49.64728682170543,
      "grad_norm": 0.0009140229085460305,
      "learning_rate": 3.527131782945737e-07,
      "loss": 0.0001,
      "step": 12809
    },
    {
      "epoch": 49.651162790697676,
      "grad_norm": 0.0009085736819542944,
      "learning_rate": 3.4883720930232557e-07,
      "loss": 0.0001,
      "step": 12810
    },
    {
      "epoch": 49.65503875968992,
      "grad_norm": 0.0014273625565692782,
      "learning_rate": 3.4496124031007757e-07,
      "loss": 0.0001,
      "step": 12811
    },
    {
      "epoch": 49.65891472868217,
      "grad_norm": 0.0006671699811704457,
      "learning_rate": 3.4108527131782946e-07,
      "loss": 0.0001,
      "step": 12812
    },
    {
      "epoch": 49.66279069767442,
      "grad_norm": 0.0006209103739820421,
      "learning_rate": 3.372093023255814e-07,
      "loss": 0.0001,
      "step": 12813
    },
    {
      "epoch": 49.666666666666664,
      "grad_norm": 0.0007469686679542065,
      "learning_rate": 3.3333333333333335e-07,
      "loss": 0.0001,
      "step": 12814
    },
    {
      "epoch": 49.67054263565891,
      "grad_norm": 0.0008797709015198052,
      "learning_rate": 3.294573643410853e-07,
      "loss": 0.0001,
      "step": 12815
    },
    {
      "epoch": 49.674418604651166,
      "grad_norm": 0.0005977905238978565,
      "learning_rate": 3.2558139534883724e-07,
      "loss": 0.0001,
      "step": 12816
    },
    {
      "epoch": 49.67829457364341,
      "grad_norm": 0.3281531035900116,
      "learning_rate": 3.2170542635658914e-07,
      "loss": 0.0136,
      "step": 12817
    },
    {
      "epoch": 49.68217054263566,
      "grad_norm": 0.0007295646355487406,
      "learning_rate": 3.178294573643411e-07,
      "loss": 0.0001,
      "step": 12818
    },
    {
      "epoch": 49.68604651162791,
      "grad_norm": 0.0009077189024537802,
      "learning_rate": 3.139534883720931e-07,
      "loss": 0.0001,
      "step": 12819
    },
    {
      "epoch": 49.689922480620154,
      "grad_norm": 0.001241500722244382,
      "learning_rate": 3.1007751937984497e-07,
      "loss": 0.0001,
      "step": 12820
    },
    {
      "epoch": 49.6937984496124,
      "grad_norm": 0.0011062865378335118,
      "learning_rate": 3.062015503875969e-07,
      "loss": 0.0001,
      "step": 12821
    },
    {
      "epoch": 49.69767441860465,
      "grad_norm": 0.0007324795587919652,
      "learning_rate": 3.0232558139534886e-07,
      "loss": 0.0001,
      "step": 12822
    },
    {
      "epoch": 49.701550387596896,
      "grad_norm": 0.0029966244474053383,
      "learning_rate": 2.984496124031008e-07,
      "loss": 0.0002,
      "step": 12823
    },
    {
      "epoch": 49.70542635658915,
      "grad_norm": 0.0009528826922178268,
      "learning_rate": 2.945736434108527e-07,
      "loss": 0.0001,
      "step": 12824
    },
    {
      "epoch": 49.7093023255814,
      "grad_norm": 0.0006137989112176001,
      "learning_rate": 2.9069767441860464e-07,
      "loss": 0.0001,
      "step": 12825
    },
    {
      "epoch": 49.713178294573645,
      "grad_norm": 0.002063135616481304,
      "learning_rate": 2.8682170542635664e-07,
      "loss": 0.0002,
      "step": 12826
    },
    {
      "epoch": 49.71705426356589,
      "grad_norm": 0.0006865902687422931,
      "learning_rate": 2.8294573643410853e-07,
      "loss": 0.0001,
      "step": 12827
    },
    {
      "epoch": 49.72093023255814,
      "grad_norm": 0.0022288295440375805,
      "learning_rate": 2.790697674418605e-07,
      "loss": 0.0002,
      "step": 12828
    },
    {
      "epoch": 49.724806201550386,
      "grad_norm": 0.0011408354621380568,
      "learning_rate": 2.7519379844961237e-07,
      "loss": 0.0001,
      "step": 12829
    },
    {
      "epoch": 49.72868217054263,
      "grad_norm": 0.0008861148380674422,
      "learning_rate": 2.7131782945736437e-07,
      "loss": 0.0001,
      "step": 12830
    },
    {
      "epoch": 49.73255813953488,
      "grad_norm": 0.41813045740127563,
      "learning_rate": 2.674418604651163e-07,
      "loss": 0.0177,
      "step": 12831
    },
    {
      "epoch": 49.736434108527135,
      "grad_norm": 0.0006771961925551295,
      "learning_rate": 2.635658914728682e-07,
      "loss": 0.0001,
      "step": 12832
    },
    {
      "epoch": 49.74031007751938,
      "grad_norm": 0.0006268323049880564,
      "learning_rate": 2.5968992248062015e-07,
      "loss": 0.0001,
      "step": 12833
    },
    {
      "epoch": 49.74418604651163,
      "grad_norm": 0.0005677096196450293,
      "learning_rate": 2.558139534883721e-07,
      "loss": 0.0001,
      "step": 12834
    },
    {
      "epoch": 49.748062015503876,
      "grad_norm": 0.0009238271159119904,
      "learning_rate": 2.5193798449612404e-07,
      "loss": 0.0001,
      "step": 12835
    },
    {
      "epoch": 49.751937984496124,
      "grad_norm": 0.0007063088123686612,
      "learning_rate": 2.48062015503876e-07,
      "loss": 0.0001,
      "step": 12836
    },
    {
      "epoch": 49.75581395348837,
      "grad_norm": 0.001868295599706471,
      "learning_rate": 2.4418604651162793e-07,
      "loss": 0.0001,
      "step": 12837
    },
    {
      "epoch": 49.75968992248062,
      "grad_norm": 0.0012328025186434388,
      "learning_rate": 2.403100775193799e-07,
      "loss": 0.0001,
      "step": 12838
    },
    {
      "epoch": 49.763565891472865,
      "grad_norm": 0.001006424194201827,
      "learning_rate": 2.3643410852713177e-07,
      "loss": 0.0001,
      "step": 12839
    },
    {
      "epoch": 49.76744186046512,
      "grad_norm": 0.0020430362783372402,
      "learning_rate": 2.3255813953488374e-07,
      "loss": 0.0001,
      "step": 12840
    },
    {
      "epoch": 49.77131782945737,
      "grad_norm": 0.000799523142632097,
      "learning_rate": 2.286821705426357e-07,
      "loss": 0.0001,
      "step": 12841
    },
    {
      "epoch": 49.775193798449614,
      "grad_norm": 0.0023736574221402407,
      "learning_rate": 2.248062015503876e-07,
      "loss": 0.0001,
      "step": 12842
    },
    {
      "epoch": 49.77906976744186,
      "grad_norm": 0.0006608662661164999,
      "learning_rate": 2.2093023255813955e-07,
      "loss": 0.0001,
      "step": 12843
    },
    {
      "epoch": 49.78294573643411,
      "grad_norm": 0.537898063659668,
      "learning_rate": 2.1705426356589147e-07,
      "loss": 0.0225,
      "step": 12844
    },
    {
      "epoch": 49.786821705426355,
      "grad_norm": 0.024679750204086304,
      "learning_rate": 2.1317829457364341e-07,
      "loss": 0.0007,
      "step": 12845
    },
    {
      "epoch": 49.7906976744186,
      "grad_norm": 0.001138088176958263,
      "learning_rate": 2.0930232558139539e-07,
      "loss": 0.0001,
      "step": 12846
    },
    {
      "epoch": 49.79457364341085,
      "grad_norm": 0.017019351944327354,
      "learning_rate": 2.0542635658914728e-07,
      "loss": 0.0006,
      "step": 12847
    },
    {
      "epoch": 49.798449612403104,
      "grad_norm": 0.13511842489242554,
      "learning_rate": 2.0155038759689925e-07,
      "loss": 0.0036,
      "step": 12848
    },
    {
      "epoch": 49.80232558139535,
      "grad_norm": 0.0007156974170356989,
      "learning_rate": 1.9767441860465114e-07,
      "loss": 0.0001,
      "step": 12849
    },
    {
      "epoch": 49.8062015503876,
      "grad_norm": 0.0006920467130839825,
      "learning_rate": 1.9379844961240311e-07,
      "loss": 0.0001,
      "step": 12850
    },
    {
      "epoch": 49.810077519379846,
      "grad_norm": 0.003352093743160367,
      "learning_rate": 1.8992248062015503e-07,
      "loss": 0.0001,
      "step": 12851
    },
    {
      "epoch": 49.81395348837209,
      "grad_norm": 1.352536916732788,
      "learning_rate": 1.86046511627907e-07,
      "loss": 0.1254,
      "step": 12852
    },
    {
      "epoch": 49.81782945736434,
      "grad_norm": 0.002138234907761216,
      "learning_rate": 1.8217054263565892e-07,
      "loss": 0.0001,
      "step": 12853
    },
    {
      "epoch": 49.82170542635659,
      "grad_norm": 0.0008892787736840546,
      "learning_rate": 1.7829457364341087e-07,
      "loss": 0.0001,
      "step": 12854
    },
    {
      "epoch": 49.825581395348834,
      "grad_norm": 0.0007252561626955867,
      "learning_rate": 1.7441860465116279e-07,
      "loss": 0.0001,
      "step": 12855
    },
    {
      "epoch": 49.82945736434109,
      "grad_norm": 0.0011783401714637876,
      "learning_rate": 1.7054263565891473e-07,
      "loss": 0.0001,
      "step": 12856
    },
    {
      "epoch": 49.833333333333336,
      "grad_norm": 0.0005946602905169129,
      "learning_rate": 1.6666666666666668e-07,
      "loss": 0.0001,
      "step": 12857
    },
    {
      "epoch": 49.83720930232558,
      "grad_norm": 0.0007337124552577734,
      "learning_rate": 1.6279069767441862e-07,
      "loss": 0.0001,
      "step": 12858
    },
    {
      "epoch": 49.84108527131783,
      "grad_norm": 0.0010402039624750614,
      "learning_rate": 1.5891472868217054e-07,
      "loss": 0.0001,
      "step": 12859
    },
    {
      "epoch": 49.84496124031008,
      "grad_norm": 0.0007320345612242818,
      "learning_rate": 1.5503875968992249e-07,
      "loss": 0.0001,
      "step": 12860
    },
    {
      "epoch": 49.848837209302324,
      "grad_norm": 0.0019346546614542603,
      "learning_rate": 1.5116279069767443e-07,
      "loss": 0.0002,
      "step": 12861
    },
    {
      "epoch": 49.85271317829457,
      "grad_norm": 0.0007951966254040599,
      "learning_rate": 1.4728682170542635e-07,
      "loss": 0.0001,
      "step": 12862
    },
    {
      "epoch": 49.85658914728682,
      "grad_norm": 0.0006330321193672717,
      "learning_rate": 1.4341085271317832e-07,
      "loss": 0.0001,
      "step": 12863
    },
    {
      "epoch": 49.86046511627907,
      "grad_norm": 0.0006474156398326159,
      "learning_rate": 1.3953488372093024e-07,
      "loss": 0.0001,
      "step": 12864
    },
    {
      "epoch": 49.86434108527132,
      "grad_norm": 0.0007575906929560006,
      "learning_rate": 1.3565891472868218e-07,
      "loss": 0.0001,
      "step": 12865
    },
    {
      "epoch": 49.86821705426357,
      "grad_norm": 0.00469626672565937,
      "learning_rate": 1.317829457364341e-07,
      "loss": 0.0002,
      "step": 12866
    },
    {
      "epoch": 49.872093023255815,
      "grad_norm": 0.0015578304883092642,
      "learning_rate": 1.2790697674418605e-07,
      "loss": 0.0001,
      "step": 12867
    },
    {
      "epoch": 49.87596899224806,
      "grad_norm": 0.002504129894077778,
      "learning_rate": 1.24031007751938e-07,
      "loss": 0.0001,
      "step": 12868
    },
    {
      "epoch": 49.87984496124031,
      "grad_norm": 0.0009255741024389863,
      "learning_rate": 1.2015503875968994e-07,
      "loss": 0.0001,
      "step": 12869
    },
    {
      "epoch": 49.883720930232556,
      "grad_norm": 0.505522608757019,
      "learning_rate": 1.1627906976744187e-07,
      "loss": 0.0205,
      "step": 12870
    },
    {
      "epoch": 49.8875968992248,
      "grad_norm": 0.0007564496481791139,
      "learning_rate": 1.124031007751938e-07,
      "loss": 0.0001,
      "step": 12871
    },
    {
      "epoch": 49.89147286821706,
      "grad_norm": 0.004109220113605261,
      "learning_rate": 1.0852713178294573e-07,
      "loss": 0.0002,
      "step": 12872
    },
    {
      "epoch": 49.895348837209305,
      "grad_norm": 0.0006827820325270295,
      "learning_rate": 1.0465116279069769e-07,
      "loss": 0.0001,
      "step": 12873
    },
    {
      "epoch": 49.89922480620155,
      "grad_norm": 0.0020214112009853125,
      "learning_rate": 1.0077519379844962e-07,
      "loss": 0.0002,
      "step": 12874
    },
    {
      "epoch": 49.9031007751938,
      "grad_norm": 0.0007413566345348954,
      "learning_rate": 9.689922480620156e-08,
      "loss": 0.0001,
      "step": 12875
    },
    {
      "epoch": 49.906976744186046,
      "grad_norm": 0.0007664707954972982,
      "learning_rate": 9.30232558139535e-08,
      "loss": 0.0001,
      "step": 12876
    },
    {
      "epoch": 49.91085271317829,
      "grad_norm": 0.004209422040730715,
      "learning_rate": 8.914728682170543e-08,
      "loss": 0.0002,
      "step": 12877
    },
    {
      "epoch": 49.91472868217054,
      "grad_norm": 0.0006727913278155029,
      "learning_rate": 8.527131782945737e-08,
      "loss": 0.0001,
      "step": 12878
    },
    {
      "epoch": 49.91860465116279,
      "grad_norm": 0.0006908570067025721,
      "learning_rate": 8.139534883720931e-08,
      "loss": 0.0001,
      "step": 12879
    },
    {
      "epoch": 49.92248062015504,
      "grad_norm": 0.0008922232082113624,
      "learning_rate": 7.751937984496124e-08,
      "loss": 0.0001,
      "step": 12880
    },
    {
      "epoch": 49.92635658914729,
      "grad_norm": 0.0009399165865033865,
      "learning_rate": 7.364341085271317e-08,
      "loss": 0.0001,
      "step": 12881
    },
    {
      "epoch": 49.93023255813954,
      "grad_norm": 0.0006180525524541736,
      "learning_rate": 6.976744186046512e-08,
      "loss": 0.0001,
      "step": 12882
    },
    {
      "epoch": 49.934108527131784,
      "grad_norm": 0.0007151353056542575,
      "learning_rate": 6.589147286821705e-08,
      "loss": 0.0001,
      "step": 12883
    },
    {
      "epoch": 49.93798449612403,
      "grad_norm": 0.0035145485308021307,
      "learning_rate": 6.2015503875969e-08,
      "loss": 0.0002,
      "step": 12884
    },
    {
      "epoch": 49.94186046511628,
      "grad_norm": 0.0013732812367379665,
      "learning_rate": 5.8139534883720935e-08,
      "loss": 0.0001,
      "step": 12885
    },
    {
      "epoch": 49.945736434108525,
      "grad_norm": 0.0006653410964645445,
      "learning_rate": 5.426356589147287e-08,
      "loss": 0.0001,
      "step": 12886
    },
    {
      "epoch": 49.94961240310077,
      "grad_norm": 0.001065646531060338,
      "learning_rate": 5.038759689922481e-08,
      "loss": 0.0001,
      "step": 12887
    },
    {
      "epoch": 49.95348837209303,
      "grad_norm": 0.0011822175001725554,
      "learning_rate": 4.651162790697675e-08,
      "loss": 0.0001,
      "step": 12888
    },
    {
      "epoch": 49.957364341085274,
      "grad_norm": 0.0011489435564726591,
      "learning_rate": 4.263565891472868e-08,
      "loss": 0.0001,
      "step": 12889
    },
    {
      "epoch": 49.96124031007752,
      "grad_norm": 0.0005951150669716299,
      "learning_rate": 3.875968992248062e-08,
      "loss": 0.0001,
      "step": 12890
    },
    {
      "epoch": 49.96511627906977,
      "grad_norm": 0.0007090203580446541,
      "learning_rate": 3.488372093023256e-08,
      "loss": 0.0001,
      "step": 12891
    },
    {
      "epoch": 49.968992248062015,
      "grad_norm": 0.0006691226735711098,
      "learning_rate": 3.10077519379845e-08,
      "loss": 0.0001,
      "step": 12892
    },
    {
      "epoch": 49.97286821705426,
      "grad_norm": 0.000958068878389895,
      "learning_rate": 2.7131782945736434e-08,
      "loss": 0.0001,
      "step": 12893
    },
    {
      "epoch": 49.97674418604651,
      "grad_norm": 0.0012868564808741212,
      "learning_rate": 2.3255813953488376e-08,
      "loss": 0.0001,
      "step": 12894
    },
    {
      "epoch": 49.98062015503876,
      "grad_norm": 0.001948761404491961,
      "learning_rate": 1.937984496124031e-08,
      "loss": 0.0002,
      "step": 12895
    },
    {
      "epoch": 49.98449612403101,
      "grad_norm": 0.0007980406517162919,
      "learning_rate": 1.550387596899225e-08,
      "loss": 0.0001,
      "step": 12896
    },
    {
      "epoch": 49.98837209302326,
      "grad_norm": 0.0007499247440136969,
      "learning_rate": 1.1627906976744188e-08,
      "loss": 0.0001,
      "step": 12897
    },
    {
      "epoch": 49.992248062015506,
      "grad_norm": 0.001172711723484099,
      "learning_rate": 7.751937984496125e-09,
      "loss": 0.0001,
      "step": 12898
    },
    {
      "epoch": 49.99612403100775,
      "grad_norm": 0.0006825748714618385,
      "learning_rate": 3.875968992248062e-09,
      "loss": 0.0001,
      "step": 12899
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.0018273481400683522,
      "learning_rate": 0.0,
      "loss": 0.0001,
      "step": 12900
    }
  ],
  "logging_steps": 1,
  "max_steps": 12900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 841140182208000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
